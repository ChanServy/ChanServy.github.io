{"pages":[{"title":"关于我","text":"个人信息： 姓名：陈思禹 性别：男 出生年月：1997年4月 毕业院校：辽宁工业大学 学历：本科 邮箱：18524509986@163.com 掌握技能： 熟练掌握SpringMVC，Spring，Mybatis，SpringBoot等J2EE的开源框架，并能熟练搭建整合SSM框架，熟练进行Junit测试、断点调试以及SpringBoot 的热部署。 了解HTML，CSS等前端技术，熟悉JQuery，BootStrap等前端框架，了解Thymeleaf模版。 熟练掌握常见的开发工具 Eclipse，IDEA，并能熟练使用常见的项目构建工具 maven 构建项目,也了解Gradle构建工具。熟悉分布式的Git协同开发工具。 熟悉Mysql关系型数据库。掌握基本sql语句的书写。 熟悉Redis非关系型数据库，熟悉Redis底层的运行流程，熟悉Redis的高并发、高可用架构，了解缓存雪崩和穿透的解决方案，知道如何保证缓存数据库双写时的数据一致性。 熟悉Spring Cloud 中的常用组件，如eureka，ribbon，feign，hystrix，zuul，config等。 熟悉RabbitMQ消息中间件，了解如何保证消息中间件的高可用以及消息的可靠性传输和顺序一致性等问题。 熟悉ElasticSearch的分布式搜索引擎，了解其分布式架构原理。 熟悉J2SE基本语法，有规范的编码习惯。熟悉JVM内存模型与GC优化。 熟悉Docker容器的常用命令，可以通过镜像部署应用服务等。 熟悉Linux操作系统的常用命令。 了解Dubbo和Zookeeper的使用，了解Zookeeper分布式锁的基本原理。 了解nginx相关配置，可实现服务器间负载均衡并通过hash一致性实现session共享。 自我评价 具备团队合作精神，人品正直诚实，有责任心，能够承受一定的工作压力； 对工作和学习善于总结，对新技术有着强烈的好奇心 对工作尽职尽责，乐于接受挑战性的工作； 乐于与用户以及同事和领导沟通，以便快速解决项目遇到的问题； 学习能力强，团队开发效率快，具有良好的逻辑与分析能力； 掌握知识夯实，实践动手能力强，具有较强的执行力； 同时具有团队管理经验。","link":"/about/index.html"}],"posts":[{"title":"Elasticsearch安装记录","text":"前言：本文章安装 elasticsearch 的方式是以 docker 的方式。 部署单点es创建网络因为我们还需要部署kibana容器，因此需要让es和kibana容器互联。这里先创建一个网络： 1docker network create es-net 加载镜像这里我们采用elasticsearch的7.12.1版本的镜像，这个镜像体积非常大，接近1G。不建议大家自己pull。 es、kibana、ik 安装资源：链接: https://pan.baidu.com/s/1p-x6WW11IKCvEsE5TBLFGQ 密码: lsir 大家将其上传到虚拟机中，然后运行命令加载即可： 12# 导入数据docker load -i es.tar 同理还有kibana的tar包也需要这样做。 运行运行docker命令，部署单点es： 1234567891011docker run -d \\ --name es \\ -e &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; \\ -e &quot;discovery.type=single-node&quot; \\ -v es-data:/usr/share/elasticsearch/data \\ -v es-plugins:/usr/share/elasticsearch/plugins \\ --privileged \\ --network es-net \\ -p 9200:9200 \\ -p 9300:9300 \\elasticsearch:7.12.1 命令解释： -e &quot;cluster.name=es-docker-cluster&quot;：设置集群名称 -e &quot;http.host=0.0.0.0&quot;：监听的地址，可以外网访问 -e &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;：内存大小 -e &quot;discovery.type=single-node&quot;：非集群模式 -v es-data:/usr/share/elasticsearch/data：挂载逻辑卷，绑定es的数据目录 -v es-logs:/usr/share/elasticsearch/logs：挂载逻辑卷，绑定es的日志目录 -v es-plugins:/usr/share/elasticsearch/plugins：挂载逻辑卷，绑定es的插件目录 --privileged：授予逻辑卷访问权 --network es-net ：加入一个名为es-net的网络中 -p 9200:9200：端口映射配置 在浏览器中输入：http://192.168.150.101:9200 即可看到elasticsearch的响应结果： 部署kibanakibana可以给我们提供一个elasticsearch的可视化界面，便于我们学习。 部署运行docker命令，部署kibana 123456docker run -d \\--name kibana \\-e ELASTICSEARCH_HOSTS=http://es:9200 \\--network=es-net \\-p 5601:5601 \\kibana:7.12.1 --network es-net ：加入一个名为es-net的网络中，与elasticsearch在同一个网络中 -e ELASTICSEARCH_HOSTS=http://es:9200&quot;：设置elasticsearch的地址，因为kibana已经与elasticsearch在一个网络，因此可以用容器名直接访问elasticsearch -p 5601:5601：端口映射配置 kibana启动一般比较慢，需要多等待一会，可以通过命令： 1docker logs -f kibana 查看运行日志，当查看到下面的日志，说明成功： 此时，在浏览器输入地址访问：http://192.168.150.101:5601，即可看到结果 DevToolskibana中提供了一个DevTools界面： 这个界面中可以编写DSL来操作elasticsearch。并且对DSL语句有自动补全功能。 安装IK分词器在线安装ik插件（较慢）12345678910# 进入容器内部docker exec -it elasticsearch /bin/bash# 在线下载并安装./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.12.1/elasticsearch-analysis-ik-7.12.1.zip#退出exit#重启容器docker restart elasticsearch 离线安装ik插件（推荐）1）查看数据卷目录安装插件需要知道elasticsearch的plugins目录位置，而我们用了数据卷挂载，因此需要查看elasticsearch的数据卷目录，通过下面命令查看: 1docker volume inspect es-plugins 显示结果： 1234567891011[ { &quot;CreatedAt&quot;: &quot;2022-05-06T10:06:34+08:00&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: null, &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/es-plugins/_data&quot;, &quot;Name&quot;: &quot;es-plugins&quot;, &quot;Options&quot;: null, &quot;Scope&quot;: &quot;local&quot; }] 说明plugins目录被挂载到了：/var/lib/docker/volumes/es-plugins/_data 这个目录中。 2）解压缩分词器安装包下面我们需要把课前资料中的ik分词器解压缩，重命名为ik 3）上传到es容器的插件数据卷中也就是/var/lib/docker/volumes/es-plugins/_data ： 4）重启容器12# 4、重启容器docker restart es 12# 查看es日志docker logs -f es 5）测试IK分词器包含两种模式： ik_smart：最少切分 ik_max_word：最细切分 12345POST _analyze{ &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;text&quot;: &quot;我是中国人&quot;} 结果： 123456789101112131415161718192021222324252627282930313233343536373839{ &quot;tokens&quot; : [ { &quot;token&quot; : &quot;我&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 1, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 0 }, { &quot;token&quot; : &quot;是&quot;, &quot;start_offset&quot; : 1, &quot;end_offset&quot; : 2, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 1 }, { &quot;token&quot; : &quot;中国人&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 5, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 2 }, { &quot;token&quot; : &quot;中国&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 4, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 3 }, { &quot;token&quot; : &quot;国人&quot;, &quot;start_offset&quot; : 3, &quot;end_offset&quot; : 5, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 4 } ]} 扩展词词典随着互联网的发展，“造词运动”也越发的频繁。出现了很多新的词语，在原有的词汇列表中并不存在。比如：“奥力给”，“嘤嘤嘤”，“注孤生” 等。 所以我们的词汇也需要不断的更新，IK分词器提供了扩展词汇的功能。 1）打开IK分词器config目录： 2）在IKAnalyzer.cfg.xml配置文件内容添加： 1234567&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE properties SYSTEM &quot;http://java.sun.com/dtd/properties.dtd&quot;&gt;&lt;properties&gt; &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt; &lt;!--用户可以在这里配置自己的扩展字典 *** 添加扩展词典--&gt; &lt;entry key=&quot;ext_dict&quot;&gt;ext.dic&lt;/entry&gt;&lt;/properties&gt; 3）新建一个 ext.dic，可以参考config目录下复制一个配置文件进行修改 1奥力给 4）重启elasticsearch 1234docker restart es# 查看 日志docker logs -f elasticsearch 日志中已经成功加载ext.dic配置文件 5）测试效果： 12345GET /_analyze{ &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;text&quot;: &quot;我是中国人,奥力给！&quot;} 注意当前文件的编码必须是 UTF-8 格式，严禁使用Windows记事本编辑 停用词词典在互联网项目中，在网络间传输的速度很快，所以很多语言是不允许在网络上传递的，如：关于宗教、政治等敏感词语，那么我们在搜索时也应该忽略当前词汇。 IK分词器也提供了强大的停用词功能，让我们在索引时就直接忽略当前的停用词汇表中的内容。 1）IKAnalyzer.cfg.xml配置文件内容添加： 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE properties SYSTEM &quot;http://java.sun.com/dtd/properties.dtd&quot;&gt;&lt;properties&gt; &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt; &lt;!--用户可以在这里配置自己的扩展字典--&gt; &lt;entry key=&quot;ext_dict&quot;&gt;ext.dic&lt;/entry&gt; &lt;!--用户可以在这里配置自己的扩展停止词字典 *** 添加停用词词典--&gt; &lt;entry key=&quot;ext_stopwords&quot;&gt;stopword.dic&lt;/entry&gt;&lt;/properties&gt; 3）在 stopword.dic 添加停用词 1习大大 4）重启elasticsearch 123456# 重启服务docker restart elasticsearchdocker restart kibana# 查看 日志docker logs -f elasticsearch 日志中已经成功加载stopword.dic配置文件 5）测试效果： 12345GET /_analyze{ &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;text&quot;: &quot;我是中国人,习大大都点赞,奥力给！&quot;} 注意当前文件的编码必须是 UTF-8 格式，严禁使用Windows记事本编辑 部署es集群部署es集群可以直接使用docker-compose来完成，不过要求你的Linux虚拟机至少有4G的内存空间。 首先编写一个docker-compose文件，内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970version: '2.2'services: es01: image: docker.elastic.co/elasticsearch/elasticsearch:7.12.1 container_name: es01 environment: - node.name=es01 - cluster.name=es-docker-cluster - discovery.seed_hosts=es02,es03 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; ulimits: memlock: soft: -1 hard: -1 volumes: - data01:/usr/share/elasticsearch/data ports: - 9200:9200 networks: - elastic es02: image: docker.elastic.co/elasticsearch/elasticsearch:7.12.1 container_name: es02 environment: - node.name=es02 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es03 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; ulimits: memlock: soft: -1 hard: -1 volumes: - data02:/usr/share/elasticsearch/data networks: - elastic es03: image: docker.elastic.co/elasticsearch/elasticsearch:7.12.1 container_name: es03 environment: - node.name=es03 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es02 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; ulimits: memlock: soft: -1 hard: -1 volumes: - data03:/usr/share/elasticsearch/data networks: - elasticvolumes: data01: driver: local data02: driver: local data03: driver: localnetworks: elastic: driver: bridge Run docker-compose to bring up the cluster: 1docker-compose up","link":"/posts/20220611/elasticsearch-install.html"},{"title":"Java NIO","text":"笔记总结源自：Nyima boke。Java NIO 简介Java NIO（New IO）是从Java 1.4版本开始引入的一个新的IO API，可以替代标准的Java IO API。NIO与原来的IO有同样的作用和目的，但是使用的方式完全不同，NIO支持面向缓冲区的、基于通道的IO操作。NIO将以更加高效的方式进行文件的读写操作。 IO与NIO的区别 IO NIO 面向流(Stream Oriented) 面向缓冲区(Buffer Oriented) 阻塞IO(Blocking IO) 非阻塞IO(NonBlocking IO) 无 选择器(Selectors) 面向流和缓冲区IO 传统IO在传输数据时，根据输入输出的不同需要分别建立不同的链接，而且传输的数据是以流的形式在链接上进行传输的。 就像自来水要通过水管将自来水厂和家连接起来一样。 NIO NIO在传输数据时，会在输入输出端之间建立通道，然后将数据放入到缓冲区中。缓冲区通过通道来传输数据。 这里通道就像是铁路，能够连通两个地点。缓冲区就像是火车，能够真正地进行数据的传输。 通道与缓冲区Java NIO系统的核心在于：通道(Channel)和缓冲区(Buffer)。通道表示打开到 IO 设备(例如：文件、套接字)的连接。若需要使用 NIO 系统，需要获取用于连接 IO 设备的通道以及用于容纳数据的缓冲区。然后操作缓冲区，对数据进行处理。 简而言之，通道负责传输，缓冲区负责存储。 缓冲区(Buffer)缓冲区类型Buffer 就像一个数组，可以保存多个相同类型的数据。根据数据类型不同(boolean 除外) ，有以下Buffer 常用子类： ByteBuffer CharBuffer ShortBuffer IntBuffer LongBuffer FloatBuffer DoubleBuffer 各种类型的缓冲区中，都有一个对应类型的数组，如： ByteBuffer 1final byte[] hb; // Non-null only for heap buffers IntBuffer 1final int[] hb; // Non-null only for heap buffers 他们的继承关系如下 获取缓冲区通过allocate方法可以获取一个对应缓冲区的对象，它是缓冲区类的一个静态方法。 例： 12// 获取一个容量大小为1024字节的字节缓冲区ByteBuffer byteBuffer = ByteBuffer.allocate(1024); 核心属性缓冲区的父类Buffer中有几个核心属性，如下： 12345// Invariants: mark &lt;= position &lt;= limit &lt;= capacityprivate int mark = -1;private int position = 0;private int limit;private int capacity; capacity：缓冲区的容量。通过构造函数赋予，一旦设置，无法更改。 limit：缓冲区的界限。位于limit 后的数据不可读写。缓冲区的限制不能为负，并且不能大于其容量。 position：下一个读写位置的索引（类似PC）。缓冲区的位置不能为负，并且不能大于limit。 mark：记录当前position的值。position被改变后，可以通过调用reset() 方法恢复到mark的位置。 以上四个属性必须满足以下要求： mark &lt;= position &lt;= limit &lt;= capacity 核心方法put()方法 put()方法可以将一个数据放入到缓冲区中。 进行该操作后，postition的值会+1，指向下一个可以放入的位置。capacity = limit ，为缓冲区容量的值。 flip()方法 flip()方法会切换对缓冲区的操作模式，由写-&gt;读 / 读-&gt;写。 进行该操作后 如果是写模式-&gt;读模式，position = 0 ， limit 指向最后一个元素的下一个位置，capacity不变。 如果是读-&gt;写，则恢复为put()方法中的值。 get()方法 get()方法会读取缓冲区中的一个值。 进行该操作后，position会+1，如果超过了limit则会抛出异常。 rewind()方法 该方法只能在读模式下使用。 rewind()方法后，会恢复position、limit和capacity的值，变为进行get()前的值。 clean()方法 clean()方法会将缓冲区中的各个属性恢复为最初的状态，position = 0, capacity = limit。 此时缓冲区的数据依然存在，处于“被遗忘”状态，下次进行写操作时会覆盖这些数据。 mark()和reset()方法 mark()方法会将postion的值保存到mark属性中。 reset()方法会将position的值改为mark中保存的值。 使用展示1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class Demo1 { public static void main(String[] args) { ByteBuffer byteBuffer = ByteBuffer.allocate(1024); System.out.println(&quot;放入前参数&quot;); System.out.println(&quot;position &quot; + byteBuffer.position()); System.out.println(&quot;limit &quot; + byteBuffer.limit()); System.out.println(&quot;capacity &quot; + byteBuffer.capacity()); System.out.println(); System.out.println(&quot;------put()------&quot;); System.out.println(&quot;放入3个数据&quot;); byte bt = 1; byteBuffer.put(bt); byteBuffer.put(bt); byteBuffer.put(bt); System.out.println(&quot;放入后参数&quot;); System.out.println(&quot;position &quot; + byteBuffer.position()); System.out.println(&quot;limit &quot; + byteBuffer.limit()); System.out.println(&quot;capacity &quot; + byteBuffer.capacity()); System.out.println(); System.out.println(&quot;------flip()-get()------&quot;); System.out.println(&quot;读取一个数据&quot;); // 切换模式 byteBuffer.flip(); byteBuffer.get(); System.out.println(&quot;读取后参数&quot;); System.out.println(&quot;position &quot; + byteBuffer.position()); System.out.println(&quot;limit &quot; + byteBuffer.limit()); System.out.println(&quot;capacity &quot; + byteBuffer.capacity()); System.out.println(); System.out.println(&quot;------rewind()------&quot;); byteBuffer.rewind(); System.out.println(&quot;恢复后参数&quot;); System.out.println(&quot;position &quot; + byteBuffer.position()); System.out.println(&quot;limit &quot; + byteBuffer.limit()); System.out.println(&quot;capacity &quot; + byteBuffer.capacity()); System.out.println(); System.out.println(&quot;------clear()------&quot;); // 清空缓冲区，这里只是恢复了各个属性的值，但是缓冲区里的数据依然存在 // 但是下次写入的时候会覆盖缓冲区中之前的数据 byteBuffer.clear(); System.out.println(&quot;清空后参数&quot;); System.out.println(&quot;position &quot; + byteBuffer.position()); System.out.println(&quot;limit &quot; + byteBuffer.limit()); System.out.println(&quot;capacity &quot; + byteBuffer.capacity()); System.out.println(); System.out.println(&quot;清空后获得数据&quot;); System.out.println(byteBuffer.get()); }} 打印结果 123456789101112131415161718192021222324252627282930313233放入前参数position 0limit 1024capacity 1024------put()------放入3个数据放入后参数position 3limit 1024capacity 1024------flip()-get()------读取一个数据读取后参数position 1limit 3capacity 1024------rewind()------恢复后参数position 0limit 3capacity 1024------clear()------清空后参数position 0limit 1024capacity 1024清空后获得数据1 非直接缓冲区和直接缓冲区非直接缓冲区通过allocate()方法获取的缓冲区都是非直接缓冲区。这些缓冲区是建立在JVM堆内存之中的。 123456789101112131415public static ByteBuffer allocate(int capacity) { if (capacity &lt; 0) throw new IllegalArgumentException(); // 在堆内存中开辟空间 return new HeapByteBuffer(capacity, capacity);}HeapByteBuffer(int cap, int lim) { // package-private // new byte[cap] 创建数组，在堆内存中开辟空间 super(-1, 0, lim, cap, new byte[cap], 0); /* hb = new byte[cap]; offset = 0; */} 通过非直接缓冲区，想要将数据写入到物理磁盘中，或者是从物理磁盘读取数据。都需要经过JVM和操作系统，数据在两个地址空间中传输时，会copy一份保存在对方的空间中。所以费直接缓冲区的读取效率较低。 直接缓冲区只有ByteBuffer可以获得直接缓冲区，通过allocateDirect()获取的缓冲区为直接缓冲区，这些缓冲区是建立在物理内存之中的。 12345678910public static ByteBuffer allocateDirect(int capacity) { return new DirectByteBuffer(capacity);}DirectByteBuffer(int cap) { // package-private ... // 申请物理内存 boolean pa = VM.isDirectMemoryPageAligned(); ...} 直接缓冲区通过在操作系统和JVM之间创建物理内存映射文件加快缓冲区数据读/写入物理磁盘的速度。放到物理内存映射文件中的数据就不归应用程序控制了，操作系统会自动将物理内存映射文件中的数据写入到物理内存中。 通道(Channel)简介Channel由java.nio.channels 包定义的。Channel 表示IO 源与目标打开的连接。Channel 类似于传统的“流”。只不过Channel 本身不能直接访问数据，Channel 只能与Buffer 进行交互。 图解应用程序进行读写操作调用函数时，底层调用的操作系统提供给用户的读写API，调用这些API时会生成对应的指令，CPU则会执行这些指令。在计算机刚出现的那段时间，所有读写请求的指令都有CPU去执行，过多的读写请求会导致CPU无法去执行其他命令，从而CPU的利用率降低。 后来，DMA(Direct Memory Access，直接存储器访问)出现了。当IO请求传到计算机底层时，DMA会向CPU请求，让DMA去处理这些IO操作，从而可以让CPU去执行其他指令。DMA处理IO操作时，会请求获取总线的使用权。当IO请求过多时，会导致大量总线用于处理IO请求，从而降低效率。 于是便有了Channel(通道)，Channel相当于一个专门用于IO操作的独立处理器，它具有独立处理IO请求的能力，当有IO请求时，它会自行处理这些IO请求。 Java Channel常用实现类 本地文件IO FileChannel 网络IO SocketChanel、ServerSocketChannel：用于TCP传输 DatagramChannel：用于UDP传输 获得通道的方法获取通道的一种方式是对支持通道的对象调用getChannel() 方法。支持通道的类如下： FileInputStream FileOutputStream RandomAccessFile DatagramSocket Socket ServerSocket 1234567891011121314151617181920212223public class Demo2 { public static void main(String[] args) throws IOException { // 本地通道 FileInputStream fileInputStream = new FileInputStream(&quot;&quot;); FileChannel channel1 = fileInputStream.getChannel(); FileOutputStream fileOutputStream = new FileOutputStream(&quot;&quot;); FileChannel channel2 = fileOutputStream.getChannel(); // 网络通道 Socket socket = new Socket(); SocketChannel channel3 = socket.getChannel(); ServerSocket serverSocket = new ServerSocket(); ServerSocketChannel channel4 = serverSocket.getChannel(); DatagramSocket datagramSocket = new DatagramSocket(); DatagramChannel channel5 = datagramSocket.getChannel(); // 最后要关闭通道 }} 也可以通过通道的静态方法open()来获取 123456public static void main(String[] args) throws IOException { FileChannel open = FileChannel.open(Paths.get(&quot;&quot;)); SocketChannel open1 = SocketChannel.open(); ...} getChannel()+非直接缓冲区 getChannel()获得通道 allocate()获得非直接缓冲区 通过非直接缓冲区读写数据，需要通过通道来传输缓冲区里的数据 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class Demo4 { public static void main(String[] args) { FileInputStream is = null; FileOutputStream os = null; // 获得通道 FileChannel inChannel = null; FileChannel outChannel = null; // 利用 try-catch-finally 保证关闭 try { is = new FileInputStream(&quot;F:\\\\JDKLearning\\\\src\\\\main\\\\NIO\\\\day1\\\\1.jpg&quot;); os = new FileOutputStream(&quot;F:\\\\JDKLearning\\\\src\\\\main\\\\NIO\\\\day1\\\\2.jpg&quot;); // 获得通道 inChannel = is.getChannel(); outChannel = os.getChannel(); // 获得缓冲区，用于在通道中传输数据 ByteBuffer byteBuffer = ByteBuffer.allocate(1024); // 循环将字节数据放入到buffer中，然后写入磁盘中 while (inChannel.read(byteBuffer) != -1) { // 切换模式 byteBuffer.flip(); outChannel.write(byteBuffer); byteBuffer.clear(); } } catch (IOException e) { e.printStackTrace(); } finally { if (inChannel != null) { try { inChannel.close(); } catch (IOException e) { e.printStackTrace(); } } if (outChannel != null) { try { outChannel.close(); } catch (IOException e) { e.printStackTrace(); } } if (is != null) { try { is.close(); } catch (IOException e) { e.printStackTrace(); } } if (os != null) { try { os.close(); } catch (IOException e) { e.printStackTrace(); } } } }} 图片读取后，被写入到了指定位置 open()+直接缓冲区 通过open获得通道 通过FileChannel.map()获取直接缓冲区 使用直接缓冲区时，无需通过通道来传输数据，直接将数据放在缓冲区内即可 1234567891011121314151617181920212223242526public class Demo5 { public static void main(String[] args) throws IOException { // 通过open()方法来获得通道 FileChannel inChannel = FileChannel.open(Paths.get(&quot;F:\\\\JDKLearning\\\\src\\\\main\\\\NIO\\\\day1\\\\1.jpg&quot;), StandardOpenOption.READ); // outChannel需要为 READ WRITE CREATE模式 // READ WRITE是因为后面获取直接缓冲区时模式为READ_WRITE模式 // CREATE是因为要创建新的文件 FileChannel outChannel = FileChannel.open(Paths.get(&quot;F:\\\\JDKLearning\\\\src\\\\main\\\\NIO\\\\day1\\\\3.jpg&quot;), StandardOpenOption.READ, StandardOpenOption.WRITE, StandardOpenOption.CREATE); // 获得直接缓冲区 MappedByteBuffer inMapBuf = inChannel.map(FileChannel.MapMode.READ_ONLY, 0, inChannel.size()); MappedByteBuffer outMapBuf = outChannel.map(FileChannel.MapMode.READ_WRITE, 0, inChannel.size()); // 字节数组 byte[] bytes = new byte[inMapBuf.limit()]; // 因为是直接缓冲区，可以直接将数据放入到内存映射文件，无需通过通道传输 inMapBuf.get(bytes); outMapBuf.put(bytes); // 关闭缓冲区，这里没有用try-catch-finally inChannel.close(); outChannel.close(); }} 运行结果，图片被创建 通道间直接传输123456789101112131415161718public static void channelToChannel() throws IOException { long start = System.currentTimeMillis(); // 通过open()方法来获得通道 FileChannel inChannel = FileChannel.open(Paths.get(&quot;F:\\\\JDKLearning\\\\src\\\\main\\\\NIO\\\\day1\\\\1.mp4&quot;), StandardOpenOption.READ); // outChannel需要为 READ WRITE CREATE模式 // READ WRITE是因为后面获取直接缓冲区时模式为READ_WRITE模式 // CREATE是因为要创建新的文件 FileChannel outChannel = FileChannel.open(Paths.get(&quot;F:\\\\JDKLearning\\\\src\\\\main\\\\NIO\\\\day1\\\\4.mp4&quot;), StandardOpenOption.READ, StandardOpenOption.WRITE, StandardOpenOption.CREATE); // 通道间直接传输 inChannel.transferTo(0, inChannel.size(), outChannel); // 对应的还有transferFrom // outChannel.transferFrom(inChannel, 0, inChannel.size()); inChannel.close(); outChannel.close();} 直接缓冲区VS非直接缓冲区效率 读取一个MP4文件，通过二者花费时间的多少来判定执行的速度 123456// getChannel() + 非直接缓冲区耗时708// open() + 直接缓冲区耗时115// channel transferTo channel耗时47 内存占用 直接缓冲区的读写速度虽然很快，但是会占用很多很多内存空间。如果文件过大，会使得计算机运行速度变慢 分散和聚集分散读取分散读取（Scattering Reads）是指从Channel 中读取的数据“分散”到多个Buffer 中 注意：按照缓冲区的顺序，从Channel 中读取的数据依次将 Buffer 填满 聚集写入聚集写入（Gathering Writes）是指将多个Buffer 中的数据“聚集”到Channel 按照缓冲区的顺序，写入position 和limit 之间的数据到Channel 代码 1234567891011121314151617181920212223public class Demo2 { public static void main(String[] args) throws IOException { FileInputStream is = new FileInputStream(&quot;F:\\\\JDKLearning\\\\src\\\\main\\\\nio\\\\day2\\\\计划.txt&quot;); FileOutputStream os = new FileOutputStream(&quot;F:\\\\JDKLearning\\\\src\\\\main\\\\nio\\\\day2\\\\计划2.txt&quot;); FileChannel inChannel = is.getChannel(); FileChannel outChannel = os.getChannel(); // 获得多个缓冲区，并且放入到缓冲区数组中 ByteBuffer byteBuffer1 = ByteBuffer.allocate(50); ByteBuffer byteBuffer2 = ByteBuffer.allocate(1024); ByteBuffer[] byteBuffers = {byteBuffer1, byteBuffer2}; // 分散读取 inChannel.read(byteBuffers); byteBuffer1.flip(); byteBuffer2.flip(); // 聚集写入 outChannel.write(byteBuffers); }} 非阻塞式网络通信概念举例双11买的快递到了，快递小哥给你打电话说马上到小区门口，麻烦在门口等一下，方便签收快递 若为阻塞式的，你到了小区门口以后，快递小哥还没到的期间，你什么事儿也做不了 若为非阻塞式的，快递小哥将快递放到门卫处，门卫给你发消息说快递到了，麻烦去取一下。当快递还没到的时候你可以做你自己的事儿 阻塞式网络通信传统的IO 流都是阻塞式的。也就是说，当一个线程调用read() 或write() 时，该线程被阻塞，直到有一些数据被读取或写入，该线程在此期间不能执行其他任务 因此，在完成网络通信进行IO 操作时，由于线程会阻塞，所以服务器端必须为每个客户端都提供一个独立的线程进行处理，当服务器端需要处理大量客户端时，性能急剧下降 也就是说，服务器在等待IO准备就绪的期间，线程处于阻塞状态，若为单线程，等待期间CPU未执行任何任务，效率降低。所以需要开启多个线程，当某些线程因为等待IO准备就绪时，CPU可以去执行其他线程中的任务。但是线程的创建、切换与销毁的开销也是不小的。当大量的任务到来时，服务器性能也急剧下降。 非阻塞式网络通信Java NIO 是非阻塞模式的。当线程从某通道进行读写数据时，若没有数据可用时，该线程可以进行其他任务。线程通常将非阻塞IO 的空闲时间用于在其他通道上执行IO 操作，所以单独的线程可以管理多个输入和输出通道 因此，NIO 可以让服务器端使用一个或有限几个线程来同时处理连接到服务器端的所有客户端 使用阻塞式网络通信演示123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class Demo1 { public static void main(String[] args) throws IOException { Thread thread1 = new Thread(() -&gt; { try { server(); } catch (IOException e) { e.printStackTrace(); } }); Thread thread2 = new Thread(() -&gt; { try { client(); } catch (IOException e) { e.printStackTrace(); } }); thread1.start(); thread2.start(); } public static void client() throws IOException { // 创建客户端通道 SocketChannel socketChannel = SocketChannel.open(new InetSocketAddress(&quot;127.0.0.1&quot;, 2022)); // 读取信息 FileChannel fileChannel = FileChannel.open(Paths.get(&quot;F:\\\\JDKLearning\\\\src\\\\main\\\\nio\\\\day3\\\\1.jpg&quot;), StandardOpenOption.READ); // 创建缓冲区 ByteBuffer byteBuffer = ByteBuffer.allocate(1024); // 写入数据 while (fileChannel.read(byteBuffer) != -1) { byteBuffer.flip(); socketChannel.write(byteBuffer); byteBuffer.clear(); } fileChannel.close(); socketChannel.close(); } public static void server() throws IOException { // 创建服务端通道 ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); FileChannel fileChannel = FileChannel.open(Paths.get(&quot;F:\\\\JDKLearning\\\\src\\\\main\\\\nio\\\\day3\\\\2.jpg&quot;), StandardOpenOption.WRITE, StandardOpenOption.CREATE); // 绑定链接 serverSocketChannel.bind(new InetSocketAddress(2022)); // 获取客户端的通道 SocketChannel socketChannel = serverSocketChannel.accept(); // 创建缓冲区 ByteBuffer byteBuffer = ByteBuffer.allocate(1024); while (socketChannel.read(byteBuffer) != -1) { byteBuffer.flip(); fileChannel.write(byteBuffer); byteBuffer.clear(); } socketChannel.close(); fileChannel.close(); serverSocketChannel.close(); }} 非阻塞式网络通信演示123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384public class DemoNIO { public static void main(String[] args) { Thread thread1 = new Thread(() -&gt; { try { server(); } catch (IOException e) { e.printStackTrace(); } }); Thread thread2 = new Thread(() -&gt; { try { client(); } catch (IOException e) { e.printStackTrace(); } }); thread1.start(); thread2.start(); } public static void client() throws IOException { SocketChannel socketChannel = SocketChannel.open(new InetSocketAddress(&quot;127.0.0.1&quot;, 2020)); // 设置为非阻塞模式 socketChannel.configureBlocking(false); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); Scanner scanner = new Scanner(System.in); while (scanner.hasNext()) { String str = scanner.next(); byteBuffer.put(str.getBytes()); byteBuffer.flip(); socketChannel.write(byteBuffer); byteBuffer.clear(); } byteBuffer.clear(); socketChannel.close(); } public static void server() throws IOException { ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.configureBlocking(false); serverSocketChannel.bind(new InetSocketAddress(2020)); // 获得选择器 Selector selector = Selector.open(); // 将通道注册到选择器中，设定为接收操作 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); // 轮训接受 while (selector.select() &gt; 0) { Iterator&lt;SelectionKey&gt; iterator = selector.selectedKeys().iterator(); // 获得事件的key while (iterator.hasNext()) { SelectionKey key = iterator.next(); if (key.isAcceptable()) { SocketChannel socketChannel = serverSocketChannel.accept(); socketChannel.configureBlocking(false); socketChannel.register(selector, SelectionKey.OP_READ); } else if (key.isReadable()) { // 从选择器中获取通道 SocketChannel socketChannel = (SocketChannel) key.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(10); while (socketChannel.read(byteBuffer) != -1) { int len = byteBuffer.limit(); byteBuffer.flip(); System.out.println(new String(byteBuffer.array(), 0, len)); byteBuffer.clear(); } socketChannel.close(); } iterator.remove(); } } serverSocketChannel.close(); }} 选择器选择器（Selector）是SelectableChannle 对象的多路复用器，Selector 可以同时监控多个SelectableChannel 的IO 状况，也就是说，利用Selector 可使一个单独的线程管理多个Channel。Selector 是非阻塞IO 的核心 选择器的创建 12// 创建一个选择器Selector selector = Selector.open(); 绑定选择器 通过调用通道的register方法可以绑定选择器，register方法有两个参数 Selector：即绑定哪个选择器 ops：监听事件类型。ops有4个值可以选择，为SelectionKey的静态属性 1234// 让选择器监听一种状态myChannel.register(selector, SelectionKey.OP_READ);// 让选择器监听多种状态myChannel.register(selector, SelectionKey.OP_READ | SelectionKey.OP_ACCEPT); SelectionKey 表示SelectableChannel 和Selector 之间的注册关系。每次向选择器注册通道时就会选择一个事件(选择键)。选择键包含两个表示为整数值的操作集。操作集的每一位都表示该键的通道所支持的一类可选择操作。","link":"/posts/20220309/java-nio.html"},{"title":"Elasticsearch学习记录","text":"前言：目标是独立安装Elasticsearch、会使用RestClient的API操作索引和文档、会使用RestClient的API查询文档、会使用RestClient的API聚合数据、简单掌握Spring Data Elasticsearch使用。 Elasticsearch介绍和安装简介ElasticElastic官网：https://www.elastic.co/cn/ Elastic有一条完整的产品线及解决方案：Elasticsearch、Kibana、Logstash等，前面说的三个就是大家常说的ELK技术栈。 ElasticsearchElasticsearch官网：https://www.elastic.co/cn/products/elasticsearch Elasticsearch具备以下特点： 分布式，无需人工搭建集群（solr就需要人为配置，使用Zookeeper作为注册中心） Restful风格，一切API都遵循Rest原则，容易上手 近实时搜索，数据更新在Elasticsearch中几乎是完全同步的。 版本需要虚拟机JDK1.8及以上，本篇博客是以 Elasticsearch7.12.1 为例。配套的Kibana的版本跟随Elasticsearch的版本一致。 总结什么是 elasticsearch ？ 一个开源的分布式搜索引擎，可以用来实现搜索、日志统计、分析、系统监控等功能 什么是 elastic stack（ELK）？ 是以 elasticsearch 为核心的技术栈，包括 beats、Logstash、kibana、elasticsearch 什么是 Lucene ？ 是 Apache 的开源搜索引擎类库，提供了搜索引擎的核心 API 安装和配置https://chanservy.github.io/posts/20220611/elasticsearch-install.html 总结分词器的作用是什么？ 创建倒排索引时对文档分词 用户搜索时，对输入的内容分词 IK分词器有几种模式？ ik_smart：智能切分，粗粒度 ik_max_word：最细切分，细粒度 IK分词器如何拓展词条？如何停用词条？ 利用config目录的IkAnalyzer.cfg.xml文件添加拓展词典和停用词典 在词典中添加拓展词条或者停用词条 APIElasticsearch提供了Rest风格的API，即http请求接口，而且也提供了各种语言的客户端API。 Rest风格API文档地址：https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html 客户端APIElasticsearch支持的客户端非常多：https://www.elastic.co/guide/en/elasticsearch/client/index.html 初识索引正向索引倒排索引的概念是基于 MySQL 这样的正向索引而言的。那么什么是正向索引呢？例如给下表（tb_goods）中的 id 创建索引： 对于数据库，它一般情况下都会基于 id 去创建一个索引，然后形成一个 B+ 树，那么根据 id 进行查询的速度则会非常的快，这种方式的索引就叫做正向索引。 如果是根据 id 查询，那么直接走索引，查询速度非常快。但是如果现在不是根据 id 字段进行搜索，而是一个普通的字段，可能这个字段比较长，比如标题字段，一般不会给它加索引，即便给它也加了索引，那如果进行的不是精确查询而是模糊查询，进行模糊匹配，即便这个字段有索引，那么索引也不会生效。 如果是基于 title 做模糊查询，只能是逐行扫描数据，流程如下： 用户搜索数据，条件是title符合&quot;%手机%&quot; 逐行获取数据，比如id为1的数据 判断数据中的title是否符合用户搜索条件 如果符合则放入结果集，不符合则丢弃。回到步骤1 逐行扫描，也就是全表扫描，随着数据量增加，其查询效率也会越来越低。当数据量达到数百万时，就是一场灾难。 倒排索引倒排索引中有两个非常重要的概念： 文档（Document）：用来搜索的数据，其中的每一条数据就是一个文档。例如一个网页、一个商品信息 词条（Term）：对文档数据或用户搜索数据，利用某种算法分词，得到的具备含义的词语就是词条。例如：我是东北人，就可以分为：我、是、东北人、东北这样的几个词条。 创建倒排索引是对正向索引的一种特殊处理，流程如下： 将每一个文档的数据利用算法分词，得到一个个词条 创建表，每行数据包括词条、词条所在文档id、位置等信息 因为词条唯一性，可以给词条创建索引，例如hash表结构索引 将每一个文档的数据利用算法分词，得到一个个词条；创建表，每行数据包括词条、词条所在文档id、位置等信息；如果有重复的词条出现，在后面记录文档的 id 即可，这样可以确保倒排索引当中，词条字段绝对不会出现重复。将来根据词条查找的速度就会变得非常之快了。 如图： 倒排索引的搜索流程如下（以搜索”华为手机”为例）： 用户输入条件&quot;华为手机&quot;进行搜索。 对用户输入内容分词，得到词条：华为、手机。 拿着词条在倒排索引中查找，可以得到包含词条的文档id：1、2、3。 拿着文档id到正向索引中查找具体文档。 如图： 虽然要先查询倒排索引，再查询正向索引，但是无论是词条、还是文档 id 都建立了索引，查询速度非常快！无需全表扫描。倒排索引更擅长于基于文档的部分内容进行搜索，最经典的就是按照异常信息进行搜索，这也就是 ElasticSearch 便于分析日志的原因，Elasticsearch 底层就是基于倒排索引来查询的。 要注意倒排索引的两个重要细节： 倒排索引中的所有词条对应一个或多个文档（id）； 倒排索引中的词条根据字典顺序升序排列 正向和倒排那么为什么一个叫做正向索引，一个叫做倒排索引呢？ 正向索引是最传统的，根据 id 索引的方式。但根据词条查询时，必须先逐条获取每个文档，然后判断文档中是否包含所需要的词条，是根据文档找词条的过程。 而倒排索引则相反，是先找到用户要搜索的词条，根据词条得到包含词条的文档的 id，然后根据 id 获取文档。是根据词条找文档的过程。 是不是恰好反过来了？那么两者方式的优缺点是什么呢？ 正向索引： 优点： 可以给多个字段创建索引 根据索引字段搜索、排序速度非常快 缺点： 根据非索引字段，或者索引字段中的部分词条查找时，只能全表扫描。 倒排索引： 优点： 根据词条搜索、模糊搜索时，速度非常快 缺点： 只能给词条创建索引，而不是字段 无法根据字段做排序 基本概念Elasticsearch 也是基于 Lucene 的全文检索库，本质也是存储数据，很多概念与 MySQL 类似的。 文档和字段elasticsearch 是面向文档（Document）存储的，可以是数据库中的一条商品数据，一个订单信息。文档数据会被序列化为 json 格式后存储在 elasticsearch 中： 而 Json 文档中往往包含很多的字段（Field），类似于数据库中的列。 索引和映射索引（Index），就是相同类型的文档的集合。 例如： 所有用户文档，就可以组织在一起，称为用户的索引； 所有商品的文档，可以组织在一起，称为商品的索引； 所有订单的文档，可以组织在一起，称为订单的索引； 因此，我们可以把索引当做是数据库中的表。数据库的表会有约束信息，用来定义表的结构、字段的名称、类型等信息。因此，索引中就有映射（mapping），是索引中的文档的字段约束信息，类似表的结构约束。 mysql与elasticsearch我们统一的把mysql与elasticsearch的概念做一下对比：（7.x版本之后） MySQL Elasticsearch 说明 Table Index 索引(index)，就是文档的集合，类似数据库的表(table) Row Document 文档（Document），就是一条条的数据，类似数据库中的行（Row），文档都是JSON格式 Column Field 字段（Field），就是JSON文档中的字段，类似数据库中的列（Column） Schema Mapping Mapping（映射）是索引中文档的约束，例如字段类型约束。类似数据库的表结构（Schema） SQL DSL DSL是elasticsearch提供的JSON风格的请求语句，用来操作elasticsearch，实现CRUD 注：在Elasticsearch7.x版本之前，有type的概念，也即是类型，类型是elasticsearch模拟mysql中的table概念，以前的版本中一个索引下可以有不同的type类型，比如商品，订单，其数据格式不同。不过这会导致索引混乱！在elasticsearch 7.0.0版本必须使用单index，单type，多type结构则会完全移除。事实上6.2.4就已经是单index，单type了。最重要的是，未来版本中会完全移除type这个概念，直接就是索引index即相当于MySQL中的table。注：至今，本人elasticsearch的版本已更新至7.12.1。 既然和MySQL很多相似，是不是说，我们学习了elasticsearch就不再需要mysql了呢？并不是如此，两者各自有自己的擅长之处： Mysql：擅长事务类型操作，可以确保数据的安全和一致性 Elasticsearch：擅长海量数据的搜索、分析、计算 因此在企业中，往往是两者结合使用： 对安全性要求较高的写操作，使用mysql实现 对查询性能要求较高的搜索需求，使用elasticsearch实现 两者再基于某种方式，实现数据的同步，保证一致性 另外，在SolrCloud中，有一些集群相关的概念，在Elasticsearch也有类似的： 索引集（Indices，index的复数）：逻辑上的完整索引。 分片（shard）：数据拆分后的各个部分。 单台机器无法存储大量数据，es 可以将一个索引中的数据切分为多个 shard，分布在多台服务器上存储。有了 shard 就可以横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能。每个 shard 都是一个 lucene index。 副本（replica）：每个分片的复制。 任何一个服务器随时可能故障或宕机，此时 shard 可能就会丢失，因此可以为每个 shard 创建多个 replica 副本。replica 可以在 shard 故障时提供备用服务，保证数据不丢失，多个 replica 还可以提升搜索操作的吞吐量和性能。primary shard（建立索引时一次设置，不能修改，默认 5 个），replica shard（随时修改数量，默认 1 个），默认每个索引 10 个 shard，5 个 primary shard，5个 replica shard，最小的高可用配置，是 2 台服务器。 要注意的是：Elasticsearch本身就是分布式的，因此即便你只有一个节点，Elasticsearch默认也会对你的数据进行分片和副本操作，当你向集群添加新数据时，数据也会在新加入的节点中进行平衡。 这么说吧，shard 分为 primary shard 和 replica shard。而 primary shard 一般简称为 shard，而 replica shard 一般简称为 replica。 es分布式架构原理你搞一个索引，这个索引可以拆分成多个 shard，每个 shard 存储部分数据。拆分多个 shard 是有好处的，一是支持横向扩展，比如你数据量是 3T，3 个 shard，每个 shard 就 1T 的数据，若现在数据量增加到 4T，怎么扩展，很简单，重新建一个有 4 个 shard 的索引，将数据导进去；二是提高性能，数据分布在多个 shard，即多台服务器上，所有的操作，都会在多台机器上并行分布式执行，提高了吞吐量和性能。 接着就是这个 shard 的数据实际是有多个备份，就是说每个 shard 都有一个 primary shard，负责写入数据，但是还有几个 replica shard。primary shard 写入数据之后，会将数据同步到其他几个 replica shard 上去。 通过这个 replica 的方案，每个 shard 的数据都有多个备份，如果某个机器宕机了，没关系啊，还有别的数据副本在别的机器上呢。高可用了吧。 es 集群多个节点，会自动选举一个节点为 master 节点，这个 master 节点其实就是干一些管理的工作的，比如维护索引元数据、负责切换 primary shard 和 replica shard 身份等。要是 master 节点宕机了，那么会重新选举一个节点为 master 节点。 如果是非 master节点宕机了，那么会由 master 节点，让那个宕机节点上的 primary shard 的身份转移到其他机器上的 replica shard。接着你要是修复了那个宕机机器，重启了之后，master 节点会控制将缺失的 replica shard 分配过去，同步后续修改的数据之类的，让集群恢复正常。 说得更简单一点，就是说如果某个非 master 节点宕机了。那么此节点上的 primary shard 不就没了。那好，master 会让 primary shard 对应的 replica shard（在其他机器上）切换为 primary shard。如果宕机的机器修复了，修复后的节点也不再是 primary shard，而是 replica shard。 其实上述就是 ElasticSearch 作为分布式搜索引擎最基本的一个架构设计。 其实 es 的分布式架构原理和之前说过的 Kafka 的高可用分布式架构原理是极其相似的，搞一个 topic ，将 topic 分为多个 partition ，比如说数据过来了，partition1 存放一部分，partition2存放一部分。。。每个 partition 都只存放部分数据，这就凸显了分布式的理念。接着，每个 partition 都有多个 replica 副本，partition 自己也是个副本，然后这些个副本中，会选举出来一个 leader，其他的都是 follower，其实到这里，都是和 Kafka 极其相似的，每台机器上的 es 进程就相当于 Kafka 中的 broker ，索引就相当于 Kafka 的 topic ， shard 就相当于 Kafka 中的 partition ，primary shard 就相当于 partition 的 leader ， replica shard 就相当于 partition 的 follower。但是从这里开始，就有一个不同之处了，在 Kafka 中，读写消息都是针对于 partition 的 leader 的；在 es 中，写数据的时候是只向 primary shard 中写，读数据的时候，是 primary shard 和 replica shard 都可以读的。另外，在 es 中有一个选举 master node 主节点的因素。 es读写数据的工作原理es 写数据过程 客户端选择一个 node 发送请求过去，这个 node 就是 coordinating node（协调节点）。 coordinating node 对 document 进行路由，将请求转发给对应的 node（有 primary shard）。 实际的 node 上的 primary shard 处理请求，然后将数据同步到 replica shard。 coordinating node 如果发现 primary shard 和所有 replica shard 都搞定之后，就返回响应结果给客户端。 图解：客户端写数据的时候，会任意挑一个进程去写，这个进程此时就会被称为协调节点，这个协调节点会对这条数据进行哈希，哈希之后就会知道这条数据属于哪个 shard 。如图，假设这条数据属于 shard01 ，但客户端比如说任意挑的是机器 2 上的 es 进程 02 节点，它就作为协调节点，写数据只能在 primary shard 上面写，一看 es 进程 02 上面的是 replica shard01 ，所以这个协调节点就会将请求转发给对应的有 primary shard01 的 node ，也就是机器 1 上的 es 进程 01 节点。然后这个 node 上的 primary shard01 处理请求，写入数据，然后将数据同步到其他的 replica shard01 上，协调节点如果发现 primary shard 和所有 replica shard 都搞定之后，就返回响应结果给客户端。 es 读数据过程可以通过 doc id 来查询，会根据 doc id 进行 hash，判断出来当时把 doc id 分配到了哪个 shard 上面去，从那个 shard 去查询。 客户端发送请求到任意一个 node，成为 coordinate node。 coordinate node 对 doc id 进行哈希路由，将请求转发到对应的 node，此时会使用 round-robin 随机轮询算法，在 primary shard 以及其所有 replica 中随机选择一个，让读请求负载均衡。 接收请求的 node 返回 document 给 coordinate node。 coordinate node 返回 document 给客户端。 es 搜索数据过程es 最强大的是做全文检索，就是比如你有三条数据： 123java真好玩儿啊java好难学啊j2ee特别牛 你根据 java 关键词来搜索，将包含 java的 document 给搜索出来。es 就会给你返回：java真好玩儿啊，java好难学啊。 客户端发送请求到一个 coordinate node。 协调节点将搜索请求转发到所有的 shard 对应的 primary shard 或 replica shard，都可以。 query phase：每个 shard 将自己的搜索结果（其实就是一些 doc id）返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果。 fetch phase：接着由协调节点根据 doc id 去各个节点上拉取实际的 document 数据，最终返回给客户端。 写请求是写入 primary shard，然后同步给所有的 replica shard；读请求可以从 primary shard 或 replica shard 读取，采用的是随机轮询算法。 写数据底层原理 先写入内存 buffer，在 buffer 里的时候数据是搜索不到的；同时将数据写入 translog 日志文件。 如果 buffer 快满了，或者到一定时间，就会将内存 buffer 数据 refresh 到一个新的 segment file 中，但是此时数据不是直接进入 segment file 磁盘文件，而是先进入 os cache 。这个过程就是 refresh。 每隔 1 秒钟，es 将 buffer 中的数据写入一个新的 segment file，每秒钟会产生一个新的磁盘文件 segment file，这个 segment file 中就存储最近 1 秒内 buffer 中写入的数据。 但是如果 buffer 里面此时没有数据，那当然不会执行 refresh 操作，如果 buffer 里面有数据，默认 1 秒钟执行一次 refresh 操作，刷入一个新的 segment file 中。 操作系统里面，磁盘文件其实都有一个东西，叫做 os cache，即操作系统缓存，就是说数据写入磁盘文件之前，会先进入 os cache，先进入操作系统级别的一个内存缓存中去。只要 buffer 中的数据被 refresh 操作刷入 os cache中，这个数据就可以被搜索到了。 为什么叫 es 是准实时的？ NRT，全称 near real-time。默认是每隔 1 秒 refresh 一次的，所以 es 是准实时的，因为写入的数据 1 秒之后才能被看到。可以通过 es 的 restful api 或者 java api，手动执行一次 refresh 操作，就是手动将 buffer 中的数据刷入 os cache中，让数据立马就可以被搜索到。只要数据被输入 os cache 中，buffer 就会被清空了，因为不需要保留 buffer 了，数据在 translog 里面已经持久化到磁盘去一份了。 重复上面的步骤，新的数据不断进入 buffer 和 translog，不断将 buffer 数据写入一个又一个新的 segment file 中去，每次 refresh 完 buffer 清空，translog 保留。随着这个过程推进，translog 会变得越来越大。当 translog 达到一定长度的时候，就会触发 commit 操作。 commit 操作发生第一步，就是将 buffer 中现有数据 refresh 到 os cache 中去，清空 buffer。然后，将一个 commit point 写入磁盘文件，里面标识着这个 commit point 对应的所有 segment file，同时强行将 os cache 中目前所有的数据都 fsync 到磁盘文件中去。最后清空 现有 translog 日志文件，重启一个 translog，此时 commit 操作完成。 这个 commit 操作叫做 flush。默认 30 分钟自动执行一次 flush，但如果 translog 过大，也会触发 flush。flush 操作就对应着 commit 的全过程，我们可以通过 es api，手动执行 flush 操作，手动将 os cache 中的数据 fsync 强刷到磁盘上去。 translog 日志文件的作用是什么？你执行 commit 操作之前，数据要么是停留在 buffer 中，要么是停留在 os cache 中，无论是 buffer 还是 os cache 都是内存，一旦这台机器死了，内存中的数据就全丢了。所以需要将数据对应的操作写入一个专门的日志文件 translog 中，一旦此时机器宕机，再次重启的时候，es 会自动读取 translog 日志文件中的数据，恢复到内存 buffer 和 os cache 中去。 translog 其实也是先写入 os cache 的，默认每隔 5 秒刷一次到磁盘中去，所以默认情况下，可能有 5 秒的数据会仅仅停留在 buffer 或者 translog 文件的 os cache 中，如果此时机器挂了，会丢失 5 秒钟的数据。但是这样性能比较好，最多丢 5 秒的数据。也可以将 translog 设置成每次写操作必须是直接 fsync 到磁盘，但是性能会差很多。 实际上你在这里，如果面试官没有问你 es 丢数据的问题，你可以在这里给面试官炫一把，你说，其实 es 第一是准实时的，数据写入 1 秒后可以搜索到；可能会丢失数据的。有 5 秒的数据，停留在 buffer、translog os cache、segment file os cache 中，而不在磁盘上，此时如果宕机，会导致 5 秒的数据丢失。 总结一下，数据先写入内存 buffer，然后每隔 1s，将数据 refresh 到 os cache，到了 os cache 数据就能被搜索到（所以我们才说 es 从写入到能被搜索到，中间有 1s 的延迟）。translog 其实也是先写入 os cache 的，每隔 5s，再将数据写入磁盘上的 translog 文件（这样如果机器宕机，内存数据全没，最多会有 5s 的数据丢失），translog 大到一定程度，或者默认每隔 30mins，会触发 commit 操作，第一步，就是将 buffer 中现有数据 refresh 到 os cache 中去，清空 buffer。然后，将一个 commit point 写入磁盘文件，里面标识着这个 commit point 对应的所有 segment file，同时强行将 os cache 中目前所有的数据都 fsync 到 segment file 磁盘文件中去。最后清空 现有 translog 日志文件，重启一个 translog，至此 commit 操作完成，成功将缓冲区的数据都 flush 到 segment file 磁盘文件中。 数据写入 segment file 之后，同时就建立好了倒排索引。 删除/更新数据底层原理如果是删除操作，commit 的时候会生成一个 .del 文件，里面将某个 doc 标识为 deleted 状态，那么搜索的时候根据 .del 文件就知道这个 doc 是否被删除了。 如果是更新操作，就是将原来的 doc 标识为 deleted 状态，然后新写入一条数据。 buffer 每 refresh 一次，就会产生一个 segment file，所以默认情况下是 1 秒钟一个 segment file，这样下来 segment file 会越来越多，此时会定期执行 merge。每次 merge 的时候，会将多个 segment file 合并成一个，同时这里会将标识为 deleted 的 doc 给物理删除掉，然后将新的 segment file 写入磁盘，这里会写一个 commit point，标识所有新的 segment file，然后打开 segment file 供搜索使用，同时删除旧的 segment file。 性能优化的杀手锏——filesystem cache你往 es 里写的数据，实际上都写到磁盘文件里去了，查询的时候，操作系统会将磁盘文件里的数据自动缓存到 filesystem cache 里面去。 es 的搜索引擎严重依赖于底层的 filesystem cache，你如果给 filesystem cache 更多的内存，尽量让内存可以容纳所有的 idx segment file 索引数据文件，那么你搜索的时候就基本都是走内存的，性能会非常高。 索引操作索引就类似数据库中的表，mapping映射就类似表的结构。我们要向es中存储数据，必须先创建“表结构”。 mapping映射属性mapping是对索引中的文档的约束，常见的mapping属性包括： type：字段数据类型，常见的简单类型有： 字符串：text（可分词的文本）、keyword（精确值，例如：品牌、国家、ip地址） 数值：long、integer、short、byte、double、float、 布尔：boolean 日期：date 对象：object 嵌入式：nested index：是否创建索引，默认为true analyzer：使用哪种分词器 properties：该字段的子字段 store：是否存储，默认为false 例如下面的json文档： 123456789101112{ &quot;age&quot;: 21, &quot;weight&quot;: 52.1, &quot;isMarried&quot;: false, &quot;info&quot;: &quot;黑马程序员Java讲师&quot;, &quot;email&quot;: &quot;zy@itcast.cn&quot;, &quot;score&quot;: [99.1, 99.5, 98.9], &quot;name&quot;: { &quot;firstName&quot;: &quot;云&quot;, &quot;lastName&quot;: &quot;赵&quot; }} 对应的每个字段映射（mapping）： age：类型为 integer；参与搜索，因此需要index为true；无需分词器 weight：类型为float；参与搜索，因此需要index为true；无需分词器 isMarried：类型为boolean；参与搜索，因此需要index为true；无需分词器 info：类型为字符串，需要分词，因此是text；参与搜索，因此需要index为true；分词器可以用ik_smart email：类型为字符串，但是不需要分词，因此是keyword；不参与搜索，因此需要index为false；无需分词器 score：虽然是数组，但是我们只看元素的类型，类型为float；参与搜索，因此需要index为true；无需分词器 name：类型为object，需要定义多个子属性 name.firstName；类型为字符串，但是不需要分词，因此是keyword；参与搜索，因此需要index为true；无需分词器 name.lastName；类型为字符串，但是不需要分词，因此是keyword；参与搜索，因此需要index为true；无需分词器 创建索引，最关键的是mapping映射，而mapping映射要考虑的信息包括： 字段名 字段数据类型 是否参与搜索 是否需要分词 如果分词，分词器是什么？ 其中： 字段名、字段数据类型，可以参考数据表结构的名称和类型 是否参与搜索要分析业务来判断，例如图片地址，就无需参与搜索 是否分词呢要看内容，内容如果是一个整体就无需分词，反之则要分词 分词器，我们可以统一使用ik_max_word 举例来看下酒店数据的索引库结构： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950PUT /hotel{ &quot;mappings&quot;: { &quot;properties&quot;: { &quot;id&quot;: { &quot;type&quot;: &quot;keyword&quot; }, &quot;name&quot;:{ &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;copy_to&quot;: &quot;all&quot; }, &quot;address&quot;:{ &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: false }, &quot;price&quot;:{ &quot;type&quot;: &quot;integer&quot; }, &quot;score&quot;:{ &quot;type&quot;: &quot;integer&quot; }, &quot;brand&quot;:{ &quot;type&quot;: &quot;keyword&quot;, &quot;copy_to&quot;: &quot;all&quot; }, &quot;city&quot;:{ &quot;type&quot;: &quot;keyword&quot;, &quot;copy_to&quot;: &quot;all&quot; }, &quot;starName&quot;:{ &quot;type&quot;: &quot;keyword&quot; }, &quot;business&quot;:{ &quot;type&quot;: &quot;keyword&quot; }, &quot;location&quot;:{ &quot;type&quot;: &quot;geo_point&quot; }, &quot;pic&quot;:{ &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: false }, &quot;all&quot;:{ &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot; } } }} 几个特殊字段说明： location：地理坐标，里面包含精度、纬度 all：一个组合字段，其目的是将多字段的值利用copy_to合并，提供给用户搜索 地理坐标说明： copy_to说明： 案例分析 项目经验，案例分析。 检索业务-es中sku的存储结构分析 （只有上架的商品存储到Elasticsearch中才能被检索） 分析-存储商品的什么信息到 es 中 需要保存 sku 信息 当搜索商品名时，查询的是 sku 的标题 sku_title； 可能通过 sku 的标题、销量、价格区间检索 需要保存品牌、分类等信息 点击分类，检索分类下的所有信息 点击品牌，检索品牌下的商品信息 需要保存 spu 信息 选择规格，检索共有这些规格的商品 分析-怎么设计存储结构来保存数据 方案1-空间换时间 1234567891011121314{ skuId:1 spuId:11 skyTitile:华为xx price:999 saleCount:99 attrs:[ {尺寸:5存}, {CPU:高通945}, {分辨率:全高清} ]}# 缺点：会产生冗余字段，对于相同类型的商品，attrs 属性字段会重复，空间占用大# 好处：方便检索 方案2-时间换空间 12345678910111213141516sku索引{ skuId:1 spuId:11}attr索引{ spuId:11 attrs:[ {尺寸:5寸}, {CPU:高通945}, {分辨率:全高清} ]}# 缺点：选择公共属性attr时,会检索当前属性的所有商品分类，然后再查询当前商品分类的所有可能属性；导致耗时变长。# 好处：空间利用率高 举例，mapping结构字段说明： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&quot;mappings&quot;: { &quot;properties&quot;: { &quot;skuId&quot;: { &quot;type&quot;: &quot;long&quot; }, &quot;spuId&quot;: { &quot;type&quot;: &quot;keyword&quot; }, # 精确检索，不分词 &quot;skuTitle&quot;: { &quot;type&quot;: &quot;text&quot;, # 全文检索 &quot;analyzer&quot;: &quot;ik_smart&quot; # 分词器 }, &quot;skuPrice&quot;: { &quot;type&quot;: &quot;keyword&quot; }, &quot;skuImg&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: false, # false 不可被检索 &quot;doc_values&quot;: false # false 不可被聚合 }, &quot;saleCount&quot;:{ &quot;type&quot;:&quot;long&quot; }, # 商品销量 &quot;hasStock&quot;: { &quot;type&quot;: &quot;boolean&quot; }, # 商品是否有库存 &quot;hotScore&quot;: { &quot;type&quot;: &quot;long&quot; }, # 商品热度评分 &quot;brandId&quot;: { &quot;type&quot;: &quot;long&quot; }, # 品牌id &quot;catalogId&quot;: { &quot;type&quot;: &quot;long&quot; }, # 分类id &quot;brandName&quot;: { # 品牌名，只用来查看，不用来检索和聚合 &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: false, &quot;doc_values&quot;: false }, &quot;brandImg&quot;:{ # 品牌图片，只用来查看，不用来检索和聚合 &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: false, &quot;doc_values&quot;: false }, &quot;catalogName&quot;: { # 分类名，只用来查看，不用来检索和聚合 &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: false, &quot;doc_values&quot;: false }, &quot;attrs&quot;: { # 属性对象 &quot;type&quot;: &quot;nested&quot;, # 嵌入式，内部属性 &quot;properties&quot;: { &quot;attrId&quot;: {&quot;type&quot;: &quot;long&quot; }, &quot;attrName&quot;: { # 属性名 &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: false, &quot;doc_values&quot;: false }, &quot;attrValue&quot;: { &quot;type&quot;: &quot;keyword&quot; } # 属性值 } } }} 关于 nested 类型官网：Nested field type，nested 类型用于 JSON 对象数组。 Object 数据类型的数组会被扁平化处理为一个简单的键与值的列表，即对象的相同属性会放到同一个数组中，在检索时会出现错误。参考官网：How arrays of objects are flattened 对于 Object 类型的数组，要使用 nested 字段类型。参考官网：Using nested fields for arrays of objects ElasticSearch-数组的扁平化处理： 举例： 1234567891011121314PUT my_index/_doc/1{ &quot;group&quot; : &quot;fans&quot;, &quot;user&quot; : [ { &quot;first&quot; : &quot;John&quot;, &quot;last&quot; : &quot;Smith&quot; }, { &quot;first&quot; : &quot;Alice&quot;, &quot;last&quot; : &quot;White&quot; } ]} 在索引index中，存入user的数据，最终 es 会将上述数据，扁平化处理，实际存储如下这样子： 12345{ &quot;group&quot; : &quot;fans&quot;, &quot;user.first&quot; : [ &quot;alice&quot;, &quot;john&quot; ], &quot;user.last&quot; : [ &quot;smith&quot;, &quot;white&quot; ]} 很明显，数据存储成这样子，丢失了first 和 last 之间关系。从这样的存储中，我们无法确定，first 为 “alice” 的对应的 last 是 “smith” 还是 “white”。因此，如果数组里存储的是对象，那么数组的类型应该是 nested，这样，在将对象数据存入数组中时，对象便不会被扁平化处理。 例如执行如下查询： 1234567891011GET my_index/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;match&quot;: { &quot;user.first&quot;: &quot;Alice&quot; }}, { &quot;match&quot;: { &quot;user.last&quot;: &quot;Smith&quot; }} ] } }} 查询到的结果： 1234567891011121314151617181920212223242526272829303132333435363738{ &quot;took&quot; : 6, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;skipped&quot; : 0, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : { &quot;value&quot; : 1, &quot;relation&quot; : &quot;eq&quot; }, &quot;max_score&quot; : 0.5753642, &quot;hits&quot; : [ { &quot;_index&quot; : &quot;my_index&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_score&quot; : 0.5753642, &quot;_source&quot; : { &quot;group&quot; : &quot;fans&quot;, &quot;user&quot; : [ { &quot;first&quot; : &quot;John&quot;, &quot;last&quot; : &quot;Smith&quot; }, { &quot;first&quot; : &quot;Alice&quot;, &quot;last&quot; : &quot;White&quot; } ] } } ] }} 虽然查询到了数据，但这样的数据并不是我们想要的。因为通过 &quot;first&quot; 为 &quot;Alice&quot; 并且 &quot;last&quot; 为 &quot;Smith&quot; 这样的条件，不应该查询到数据，（约翰史密斯、爱丽丝怀特）。之所以查询到数据，是因为数组中存储的对象被扁平化处理了。 因此需要修改索引的mapping信息，将user数组的类型定义为 nested 并存入数据，重新执行检索。 12345678910111213141516171819202122232425PUT my_index{ &quot;mappings&quot;: { &quot;properties&quot;: { &quot;user&quot;: { &quot;type&quot;: &quot;nested&quot; } } }}PUT my_index/_doc/1{ &quot;group&quot; : &quot;fans&quot;, &quot;user&quot; : [ { &quot;first&quot; : &quot;John&quot;, &quot;last&quot; : &quot;Smith&quot; }, { &quot;first&quot; : &quot;Alice&quot;, &quot;last&quot; : &quot;White&quot; } ]} 执行同样查询： 1234567891011GET my_index/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;match&quot;: { &quot;user.first&quot;: &quot;Alice&quot; }}, { &quot;match&quot;: { &quot;user.last&quot;: &quot;Smith&quot; }} ] } }} 这次获取到的结果为空： 123456789101112131415161718{ &quot;took&quot; : 11, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;skipped&quot; : 0, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : { &quot;value&quot; : 0, &quot;relation&quot; : &quot;eq&quot; }, &quot;max_score&quot; : null, &quot;hits&quot; : [ ] }} 这样的结果才是我们想要的，这样防止了 frist 和 last 之间关系的丢失。 索引的CRUD创建索引和映射基本语法： 请求方式：PUT 请求路径：/索引名，可以自定义 请求参数：mapping映射 格式： 1234567891011121314151617181920212223PUT /索引名称{ &quot;mappings&quot;: { &quot;properties&quot;: { &quot;字段名&quot;:{ &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_smart&quot; }, &quot;字段名2&quot;:{ &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: &quot;false&quot; }, &quot;字段名3&quot;:{ &quot;properties&quot;: { &quot;子字段&quot;: { &quot;type&quot;: &quot;keyword&quot; } } }, // ...略 } }} 示例： 1234567891011121314151617181920212223PUT /heima{ &quot;mappings&quot;: { &quot;properties&quot;: { &quot;info&quot;:{ &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_smart&quot; }, &quot;email&quot;:{ &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: &quot;falsae&quot; }, &quot;name&quot;:{ &quot;properties&quot;: { &quot;firstName&quot;: { &quot;type&quot;: &quot;keyword&quot; } } }, // ... 略 } }} 查询索引基本语法： 请求方式：GET 请求路径：/索引名 请求参数：无 格式： 1GET /索引名 示例： 修改索引倒排索引结构虽然不复杂，但是一旦数据结构改变（比如改变了分词器），就需要重新创建倒排索引，这简直是灾难。因此索引一旦创建，无法修改mapping。虽然无法修改mapping中已有的字段，但是却允许添加新的字段到mapping中，因为不会对倒排索引产生影响。 语法说明： 12345678PUT /索引名/_mapping{ &quot;properties&quot;: { &quot;新字段名&quot;:{ &quot;type&quot;: &quot;integer&quot; } }} 示例： 删除索引语法： 请求方式：DELETE 请求路径：/索引名 请求参数：无 格式： 1DELETE /索引名 在kibana中测试： 总结索引操作有哪些？ 创建索引：PUT /索引名 查询索引：GET /索引名 删除索引：DELETE /索引名 添加字段：PUT /索引名/_mapping 查看索引的配置Get请求可以帮我们查看索引信息，格式： 1GET /索引名 或者，我们可以使用*来查询所有索引的配置： 查看映射关系语法格式： 1GET /索引名/_mapping 示例： 1GET /csy/_mapping 响应： 123456789101112131415161718192021{ &quot;csy&quot;: { &quot;mappings&quot;: { &quot;goods&quot;: { &quot;properties&quot;: { &quot;images&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: false }, &quot;price&quot;: { &quot;type&quot;: &quot;float&quot; }, &quot;title&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot; } } } } }} 字段属性详解typeElasticsearch中支持的数据类型非常丰富： 我们说几个关键的： String类型，又分两种： text：可分词，不可参与聚合 keyword：不可分词，数据会作为完整字段进行匹配，可以参与聚合 Numerical：数值类型，分两类 基本数据类型：long、interger、short、byte、double、float、half_float 浮点数的高精度类型：scaled_float 需要指定一个精度因子，比如10或100。elasticsearch会把真实值乘以这个因子后存储，取出时再还原。 Date：日期类型 elasticsearch可以对日期格式化为字符串存储，但是建议我们存储为毫秒值，存储为long，节省空间。 如果存的是对象 比如：{girl: {name: “rose”,age: 22}} 会处理成两个字段：girl.name和girl.age。 indexindex影响字段的索引情况。 true：字段会被索引，则可以用来进行搜索。默认值就是true false：字段不会被索引，不能用来搜索 index的默认值就是true，也就是说你不进行任何配置，所有字段都会被索引。 但是有些字段是我们不希望被索引的，比如商品的图片信息，就需要手动设置index为false。 store是否将数据进行额外存储。 在lucene和solr中，我们知道如果一个字段的store设置为false，那么在文档列表中就不会有这个字段的值，用户的搜索结果中不会显示出来。 但是在Elasticsearch中，即便store设置为false，也可以搜索到结果。 原因是Elasticsearch在创建文档索引时，会将文档中的原始数据备份，保存到一个叫做_source的属性中。而且我们可以通过过滤_source来选择哪些要显示，哪些不显示。 而如果设置store为true，就会在_source以外额外存储一份数据，多余，因此一般我们都会将store设置为false，事实上，store的默认值就是false。 数据迁移先创建出 new_twitter 的正确映射。然后使用如下方式进行数据迁移 123456789POST _reindex [固定写法]{ &quot;source&quot;: { &quot;index&quot;: &quot;twitter&quot; }, &quot;dest&quot;: { &quot;index&quot;: &quot;new_twitter&quot; }} RestClient操作索引ES官方提供了各种不同语言的客户端，用来操作ES。这些客户端的本质就是组装DSL语句，通过http请求发送给ES。官方文档地址：https://www.elastic.co/guide/en/elasticsearch/client/index.html 其中的Java Rest Client又包括两种： Java Low Level Rest Client Java High Level Rest Client 我们学习的是Java HighLevel Rest Client客户端API。 导入数据数据结构如下： 123456789101112131415CREATE TABLE `tb_hotel` ( `id` bigint(20) NOT NULL COMMENT '酒店id', `name` varchar(255) NOT NULL COMMENT '酒店名称；例：7天酒店', `address` varchar(255) NOT NULL COMMENT '酒店地址；例：航头路', `price` int(10) NOT NULL COMMENT '酒店价格；例：329', `score` int(2) NOT NULL COMMENT '酒店评分；例：45，就是4.5分', `brand` varchar(32) NOT NULL COMMENT '酒店品牌；例：如家', `city` varchar(32) NOT NULL COMMENT '所在城市；例：上海', `star_name` varchar(16) DEFAULT NULL COMMENT '酒店星级，从低到高分别是：1星到5星，1钻到5钻', `business` varchar(255) DEFAULT NULL COMMENT '商圈；例：虹桥', `latitude` varchar(32) NOT NULL COMMENT '纬度；例：31.2497', `longitude` varchar(32) NOT NULL COMMENT '经度；例：120.3925', `pic` varchar(255) DEFAULT NULL COMMENT '酒店图片；例:/img/1.jpg', PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 导入项目项目结构如图： mapping映射分析创建索引库，最关键的是mapping映射，而mapping映射要考虑的信息包括： 字段名 字段数据类型 是否参与搜索 是否需要分词 如果分词，分词器是什么？ 其中： 字段名、字段数据类型，可以参考数据表结构的名称和类型 是否参与搜索要分析业务来判断，例如图片地址，就无需参与搜索 是否分词呢要看内容，内容如果是一个整体就无需分词，反之则要分词 分词器，我们可以统一使用ik_max_word 来看下酒店数据的索引库结构: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950PUT /hotel{ &quot;mappings&quot;: { &quot;properties&quot;: { &quot;id&quot;: { &quot;type&quot;: &quot;keyword&quot; }, &quot;name&quot;:{ &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;copy_to&quot;: &quot;all&quot; }, &quot;address&quot;:{ &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: false }, &quot;price&quot;:{ &quot;type&quot;: &quot;integer&quot; }, &quot;score&quot;:{ &quot;type&quot;: &quot;integer&quot; }, &quot;brand&quot;:{ &quot;type&quot;: &quot;keyword&quot;, &quot;copy_to&quot;: &quot;all&quot; }, &quot;city&quot;:{ &quot;type&quot;: &quot;keyword&quot;, &quot;copy_to&quot;: &quot;all&quot; }, &quot;starName&quot;:{ &quot;type&quot;: &quot;keyword&quot; }, &quot;business&quot;:{ &quot;type&quot;: &quot;keyword&quot; }, &quot;location&quot;:{ &quot;type&quot;: &quot;geo_point&quot; }, &quot;pic&quot;:{ &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: false }, &quot;all&quot;:{ &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot; } } }} 几个特殊字段说明： location：地理坐标，里面包含精度、纬度 all：一个组合字段，其目的是将多字段的值 利用copy_to合并，提供给用户搜索 地理坐标说明： copy_to说明： 初始化RestClient在elasticsearch提供的API中，与elasticsearch一切交互都封装在一个名为RestHighLevelClient的类中，必须先完成这个对象的初始化，建立与elasticsearch的连接。 分为三步： 1）引入es的RestHighLevelClient依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt;&lt;/dependency&gt; 2）因为SpringBoot默认的ES版本是7.6.2，所以我们需要覆盖默认的ES版本： 1234&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;elasticsearch.version&gt;7.12.1&lt;/elasticsearch.version&gt;&lt;/properties&gt; 3）初始化RestHighLevelClient： 初始化的代码如下： 123RestHighLevelClient client = new RestHighLevelClient(RestClient.builder( HttpHost.create(&quot;http://192.168.150.101:9200&quot;))); 这里为了单元测试方便，我们创建一个测试类HotelIndexTest，然后将初始化的代码编写在@BeforeEach方法中： 12345678910111213141516171819202122232425package cn.itcast.hotel;import org.apache.http.HttpHost;import org.elasticsearch.client.RestHighLevelClient;import org.junit.jupiter.api.AfterEach;import org.junit.jupiter.api.BeforeEach;import org.junit.jupiter.api.Test;import java.io.IOException;public class HotelIndexTest { private RestHighLevelClient client; @BeforeEach void setUp() { this.client = new RestHighLevelClient(RestClient.builder( HttpHost.create(&quot;http://192.168.150.101:9200&quot;) )); } @AfterEach void tearDown() throws IOException { this.client.close(); }} 创建索引库代码解读创建索引库的API如下： 代码分为三步： 1）创建Request对象。因为是创建索引库的操作，因此Request是CreateIndexRequest。 2）添加请求参数，其实就是DSL的JSON参数部分。因为json字符串很长，这里是定义了静态字符串常量MAPPING_TEMPLATE，让代码看起来更加优雅。 3）发送请求，client.indices()方法的返回值是IndicesClient类型，封装了所有与索引库操作有关的方法。 完整示例定义mapping映射的JSON字符串常量： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package cn.itcast.hotel.constants;public class HotelConstants { public static final String MAPPING_TEMPLATE = &quot;{\\n&quot; + &quot; \\&quot;mappings\\&quot;: {\\n&quot; + &quot; \\&quot;properties\\&quot;: {\\n&quot; + &quot; \\&quot;id\\&quot;: {\\n&quot; + &quot; \\&quot;type\\&quot;: \\&quot;keyword\\&quot;\\n&quot; + &quot; },\\n&quot; + &quot; \\&quot;name\\&quot;:{\\n&quot; + &quot; \\&quot;type\\&quot;: \\&quot;text\\&quot;,\\n&quot; + &quot; \\&quot;analyzer\\&quot;: \\&quot;ik_max_word\\&quot;,\\n&quot; + &quot; \\&quot;copy_to\\&quot;: \\&quot;all\\&quot;\\n&quot; + &quot; },\\n&quot; + &quot; \\&quot;address\\&quot;:{\\n&quot; + &quot; \\&quot;type\\&quot;: \\&quot;keyword\\&quot;,\\n&quot; + &quot; \\&quot;index\\&quot;: false\\n&quot; + &quot; },\\n&quot; + &quot; \\&quot;price\\&quot;:{\\n&quot; + &quot; \\&quot;type\\&quot;: \\&quot;integer\\&quot;\\n&quot; + &quot; },\\n&quot; + &quot; \\&quot;score\\&quot;:{\\n&quot; + &quot; \\&quot;type\\&quot;: \\&quot;integer\\&quot;\\n&quot; + &quot; },\\n&quot; + &quot; \\&quot;brand\\&quot;:{\\n&quot; + &quot; \\&quot;type\\&quot;: \\&quot;keyword\\&quot;,\\n&quot; + &quot; \\&quot;copy_to\\&quot;: \\&quot;all\\&quot;\\n&quot; + &quot; },\\n&quot; + &quot; \\&quot;city\\&quot;:{\\n&quot; + &quot; \\&quot;type\\&quot;: \\&quot;keyword\\&quot;,\\n&quot; + &quot; \\&quot;copy_to\\&quot;: \\&quot;all\\&quot;\\n&quot; + &quot; },\\n&quot; + &quot; \\&quot;starName\\&quot;:{\\n&quot; + &quot; \\&quot;type\\&quot;: \\&quot;keyword\\&quot;\\n&quot; + &quot; },\\n&quot; + &quot; \\&quot;business\\&quot;:{\\n&quot; + &quot; \\&quot;type\\&quot;: \\&quot;keyword\\&quot;\\n&quot; + &quot; },\\n&quot; + &quot; \\&quot;location\\&quot;:{\\n&quot; + &quot; \\&quot;type\\&quot;: \\&quot;geo_point\\&quot;\\n&quot; + &quot; },\\n&quot; + &quot; \\&quot;pic\\&quot;:{\\n&quot; + &quot; \\&quot;type\\&quot;: \\&quot;keyword\\&quot;,\\n&quot; + &quot; \\&quot;index\\&quot;: false\\n&quot; + &quot; },\\n&quot; + &quot; \\&quot;all\\&quot;:{\\n&quot; + &quot; \\&quot;type\\&quot;: \\&quot;text\\&quot;,\\n&quot; + &quot; \\&quot;analyzer\\&quot;: \\&quot;ik_max_word\\&quot;\\n&quot; + &quot; }\\n&quot; + &quot; }\\n&quot; + &quot; }\\n&quot; + &quot;}&quot;;} 在hotel-demo中的HotelIndexTest测试类中，编写单元测试，实现创建索引： 123456789@Testvoid createHotelIndex() throws IOException { // 1.创建Request对象 CreateIndexRequest request = new CreateIndexRequest(&quot;hotel&quot;); // 2.准备请求的参数：DSL语句 request.source(MAPPING_TEMPLATE, XContentType.JSON); // 3.发送请求 client.indices().create(request, RequestOptions.DEFAULT);} 删除索引库删除索引库的DSL语句非常简单： 1DELETE /hotel 与创建索引库相比： 请求方式从PUT变为DELTE 请求路径不变 无请求参数 所以代码的差异，注意体现在Request对象上。依然是三步走： 1）创建Request对象。这次是DeleteIndexRequest对象 2）准备参数。这里是无参 3）发送请求。改用delete方法 在hotel-demo中的HotelIndexTest测试类中，编写单元测试，实现删除索引： 1234567@Testvoid testDeleteHotelIndex() throws IOException { // 1.创建Request对象 DeleteIndexRequest request = new DeleteIndexRequest(&quot;hotel&quot;); // 2.发送请求 client.indices().delete(request, RequestOptions.DEFAULT);} 判断索引库是否存在判断索引库是否存在，本质就是查询，对应的DSL是： 1GET /hotel 因此与删除的Java代码流程是类似的。依然是三步走： 1）创建Request对象。这次是GetIndexRequest对象 2）准备参数。这里是无参 3）发送请求。改用exists方法 123456789@Testvoid testExistsHotelIndex() throws IOException { // 1.创建Request对象 GetIndexRequest request = new GetIndexRequest(&quot;hotel&quot;); // 2.发送请求 boolean exists = client.indices().exists(request, RequestOptions.DEFAULT); // 3.输出 System.err.println(exists ? &quot;索引库已经存在！&quot; : &quot;索引库不存在！&quot;);} 总结JavaRestClient操作elasticsearch的流程基本类似。核心是client.indices()方法来获取索引库的操作对象。 索引库操作的基本步骤： 初始化RestHighLevelClient 创建XxxIndexRequest。XXX是Create、Get、Delete 准备DSL（ Create时需要，其它是无参） 发送请求。调用RestHighLevelClient#indices().xxx()方法，xxx是create、exists、delete 文档操作新增文档语法： 12345678910POST /索引名/_doc/文档id{ &quot;字段1&quot;: &quot;值1&quot;, &quot;字段2&quot;: &quot;值2&quot;, &quot;字段3&quot;: { &quot;子属性1&quot;: &quot;值3&quot;, &quot;子属性2&quot;: &quot;值4&quot; }, // ...} 示例： 123456789POST /heima/_doc/1{ &quot;info&quot;: &quot;黑马程序员Java讲师&quot;, &quot;email&quot;: &quot;zy@itcast.cn&quot;, &quot;name&quot;: { &quot;firstName&quot;: &quot;云&quot;, &quot;lastName&quot;: &quot;赵&quot; }} 响应： 查询文档根据rest风格，新增是post，查询应该是get，不过查询一般都需要条件，这里我们把文档id带上，这里是按照id查询，一些复杂查询后面说。 语法： 1GET /{索引名称}/_doc/{id} 通过kibana查看数据： 1GET /heima/_doc/1 查看结果： 删除文档删除使用DELETE请求，同样，需要根据id进行删除： 语法： 1DELETE /{索引名}/_doc/id值 示例： 12# 根据id删除数据DELETE /heima/_doc/1 结果： 修改文档修改有两种方式： 全量修改：直接覆盖原来的文档 增量修改：修改文档中的部分字段 全量修改全量修改是覆盖原来的文档，其本质是： 根据指定的id删除文档 新增一个相同id的文档 注意：如果根据id删除时，id不存在，第二步的新增也会执行，也就从修改变成了新增操作了。 语法： 1234567PUT /{索引名}/_doc/文档id{ &quot;字段1&quot;: &quot;值1&quot;, &quot;字段2&quot;: &quot;值2&quot;, // ... 略} 示例： 123456789PUT /heima/_doc/1{ &quot;info&quot;: &quot;黑马程序员高级Java讲师&quot;, &quot;email&quot;: &quot;zy@itcast.cn&quot;, &quot;name&quot;: { &quot;firstName&quot;: &quot;云&quot;, &quot;lastName&quot;: &quot;赵&quot; }} 增量修改增量修改是只修改指定id匹配的文档中的部分字段。 语法： 123456POST /{索引名}/_update/文档id{ &quot;doc&quot;: { &quot;字段名&quot;: &quot;新的值&quot;, }} 示例： 123456POST /heima/_update/1{ &quot;doc&quot;: { &quot;email&quot;: &quot;ZhaoYun@itcast.cn&quot; }} 总结文档操作有哪些？ 创建文档：POST /{索引名}/_doc/文档id { json文档 } 查询文档：GET /{索引名}/_doc/文档id 删除文档：DELETE /{索引名}/_doc/文档id 修改文档： 全量修改：PUT /{索引名}/_doc/文档id { json文档 } 增量修改：POST /{索引名}/_update/文档id { “doc”: {字段}} RestClient操作文档为了与索引库操作分离，我们再次参加一个测试类，做两件事情： 初始化RestHighLevelClient 我们的酒店数据在数据库，需要利用IHotelService去查询，所以注入这个接口 123456789101112131415161718192021222324252627282930313233package cn.itcast.hotel;import cn.itcast.hotel.pojo.Hotel;import cn.itcast.hotel.service.IHotelService;import org.junit.jupiter.api.AfterEach;import org.junit.jupiter.api.BeforeEach;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import java.io.IOException;import java.util.List;@SpringBootTestpublic class HotelDocumentTest { @Autowired private IHotelService hotelService; private RestHighLevelClient client; @BeforeEach void setUp() { this.client = new RestHighLevelClient(RestClient.builder( HttpHost.create(&quot;http://192.168.150.101:9200&quot;) )); } @AfterEach void tearDown() throws IOException { this.client.close(); }} 新增文档我们要将数据库的酒店数据查询出来，写入elasticsearch中。 索引库实体类数据库查询后的结果是一个Hotel类型的对象。结构如下： 1234567891011121314151617@Data@TableName(&quot;tb_hotel&quot;)public class Hotel { @TableId(type = IdType.INPUT) private Long id; private String name; private String address; private Integer price; private Integer score; private String brand; private String city; private String starName; private String business; private String longitude; private String latitude; private String pic;} 与我们的索引库结构存在差异： longitude和latitude需要合并为location 因此，我们需要定义一个新的类型，与索引库结构吻合： 1234567891011121314151617181920212223242526272829303132333435package cn.itcast.hotel.pojo;import lombok.Data;import lombok.NoArgsConstructor;@Data@NoArgsConstructorpublic class HotelDoc { private Long id; private String name; private String address; private Integer price; private Integer score; private String brand; private String city; private String starName; private String business; private String location; private String pic; public HotelDoc(Hotel hotel) { this.id = hotel.getId(); this.name = hotel.getName(); this.address = hotel.getAddress(); this.price = hotel.getPrice(); this.score = hotel.getScore(); this.brand = hotel.getBrand(); this.city = hotel.getCity(); this.starName = hotel.getStarName(); this.business = hotel.getBusiness(); this.location = hotel.getLatitude() + &quot;, &quot; + hotel.getLongitude(); this.pic = hotel.getPic(); }} 语法说明新增文档的DSL语句如下： 12345POST /{索引库名}/_doc/1{ &quot;name&quot;: &quot;Jack&quot;, &quot;age&quot;: 21} 对应的java代码如图： 可以看到与创建索引库类似，同样是三步走： 1）创建Request对象 2）准备请求参数，也就是DSL中的JSON文档 3）发送请求 变化的地方在于，这里直接使用client.xxx()的API，不再需要client.indices()了。 完整代码我们导入酒店数据，基本流程一致，但是需要考虑几点变化： 酒店数据来自于数据库，我们需要先查询出来，得到hotel对象 hotel对象需要转为HotelDoc对象 HotelDoc需要序列化为json格式 因此，代码整体步骤如下： 1）根据id查询酒店数据Hotel 2）将Hotel封装为HotelDoc 3）将HotelDoc序列化为JSON 4）创建IndexRequest，指定索引库名和id 5）准备请求参数，也就是JSON文档 6）发送请求 在hotel-demo的HotelDocumentTest测试类中，编写单元测试： 12345678910111213141516@Testvoid testAddDocument() throws IOException { // 1.根据id查询酒店数据 Hotel hotel = hotelService.getById(61083L); // 2.转换为文档类型 HotelDoc hotelDoc = new HotelDoc(hotel); // 3.将HotelDoc转json String json = JSON.toJSONString(hotelDoc); // 1.准备Request对象 IndexRequest request = new IndexRequest(&quot;hotel&quot;).id(hotelDoc.getId().toString()); // 2.准备Json文档 request.source(json, XContentType.JSON); // 3.发送请求 client.index(request, RequestOptions.DEFAULT);} 查询文档语法说明查询的DSL语句如下： 1GET /hotel/_doc/{id} 非常简单，因此代码大概分两步： 准备Request对象 发送请求 不过查询的目的是得到结果，解析为HotelDoc，因此难点是结果的解析。完整代码如下： 可以看到，结果是一个JSON，其中文档放在一个_source属性中，因此解析就是拿到_source，反序列化为Java对象即可。 与之前类似，也是三步走： 1）准备Request对象。这次是查询，所以是GetRequest 2）发送请求，得到结果。因为是查询，这里调用client.get()方法 3）解析结果，就是对JSON做反序列化 完整代码在hotel-demo的HotelDocumentTest测试类中，编写单元测试： 123456789101112@Testvoid testGetDocumentById() throws IOException { // 1.准备Request GetRequest request = new GetRequest(&quot;hotel&quot;, &quot;61082&quot;); // 2.发送请求，得到响应 GetResponse response = client.get(request, RequestOptions.DEFAULT); // 3.解析响应结果 String json = response.getSourceAsString(); HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class); System.out.println(hotelDoc);} 删除文档删除的DSL为是这样的： 1DELETE /hotel/_doc/{id} 与查询相比，仅仅是请求方式从DELETE变成GET，可以想象Java代码应该依然是三步走： 1）准备Request对象，因为是删除，这次是DeleteRequest对象。要指定索引库名和id 2）准备参数，无参 3）发送请求。因为是删除，所以是client.delete()方法 在hotel-demo的HotelDocumentTest测试类中，编写单元测试： 1234567@Testvoid testDeleteDocument() throws IOException { // 1.准备Request DeleteRequest request = new DeleteRequest(&quot;hotel&quot;, &quot;61083&quot;); // 2.发送请求 client.delete(request, RequestOptions.DEFAULT);} 修改文档语法说明修改我们讲过两种方式： 全量修改：本质是先根据id删除，再新增 增量修改：修改文档中的指定字段值 在RestClient的API中，全量修改与新增的API完全一致，判断依据是ID： 如果新增时，ID已经存在，则修改 如果新增时，ID不存在，则新增 这里不再赘述，我们主要关注增量修改。 代码示例如图： 与之前类似，也是三步走： 1）准备Request对象。这次是修改，所以是UpdateRequest 2）准备参数。也就是JSON文档，里面包含要修改的字段 3）更新文档。这里调用client.update()方法 完整代码在hotel-demo的HotelDocumentTest测试类中，编写单元测试： 123456789101112@Testvoid testUpdateDocument() throws IOException { // 1.准备Request UpdateRequest request = new UpdateRequest(&quot;hotel&quot;, &quot;61083&quot;); // 2.准备请求参数 request.doc( &quot;price&quot;, &quot;952&quot;, &quot;starName&quot;, &quot;四钻&quot; ); // 3.发送请求 client.update(request, RequestOptions.DEFAULT);} 批量导入文档案例需求：利用BulkRequest批量将数据库数据导入到索引库中。 步骤如下： 利用mybatis-plus查询酒店数据 将查询到的酒店数据（Hotel）转换为文档类型数据（HotelDoc） 利用JavaRestClient中的BulkRequest批处理，实现批量新增文档 语法说明批量处理BulkRequest，其本质就是将多个普通的CRUD请求组合在一起发送。 其中提供了一个add方法，用来添加其他请求： 可以看到，能添加的请求包括： IndexRequest，也就是新增 UpdateRequest，也就是修改 DeleteRequest，也就是删除 因此Bulk中添加了多个IndexRequest，就是批量新增功能了。示例： 其实还是三步走： 1）创建Request对象。这里是BulkRequest 2）准备参数。批处理的参数，就是其它Request对象，这里就是多个IndexRequest 3）发起请求。这里是批处理，调用的方法为client.bulk()方法 我们在导入酒店数据时，将上述代码改造成for循环处理即可。 完整代码在hotel-demo的HotelDocumentTest测试类中，编写单元测试： 12345678910111213141516171819@Testvoid testBulkRequest() throws IOException { // 批量查询酒店数据 List&lt;Hotel&gt; hotels = hotelService.list(); // 1.创建Request BulkRequest request = new BulkRequest(); // 2.准备参数，添加多个新增的Request for (Hotel hotel : hotels) { // 2.1.转换为文档类型HotelDoc HotelDoc hotelDoc = new HotelDoc(hotel); // 2.2.创建新增文档的Request对象 request.add(new IndexRequest(&quot;hotel&quot;) .id(hotelDoc.getId().toString()) .source(JSON.toJSONString(hotelDoc), XContentType.JSON)); } // 3.发送请求 client.bulk(request, RequestOptions.DEFAULT);} 小结文档操作的基本步骤： 初始化RestHighLevelClient 创建XxxRequest。XXX是Index、Get、Update、Delete、Bulk 准备参数（Index、Update、Bulk时需要） 发送请求。调用RestHighLevelClient#.xxx()方法，xxx是index、get、update、delete、bulk 解析结果（Get时需要） DSL查询文档elasticsearch的查询依然是基于JSON风格的DSL来实现的。 DSL查询分类Elasticsearch提供了基于JSON的DSL（Domain Specific Language）来定义查询。常见的查询类型包括： 查询所有：查询出所有数据，一般测试用。例如：match_all 全文检索（full text）查询：利用分词器对用户输入内容分词，然后去倒排索引库中匹配。例如： match_query multi_match_query 精确查询：根据精确词条值查找数据，一般是查找keyword、数值、日期、boolean等类型字段。例如： ids range term 地理（geo）查询：根据经纬度查询。例如： geo_distance geo_bounding_box 复合（compound）查询：复合查询可以将上述各种查询条件组合起来，合并查询条件。例如： bool function_score 查询的语法基本一致： 12345678GET /indexName/_search{ &quot;query&quot;: { &quot;查询类型&quot;: { &quot;查询条件&quot;: &quot;条件值&quot; } }} 我们以查询所有为例，其中： 查询类型为match_all 没有查询条件 12345678// 查询所有GET /indexName/_search{ &quot;query&quot;: { &quot;match_all&quot;: { } }} 其它查询无非就是查询类型、查询条件的变化。 全文检索查询使用场景全文检索查询的基本流程如下： 对用户搜索的内容做分词，得到词条 根据词条去倒排索引库中匹配，得到文档id 根据文档id找到文档，返回给用户 比较常用的场景包括： 商城的输入框搜索 百度输入框搜索 例如京东： 因为是拿着词条去匹配，因此参与搜索的字段也必须是可分词的text类型的字段。 基本语法常见的全文检索查询包括： match查询：单字段查询 multi_match查询：多字段查询，任意一个字段符合条件就算符合查询条件 match查询语法如下： 12345678GET /indexName/_search{ &quot;query&quot;: { &quot;match&quot;: { &quot;FIELD&quot;: &quot;TEXT&quot; } }} or关系：match类型查询，会把查询条件进行分词，然后进行查询，多个词条之间默认是or的关系，或的意思，表示满足一个条件就行。 某些情况下，我们需要更精确查找，我们希望这个关系变成and，所有条件都要满足，可以这样做： 1234567891011GET /hotel/_search{ &quot;query&quot;:{ &quot;match&quot;: { &quot;title&quot;: { &quot;query&quot;: &quot;外滩如家&quot;, &quot;operator&quot;: &quot;and&quot; } } }} 本例中，只有同时包含外滩和如家的词条才会被搜索到。 or和and之间？ 在 or 与 and 间二选一有点过于非黑即白。 如果用户给定的条件分词后有 5 个查询词项，想查找只包含其中 4 个词的文档，该如何处理？将 operator 操作符参数设置成 and 只会将此文档排除。 有时候这正是我们期望的，但在全文搜索的大多数应用场景下，我们既想包含那些可能相关的文档，同时又排除那些不太相关的。换句话说，我们想要处于中间某种结果。 match 查询支持 minimum_should_match 最小匹配参数， 这让我们可以指定必须匹配的词项数用来表示一个文档是否相关。我们可以将其设置为某个具体数字，更常用的做法是将其设置为一个百分数，因为我们无法控制用户搜索时输入的单词数量： 1234567891011GET /hotel/_search{ &quot;query&quot;:{ &quot;match&quot;:{ &quot;title&quot;:{ &quot;query&quot;:&quot;外滩如家酒店&quot;, &quot;minimum_should_match&quot;: &quot;75%&quot; } } }} 本例中，搜索语句可以分为3个词，如果使用and关系，需要同时满足3个词才会被搜索到。这里我们采用最小匹配参数：75%，那么也就是说只要匹配到总词条数量的75%即可，这里3*75% 约等于2。所以只要包含2个词条就算满足条件了。 mulit_match语法如下： 123456789GET /indexName/_search{ &quot;query&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot;TEXT&quot;, &quot;fields&quot;: [&quot;FIELD1&quot;, &quot; FIELD12&quot;] } }} 示例match查询示例： multi_match查询示例： 可以看到，两种查询结果是一样的，为什么？ 因为我们将brand、name、business值都利用copy_to复制到了all字段中。因此你根据三个字段搜索，和根据all字段搜索效果当然一样了。 但是，搜索字段越多，对查询性能影响越大，因此建议采用copy_to，然后单字段查询的方式。 总结match和multi_match的区别是什么？ match：根据一个字段查询 multi_match：根据多个字段查询，参与查询字段越多，查询性能越差 精准查询精确查询一般是查找keyword、数值、日期、boolean等类型字段。所以不会对搜索条件分词。常见的有： term：根据词条精确值查询 range：根据值的范围查询 term查询因为精确查询的字段搜是不分词的字段，因此查询的条件也必须是不分词的词条。查询时，用户输入的内容跟自动值完全匹配时才认为符合条件。如果用户输入的内容过多，反而搜索不到数据。 语法说明： 1234567891011// term查询GET /indexName/_search{ &quot;query&quot;: { &quot;term&quot;: { &quot;FIELD&quot;: { &quot;value&quot;: &quot;VALUE&quot; } } }} 示例： 当我搜索的是精确词条时，能正确查询出结果： 但是，当我搜索的内容不是词条，而是多个词语形成的短语时，反而搜索不到： terms查询（多词条）terms 查询和 term 查询一样，但它允许你指定多值进行匹配。如果这个字段包含了指定值中的任何一个值，那么这个文档满足条件。 range查询范围查询，一般应用在对数值类型做范围过滤的时候。比如做价格范围过滤。 基本语法： 123456789101112// range查询GET /indexName/_search{ &quot;query&quot;: { &quot;range&quot;: { &quot;FIELD&quot;: { &quot;gte&quot;: 10, // 这里的gte代表大于等于，gt则代表大于 &quot;lte&quot;: 20 // lte代表小于等于，lt则代表小于 } } }} range查询允许以下字符： 操作符 说明 gt 大于 gte 大于等于 lt 小于 lte 小于等于 示例： 总结精确查询常见的有哪些？ term查询：根据词条精确匹配，一般搜索keyword类型、数值类型、布尔类型、日期类型字段 range查询：根据数值范围查询，可以是数值、日期的范围 结果过滤默认情况下，elasticsearch在搜索的结果中，会把文档中保存在_source的所有字段都返回。 如果我们只想获取其中的部分字段，我们可以添加_source的过滤，属于一种优化，对不用的字段不做查询。 直接指定字段示例： 123456789GET /hotel/_search{ &quot;_source&quot;: [&quot;title&quot;,&quot;price&quot;], &quot;query&quot;: { &quot;term&quot;: { &quot;price&quot;: 2699 } }} 指定includes和excludes我们也可以通过： includes：来指定想要显示的字段 excludes：来指定不想要显示的字段 二者都是可选的。 示例： 1234567891011GET /hotel/_search{ &quot;_source&quot;: { &quot;includes&quot;:[&quot;title&quot;,&quot;price&quot;] }, &quot;query&quot;: { &quot;term&quot;: { &quot;price&quot;: 2699 } }} 如果只有title，price，images这三个属性，那么上面与下面的结果将是一样的： 1234567891011GET /hotel/_search{ &quot;_source&quot;: { &quot;excludes&quot;: [&quot;images&quot;] }, &quot;query&quot;: { &quot;term&quot;: { &quot;price&quot;: 2699 } }} 地理坐标查询所谓的地理坐标查询，其实就是根据经纬度查询，官方文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-queries.html 常见的使用场景包括： 携程：搜索我附近的酒店 滴滴：搜索我附近的出租车 微信：搜索我附近的人 附近的酒店： 附近的车： 矩形范围查询矩形范围查询，也就是geo_bounding_box查询，查询坐标落在某个矩形范围的所有文档： 查询时，需要指定矩形的左上、右下两个点的坐标，然后画出一个矩形，落在该矩形内的都是符合条件的点。 语法如下： 123456789101112131415161718// geo_bounding_box查询GET /indexName/_search{ &quot;query&quot;: { &quot;geo_bounding_box&quot;: { &quot;FIELD&quot;: { &quot;top_left&quot;: { // 左上点 &quot;lat&quot;: 31.1, &quot;lon&quot;: 121.5 }, &quot;bottom_right&quot;: { // 右下点 &quot;lat&quot;: 30.9, &quot;lon&quot;: 121.7 } } } }} 这种并不符合“附近的人”这样的需求，所以我们就不做了。 附近查询附近查询，也叫做距离查询（geo_distance）：查询到指定中心点小于某个距离值的所有文档。 换句话来说，在地图上找一个点作为圆心，以指定距离为半径，画一个圆，落在圆内的坐标都算符合条件： 语法说明： 12345678910// geo_distance 查询GET /indexName/_search{ &quot;query&quot;: { &quot;geo_distance&quot;: { &quot;distance&quot;: &quot;15km&quot;, // 半径 &quot;FIELD&quot;: &quot;31.21,121.5&quot; // 圆心 } }} 示例： 我们先搜索陆家嘴附近15km的酒店： 发现共有47家酒店。 然后把半径缩短到3公里： 可以发现，搜索到的酒店数量减少到了5家。 过滤（filter） 条件查询中进行过滤 所有的查询都会影响到文档的评分及排名。如果我们需要在查询结果中进行过滤，并且不希望过滤条件影响评分，那么就不要把过滤条件作为查询条件来用。而是使用filter方式，也就是说将范围查询写到filter中。其实范围查询就相当于过滤啦。 1234567891011GET /csy2/_search{ &quot;query&quot;:{ &quot;bool&quot;:{ &quot;must&quot;:{ &quot;match&quot;: { &quot;title&quot;: &quot;小米手机&quot; }}, &quot;filter&quot;:{ &quot;range&quot;:{&quot;price&quot;:{&quot;gt&quot;:2000.00,&quot;lt&quot;:3800.00}} } } }} 注意：filter中还可以再次进行bool组合条件过滤。 无查询条件，直接过滤 如果一次查询只有过滤，没有查询条件，不希望进行评分，我们可以使用constant_score取代只有 filter 语句的 bool 查询。在性能上是完全相同的，但对于提高查询简洁性和清晰度有很大帮助。 12345678910GET /csy2/_search{ &quot;query&quot;:{ &quot;constant_score&quot;:{ &quot;filter&quot;:{ &quot;range&quot;:{&quot;price&quot;:{&quot;gt&quot;:2000.00,&quot;lt&quot;:3800.00}} } } }} 复合查询复合（compound）查询：复合查询可以将其它简单查询组合起来，实现更复杂的搜索逻辑。常见的有两种： fuction score：算分函数查询，可以控制文档相关性算分，控制文档排名 bool query：布尔查询，利用逻辑关系组合多个其它的查询，实现复杂搜索 相关性算分当我们利用match查询时，文档结果会根据与搜索词条的关联度打分（_score），返回结果时按照分值降序排列。 例如，我们搜索 “虹桥如家”，结果如下： 1234567891011121314151617181920[ { &quot;_score&quot; : 17.850193, &quot;_source&quot; : { &quot;name&quot; : &quot;虹桥如家酒店真不错&quot;, } }, { &quot;_score&quot; : 12.259849, &quot;_source&quot; : { &quot;name&quot; : &quot;外滩如家酒店真不错&quot;, } }, { &quot;_score&quot; : 11.91091, &quot;_source&quot; : { &quot;name&quot; : &quot;迪士尼如家酒店真不错&quot;, } }] 在elasticsearch中，早期使用的打分算法是TF-IDF算法，公式如下： 在后来的5.1版本升级中，elasticsearch将算法改进为BM25算法，公式如下： TF-IDF算法有一各缺陷，就是词条频率越高，文档得分也会越高，单个词条对文档影响较大。而BM25则会让单个词条的算分有一个上限，曲线更加平滑： 小结：elasticsearch会根据词条和文档的相关度做打分，算法由两种： TF-IDF算法 BM25算法，elasticsearch5.1版本后采用的算法 算分函数查询根据相关度打分是比较合理的需求，但合理的不一定是产品经理需要的。 以百度为例，你搜索的结果中，并不是相关度越高排名越靠前，而是谁掏的钱多排名就越靠前。如图： 要想认为控制相关性算分，就需要利用elasticsearch中的function score 查询了。 1）语法说明 function score 查询中包含四部分内容： 原始查询条件：query部分，基于这个条件搜索文档，并且基于BM25算法给文档打分，原始算分（query score) 过滤条件：filter部分，符合该条件的文档才会重新算分 算分函数：符合filter条件的文档要根据这个函数做运算，得到的函数算分（function score），有四种函数 weight：函数结果是常量 field_value_factor：以文档中的某个字段值作为函数结果 random_score：以随机数作为函数结果 script_score：自定义算分函数算法 运算模式：算分函数的结果、原始查询的相关性算分，两者之间的运算方式，包括： multiply：相乘 replace：用function score替换query score 其它，例如：sum、avg、max、min function score的运行流程如下： 1）根据原始条件查询搜索文档，并且计算相关性算分，称为原始算分（query score） 2）根据过滤条件，过滤文档 3）符合过滤条件的文档，基于算分函数运算，得到函数算分（function score） 4）将原始算分（query score）和函数算分（function score）基于运算模式做运算，得到最终结果，作为相关性算分。 因此，其中的关键点是： 过滤条件：决定哪些文档的算分被修改 算分函数：决定函数算分的算法 运算模式：决定最终算分结果 2）示例需求：给“如家”这个品牌的酒店排名靠前一些 翻译一下这个需求，转换为之前说的四个要点： 原始条件：不确定，可以任意变化 过滤条件：brand = “如家” 算分函数：可以简单粗暴，直接给固定的算分结果，weight 运算模式：比如求和 因此最终的DSL语句如下： 12345678910111213141516171819GET /hotel/_search{ &quot;query&quot;: { &quot;function_score&quot;: { &quot;query&quot;: { .... }, // 原始查询，可以是任意条件 &quot;functions&quot;: [ // 算分函数 { &quot;filter&quot;: { // 满足的条件，品牌必须是如家 &quot;term&quot;: { &quot;brand&quot;: &quot;如家&quot; } }, &quot;weight&quot;: 2 // 算分权重为2 } ], &quot;boost_mode&quot;: &quot;sum&quot; // 加权模式，求和 } }} 测试，在未添加算分函数时，如家得分如下： 添加了算分函数后，如家得分就提升了： 3）小结function score query定义的三要素是什么？ 过滤条件：哪些文档要加分 算分函数：如何计算function score 加权方式：function score 与 query score如何运算 布尔查询布尔查询是一个或多个查询子句的组合，每一个子句就是一个子查询。子查询的组合方式有： must：必须匹配每个子查询，类似“与” should：选择性匹配子查询，类似“或” must_not：必须不匹配，不参与算分，类似“非” filter：必须匹配，不参与算分 bool把各种其它查询通过must（与）、must_not（非）、should（或）的方式进行组合。 比如在搜索酒店时，除了关键字搜索外，我们还可能根据品牌、价格、城市等字段做过滤： 每一个不同的字段，其查询的条件、方式都不一样，必须是多个不同的查询，而要组合这些查询，就必须用bool查询了。 需要注意的是，搜索时，参与打分的字段越多，查询的性能也越差。因此这种多条件查询时，建议这样做： 搜索框的关键字搜索，是全文检索查询，使用must查询，参与算分 其它过滤条件，采用filter查询。不参与算分 1）语法示例1234567891011121314151617181920GET /hotel/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ {&quot;term&quot;: {&quot;city&quot;: &quot;上海&quot; }} ], &quot;should&quot;: [ {&quot;term&quot;: {&quot;brand&quot;: &quot;皇冠假日&quot; }}, {&quot;term&quot;: {&quot;brand&quot;: &quot;华美达&quot; }} ], &quot;must_not&quot;: [ { &quot;range&quot;: { &quot;price&quot;: { &quot;lte&quot;: 500 } }} ], &quot;filter&quot;: [ { &quot;range&quot;: {&quot;score&quot;: { &quot;gte&quot;: 45 } }} ] } }} 2）示例需求：搜索名字包含“如家”，价格不高于400，在坐标31.21,121.5周围10km范围内的酒店。 分析： 名称搜索，属于全文检索查询，应该参与算分。放到must中 价格不高于400，用range查询，属于过滤条件，不参与算分。放到must_not中 周围10km范围内，用geo_distance查询，属于过滤条件，不参与算分。放到filter中 3）小结bool查询有几种逻辑关系？ must：必须匹配的条件，可以理解为“与” should：选择性匹配的条件，可以理解为“或” must_not：必须不匹配的条件，不参与打分 filter：必须匹配的条件，不参与打分 搜索结果处理搜索的结果可以按照用户指定的方式去处理或展示。 排序elasticsearch默认是根据相关度算分（_score）来排序，但是也支持自定义方式对搜索结果排序。可以排序字段类型有：keyword类型、数值类型、地理坐标类型、日期类型等。 普通字段排序keyword、数值、日期类型排序的语法基本一致。 语法： 1234567891011GET /indexName/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;sort&quot;: [ { &quot;FIELD&quot;: &quot;desc&quot; // 排序字段、排序方式ASC、DESC } ]} 排序条件是一个数组，也就是可以写多个排序条件。按照声明的顺序，当第一个条件相等时，再按照第二个条件排序，以此类推 示例： 需求描述：酒店数据按照用户评价（score)降序排序，评价相同的按照价格(price)升序排序 地理坐标排序地理坐标排序略有不同。 语法说明： 123456789101112131415GET /indexName/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;sort&quot;: [ { &quot;_geo_distance&quot; : { &quot;FIELD&quot; : &quot;纬度，经度&quot;, // 文档中geo_point类型的字段名、目标坐标点 &quot;order&quot; : &quot;asc&quot;, // 排序方式 &quot;unit&quot; : &quot;km&quot; // 排序的距离单位 } } ]} 这个查询的含义是： 指定一个坐标，作为目标点 计算每一个文档中，指定字段（必须是geo_point类型）的坐标 到目标点的距离是多少 根据距离排序 示例： 需求描述：实现对酒店数据按照到你的位置坐标的距离升序排序 提示：获取你的位置的经纬度的方式：https://lbs.amap.com/demo/jsapi-v2/example/map/click-to-get-lnglat/ 假设我的位置是：31.034661，121.612282，寻找我周围距离最近的酒店。 分页elasticsearch 默认情况下只返回top10的数据。而如果要查询更多数据就需要修改分页参数了。elasticsearch中通过修改from、size参数来控制要返回的分页结果： from：从第几个文档开始 size：总共查询几个文档 类似于mysql中的limit ?, ? 基本的分页分页的基本语法如下： 1234567891011GET /hotel/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;from&quot;: 0, // 分页开始的位置，默认为0 &quot;size&quot;: 10, // 期望获取的文档总数 &quot;sort&quot;: [ {&quot;price&quot;: &quot;asc&quot;} ]} 深度分页问题现在，我要查询990~1000的数据，查询逻辑要这么写： 1234567891011GET /hotel/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;from&quot;: 990, // 分页开始的位置，默认为0 &quot;size&quot;: 10, // 期望获取的文档总数 &quot;sort&quot;: [ {&quot;price&quot;: &quot;asc&quot;} ]} 这里是查询990开始的数据，也就是 第990~第1000条 数据。 不过，elasticsearch内部分页时，必须先查询 0~1000条，然后截取其中的990 ~ 1000的这10条： 查询TOP1000，如果es是单点模式，这并无太大影响。 但是elasticsearch将来一定是集群，例如我集群有5个节点，我要查询TOP1000的数据，并不是每个节点查询200条就可以了。 因为节点A的TOP200，在另一个节点可能排到10000名以外了。 因此要想获取整个集群的TOP1000，必须先查询出每个节点的TOP1000，汇总结果后，重新排名，重新截取TOP1000。 那如果我要查询9900~10000的数据呢？是不是要先查询TOP10000呢？那每个节点都要查询10000条？汇总到内存中？ 当查询分页深度较大时，汇总数据过多，对内存和CPU会产生非常大的压力，因此elasticsearch会禁止from+ size 超过10000的请求。 针对深度分页，ES提供了两种解决方案，官方文档： search after：分页时需要排序，原理是从上一次的排序值开始，查询下一页数据。官方推荐使用的方式。 scroll：原理将排序后的文档id形成快照，保存在内存。官方已经不推荐使用。 小结分页查询的常见实现方案以及优缺点： from + size： 优点：支持随机翻页 缺点：深度分页问题，默认查询上限（from + size）是10000 场景：百度、京东、谷歌、淘宝这样的随机翻页搜索 after search： 优点：没有查询上限（单次查询的size不超过10000） 缺点：只能向后逐页查询，不支持随机翻页 场景：没有随机翻页需求的搜索，例如手机向下滚动翻页 scroll： 优点：没有查询上限（单次查询的size不超过10000） 缺点：会有额外内存消耗，并且搜索结果是非实时的 场景：海量数据的获取和迁移。从ES7.1开始不推荐，建议用 after search方案。 高亮高亮原理什么是高亮显示呢？ 我们在百度，京东搜索时，关键字会变成红色，比较醒目，这叫高亮显示： 高亮显示的实现分为两步： 1）给文档中的所有关键字都添加一个标签，例如&lt;em&gt;标签 2）页面给&lt;em&gt;标签编写CSS样式 实现高亮高亮的语法： 12345678910111213141516GET /hotel/_search{ &quot;query&quot;: { &quot;match&quot;: { &quot;FIELD&quot;: &quot;TEXT&quot; // 查询条件，高亮一定要使用全文检索查询 } }, &quot;highlight&quot;: { &quot;fields&quot;: { // 指定要高亮的字段 &quot;FIELD&quot;: { &quot;pre_tags&quot;: &quot;&lt;em&gt;&quot;, // 用来标记高亮字段的前置标签 &quot;post_tags&quot;: &quot;&lt;/em&gt;&quot; // 用来标记高亮字段的后置标签 } } }} 注意： 高亮是对关键字高亮，因此搜索条件必须带有关键字，而不能是范围这样的查询。 默认情况下，高亮的字段，必须与搜索指定的字段一致，否则无法高亮 如果要对非搜索字段高亮，则需要添加一个属性：required_field_match=false 示例： 总结查询的DSL是一个大的JSON对象，包含下列属性： query：查询条件 from和size：分页条件 sort：排序条件 highlight：高亮条件 示例： RestClient之DSL查询文档文档的查询同样适用于 RestHighLevelClient 对象，基本步骤包括： 1）准备Request对象 2）准备请求参数 3）发起请求 4）解析响应 快速入门我们以match_all查询为例 发起查询请求 代码解读： 第一步，创建SearchRequest对象，指定索引库名 第二步，利用request.source()构建DSL，DSL中可以包含查询、分页、排序、高亮等 query()：代表查询条件，利用QueryBuilders.matchAllQuery()构建一个match_all查询的DSL 第三步，利用client.search()发送请求，得到响应 这里关键的API有两个，一个是request.source()，其中包含了查询、排序、分页、高亮等所有功能： 另一个是QueryBuilders，其中包含match、term、function_score、bool等各种查询： 解析响应响应结果的解析： elasticsearch返回的结果是一个JSON字符串，结构包含： hits：命中的结果 total：总条数，其中的value是具体的总条数值 max_score：所有结果中得分最高的文档的相关性算分 hits：搜索结果的文档数组，其中的每个文档都是一个json对象 _source：文档中的原始数据，也是json对象 因此，我们解析响应结果，就是逐层解析JSON字符串，流程如下： SearchHits：通过response.getHits()获取，就是JSON中的最外层的hits，代表命中的结果 SearchHits#getTotalHits().value：获取总条数信息 SearchHits#getHits()：获取SearchHit数组，也就是文档数组 SearchHit#getSourceAsString()：获取文档结果中的_source，也就是原始的json文档数据 完整代码完整代码如下： 12345678910111213141516171819202122232425262728293031@Testvoid testMatchAll() throws IOException { // 1.准备Request SearchRequest request = new SearchRequest(&quot;hotel&quot;); // 2.准备DSL request.source() .query(QueryBuilders.matchAllQuery()); // 3.发送请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析响应 handleResponse(response);}private void handleResponse(SearchResponse response) { // 4.解析响应 SearchHits searchHits = response.getHits(); // 4.1.获取总条数 long total = searchHits.getTotalHits().value; System.out.println(&quot;共搜索到&quot; + total + &quot;条数据&quot;); // 4.2.文档数组 SearchHit[] hits = searchHits.getHits(); // 4.3.遍历 for (SearchHit hit : hits) { // 获取文档source String json = hit.getSourceAsString(); // 反序列化 HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class); System.out.println(&quot;hotelDoc = &quot; + hotelDoc); }} 小结查询的基本步骤是： 创建SearchRequest对象 准备Request.source()，也就是DSL。 ① QueryBuilders来构建查询条件 ② 传入Request.source() 的 query() 方法 发送请求，得到结果 解析结果（参考JSON结果，从外到内，逐层解析） match查询全文检索的match和multi_match查询与match_all的API基本一致。差别是查询条件，也就是query的部分。 因此，Java代码上的差异主要是request.source().query()中的参数了。同样是利用QueryBuilders提供的方法： 而结果解析代码则完全一致，可以抽取并共享。 完整代码如下： 12345678910111213@Testvoid testMatch() throws IOException { // 1.准备Request SearchRequest request = new SearchRequest(&quot;hotel&quot;); // 2.准备DSL request.source() .query(QueryBuilders.matchQuery(&quot;all&quot;, &quot;如家&quot;)); // 3.发送请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析响应 handleResponse(response);} 精确查询精确查询主要是两者： term：词条精确匹配 range：范围查询 与之前的查询相比，差异同样在查询条件，其它都一样。 查询条件构造的API如下： 布尔查询布尔查询是用must、must_not、filter等方式组合其它查询，代码示例如下： 可以看到，API与其它查询的差别同样是在查询条件的构建，QueryBuilders，结果解析等其他代码完全不变。 完整代码如下： 12345678910111213141516171819@Testvoid testBool() throws IOException { // 1.准备Request SearchRequest request = new SearchRequest(&quot;hotel&quot;); // 2.准备DSL // 2.1.准备BooleanQuery BoolQueryBuilder boolQuery = QueryBuilders.boolQuery(); // 2.2.添加term boolQuery.must(QueryBuilders.termQuery(&quot;city&quot;, &quot;杭州&quot;)); // 2.3.添加range boolQuery.filter(QueryBuilders.rangeQuery(&quot;price&quot;).lte(250)); request.source().query(boolQuery); // 3.发送请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析响应 handleResponse(response);} 排序、分页搜索结果的排序和分页是与query同级的参数，因此同样是使用request.source()来设置。 对应的API如下： 完整代码示例： 1234567891011121314151617181920@Testvoid testPageAndSort() throws IOException { // 页码，每页大小 int page = 1, size = 5; // 1.准备Request SearchRequest request = new SearchRequest(&quot;hotel&quot;); // 2.准备DSL // 2.1.query request.source().query(QueryBuilders.matchAllQuery()); // 2.2.排序 sort request.source().sort(&quot;price&quot;, SortOrder.ASC); // 2.3.分页 from、size request.source().from((page - 1) * size).size(5); // 3.发送请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析响应 handleResponse(response);} 高亮高亮的代码与之前代码差异较大，有两点： 查询的DSL：其中除了查询条件，还需要添加高亮条件，同样是与query同级。 结果解析：结果除了要解析_source文档数据，还要解析高亮结果 高亮请求构建高亮请求的构建API如下： 上述代码省略了查询条件部分，但是大家不要忘了：高亮查询必须使用全文检索查询，并且要有搜索关键字，将来才可以对关键字高亮。 完整代码如下： 123456789101112131415@Testvoid testHighlight() throws IOException { // 1.准备Request SearchRequest request = new SearchRequest(&quot;hotel&quot;); // 2.准备DSL // 2.1.query request.source().query(QueryBuilders.matchQuery(&quot;all&quot;, &quot;如家&quot;)); // 2.2.高亮 request.source().highlighter(new HighlightBuilder().field(&quot;name&quot;).requireFieldMatch(false)); // 3.发送请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析响应 handleResponse(response);} 高亮结果解析高亮的结果与查询的文档结果默认是分离的，并不在一起。 因此解析高亮的代码需要额外处理： 代码解读： 第一步：从结果中获取source。hit.getSourceAsString()，这部分是非高亮结果，json字符串。还需要反序列为HotelDoc对象 第二步：获取高亮结果。hit.getHighlightFields()，返回值是一个Map，key是高亮字段名称，值是HighlightField对象，代表高亮值 第三步：从map中根据高亮字段名称，获取高亮字段值对象HighlightField 第四步：从HighlightField中获取Fragments，并且转为字符串。这部分就是真正的高亮字符串了 第五步：用高亮的结果替换HotelDoc中的非高亮结果 完整代码如下： 1234567891011121314151617181920212223242526272829private void handleResponse(SearchResponse response) { // 4.解析响应 SearchHits searchHits = response.getHits(); // 4.1.获取总条数 long total = searchHits.getTotalHits().value; System.out.println(&quot;共搜索到&quot; + total + &quot;条数据&quot;); // 4.2.文档数组 SearchHit[] hits = searchHits.getHits(); // 4.3.遍历 for (SearchHit hit : hits) { // 获取文档source String json = hit.getSourceAsString(); // 反序列化 HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class); // 获取高亮结果 Map&lt;String, HighlightField&gt; highlightFields = hit.getHighlightFields(); if (!CollectionUtils.isEmpty(highlightFields)) { // 根据字段名获取高亮结果 HighlightField highlightField = highlightFields.get(&quot;name&quot;); if (highlightField != null) { // 获取高亮值 String name = highlightField.getFragments()[0].string(); // 覆盖非高亮结果 hotelDoc.setName(name); } } System.out.println(&quot;hotelDoc = &quot; + hotelDoc); }} 黑马旅游案例下面，我们通过黑马旅游的案例来实战演练下之前学习的知识。 我们实现四部分功能： 酒店搜索和分页 酒店结果过滤 我周边的酒店 酒店竞价排名 启动我们提供的hotel-demo项目，其默认端口是8089，访问http://localhost:8090，就能看到项目页面了： 酒店搜索和分页案例需求：实现黑马旅游的酒店搜索功能，完成关键字搜索和分页 需求分析在项目的首页，有一个大大的搜索框，还有分页按钮： 点击搜索按钮，可以看到浏览器控制台发出了请求： 请求参数如下： 由此可以知道，我们这个请求的信息如下： 请求方式：POST 请求路径：/hotel/list 请求参数：JSON对象，包含4个字段： key：搜索关键字 page：页码 size：每页大小 sortBy：排序，目前暂不实现 返回值：分页查询，需要返回分页结果PageResult，包含两个属性： total：总条数 List&lt;HotelDoc&gt;：当前页的数据 因此，我们实现业务的流程如下： 步骤一：定义实体类，接收请求参数的JSON对象 步骤二：编写controller，接收页面的请求 步骤三：编写业务实现，利用RestHighLevelClient实现搜索、分页 定义实体类实体类有两个，一个是前端的请求参数实体，一个是服务端应该返回的响应结果实体。 1）请求参数 前端请求的json结构如下： 123456{ &quot;key&quot;: &quot;搜索关键字&quot;, &quot;page&quot;: 1, &quot;size&quot;: 3, &quot;sortBy&quot;: &quot;default&quot;} 因此，我们在cn.itcast.hotel.pojo包下定义一个实体类： 1234567891011package cn.itcast.hotel.pojo;import lombok.Data;@Datapublic class RequestParams { private String key; private Integer page; private Integer size; private String sortBy;} 2）返回值 分页查询，需要返回分页结果PageResult，包含两个属性： total：总条数 List&lt;HotelDoc&gt;：当前页的数据 因此，我们在cn.itcast.hotel.pojo中定义返回结果： 12345678910111213141516171819package cn.itcast.hotel.pojo;import lombok.Data;import java.util.List;@Datapublic class PageResult { private Long total; private List&lt;HotelDoc&gt; hotels; public PageResult() { } public PageResult(Long total, List&lt;HotelDoc&gt; hotels) { this.total = total; this.hotels = hotels; }} 定义controller定义一个HotelController，声明查询接口，满足下列要求： 请求方式：Post 请求路径：/hotel/list 请求参数：对象，类型为RequestParam 返回值：PageResult，包含两个属性 Long total：总条数 List&lt;HotelDoc&gt; hotels：酒店数据 因此，我们在cn.itcast.hotel.web中定义HotelController： 123456789101112@RestController@RequestMapping(&quot;/hotel&quot;)public class HotelController { @Autowired private IHotelService hotelService; // 搜索酒店数据 @PostMapping(&quot;/list&quot;) public PageResult search(@RequestBody RequestParams params){ return hotelService.search(params); }} 实现搜索业务我们在controller调用了IHotelService，并没有实现该方法，因此下面我们就在IHotelService中定义方法，并且去实现业务逻辑。 1）在cn.itcast.hotel.service中的IHotelService接口中定义一个方法： 123456/** * 根据关键字搜索酒店信息 * @param params 请求参数对象，包含用户输入的关键字 * @return 酒店文档列表 */PageResult search(RequestParams params); 2）实现搜索业务，肯定离不开RestHighLevelClient，我们需要把它注册到Spring中作为一个Bean。在cn.itcast.hotel中的HotelDemoApplication中声明这个Bean： 123456@Beanpublic RestHighLevelClient client(){ return new RestHighLevelClient(RestClient.builder( HttpHost.create(&quot;http://192.168.150.101:9200&quot;) ));} 3）在cn.itcast.hotel.service.impl中的HotelService中实现search方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Overridepublic PageResult search(RequestParams params) { try { // 1.准备Request SearchRequest request = new SearchRequest(&quot;hotel&quot;); // 2.准备DSL // 2.1.query String key = params.getKey(); if (key == null || &quot;&quot;.equals(key)) { boolQuery.must(QueryBuilders.matchAllQuery()); } else { boolQuery.must(QueryBuilders.matchQuery(&quot;all&quot;, key)); } // 2.2.分页 int page = params.getPage(); int size = params.getSize(); request.source().from((page - 1) * size).size(size); // 3.发送请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析响应 return handleResponse(response); } catch (IOException e) { throw new RuntimeException(e); }}// 结果解析private PageResult handleResponse(SearchResponse response) { // 4.解析响应 SearchHits searchHits = response.getHits(); // 4.1.获取总条数 long total = searchHits.getTotalHits().value; // 4.2.文档数组 SearchHit[] hits = searchHits.getHits(); // 4.3.遍历 List&lt;HotelDoc&gt; hotels = new ArrayList&lt;&gt;(); for (SearchHit hit : hits) { // 获取文档source String json = hit.getSourceAsString(); // 反序列化 HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class); // 放入集合 hotels.add(hotelDoc); } // 4.4.封装返回 return new PageResult(total, hotels);} 酒店结果过滤需求：添加品牌、城市、星级、价格等过滤功能 需求分析在页面搜索框下面，会有一些过滤项： 传递的参数如图： 包含的过滤条件有： brand：品牌值 city：城市 minPrice~maxPrice：价格范围 starName：星级 我们需要做两件事情： 修改请求参数的对象RequestParams，接收上述参数 修改业务逻辑，在搜索条件之外，添加一些过滤条件 修改实体类修改在cn.itcast.hotel.pojo包下的实体类RequestParams： 12345678910111213@Datapublic class RequestParams { private String key; private Integer page; private Integer size; private String sortBy; // 下面是新增的过滤条件参数 private String city; private String brand; private String starName; private Integer minPrice; private Integer maxPrice;} 修改搜索业务在HotelService的search方法中，只有一个地方需要修改：requet.source().query( … )其中的查询条件。 在之前的业务中，只有match查询，根据关键字搜索，现在要添加条件过滤，包括： 品牌过滤：是keyword类型，用term查询 星级过滤：是keyword类型，用term查询 价格过滤：是数值类型，用range查询 城市过滤：是keyword类型，用term查询 多个查询条件组合，肯定是boolean查询来组合： 关键字搜索放到must中，参与算分 其它过滤条件放到filter中，不参与算分 因为条件构建的逻辑比较复杂，这里先封装为一个函数： buildBasicQuery的代码如下： 123456789101112131415161718192021222324252627282930313233private void buildBasicQuery(RequestParams params, SearchRequest request) { // 1.构建BooleanQuery BoolQueryBuilder boolQuery = QueryBuilders.boolQuery(); // 2.关键字搜索 String key = params.getKey(); if (key == null || &quot;&quot;.equals(key)) { boolQuery.must(QueryBuilders.matchAllQuery()); } else { boolQuery.must(QueryBuilders.matchQuery(&quot;all&quot;, key)); } // 3.城市条件 if (params.getCity() != null &amp;&amp; !params.getCity().equals(&quot;&quot;)) { boolQuery.filter(QueryBuilders.termQuery(&quot;city&quot;, params.getCity())); } // 4.品牌条件 if (params.getBrand() != null &amp;&amp; !params.getBrand().equals(&quot;&quot;)) { boolQuery.filter(QueryBuilders.termQuery(&quot;brand&quot;, params.getBrand())); } // 5.星级条件 if (params.getStarName() != null &amp;&amp; !params.getStarName().equals(&quot;&quot;)) { boolQuery.filter(QueryBuilders.termQuery(&quot;starName&quot;, params.getStarName())); } // 6.价格 if (params.getMinPrice() != null &amp;&amp; params.getMaxPrice() != null) { boolQuery.filter(QueryBuilders .rangeQuery(&quot;price&quot;) .gte(params.getMinPrice()) .lte(params.getMaxPrice()) ); } // 7.放入source request.source().query(boolQuery);} 我周边的酒店需求：我附近的酒店 需求分析在酒店列表页的右侧，有一个小地图，点击地图的定位按钮，地图会找到你所在的位置： 并且，在前端会发起查询请求，将你的坐标发送到服务端： 我们要做的事情就是基于这个location坐标，然后按照距离对周围酒店排序。实现思路如下： 修改RequestParams参数，接收location字段 修改search方法业务逻辑，如果location有值，添加根据geo_distance排序的功能 修改实体类修改在cn.itcast.hotel.pojo包下的实体类RequestParams： 12345678910111213141516171819package cn.itcast.hotel.pojo;import lombok.Data;@Datapublic class RequestParams { private String key; private Integer page; private Integer size; private String sortBy; private String city; private String brand; private String starName; private Integer minPrice; private Integer maxPrice; // 我当前的地理坐标 private String location;} 距离排序API我们以前学习过排序功能，包括两种： 普通字段排序 地理坐标排序 我们只讲了普通字段排序对应的java写法。地理坐标排序只学过DSL语法，如下： 123456789101112131415161718GET /indexName/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;sort&quot;: [ { &quot;price&quot;: &quot;asc&quot; }, { &quot;_geo_distance&quot; : { &quot;FIELD&quot; : &quot;纬度，经度&quot;, &quot;order&quot; : &quot;asc&quot;, &quot;unit&quot; : &quot;km&quot; } } ]} 对应的java代码示例： 添加距离排序在cn.itcast.hotel.service.impl的HotelService的search方法中，添加一个排序功能： 完整代码： 1234567891011121314151617181920212223242526272829303132@Overridepublic PageResult search(RequestParams params) { try { // 1.准备Request SearchRequest request = new SearchRequest(&quot;hotel&quot;); // 2.准备DSL // 2.1.query buildBasicQuery(params, request); // 2.2.分页 int page = params.getPage(); int size = params.getSize(); request.source().from((page - 1) * size).size(size); // 2.3.排序 String location = params.getLocation(); if (location != null &amp;&amp; !location.equals(&quot;&quot;)) { request.source().sort(SortBuilders .geoDistanceSort(&quot;location&quot;, new GeoPoint(location)) .order(SortOrder.ASC) .unit(DistanceUnit.KILOMETERS) ); } // 3.发送请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析响应 return handleResponse(response); } catch (IOException e) { throw new RuntimeException(e); }} 排序距离显示重启服务后，测试我的酒店功能： 发现确实可以实现对我附近酒店的排序，不过并没有看到酒店到底距离我多远，这该怎么办？ 排序完成后，页面还要获取我附近每个酒店的具体距离值，这个值在响应结果中是独立的： 因此，我们在结果解析阶段，除了解析source部分以外，还要得到sort部分，也就是排序的距离，然后放到响应结果中。 我们要做两件事： 修改HotelDoc，添加排序距离字段，用于页面显示 修改HotelService类中的handleResponse方法，添加对sort值的获取 1）修改HotelDoc类，添加距离字段 1234567891011121314151617181920212223242526272829303132333435363738package cn.itcast.hotel.pojo;import lombok.Data;import lombok.NoArgsConstructor;@Data@NoArgsConstructorpublic class HotelDoc { private Long id; private String name; private String address; private Integer price; private Integer score; private String brand; private String city; private String starName; private String business; private String location; private String pic; // 排序时的 距离值 private Object distance; public HotelDoc(Hotel hotel) { this.id = hotel.getId(); this.name = hotel.getName(); this.address = hotel.getAddress(); this.price = hotel.getPrice(); this.score = hotel.getScore(); this.brand = hotel.getBrand(); this.city = hotel.getCity(); this.starName = hotel.getStarName(); this.business = hotel.getBusiness(); this.location = hotel.getLatitude() + &quot;, &quot; + hotel.getLongitude(); this.pic = hotel.getPic(); }} 2）修改HotelService中的handleResponse方法 重启后测试，发现页面能成功显示距离了： 酒店竞价排名需求：让指定的酒店在搜索结果中排名置顶 需求分析要让指定酒店在搜索结果中排名置顶，效果如图： 页面会给指定的酒店添加广告标记。 那怎样才能让指定的酒店排名置顶呢？ 我们之前学习过的function_score查询可以影响算分，算分高了，自然排名也就高了。而function_score包含3个要素： 过滤条件：哪些文档要加分 算分函数：如何计算function score 加权方式：function score 与 query score如何运算 这里的需求是：让指定酒店排名靠前。因此我们需要给这些酒店添加一个标记，这样在过滤条件中就可以根据这个标记来判断，是否要提高算分。 比如，我们给酒店添加一个字段：isAD，Boolean类型： true：是广告 false：不是广告 这样function_score包含3个要素就很好确定了： 过滤条件：判断isAD 是否为true 算分函数：我们可以用最简单暴力的weight，固定加权值 加权方式：可以用默认的相乘，大大提高算分 因此，业务的实现步骤包括： 给HotelDoc类添加isAD字段，Boolean类型 挑选几个你喜欢的酒店，给它的文档数据添加isAD字段，值为true 修改search方法，添加function score功能，给isAD值为true的酒店增加权重 修改HotelDoc实体给cn.itcast.hotel.pojo包下的HotelDoc类添加isAD字段： 1private Boolean isAD; // 广告标记 添加广告标记接下来，我们挑几个酒店，添加isAD字段，设置为true： 123456789101112131415161718192021222324POST /hotel/_update/1902197537{ &quot;doc&quot;: { &quot;isAD&quot;: true }}POST /hotel/_update/2056126831{ &quot;doc&quot;: { &quot;isAD&quot;: true }}POST /hotel/_update/1989806195{ &quot;doc&quot;: { &quot;isAD&quot;: true }}POST /hotel/_update/2056105938{ &quot;doc&quot;: { &quot;isAD&quot;: true }} 添加算分函数查询接下来我们就要修改查询条件了。之前是用的boolean 查询，现在要改成function_socre查询。 function_score查询结构如下： 对应的JavaAPI如下： 我们可以将之前写的boolean查询作为原始查询条件放到query中，接下来就是添加过滤条件、算分函数、加权模式了。所以原来的代码依然可以沿用。 修改cn.itcast.hotel.service.impl包下的HotelService类中的buildBasicQuery方法，添加算分函数查询： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748private void buildBasicQuery(RequestParams params, SearchRequest request) { // 1.构建BooleanQuery BoolQueryBuilder boolQuery = QueryBuilders.boolQuery(); // 关键字搜索 String key = params.getKey(); if (key == null || &quot;&quot;.equals(key)) { boolQuery.must(QueryBuilders.matchAllQuery()); } else { boolQuery.must(QueryBuilders.matchQuery(&quot;all&quot;, key)); } // 城市条件 if (params.getCity() != null &amp;&amp; !params.getCity().equals(&quot;&quot;)) { boolQuery.filter(QueryBuilders.termQuery(&quot;city&quot;, params.getCity())); } // 品牌条件 if (params.getBrand() != null &amp;&amp; !params.getBrand().equals(&quot;&quot;)) { boolQuery.filter(QueryBuilders.termQuery(&quot;brand&quot;, params.getBrand())); } // 星级条件 if (params.getStarName() != null &amp;&amp; !params.getStarName().equals(&quot;&quot;)) { boolQuery.filter(QueryBuilders.termQuery(&quot;starName&quot;, params.getStarName())); } // 价格 if (params.getMinPrice() != null &amp;&amp; params.getMaxPrice() != null) { boolQuery.filter(QueryBuilders .rangeQuery(&quot;price&quot;) .gte(params.getMinPrice()) .lte(params.getMaxPrice()) ); } // 2.算分控制 FunctionScoreQueryBuilder functionScoreQuery = QueryBuilders.functionScoreQuery( // 原始查询，相关性算分的查询 boolQuery, // function score的数组 new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{ // 其中的一个function score 元素 new FunctionScoreQueryBuilder.FilterFunctionBuilder( // 过滤条件 QueryBuilders.termQuery(&quot;isAD&quot;, true), // 算分函数 ScoreFunctionBuilders.weightFactorFunction(10) ) }); request.source().query(functionScoreQuery);} 聚合aggregations**聚合（aggregations）**可以让我们极其方便的实现对数据的统计、分析、运算。例如： 什么品牌的手机最受欢迎？ 这些手机的平均价格、最高价格、最低价格？ 这些手机每月的销售情况如何？ 实现这些统计功能的比数据库的sql要方便的多，而且查询速度非常快，可以实现实时搜索效果。 基本概念Elasticsearch中的聚合，包含多种类型，最常用的两种，一个叫桶，一个叫度量： 桶（bucket） 桶的作用，是按照某种方式对数据进行分组，每一组数据在ES中称为一个桶，例如我们根据国籍对人划分，可以得到中国桶、英国桶，日本桶……或者我们按照年龄段对人进行划分：010,1020,2030,3040等。 Elasticsearch中提供的划分桶的方式有很多： Date Histogram Aggregation：根据日期阶梯分组，例如给定阶梯为周，会自动每周分为一组 Histogram Aggregation：根据数值阶梯分组，与日期类似 Terms Aggregation：根据词条内容分组，词条内容完全匹配的为一组 Range Aggregation：数值和日期的范围分组，指定开始和结束，然后按段分组 …… 综上所述，我们发现bucket aggregations 只负责对数据进行分组，并不进行计算，因此往往bucket中往往会嵌套另一种聚合：metrics aggregations即度量 度量（metrics） 分组完成以后，我们一般会对组中的数据进行聚合运算，例如求平均值、最大、最小、求和等，这些在ES中称为度量 比较常用的一些度量聚合方式： Avg Aggregation：求平均值 Max Aggregation：求最大值 Min Aggregation：求最小值 Percentiles Aggregation：求百分比 Stats Aggregation：同时返回avg、max、min、sum、count等 Sum Aggregation：求和 Top hits Aggregation：求前几 Value Count Aggregation：求总数 …… 为了测试聚合，我们先批量导入一些数据 创建索引： 1234567891011121314151617PUT /cars{ &quot;settings&quot;: { &quot;number_of_shards&quot;: 1, &quot;number_of_replicas&quot;: 0 }, &quot;mappings&quot;: { &quot;properties&quot;: { &quot;color&quot;: { &quot;type&quot;: &quot;keyword&quot; }, &quot;make&quot;: { &quot;type&quot;: &quot;keyword&quot; } } }} 注意：在ES中，需要进行聚合、排序、过滤的字段其处理方式比较特殊，因此不能被分词。这里我们将color和make这两个文字类型的字段设置为keyword类型，这个类型不会被分词，将来就可以参与聚合 批量导入数据，_bulk代表批量 1234567891011121314151617POST /cars/_bulk{ &quot;index&quot;: {}}{ &quot;price&quot; : 10000, &quot;color&quot; : &quot;red&quot;, &quot;make&quot; : &quot;honda&quot;, &quot;sold&quot; : &quot;2014-10-28&quot; }{ &quot;index&quot;: {}}{ &quot;price&quot; : 20000, &quot;color&quot; : &quot;red&quot;, &quot;make&quot; : &quot;honda&quot;, &quot;sold&quot; : &quot;2014-11-05&quot; }{ &quot;index&quot;: {}}{ &quot;price&quot; : 30000, &quot;color&quot; : &quot;green&quot;, &quot;make&quot; : &quot;ford&quot;, &quot;sold&quot; : &quot;2014-05-18&quot; }{ &quot;index&quot;: {}}{ &quot;price&quot; : 15000, &quot;color&quot; : &quot;blue&quot;, &quot;make&quot; : &quot;toyota&quot;, &quot;sold&quot; : &quot;2014-07-02&quot; }{ &quot;index&quot;: {}}{ &quot;price&quot; : 12000, &quot;color&quot; : &quot;green&quot;, &quot;make&quot; : &quot;toyota&quot;, &quot;sold&quot; : &quot;2014-08-19&quot; }{ &quot;index&quot;: {}}{ &quot;price&quot; : 20000, &quot;color&quot; : &quot;red&quot;, &quot;make&quot; : &quot;honda&quot;, &quot;sold&quot; : &quot;2014-11-05&quot; }{ &quot;index&quot;: {}}{ &quot;price&quot; : 80000, &quot;color&quot; : &quot;red&quot;, &quot;make&quot; : &quot;bmw&quot;, &quot;sold&quot; : &quot;2014-01-01&quot; }{ &quot;index&quot;: {}}{ &quot;price&quot; : 25000, &quot;color&quot; : &quot;blue&quot;, &quot;make&quot; : &quot;ford&quot;, &quot;sold&quot; : &quot;2014-02-12&quot; } 结果：（注：这里的”_id”因为未指定，是es自动随机生成的。） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142{ &quot;took&quot; : 1474, &quot;errors&quot; : false, &quot;items&quot; : [ { &quot;index&quot; : { &quot;_index&quot; : &quot;cars&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;gSIT0oABY2btytp3yIaR&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;created&quot;, &quot;_shards&quot; : { &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;failed&quot; : 0 }, &quot;_seq_no&quot; : 0, &quot;_primary_term&quot; : 1, &quot;status&quot; : 201 } }, { &quot;index&quot; : { &quot;_index&quot; : &quot;cars&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;giIT0oABY2btytp3yIaR&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;created&quot;, &quot;_shards&quot; : { &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;failed&quot; : 0 }, &quot;_seq_no&quot; : 1, &quot;_primary_term&quot; : 1, &quot;status&quot; : 201 } }, { &quot;index&quot; : { &quot;_index&quot; : &quot;cars&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;gyIT0oABY2btytp3yIaR&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;created&quot;, &quot;_shards&quot; : { &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;failed&quot; : 0 }, &quot;_seq_no&quot; : 2, &quot;_primary_term&quot; : 1, &quot;status&quot; : 201 } }, { &quot;index&quot; : { &quot;_index&quot; : &quot;cars&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;hCIT0oABY2btytp3yIaR&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;created&quot;, &quot;_shards&quot; : { &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;failed&quot; : 0 }, &quot;_seq_no&quot; : 3, &quot;_primary_term&quot; : 1, &quot;status&quot; : 201 } }, { &quot;index&quot; : { &quot;_index&quot; : &quot;cars&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;hSIT0oABY2btytp3yIaR&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;created&quot;, &quot;_shards&quot; : { &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;failed&quot; : 0 }, &quot;_seq_no&quot; : 4, &quot;_primary_term&quot; : 1, &quot;status&quot; : 201 } }, { &quot;index&quot; : { &quot;_index&quot; : &quot;cars&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;hiIT0oABY2btytp3yIaR&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;created&quot;, &quot;_shards&quot; : { &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;failed&quot; : 0 }, &quot;_seq_no&quot; : 5, &quot;_primary_term&quot; : 1, &quot;status&quot; : 201 } }, { &quot;index&quot; : { &quot;_index&quot; : &quot;cars&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;hyIT0oABY2btytp3yIaR&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;created&quot;, &quot;_shards&quot; : { &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;failed&quot; : 0 }, &quot;_seq_no&quot; : 6, &quot;_primary_term&quot; : 1, &quot;status&quot; : 201 } }, { &quot;index&quot; : { &quot;_index&quot; : &quot;cars&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;iCIT0oABY2btytp3yIaR&quot;, &quot;_version&quot; : 1, &quot;result&quot; : &quot;created&quot;, &quot;_shards&quot; : { &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;failed&quot; : 0 }, &quot;_seq_no&quot; : 7, &quot;_primary_term&quot; : 1, &quot;status&quot; : 201 } } ]} 聚合为桶首先，我们按照汽车的颜色color来划分桶： 1234567891011GET /cars/_search{ &quot;size&quot; : 0, &quot;aggs&quot; : { &quot;popular_colors&quot; : { &quot;terms&quot; : { &quot;field&quot; : &quot;color&quot; } } }} size： 查询条数，这里设置为0，因为我们不关心搜索到的数据，只关心聚合结果，提高效率 aggs：声明这是一个聚合查询，是aggregations的缩写 popular_colors：给这次聚合起一个名字，任意。 terms：划分桶的方式，这里是根据词条划分 field：划分桶的字段 结果： 1234567891011121314151617181920212223242526272829303132333435363738{ &quot;took&quot; : 5, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;skipped&quot; : 0, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : { &quot;value&quot; : 8, &quot;relation&quot; : &quot;eq&quot; }, &quot;max_score&quot; : null, &quot;hits&quot; : [ ] }, &quot;aggregations&quot; : { &quot;popular_colors&quot; : { &quot;doc_count_error_upper_bound&quot; : 0, &quot;sum_other_doc_count&quot; : 0, &quot;buckets&quot; : [ { &quot;key&quot; : &quot;red&quot;, &quot;doc_count&quot; : 4 }, { &quot;key&quot; : &quot;blue&quot;, &quot;doc_count&quot; : 2 }, { &quot;key&quot; : &quot;green&quot;, &quot;doc_count&quot; : 2 } ] } }} hits：查询结果为空，因为我们设置了size为0 aggregations：聚合的结果 popular_colors：我们定义的聚合名称 buckets：查找到的桶，每个不同的color字段值都会形成一个桶 key：这个桶对应的color字段的值 doc_count：这个桶中的文档数量 通过聚合的结果我们发现，目前红色的小车比较畅销！ 桶内度量前面的例子告诉我们每个桶里面的文档数量，这很有用。 但通常，我们的应用需要提供更复杂的文档度量。 例如，每种颜色汽车的平均价格是多少？ 因此，我们需要告诉Elasticsearch使用哪个字段，使用何种度量方式进行运算，这些信息要嵌套在桶内，度量的运算会基于桶内的文档进行 现在，我们为刚刚的聚合结果添加求价格平均值的度量： 123456789101112131415161718GET /cars/_search{ &quot;size&quot; : 0, &quot;aggs&quot; : { &quot;popular_colors&quot; : { &quot;terms&quot; : { &quot;field&quot; : &quot;color&quot; }, &quot;aggs&quot;:{ &quot;avg_price&quot;: { &quot;avg&quot;: { &quot;field&quot;: &quot;price&quot; } } } } }} aggs：我们在上一个aggs(popular_colors)中添加新的aggs。可见度量也是一个聚合，度量是在桶内的聚合 avg_price：聚合的名称 avg：度量的类型，这里是求平均值 field：度量运算的字段 结果： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647{ &quot;took&quot; : 14, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;skipped&quot; : 0, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : { &quot;value&quot; : 8, &quot;relation&quot; : &quot;eq&quot; }, &quot;max_score&quot; : null, &quot;hits&quot; : [ ] }, &quot;aggregations&quot; : { &quot;popular_colors&quot; : { &quot;doc_count_error_upper_bound&quot; : 0, &quot;sum_other_doc_count&quot; : 0, &quot;buckets&quot; : [ { &quot;key&quot; : &quot;red&quot;, &quot;doc_count&quot; : 4, &quot;avg_price&quot; : { &quot;value&quot; : 32500.0 } }, { &quot;key&quot; : &quot;blue&quot;, &quot;doc_count&quot; : 2, &quot;avg_price&quot; : { &quot;value&quot; : 20000.0 } }, { &quot;key&quot; : &quot;green&quot;, &quot;doc_count&quot; : 2, &quot;avg_price&quot; : { &quot;value&quot; : 21000.0 } } ] } }} 可以看到每个桶中都有自己的avg_price字段，这是度量聚合的结果 桶内嵌套桶刚刚的案例中，我们在桶内嵌套度量运算。事实上桶不仅可以嵌套运算， 还可以再嵌套其它桶。也就是说在每个分组中，再分更多组。 比如：我们想统计每种颜色的汽车中，分别属于哪个制造商，按照make字段再进行分桶 1234567891011121314151617181920212223GET /cars/_search{ &quot;size&quot; : 0, &quot;aggs&quot; : { &quot;popular_colors&quot; : { &quot;terms&quot; : { &quot;field&quot; : &quot;color&quot; }, &quot;aggs&quot;:{ &quot;avg_price&quot;: { &quot;avg&quot;: { &quot;field&quot;: &quot;price&quot; } }, &quot;maker&quot;:{ &quot;terms&quot;:{ &quot;field&quot;:&quot;make&quot; } } } } }} 原来的color桶和avg计算我们不变 maker：在嵌套的aggs下新添一个桶，叫做maker terms：桶的划分类型依然是词条 filed：这里根据make字段进行划分 注意：前面的概念说了，Elasticsearch中的聚合，包含多种类型，最常用的两种，一个叫桶，一个叫度量，这说明什么，说明了桶是一种聚合，度量是另一种聚合。因此不能将桶查询和度量写在同一个聚合名下，一种桶查询对应一个聚合名，一种度量也要对应一个聚合名。像上面的这种例子，桶内桶，桶内度量，写查询的时候要注意嵌套关系。 结果 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889{ &quot;took&quot; : 9, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;skipped&quot; : 0, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : { &quot;value&quot; : 8, &quot;relation&quot; : &quot;eq&quot; }, &quot;max_score&quot; : null, &quot;hits&quot; : [ ] }, &quot;aggregations&quot; : { &quot;popular_colors&quot; : { &quot;doc_count_error_upper_bound&quot; : 0, &quot;sum_other_doc_count&quot; : 0, &quot;buckets&quot; : [ { &quot;key&quot; : &quot;red&quot;, &quot;doc_count&quot; : 4, &quot;maker&quot; : { &quot;doc_count_error_upper_bound&quot; : 0, &quot;sum_other_doc_count&quot; : 0, &quot;buckets&quot; : [ { &quot;key&quot; : &quot;honda&quot;, &quot;doc_count&quot; : 3 }, { &quot;key&quot; : &quot;bmw&quot;, &quot;doc_count&quot; : 1 } ] }, &quot;avg_price&quot; : { &quot;value&quot; : 32500.0 } }, { &quot;key&quot; : &quot;blue&quot;, &quot;doc_count&quot; : 2, &quot;maker&quot; : { &quot;doc_count_error_upper_bound&quot; : 0, &quot;sum_other_doc_count&quot; : 0, &quot;buckets&quot; : [ { &quot;key&quot; : &quot;ford&quot;, &quot;doc_count&quot; : 1 }, { &quot;key&quot; : &quot;toyota&quot;, &quot;doc_count&quot; : 1 } ] }, &quot;avg_price&quot; : { &quot;value&quot; : 20000.0 } }, { &quot;key&quot; : &quot;green&quot;, &quot;doc_count&quot; : 2, &quot;maker&quot; : { &quot;doc_count_error_upper_bound&quot; : 0, &quot;sum_other_doc_count&quot; : 0, &quot;buckets&quot; : [ { &quot;key&quot; : &quot;ford&quot;, &quot;doc_count&quot; : 1 }, { &quot;key&quot; : &quot;toyota&quot;, &quot;doc_count&quot; : 1 } ] }, &quot;avg_price&quot; : { &quot;value&quot; : 21000.0 } } ] } }} 我们可以看到，新的聚合maker被嵌套在原来每一个color的桶中。 每个颜色下面都根据 make字段进行了分组 我们能读取到的信息： 红色车共有4辆 红色车的平均售价是 $32，500 美元。 其中3辆是 Honda 本田制造，1辆是 BMW 宝马制造。 划分桶的其它方式前面讲了，划分桶的方式有很多，例如： Date Histogram Aggregation：根据日期阶梯分组，例如给定阶梯为周，会自动每周分为一组 Histogram Aggregation：根据数值阶梯分组，与日期类似 Terms Aggregation：根据词条内容分组，词条内容完全匹配的为一组 Range Aggregation：数值和日期的范围分组，指定开始和结束，然后按段分组 刚刚的案例中，我们采用的是Terms Aggregation，即根据词条划分桶。 接下来，我们再学习几个比较实用的： 阶梯分桶Histogram 原理： histogram是把数值类型的字段，按照一定的阶梯大小进行分组。你需要指定一个阶梯值（interval）来划分阶梯大小。 举例： 比如你有价格字段，如果你设定interval的值为200，那么阶梯就会是这样的： 0，200，400，600，… 上面列出的是每个阶梯的key，也是区间的启点。 如果一件商品的价格是450，会落入哪个阶梯区间呢？计算公式如下： 1bucket_key = Math.floor((value - offset) / interval) * interval + offset value：就是当前数据的值，本例中是450 offset：起始偏移量，默认为0 interval：阶梯间隔，比如200 因此你得到的key = Math.floor((450 - 0) / 200) * 200 + 0 = 400 操作一下： 比如，我们对汽车的价格进行分组，指定间隔interval为5000： 123456789101112GET /cars/_search{ &quot;size&quot;:0, &quot;aggs&quot;:{ &quot;price&quot;:{ &quot;histogram&quot;: { &quot;field&quot;: &quot;price&quot;, &quot;interval&quot;: 5000 } } }} 结果 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384{ &quot;took&quot; : 24, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;skipped&quot; : 0, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : { &quot;value&quot; : 8, &quot;relation&quot; : &quot;eq&quot; }, &quot;max_score&quot; : null, &quot;hits&quot; : [ ] }, &quot;aggregations&quot; : { &quot;price&quot; : { &quot;buckets&quot; : [ { &quot;key&quot; : 10000.0, &quot;doc_count&quot; : 2 }, { &quot;key&quot; : 15000.0, &quot;doc_count&quot; : 1 }, { &quot;key&quot; : 20000.0, &quot;doc_count&quot; : 2 }, { &quot;key&quot; : 25000.0, &quot;doc_count&quot; : 1 }, { &quot;key&quot; : 30000.0, &quot;doc_count&quot; : 1 }, { &quot;key&quot; : 35000.0, &quot;doc_count&quot; : 0 }, { &quot;key&quot; : 40000.0, &quot;doc_count&quot; : 0 }, { &quot;key&quot; : 45000.0, &quot;doc_count&quot; : 0 }, { &quot;key&quot; : 50000.0, &quot;doc_count&quot; : 0 }, { &quot;key&quot; : 55000.0, &quot;doc_count&quot; : 0 }, { &quot;key&quot; : 60000.0, &quot;doc_count&quot; : 0 }, { &quot;key&quot; : 65000.0, &quot;doc_count&quot; : 0 }, { &quot;key&quot; : 70000.0, &quot;doc_count&quot; : 0 }, { &quot;key&quot; : 75000.0, &quot;doc_count&quot; : 0 }, { &quot;key&quot; : 80000.0, &quot;doc_count&quot; : 1 } ] } }} 你会发现，中间有大量的文档数量为0 的桶，看起来很丑。 我们可以增加一个参数min_doc_count为1，来约束最少文档数量为1，这样文档数量为0的桶会被过滤 示例： 12345678910111213GET /cars/_search{ &quot;size&quot;:0, &quot;aggs&quot;:{ &quot;price&quot;:{ &quot;histogram&quot;: { &quot;field&quot;: &quot;price&quot;, &quot;interval&quot;: 5000, &quot;min_doc_count&quot;: 1 } } }} 结果 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748{ &quot;took&quot; : 2, &quot;timed_out&quot; : false, &quot;_shards&quot; : { &quot;total&quot; : 1, &quot;successful&quot; : 1, &quot;skipped&quot; : 0, &quot;failed&quot; : 0 }, &quot;hits&quot; : { &quot;total&quot; : { &quot;value&quot; : 8, &quot;relation&quot; : &quot;eq&quot; }, &quot;max_score&quot; : null, &quot;hits&quot; : [ ] }, &quot;aggregations&quot; : { &quot;price&quot; : { &quot;buckets&quot; : [ { &quot;key&quot; : 10000.0, &quot;doc_count&quot; : 2 }, { &quot;key&quot; : 15000.0, &quot;doc_count&quot; : 1 }, { &quot;key&quot; : 20000.0, &quot;doc_count&quot; : 2 }, { &quot;key&quot; : 25000.0, &quot;doc_count&quot; : 1 }, { &quot;key&quot; : 30000.0, &quot;doc_count&quot; : 1 }, { &quot;key&quot; : 80000.0, &quot;doc_count&quot; : 1 } ] } }} 完美！ 如果你用kibana将结果变为柱形图，会更好看： 范围分桶range范围分桶与阶梯分桶类似，也是把数字按照阶段进行分组，只不过range方式需要你自己指定每一组的起始和结束大小。 总结聚合常见的有三类： 桶（Bucket）聚合：用来对文档做分组 TermAggregation：按照文档字段值分组，例如按照品牌值分组、按照国家分组 Date Histogram：按照日期阶梯分组，例如一周为一组，或者一月为一组 度量（Metric）聚合：用以计算一些值，比如：最大值、最小值、平均值等 Avg：求平均值 Max：求最大值 Min：求最小值 Stats：同时求max、min、avg、sum等 管道（pipeline）聚合：其它聚合的结果为基础做聚合 注意：参加聚合的字段必须是keyword、日期、数值、布尔类型 黑马旅游案例黑马旅游案例中的聚合需求。 DSL实现聚合现在，我们要统计所有数据中的酒店品牌有几种，其实就是按照品牌对数据分组。此时可以根据酒店品牌的名称做聚合，也就是Bucket聚合。 Bucket聚合语法语法如下： 123456789101112GET /hotel/_search{ &quot;size&quot;: 0, // 设置size为0，结果中不包含文档，只包含聚合结果 &quot;aggs&quot;: { // 定义聚合 &quot;brandAgg&quot;: { //给聚合起个名字 &quot;terms&quot;: { // 聚合的类型，按照品牌值聚合，所以选择term &quot;field&quot;: &quot;brand&quot;, // 参与聚合的字段 &quot;size&quot;: 20 // 希望获取的聚合结果数量 } } }} 结果如图： 聚合结果排序默认情况下，Bucket聚合会统计Bucket内的文档数量，记为_count，并且按照_count降序排序。 我们可以指定order属性，自定义聚合的排序方式： 123456789101112131415GET /hotel/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;brandAgg&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;brand&quot;, &quot;order&quot;: { &quot;_count&quot;: &quot;asc&quot; // 按照_count升序排列 }, &quot;size&quot;: 20 } } }} 限定聚合范围默认情况下，Bucket聚合是对索引库的所有文档做聚合，但真实场景下，用户会输入搜索条件，因此聚合必须是对搜索结果聚合。那么聚合必须添加限定条件。 我们可以限定要聚合的文档范围，只要添加query条件即可： 12345678910111213141516171819GET /hotel/_search{ &quot;query&quot;: { &quot;range&quot;: { &quot;price&quot;: { &quot;lte&quot;: 200 // 只对200元以下的文档聚合 } } }, &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;brandAgg&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;brand&quot;, &quot;size&quot;: 20 } } }} 这次，聚合得到的品牌明显变少了： Metric聚合语法前面我们对酒店按照品牌分组，形成了一个个桶。现在我们需要对桶内的酒店做运算，获取每个品牌的用户评分的min、max、avg等值。 这就要用到Metric聚合了，例如stat聚合：就可以获取min、max、avg等结果。 语法如下： 12345678910111213141516171819GET /hotel/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;brandAgg&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;brand&quot;, &quot;size&quot;: 20 }, &quot;aggs&quot;: { // 是brands聚合的子聚合，也就是分组后对每组分别计算 &quot;score_stats&quot;: { // 聚合名称 &quot;stats&quot;: { // 聚合类型，这里stats可以计算min、max、avg等 &quot;field&quot;: &quot;score&quot; // 聚合字段，这里是score } } } } }} 这次的score_stats聚合是在brandAgg的聚合内部嵌套的子聚合。因为我们需要在每个桶分别计算。 另外，我们还可以给聚合结果做个排序，例如按照每个桶的酒店平均分做排序： 小结aggs代表聚合，与query同级，此时query的作用是？ 限定聚合的的文档范围 聚合必须的三要素： 聚合名称 聚合类型 聚合字段 聚合可配置属性有： size：指定聚合结果数量 order：指定聚合结果排序方式 field：指定聚合字段 RestAPI实现聚合API语法聚合条件与query条件同级别，因此需要使用request.source()来指定聚合条件。 聚合条件的语法： 聚合的结果也与查询结果不同，API也比较特殊。不过同样是JSON逐层解析： 业务需求需求：搜索页面的品牌、城市等信息不应该是在页面写死，而是通过聚合索引库中的酒店数据得来的： 分析： 目前，页面的城市列表、星级列表、品牌列表都是写死的，并不会随着搜索结果的变化而变化。但是用户搜索条件改变时，搜索结果会跟着变化。 例如：用户搜索“东方明珠”，那搜索的酒店肯定是在上海东方明珠附近，因此，城市只能是上海，此时城市列表中就不应该显示北京、深圳、杭州这些信息了。 也就是说，搜索结果中包含哪些城市，页面就应该列出哪些城市；搜索结果中包含哪些品牌，页面就应该列出哪些品牌。 如何得知搜索结果中包含哪些品牌？如何得知搜索结果中包含哪些城市？ 使用聚合功能，利用Bucket聚合，对搜索结果中的文档基于品牌分组、基于城市分组，就能得知包含哪些品牌、哪些城市了。 因为是对搜索结果聚合，因此聚合是限定范围的聚合，也就是说聚合的限定条件跟搜索文档的条件一致。 查看浏览器可以发现，前端其实已经发出了这样的一个请求： 请求参数与搜索文档的参数完全一致。 返回值类型就是页面要展示的最终结果： 结果是一个Map结构： key是字符串，城市、星级、品牌、价格 value是集合，例如多个城市的名称 业务实现在cn.itcast.hotel.web包的HotelController中添加一个方法，遵循下面的要求： 请求方式：POST 请求路径：/hotel/filters 请求参数：RequestParams，与搜索文档的参数一致 返回值类型：Map&lt;String, List&lt;String&gt;&gt; 代码： 1234@PostMapping(&quot;filters&quot;)public Map&lt;String, List&lt;String&gt;&gt; getFilters(@RequestBody RequestParams params){ return hotelService.getFilters(params);} 这里调用了IHotelService中的getFilters方法，尚未实现。 在cn.itcast.hotel.service.IHotelService中定义新方法： 1Map&lt;String, List&lt;String&gt;&gt; filters(RequestParams params); 在cn.itcast.hotel.service.impl.HotelService中实现该方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465@Overridepublic Map&lt;String, List&lt;String&gt;&gt; filters(RequestParams params) { try { // 1.准备Request SearchRequest request = new SearchRequest(&quot;hotel&quot;); // 2.准备DSL // 2.1.query buildBasicQuery(params, request); // 2.2.设置size request.source().size(0); // 2.3.聚合 buildAggregation(request); // 3.发出请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析结果 Map&lt;String, List&lt;String&gt;&gt; result = new HashMap&lt;&gt;(); Aggregations aggregations = response.getAggregations(); // 4.1.根据品牌名称，获取品牌结果 List&lt;String&gt; brandList = getAggByName(aggregations, &quot;brandAgg&quot;); result.put(&quot;品牌&quot;, brandList); // 4.2.根据品牌名称，获取品牌结果 List&lt;String&gt; cityList = getAggByName(aggregations, &quot;cityAgg&quot;); result.put(&quot;城市&quot;, cityList); // 4.3.根据品牌名称，获取品牌结果 List&lt;String&gt; starList = getAggByName(aggregations, &quot;starAgg&quot;); result.put(&quot;星级&quot;, starList); return result; } catch (IOException e) { throw new RuntimeException(e); }}private void buildAggregation(SearchRequest request) { request.source().aggregation(AggregationBuilders .terms(&quot;brandAgg&quot;) .field(&quot;brand&quot;) .size(100) ); request.source().aggregation(AggregationBuilders .terms(&quot;cityAgg&quot;) .field(&quot;city&quot;) .size(100) ); request.source().aggregation(AggregationBuilders .terms(&quot;starAgg&quot;) .field(&quot;starName&quot;) .size(100) );}private List&lt;String&gt; getAggByName(Aggregations aggregations, String aggName) { // 4.1.根据聚合名称获取聚合结果 Terms brandTerms = aggregations.get(aggName); // 4.2.获取buckets List&lt;? extends Terms.Bucket&gt; buckets = brandTerms.getBuckets(); // 4.3.遍历 List&lt;String&gt; brandList = new ArrayList&lt;&gt;(); for (Terms.Bucket bucket : buckets) { // 4.4.获取key String key = bucket.getKeyAsString(); brandList.add(key); } return brandList;} 自动补全当用户在搜索框输入字符时，我们应该提示出与该字符有关的搜索项，如图： 这种根据用户输入的字母，提示完整词条的功能，就是自动补全了。 因为需要根据拼音字母来推断，因此要用到拼音分词功能。 拼音分词器要实现根据字母做补全，就必须对文档按照拼音分词。在GitHub上恰好有elasticsearch的拼音分词插件。地址：https://github.com/medcl/elasticsearch-analysis-pinyin 拼音分词器的安装包的安装方式与IK分词器一样，分三步： ​ ①解压 ​ ②上传到虚拟机中，elasticsearch的plugin目录 ​ ③重启elasticsearch ​ ④测试 详细安装步骤可以参考IK分词器的安装过程。 测试用法如下： 12345POST /_analyze{ &quot;text&quot;: &quot;如家酒店还不错&quot;, &quot;analyzer&quot;: &quot;pinyin&quot;} 结果： 自定义分词器默认的拼音分词器会将每个汉字单独分为拼音，而我们希望的是每个词条形成一组拼音，需要对拼音分词器做个性化定制，形成自定义分词器。 elasticsearch中分词器（analyzer）的组成包含三部分： character filters：在tokenizer之前对文本进行处理。例如删除字符、替换字符 tokenizer：将文本按照一定的规则切割成词条（term）。例如keyword，就是不分词；还有ik_smart tokenizer filter：将tokenizer输出的词条做进一步处理。例如大小写转换、同义词处理、拼音处理等 文档分词时会依次由这三部分来处理文档： 声明自定义分词器的语法如下： 123456789101112131415161718192021222324252627282930313233PUT /test{ &quot;settings&quot;: { &quot;analysis&quot;: { &quot;analyzer&quot;: { // 自定义分词器 &quot;my_analyzer&quot;: { // 分词器名称 &quot;tokenizer&quot;: &quot;ik_max_word&quot;, &quot;filter&quot;: &quot;py&quot; } }, &quot;filter&quot;: { // 自定义tokenizer filter &quot;py&quot;: { // 过滤器名称 &quot;type&quot;: &quot;pinyin&quot;, // 过滤器类型，这里是pinyin &quot;keep_full_pinyin&quot;: false, &quot;keep_joined_full_pinyin&quot;: true, &quot;keep_original&quot;: true, &quot;limit_first_letter_length&quot;: 16, &quot;remove_duplicated_term&quot;: true, &quot;none_chinese_pinyin_tokenize&quot;: false } } } }, &quot;mappings&quot;: { &quot;properties&quot;: { &quot;name&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;my_analyzer&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; } } }} 测试： 12345POST /test/_analyze{ &quot;text&quot;: &quot;如家酒店还不错&quot;, &quot;analyzer&quot;: &quot;my_analyzer&quot;} 结果： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889{ &quot;tokens&quot; : [ { &quot;token&quot; : &quot;如家&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 2, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 0 }, { &quot;token&quot; : &quot;rujia&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 2, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 0 }, { &quot;token&quot; : &quot;rj&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 2, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 0 }, { &quot;token&quot; : &quot;酒店&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 4, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 1 }, { &quot;token&quot; : &quot;jiudian&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 4, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 1 }, { &quot;token&quot; : &quot;jd&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 4, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 1 }, { &quot;token&quot; : &quot;还不&quot;, &quot;start_offset&quot; : 4, &quot;end_offset&quot; : 6, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 2 }, { &quot;token&quot; : &quot;haibu&quot;, &quot;start_offset&quot; : 4, &quot;end_offset&quot; : 6, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 2 }, { &quot;token&quot; : &quot;hb&quot;, &quot;start_offset&quot; : 4, &quot;end_offset&quot; : 6, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 2 }, { &quot;token&quot; : &quot;不错&quot;, &quot;start_offset&quot; : 5, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 3 }, { &quot;token&quot; : &quot;bucuo&quot;, &quot;start_offset&quot; : 5, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 3 }, { &quot;token&quot; : &quot;bc&quot;, &quot;start_offset&quot; : 5, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 3 } ]} 如图： 总结： 如何使用拼音分词器？ ①下载pinyin分词器 ②解压并放到elasticsearch的plugin目录 ③重启即可 如何自定义分词器？ ①创建索引库时，在settings中配置，可以包含三部分 ②character filter ③tokenizer ④filter 拼音分词器注意事项？ 为了避免搜索到同音字，搜索时不要使用拼音分词器 自动补全查询elasticsearch提供了Completion Suggester查询来实现自动补全功能。这个查询会匹配以用户输入内容开头的词条并返回。为了提高补全查询的效率，对于文档中字段的类型有一些约束： 参与补全查询的字段必须是completion类型。 字段的内容一般是用来补全的多个词条形成的数组。 比如，一个这样的索引库： 1234567891011// 创建索引库PUT test{ &quot;mappings&quot;: { &quot;properties&quot;: { &quot;title&quot;:{ &quot;type&quot;: &quot;completion&quot; } } }} 然后插入下面的数据： 12345678910111213// 示例数据POST test/_doc{ &quot;title&quot;: [&quot;Sony&quot;, &quot;WH-1000XM3&quot;]}POST test/_doc{ &quot;title&quot;: [&quot;SK-II&quot;, &quot;PITERA&quot;]}POST test/_doc{ &quot;title&quot;: [&quot;Nintendo&quot;, &quot;switch&quot;]} 查询的DSL语句如下： 1234567891011121314// 自动补全查询GET /test/_search{ &quot;suggest&quot;: { &quot;title_suggest&quot;: { &quot;text&quot;: &quot;s&quot;, // 关键字 &quot;completion&quot;: { &quot;field&quot;: &quot;title&quot;, // 补全查询的字段 &quot;skip_duplicates&quot;: true, // 跳过重复的 &quot;size&quot;: 10 // 获取前10条结果 } } }} 实现酒店搜索框自动补全现在，我们的hotel索引库还没有设置拼音分词器，需要修改索引库中的配置。但是我们知道索引库是无法修改的，只能删除然后重新创建。 另外，我们需要添加一个字段，用来做自动补全，将brand、suggestion、city等都放进去，作为自动补全的提示。 因此，总结一下，我们需要做的事情包括： 修改hotel索引库结构，设置自定义拼音分词器 修改索引库的name、all字段，使用自定义分词器 索引库添加一个新字段suggestion，类型为completion类型，使用自定义的分词器 给HotelDoc类添加suggestion字段，内容包含brand、business 重新导入数据到hotel库 修改酒店映射结构代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182// 酒店数据索引库PUT /hotel{ &quot;settings&quot;: { &quot;analysis&quot;: { &quot;analyzer&quot;: { &quot;text_anlyzer&quot;: { &quot;tokenizer&quot;: &quot;ik_max_word&quot;, &quot;filter&quot;: &quot;py&quot; }, &quot;completion_analyzer&quot;: { &quot;tokenizer&quot;: &quot;keyword&quot;, &quot;filter&quot;: &quot;py&quot; } }, &quot;filter&quot;: { &quot;py&quot;: { &quot;type&quot;: &quot;pinyin&quot;, &quot;keep_full_pinyin&quot;: false, &quot;keep_joined_full_pinyin&quot;: true, &quot;keep_original&quot;: true, &quot;limit_first_letter_length&quot;: 16, &quot;remove_duplicated_term&quot;: true, &quot;none_chinese_pinyin_tokenize&quot;: false } } } }, &quot;mappings&quot;: { &quot;properties&quot;: { &quot;id&quot;:{ &quot;type&quot;: &quot;keyword&quot; }, &quot;name&quot;:{ &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;text_anlyzer&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot;, &quot;copy_to&quot;: &quot;all&quot; }, &quot;address&quot;:{ &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: false }, &quot;price&quot;:{ &quot;type&quot;: &quot;integer&quot; }, &quot;score&quot;:{ &quot;type&quot;: &quot;integer&quot; }, &quot;brand&quot;:{ &quot;type&quot;: &quot;keyword&quot;, &quot;copy_to&quot;: &quot;all&quot; }, &quot;city&quot;:{ &quot;type&quot;: &quot;keyword&quot; }, &quot;starName&quot;:{ &quot;type&quot;: &quot;keyword&quot; }, &quot;business&quot;:{ &quot;type&quot;: &quot;keyword&quot;, &quot;copy_to&quot;: &quot;all&quot; }, &quot;location&quot;:{ &quot;type&quot;: &quot;geo_point&quot; }, &quot;pic&quot;:{ &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: false }, &quot;all&quot;:{ &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;text_anlyzer&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; }, &quot;suggestion&quot;:{ &quot;type&quot;: &quot;completion&quot;, &quot;analyzer&quot;: &quot;completion_analyzer&quot; } } }} 修改HotelDoc实体HotelDoc中要添加一个字段，用来做自动补全，内容可以是酒店品牌、城市、商圈等信息。按照自动补全字段的要求，最好是这些字段的数组。 因此我们在HotelDoc中添加一个suggestion字段，类型为List&lt;String&gt;，然后将brand、city、business等信息放到里面。 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package cn.itcast.hotel.pojo;import lombok.Data;import lombok.NoArgsConstructor;import java.util.ArrayList;import java.util.Arrays;import java.util.Collections;import java.util.List;@Data@NoArgsConstructorpublic class HotelDoc { private Long id; private String name; private String address; private Integer price; private Integer score; private String brand; private String city; private String starName; private String business; private String location; private String pic; private Object distance; private Boolean isAD; private List&lt;String&gt; suggestion; public HotelDoc(Hotel hotel) { this.id = hotel.getId(); this.name = hotel.getName(); this.address = hotel.getAddress(); this.price = hotel.getPrice(); this.score = hotel.getScore(); this.brand = hotel.getBrand(); this.city = hotel.getCity(); this.starName = hotel.getStarName(); this.business = hotel.getBusiness(); this.location = hotel.getLatitude() + &quot;, &quot; + hotel.getLongitude(); this.pic = hotel.getPic(); // 组装suggestion if(this.business.contains(&quot;/&quot;)){ // business有多个值，需要切割 String[] arr = this.business.split(&quot;/&quot;); // 添加元素 this.suggestion = new ArrayList&lt;&gt;(); this.suggestion.add(this.brand); Collections.addAll(this.suggestion, arr); }else { this.suggestion = Arrays.asList(this.brand, this.business); } }} 重新导入重新执行之前编写的导入数据功能，可以看到新的酒店数据中包含了suggestion： 自动补全查询的JavaAPI之前我们学习了自动补全查询的DSL，而没有学习对应的JavaAPI，这里给出一个示例： 而自动补全的结果也比较特殊，解析的代码如下： 实现搜索框自动补全查看前端页面，可以发现当我们在输入框键入时，前端会发起ajax请求： 返回值是补全词条的集合，类型为List&lt;String&gt; 1）在cn.itcast.hotel.web包下的HotelController中添加新接口，接收新的请求： 1234@GetMapping(&quot;suggestion&quot;)public List&lt;String&gt; getSuggestions(@RequestParam(&quot;key&quot;) String prefix) { return hotelService.getSuggestions(prefix);} 2）在cn.itcast.hotel.service包下的IhotelService中添加方法： 1List&lt;String&gt; getSuggestions(String prefix); 3）在cn.itcast.hotel.service.impl.HotelService中实现该方法： 1234567891011121314151617181920212223242526272829303132@Overridepublic List&lt;String&gt; getSuggestions(String prefix) { try { // 1.准备Request SearchRequest request = new SearchRequest(&quot;hotel&quot;); // 2.准备DSL request.source().suggest(new SuggestBuilder().addSuggestion( &quot;suggestions&quot;, SuggestBuilders.completionSuggestion(&quot;suggestion&quot;) .prefix(prefix) .skipDuplicates(true) .size(10) )); // 3.发起请求 SearchResponse response = client.search(request, RequestOptions.DEFAULT); // 4.解析结果 Suggest suggest = response.getSuggest(); // 4.1.根据补全查询名称，获取补全结果 CompletionSuggestion suggestions = suggest.getSuggestion(&quot;suggestions&quot;); // 4.2.获取options List&lt;CompletionSuggestion.Entry.Option&gt; options = suggestions.getOptions(); // 4.3.遍历 List&lt;String&gt; list = new ArrayList&lt;&gt;(options.size()); for (CompletionSuggestion.Entry.Option option : options) { String text = option.getText().toString(); list.add(text); } return list; } catch (IOException e) { throw new RuntimeException(e); }} 数据同步elasticsearch中的酒店数据来自于mysql数据库，因此mysql数据发生改变时，elasticsearch也必须跟着改变，这个就是elasticsearch与mysql之间的数据同步。 思路分析常见的数据同步方案有三种： 同步调用 异步通知 监听binlog 同步调用方案一：同步调用 基本步骤如下： hotel-demo对外提供接口，用来修改elasticsearch中的数据 酒店管理服务在完成数据库操作后，直接调用hotel-demo提供的接口， 异步通知方案二：异步通知 流程如下： hotel-admin对mysql数据库数据完成增、删、改后，发送MQ消息 hotel-demo监听MQ，接收到消息后完成elasticsearch数据修改 监听binlog方案三：监听binlog 流程如下： 给mysql开启binlog功能 mysql完成增、删、改操作都会记录在binlog中 hotel-demo基于canal监听binlog变化，实时更新elasticsearch中的内容 选择方式一：同步调用 优点：实现简单，粗暴 缺点：业务耦合度高 方式二：异步通知 优点：低耦合，实现难度一般 缺点：依赖mq的可靠性 方式三：监听binlog 优点：完全解除服务间耦合 缺点：开启binlog增加数据库负担、实现复杂度高 实现数据同步思路hotel-admin项目作为酒店管理的微服务。当酒店数据发生增、删、改时，要求对elasticsearch中数据也要完成相同操作。 步骤： hotel-admin项目，启动并测试酒店数据的CRUD 声明exchange、queue、RoutingKey 在hotel-admin中的增、删、改业务中完成消息发送 在hotel-demo中完成消息监听，并更新elasticsearch中数据 启动并测试数据同步功能 hotel-admin项目其中包含了酒店的CRUD功能。 声明交换机、队列MQ结构如图： 1）引入依赖在hotel-admin、hotel-demo中引入rabbitmq的依赖： 12345&lt;!--amqp--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 并且修改这两个微服务的配置文件，添加： 123456spring: rabbitmq: host: localhost username: root password: 123456 virtual-host: hotel 2）声明队列交换机名称在hotel-admin和hotel-demo中的cn.itcast.hotel.constatnts包下新建一个类MqConstants： 123456789101112131415161718192021222324package cn.itcast.hotel.constatnts; public class MqConstants { /** * 交换机 */ public final static String HOTEL_EXCHANGE = &quot;hotel.topic&quot;; /** * 监听新增和修改的队列 */ public final static String HOTEL_INSERT_QUEUE = &quot;hotel.insert.queue&quot;; /** * 监听删除的队列 */ public final static String HOTEL_DELETE_QUEUE = &quot;hotel.delete.queue&quot;; /** * 新增或修改的RoutingKey */ public final static String HOTEL_INSERT_KEY = &quot;hotel.insert&quot;; /** * 删除的RoutingKey */ public final static String HOTEL_DELETE_KEY = &quot;hotel.delete&quot;;} 3）声明队列交换机在hotel-demo中，定义配置类，声明队列、交换机： 12345678910111213141516171819202122232425262728293031323334353637package cn.itcast.hotel.config;import cn.itcast.hotel.constants.MqConstants;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.Queue;import org.springframework.amqp.core.TopicExchange;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class MqConfig { @Bean public TopicExchange topicExchange(){ return new TopicExchange(MqConstants.HOTEL_EXCHANGE, true, false); } @Bean public Queue insertQueue(){ return new Queue(MqConstants.HOTEL_INSERT_QUEUE, true); } @Bean public Queue deleteQueue(){ return new Queue(MqConstants.HOTEL_DELETE_QUEUE, true); } @Bean public Binding insertQueueBinding(){ return BindingBuilder.bind(insertQueue()).to(topicExchange()).with(MqConstants.HOTEL_INSERT_KEY); } @Bean public Binding deleteQueueBinding(){ return BindingBuilder.bind(deleteQueue()).to(topicExchange()).with(MqConstants.HOTEL_DELETE_KEY); }} 发送MQ消息在hotel-admin中的增、删、改业务中分别发送MQ消息： 接收MQ消息hotel-demo接收到MQ消息要做的事情包括： 新增消息：根据传递的hotel的id查询hotel信息，然后新增一条数据到索引库 删除消息：根据传递的hotel的id删除索引库中的一条数据 1）首先在hotel-demo的cn.itcast.hotel.service包下的IHotelService中新增新增、删除业务 123void deleteById(Long id);void insertById(Long id); 2）给hotel-demo中的cn.itcast.hotel.service.impl包下的HotelService中实现业务： 123456789101112131415161718192021222324252627282930@Overridepublic void deleteById(Long id) { try { // 1.准备Request DeleteRequest request = new DeleteRequest(&quot;hotel&quot;, id.toString()); // 2.发送请求 client.delete(request, RequestOptions.DEFAULT); } catch (IOException e) { throw new RuntimeException(e); }}@Overridepublic void insertById(Long id) { try { // 0.根据id查询酒店数据 Hotel hotel = getById(id); // 转换为文档类型 HotelDoc hotelDoc = new HotelDoc(hotel); // 1.准备Request对象 IndexRequest request = new IndexRequest(&quot;hotel&quot;).id(hotel.getId().toString()); // 2.准备Json文档 request.source(JSON.toJSONString(hotelDoc), XContentType.JSON); // 3.发送请求 client.index(request, RequestOptions.DEFAULT); } catch (IOException e) { throw new RuntimeException(e); }} 3）编写监听器 在hotel-demo中的cn.itcast.hotel.mq包新增一个类： 1234567891011121314151617181920212223242526272829303132package cn.itcast.hotel.mq;import cn.itcast.hotel.constants.MqConstants;import cn.itcast.hotel.service.IHotelService;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;@Componentpublic class HotelListener { @Autowired private IHotelService hotelService; /** * 监听酒店新增或修改的业务 * @param id 酒店id */ @RabbitListener(queues = MqConstants.HOTEL_INSERT_QUEUE) public void listenHotelInsertOrUpdate(Long id){ hotelService.insertById(id); } /** * 监听酒店删除的业务 * @param id 酒店id */ @RabbitListener(queues = MqConstants.HOTEL_DELETE_QUEUE) public void listenHotelDelete(Long id){ hotelService.deleteById(id); }} Spring Data ElasticsearchElasticsearch提供的Java客户端有一些不太方便的地方： 很多地方需要拼接Json字符串，在java中拼接字符串有多恐怖你应该懂的 需要自己把对象序列化为json存储 查询到结果也需要自己反序列化为对象 因此，就有了套件：Spring Data Elasticsearch。 spring-data-Elasticsearch 使用之前，必须先确定版本，elasticsearch 对版本的要求特别高！ 简介Spring Data Elasticsearch是Spring Data项目下的一个子模块。 查看 Spring Data的官网：http://projects.spring.io/spring-data/ Spring Data的使命是为数据访问提供熟悉且一致的基于Spring的编程模型，同时仍保留底层数据存储的特殊特性。 它使得使用数据访问技术，关系数据库和非关系数据库，map-reduce框架和基于云的数据服务变得容易。这是一个总括项目，其中包含许多特定于给定数据库的子项目。这些令人兴奋的技术项目背后，是由许多公司和开发人员合作开发的。 Spring Data 的使命是给各种数据访问提供统一的编程接口，不管是关系型数据库（如MySQL），还是非关系数据库（如Redis），或者类似Elasticsearch这样的索引数据库。从而简化开发人员的代码，提高开发效率。 包含很多不同数据操作的模块： Spring Data Elasticsearch的页面：https://projects.spring.io/spring-data-elasticsearch/ 特征： 支持Spring的基于@Configuration的java配置方式，或者XML配置方式 提供了用于操作ES的便捷工具类**ElasticsearchTemplate**。包括实现文档到POJO之间的自动智能映射。 利用Spring的数据转换服务实现的功能丰富的对象映射 基于注解的元数据映射方式，而且可扩展以支持更多不同的数据格式 根据持久层接口自动生成对应实现方法，无需人工编写基本操作代码（类似mybatis，根据接口自动得到实现）。当然，也支持人工定制查询 创建Demo工程我们新建一个demo，学习Elasticsearch 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.chan&lt;/groupId&gt; &lt;artifactId&gt;es-demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!-- 这是Spring Boot的父级依赖，这样当前的项目就是Spring Boot项目了。spring-boot-starter-parent是一个特殊的starter， 它用来提供相关的Maven默认依赖。使用它之后，常用的包依赖可以省去version标签 --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 12345spring: data: elasticsearch: cluster-name: elasticsearch cluster-nodes: 192.168.1.104:9300 123456789101112/** * @Classname EsApplication * @Description TODO * @Date 2021/2/25 19:09 * @Created by ChenSiYu */@SpringBootApplicationpublic class EsApplication { public static void main(String[] args) { SpringApplication.run(EsApplication.class, args); }} 实体类及注解首先我们准备好实体类： 12345678public class Item { Long id; String title; //标题 String category;// 分类 String brand; // 品牌 Double price; // 价格 String images; // 图片地址} 映射 Spring Data通过注解来声明字段的映射属性，有下面的三个注解： @Document 作用在类，标记实体类为文档对象，一般有两个属性 indexName：对应索引名称 type：对应在索引中的类型（新版本中已舍弃，不用写它。） shards：分片数量，默认5 replicas：副本数量，默认1 @Id 作用在成员变量，标记一个字段作为id主键 @Field 作用在成员变量，标记为文档的字段，并指定字段映射属性： type：字段类型，取值是枚举：FieldType index：是否索引，布尔类型，默认是true store：是否存储，布尔类型，默认是false analyzer：分词器名称 示例： 123456789101112131415161718192021222324@Data@AllArgsConstructor@NoArgsConstructor@Document(indexName = &quot;item&quot;, shards = 1, replicas = 0)public class Item { @Id @Field(type = FieldType.Long) private Long id;// 如果id不指定，es会随机生成一个文档id @Field(type = FieldType.Text, analyzer = &quot;ik_max_word&quot;) private String title; //标题 @Field(type = FieldType.Keyword) private String category;// 分类 @Field(type = FieldType.Keyword) private String brand; // 品牌 @Field(type = FieldType.Double) private Double price; // 价格 @Field(type = FieldType.Keyword, index = false) private String images; // 图片地址} Template索引操作创建Spring Boot测试类。 创建索引和映射 索引 ElasticsearchTemplate中提供了创建索引的API： 可以根据类的信息自动生成，也可以手动指定indexName和Settings 映射 映射相关的API： 可以根据类的字节码信息（注解配置）来生成映射，或者手动编写映射 我们这里采用类的字节码信息创建索引并映射： 1234567891011121314151617181920212223242526@RunWith(SpringRunner.class)@SpringBootTest(classes = EsApplication.class)// 就是你springboot的启动类public class EsTest { // ElasticsearchTemplate一般用来处理Repository文档操作处理不了的需求 @Autowired private ElasticsearchTemplate elasticsearchTemplate; @Autowired private ItemRepository itemRepository; /** * @Description 测试创建索引并创建映射 * @Param [] * @return void * @Date 2021/2/25 21:09 * @Author ChenSiYu */ @Test public void testCreate(){ // 创建索引 会根据Item类的@Document注解信息来创建 elasticsearchTemplate.createIndex(Item.class); // 创建映射 会根据Item类中的id、Field等字段来自动完成映射 elasticsearchTemplate.putMapping(Item.class); }} GET /item 的结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445{ &quot;item&quot; : { &quot;aliases&quot; : { }, &quot;mappings&quot; : { &quot;properties&quot; : { &quot;brand&quot; : { &quot;type&quot; : &quot;keyword&quot; }, &quot;category&quot; : { &quot;type&quot; : &quot;keyword&quot; }, &quot;id&quot; : { &quot;type&quot; : &quot;keyword&quot; }, &quot;images&quot; : { &quot;type&quot; : &quot;keyword&quot;, &quot;index&quot; : false }, &quot;price&quot; : { &quot;type&quot; : &quot;double&quot; }, &quot;title&quot; : { &quot;type&quot; : &quot;text&quot;, &quot;analyzer&quot; : &quot;ik_max_word&quot; } } }, &quot;settings&quot; : { &quot;index&quot; : { &quot;refresh_interval&quot; : &quot;1s&quot;, &quot;number_of_shards&quot; : &quot;1&quot;, &quot;provided_name&quot; : &quot;item&quot;, &quot;creation_date&quot; : &quot;1652763123385&quot;, &quot;store&quot; : { &quot;type&quot; : &quot;fs&quot; }, &quot;number_of_replicas&quot; : &quot;0&quot;, &quot;uuid&quot; : &quot;YZLIiLacRJqEMWAARDhl8A&quot;, &quot;version&quot; : { &quot;created&quot; : &quot;7070099&quot; } } } }} 删除索引删除索引的API： 可以根据类名或索引名删除。 示例： 123456 @Test public void testDelete(){ // 两种都可以// elasticsearchTemplate.deleteIndex(&quot;item&quot;); elasticsearchTemplate.deleteIndex(Item.class); } Repository文档操作Spring Data 的强大之处，就在于你不用写任何DAO处理，自动根据方法名或类的信息进行CRUD操作。只要你定义一个接口，然后继承Repository提供的一些子接口，就能具备各种基本的CRUD功能。 我们只需要定义接口，然后继承它就OK了。 12public interface ItemRepository extends ElasticsearchRepository&lt;Item, Long&gt; {} 来看下Repository的继承关系： 我们看到有一个ElasticsearchRepository接口： 新增文档123456789@Autowiredprivate ItemRepository itemRepository;@Testpublic void addDoc(){ Item item = new Item(1L, &quot;小米手机7&quot;, &quot; 手机&quot;, &quot;小米&quot;, 3499.00, &quot;http://image.leyou.com/13123.jpg&quot;); // save方法有增又有改 好比PUT itemRepository.save(item);} 去页面查询看看： 123456GET /item/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }} 结果： 123456789101112131415161718192021222324252627282930{ &quot;took&quot;: 14, &quot;timed_out&quot;: false, &quot;_shards&quot;: { &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 }, &quot;hits&quot;: { &quot;total&quot;: 1, &quot;max_score&quot;: 1, &quot;hits&quot;: [ { &quot;_index&quot;: &quot;item&quot;, &quot;_type&quot;: &quot;item&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;id&quot;: 1, &quot;title&quot;: &quot;小米手机7&quot;, &quot;category&quot;: &quot; 手机&quot;, &quot;brand&quot;: &quot;小米&quot;, &quot;price&quot;: 3499, &quot;images&quot;: &quot;http://image.leyou.com/13123.jpg&quot; } } ] }} 批量新增12345678@Testpublic void addDocs(){ List&lt;Item&gt; list = new ArrayList&lt;&gt;(); list.add(new Item(2L, &quot;坚果手机R1&quot;, &quot; 手机&quot;, &quot;锤子&quot;, 3699.00, &quot;http://image.leyou.com/123.jpg&quot;)); list.add(new Item(3L, &quot;华为META10&quot;, &quot; 手机&quot;, &quot;华为&quot;, 4499.00, &quot;http://image.leyou.com/3.jpg&quot;)); // 接收对象的集合，实现批量新增 itemRepository.saveAll(list);} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758{ &quot;took&quot;: 1, &quot;timed_out&quot;: false, &quot;_shards&quot;: { &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 }, &quot;hits&quot;: { &quot;total&quot;: 3, &quot;max_score&quot;: 1, &quot;hits&quot;: [ { &quot;_index&quot;: &quot;item&quot;, &quot;_type&quot;: &quot;item&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;id&quot;: 1, &quot;title&quot;: &quot;小米手机7&quot;, &quot;category&quot;: &quot; 手机&quot;, &quot;brand&quot;: &quot;小米&quot;, &quot;price&quot;: 3499, &quot;images&quot;: &quot;http://image.leyou.com/13123.jpg&quot; } }, { &quot;_index&quot;: &quot;item&quot;, &quot;_type&quot;: &quot;item&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;id&quot;: 2, &quot;title&quot;: &quot;坚果手机R1&quot;, &quot;category&quot;: &quot; 手机&quot;, &quot;brand&quot;: &quot;锤子&quot;, &quot;price&quot;: 3699, &quot;images&quot;: &quot;http://image.leyou.com/123.jpg&quot; } }, { &quot;_index&quot;: &quot;item&quot;, &quot;_type&quot;: &quot;item&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: { &quot;id&quot;: 3, &quot;title&quot;: &quot;华为META10&quot;, &quot;category&quot;: &quot; 手机&quot;, &quot;brand&quot;: &quot;华为&quot;, &quot;price&quot;: 4499, &quot;images&quot;: &quot;http://image.leyou.com/3.jpg&quot; } } ] }} 修改文档修改和新增是同一个接口，区分的依据就是id，这一点跟我们在页面发起PUT请求是类似的。 基本查询ElasticsearchRepository提供了一些基本的查询方法： 我们来试试查询所有： 1234567@Testpublic void testFind(){ // 查询全部，并按照价格降序排序 Iterable&lt;Item&gt; items = this.itemRepository.findAll(Sort.by(Sort.Direction.DESC, &quot;price&quot;)); // items.forEach(item-&gt; System.out.println(item)); items.forEach(System.out::println);} 结果： 自定义方法Spring Data 的另一个强大功能，是根据方法名称自动实现功能。 比如：你的方法名叫做：findByTitle，那么它就知道你是根据title查询，然后自动帮你完成，无需写实现类。 当然，方法名称要符合一定的约定： Keyword Sample Elasticsearch Query String And findByNameAndPrice {&quot;bool&quot; : {&quot;must&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;price&quot; : &quot;?&quot;}} ]}} Or findByNameOrPrice {&quot;bool&quot; : {&quot;should&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;price&quot; : &quot;?&quot;}} ]}} Is findByName {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}} Not findByNameNot {&quot;bool&quot; : {&quot;must_not&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}} Between findByPriceBetween {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} LessThanEqual findByPriceLessThan {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : null,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} GreaterThanEqual findByPriceGreaterThan {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : null,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} Before findByPriceBefore {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : null,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} After findByPriceAfter {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : null,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} Like findByNameLike {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;?*&quot;,&quot;analyze_wildcard&quot; : true}}}}} StartingWith findByNameStartingWith {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;?*&quot;,&quot;analyze_wildcard&quot; : true}}}}} EndingWith findByNameEndingWith {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;*?&quot;,&quot;analyze_wildcard&quot; : true}}}}} Contains/Containing findByNameContaining {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;**?**&quot;,&quot;analyze_wildcard&quot; : true}}}}} In findByNameIn(Collection&lt;String&gt;names) {&quot;bool&quot; : {&quot;must&quot; : {&quot;bool&quot; : {&quot;should&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}} ]}}}} NotIn findByNameNotIn(Collection&lt;String&gt;names) {&quot;bool&quot; : {&quot;must_not&quot; : {&quot;bool&quot; : {&quot;should&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}}}} Near findByStoreNear Not Supported Yet ! True findByAvailableTrue {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : true}}}} False findByAvailableFalse {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : false}}}} OrderBy findByAvailableTrueOrderByNameDesc {&quot;sort&quot; : [{ &quot;name&quot; : {&quot;order&quot; : &quot;desc&quot;} }],&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : true}}}} 例如，我们来按照价格区间查询，定义这样的一个方法： 12345678910public interface ItemRepository extends ElasticsearchRepository&lt;Item,Long&gt; { /** * 根据价格区间查询 * @param price1 * @param price2 * @return */ List&lt;Item&gt; findByPriceBetween(double price1, double price2);} 然后再多添加一些测试数据： 1234567891011@Testpublic void indexList() { List&lt;Item&gt; list = new ArrayList&lt;&gt;(); list.add(new Item(1L, &quot;小米手机7&quot;, &quot;手机&quot;, &quot;小米&quot;, 3299.00, &quot;http://image.leyou.com/13123.jpg&quot;)); list.add(new Item(2L, &quot;坚果手机R1&quot;, &quot;手机&quot;, &quot;锤子&quot;, 3699.00, &quot;http://image.leyou.com/13123.jpg&quot;)); list.add(new Item(3L, &quot;华为META10&quot;, &quot;手机&quot;, &quot;华为&quot;, 4499.00, &quot;http://image.leyou.com/13123.jpg&quot;)); list.add(new Item(4L, &quot;小米Mix2S&quot;, &quot;手机&quot;, &quot;小米&quot;, 4299.00, &quot;http://image.leyou.com/13123.jpg&quot;)); list.add(new Item(5L, &quot;荣耀V10&quot;, &quot;手机&quot;, &quot;华为&quot;, 2799.00, &quot;http://image.leyou.com/13123.jpg&quot;)); // 接收对象集合，实现批量新增 itemRepository.saveAll(list);} 不需要写实现类，然后我们直接去运行： 1234567@Testpublic void queryByPriceBetween(){ List&lt;Item&gt; list = this.itemRepository.findByPriceBetween(2000.00, 3500.00); for (Item item : list) { System.out.println(&quot;item = &quot; + item); }} 结果： 虽然基本查询和自定义方法已经很强大了，但是如果是复杂查询（模糊、通配符、词条查询等）就显得力不从心了。所以继续往下看。 高级查询高级查询中的基本查询先看看基本玩法 12345678@Testpublic void testQuery(){ // 词条查询 MatchQueryBuilder queryBuilder = QueryBuilders.matchQuery(&quot;title&quot;, &quot;小米&quot;); // 执行查询 Iterable&lt;Item&gt; items = this.itemRepository.search(queryBuilder); items.forEach(System.out::println);} Repository的search方法需要QueryBuilder参数，elasticSearch为我们提供了一个对象QueryBuilders： QueryBuilders提供了大量的静态方法，用于生成各种不同类型的查询对象，例如：词条、模糊、通配符等QueryBuilder对象。 结果： elasticsearch提供很多可用的查询方式，但是不够灵活。如果想玩过滤或者聚合查询等就很难了。 自定义查询看看ElasticsearchRepository的底层先： 123456789101112131415161718192021222324252627282930//// Source code recreated from a .class file by IntelliJ IDEA// (powered by Fernflower decompiler)//package org.springframework.data.elasticsearch.repository;import java.io.Serializable;import org.elasticsearch.index.query.QueryBuilder;import org.springframework.data.domain.Page;import org.springframework.data.domain.Pageable;import org.springframework.data.elasticsearch.core.query.SearchQuery;import org.springframework.data.repository.NoRepositoryBean;@NoRepositoryBeanpublic interface ElasticsearchRepository&lt;T, ID extends Serializable&gt; extends ElasticsearchCrudRepository&lt;T, ID&gt; { &lt;S extends T&gt; S index(S var1); Iterable&lt;T&gt; search(QueryBuilder var1); Page&lt;T&gt; search(QueryBuilder var1, Pageable var2); Page&lt;T&gt; search(SearchQuery var1); Page&lt;T&gt; searchSimilar(T var1, String[] var2, Pageable var3); void refresh(); Class&lt;T&gt; getEntityClass();} 先来看最基本的match query： 1234567891011121314@Testpublic void testNativeQuery(){ // 构建查询条件 NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 添加基本的分词查询 queryBuilder.withQuery(QueryBuilders.matchQuery(&quot;title&quot;, &quot;小米&quot;)); // 执行搜索，获取结果 Page&lt;Item&gt; items = this.itemRepository.search(queryBuilder.build()); // 打印总条数 System.out.println(items.getTotalElements()); // 打印总页数 System.out.println(items.getTotalPages()); items.forEach(System.out::println);} this.itemRepository.search()中传入的是queryBuilder.build()，这里用到的就是上面底层代码中的第四个方法，Page&lt;T&gt; search(SearchQuery var1);，在这里，queryBuilder.build();正常返回的是NativeSearchQuery的对象，而NativeSearchQuery类正是SearchQuery接口的实现类。 NativeSearchQueryBuilder：Spring提供的一个查询条件构建器，帮助构建json格式的请求体。 Page&lt;item&gt;：默认是分页查询，因此返回的是一个分页的结果对象，包含属性： totalElements：总条数 totalPages：总页数 Iterator：迭代器，本身实现了Iterator接口，因此可直接迭代得到当前页的数据 其它属性： 结果 分页查询利用NativeSearchQueryBuilder可以方便的实现分页： 12345678910111213141516171819202122232425@Testpublic void testNativeQuery(){ // 构建查询条件 NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 添加基本的分词查询 queryBuilder.withQuery(QueryBuilders.termQuery(&quot;category&quot;, &quot;手机&quot;)); // 初始化分页参数 int page = 0; int size = 3; // 设置分页参数 queryBuilder.withPageable(PageRequest.of(page, size)); // 执行搜索，获取结果 Page&lt;Item&gt; items = this.itemRepository.search(queryBuilder.build()); // 打印总条数 System.out.println(items.getTotalElements()); // 打印总页数 System.out.println(items.getTotalPages()); // 每页大小 System.out.println(items.getSize()); // 当前页 System.out.println(items.getNumber()); items.forEach(System.out::println);} 结果： 可以发现，Elasticsearch中的分页是从第0页开始。 排序排序也通用通过NativeSearchQueryBuilder完成： 12345678910111213141516@Testpublic void testSort(){ // 构建查询条件 NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 添加基本的分词查询 queryBuilder.withQuery(QueryBuilders.termQuery(&quot;category&quot;, &quot;手机&quot;)); // 排序 queryBuilder.withSort(SortBuilders.fieldSort(&quot;price&quot;).order(SortOrder.DESC)); // 执行搜索，获取结果 Page&lt;Item&gt; items = this.itemRepository.search(queryBuilder.build()); // 打印总条数 System.out.println(items.getTotalElements()); items.forEach(System.out::println);} 结果： 聚合聚合为桶桶就是分组，比如这里我们按照品牌brand进行分组： 12345678910111213141516171819202122232425@Testpublic void testAgg(){ NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 不查询任何结果 queryBuilder.withSourceFilter(new FetchSourceFilter(new String[]{&quot;&quot;}, null)); // 1、添加一个新的聚合，聚合类型为terms，聚合名称为brands，聚合字段为brand queryBuilder.addAggregation( AggregationBuilders.terms(&quot;brands&quot;).field(&quot;brand&quot;)); // 2、查询,需要把结果强转为AggregatedPage类型 AggregatedPage&lt;Item&gt; aggPage = (AggregatedPage&lt;Item&gt;) this.itemRepository.search(queryBuilder.build()); // 3、解析 // 3.1、从结果中取出名为brands的那个聚合， // 因为是利用String类型字段来进行的term聚合，所以结果要强转为StringTerm类型 StringTerms agg = (StringTerms) aggPage.getAggregation(&quot;brands&quot;); // 3.2、获取桶 List&lt;StringTerms.Bucket&gt; buckets = agg.getBuckets(); // 3.3、遍历 for (StringTerms.Bucket bucket : buckets) { // 3.4、获取桶中的key，即品牌名称 System.out.println(bucket.getKeyAsString()); // 3.5、获取桶中的文档数量 System.out.println(bucket.getDocCount()); }} 显示的结果： 关键API： AggregationBuilders：聚合的构建工厂类。所有聚合都由这个类来构建，看看他的静态方法： AggregatedPage：聚合查询的结果类。它是Page&lt;T&gt;的子接口： AggregatedPage在Page功能的基础上，拓展了与聚合相关的功能，它其实就是对聚合结果的一种封装，大家可以对照聚合结果的JSON结构来看。 而返回的结果都是Aggregation类型对象，不过根据字段类型不同，又有不同的子类表示 我们看下页面的查询的JSON结果与Java类的对照关系： 嵌套聚合，求平均值代码： 1234567891011121314151617181920212223242526272829@Testpublic void testSubAgg(){ NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 不查询任何结果 queryBuilder.withSourceFilter(new FetchSourceFilter(new String[]{&quot;&quot;}, null)); // 1、添加一个新的聚合，聚合类型为terms，聚合名称为brands，聚合字段为brand queryBuilder.addAggregation( AggregationBuilders.terms(&quot;brands&quot;).field(&quot;brand&quot;) .subAggregation(AggregationBuilders.avg(&quot;priceAvg&quot;).field(&quot;price&quot;)) // 在品牌聚合桶内进行嵌套聚合，求平均值 ); // 2、查询,需要把结果强转为AggregatedPage类型 AggregatedPage&lt;Item&gt; aggPage = (AggregatedPage&lt;Item&gt;) this.itemRepository.search(queryBuilder.build()); // 3、解析 // 3.1、从结果中取出名为brands的那个聚合， // 因为是利用String类型字段来进行的term聚合，所以结果要强转为StringTerm类型 StringTerms agg = (StringTerms) aggPage.getAggregation(&quot;brands&quot;); // 3.2、获取桶 List&lt;StringTerms.Bucket&gt; buckets = agg.getBuckets(); // 3.3、遍历 for (StringTerms.Bucket bucket : buckets) { // 3.4、获取桶中的key，即品牌名称 3.5、获取桶中的文档数量 System.out.println(bucket.getKeyAsString() + &quot;，共&quot; + bucket.getDocCount() + &quot;台&quot;); // 3.6.获取子聚合结果： InternalAvg avg = (InternalAvg) bucket.getAggregations().asMap().get(&quot;priceAvg&quot;); System.out.println(&quot;平均售价：&quot; + avg.getValue()); }} 结果： 集群单机的elasticsearch做数据存储，必然面临两个问题：海量数据存储问题、单点故障问题。 海量数据存储问题：将索引库从逻辑上拆分为N个分片（shard），存储到多个节点 单点故障问题：将分片数据在不同节点备份（replica ） ES集群相关概念: 集群（cluster）：一组拥有共同的 cluster name 的 节点。 节点（node) ：集群中的一个 Elasticearch 实例 分片（shard）：索引可以被拆分为不同的部分进行存储，称为分片。在集群环境下，一个索引的不同分片可以拆分到不同的节点中 解决问题：数据量太大，单点存储量有限的问题。 此处，我们把数据分成3片：shard0、shard1、shard2 主分片（Primary shard）：相对于副本分片的定义。 副本分片（Replica shard）每个主分片可以有一个或者多个副本，数据和主分片一样。 ​ 数据备份可以保证高可用，但是每个分片备份一份，所需要的节点数量就会翻一倍，成本实在是太高了！ 为了在高可用和成本间寻求平衡，我们可以这样做： 首先对数据分片，存储到不同节点 然后对每个分片进行备份，放到对方节点，完成互相备份 这样可以大大减少所需要的服务节点数量，如图，我们以3分片，每个分片备份一份为例： 现在，每个分片都有1个备份，存储在3个节点： node0：保存了分片0和1 node1：保存了分片0和2 node2：保存了分片1和2 搭建ES集群参考：https://chanservy.github.io/posts/20220611/elasticsearch-install.html#%E9%83%A8%E7%BD%B2es%E9%9B%86%E7%BE%A4 集群脑裂问题集群职责划分elasticsearch中集群节点有不同的职责划分： 默认情况下，集群中的任何一个节点都同时具备上述四种角色。 但是真实的集群一定要将集群职责分离： master节点：对CPU要求高，但是内存要求第 data节点：对CPU和内存要求都高 coordinating节点：对网络带宽、CPU要求高 职责分离可以让我们根据不同节点的需求分配不同的硬件去部署。而且避免业务之间的互相干扰。 一个典型的es集群职责划分如图： 脑裂问题脑裂是因为集群中的节点失联导致的。 例如一个集群中，主节点与其它节点失联： 此时，node2和node3认为node1宕机，就会重新选主： 当node3当选后，集群继续对外提供服务，node2和node3自成集群，node1自成集群，两个集群数据不同步，出现数据差异。 当网络恢复后，因为集群中有两个master节点，集群状态的不一致，出现脑裂的情况： 解决脑裂的方案是，要求选票超过 ( eligible节点数量 + 1 ）/ 2 才能当选为主，因此eligible节点数量最好是奇数。对应配置项是discovery.zen.minimum_master_nodes，在es7.0以后，已经成为默认配置，因此一般不会发生脑裂问题 例如：3个节点形成的集群，选票必须超过 （3 + 1） / 2 ，也就是2票。node3得到node2和node3的选票，当选为主。node1只有自己1票，没有当选。集群中依然只有1个主节点，没有出现脑裂。 小结master eligible节点的作用是什么？ 参与集群选主 主节点可以管理集群状态、管理分片信息、处理创建和删除索引库的请求 data节点的作用是什么？ 数据的CRUD coordinator节点的作用是什么？ 路由请求到其它节点 合并查询到的结果，返回给用户 集群分布式存储当新增文档时，应该保存到不同分片，保证数据均衡，那么coordinating node如何确定数据该存储到哪个分片呢？ 分片存储测试插入三条数据： 测试可以看到，三条数据分别在不同分片： 结果： 分片存储原理elasticsearch会通过hash算法来计算文档应该存储到哪个分片： 说明： _routing默认是文档的id 算法与分片数量有关，因此索引库一旦创建，分片数量不能修改！ 新增文档的流程如下： 解读： 1）新增一个id=1的文档 2）对id做hash运算，假如得到的是2，则应该存储到shard-2 3）shard-2的主分片在node3节点，将数据路由到node3 4）保存文档 5）同步给shard-2的副本replica-2，在node2节点 6）返回结果给coordinating-node节点 集群分布式查询elasticsearch的查询分成两个阶段： scatter phase：分散阶段，coordinating node会把请求分发到每一个分片 gather phase：聚集阶段，coordinating node汇总data node的搜索结果，并处理为最终结果集返回给用户 集群故障转移集群的master节点会监控集群中的节点状态，如果发现有节点宕机，会立即将宕机节点的分片数据迁移到其它节点，确保数据安全，这个叫做故障转移。 1）例如一个集群结构如图： 现在，node1是主节点，其它两个节点是从节点。 2）突然，node1发生了故障： 宕机后的第一件事，需要重新选主，例如选中了node2： node2成为主节点后，会检测集群监控状态，发现：shard-1、shard-0没有副本节点。因此需要将node1上的数据迁移到node2、node3： 博客中的案例代码： https://github.com/ChanServy/hotel_admin https://github.com/ChanServy/hotel_demo Over!!!","link":"/posts/20220409/elasticsearch-study.html"},{"title":"RabbitMQ部署指南","text":"单机部署我们在Centos7虚拟机中使用Docker来安装。 下载镜像在线拉取 1docker pull rabbitmq:3.8-management 安装MQ执行下面的命令来运行MQ容器： 12345678910docker run \\ -e RABBITMQ_DEFAULT_USER=itcast \\ -e RABBITMQ_DEFAULT_PASS=123321 \\ -v mq-plugins:/plugins \\ --name mq \\ --hostname mq1 \\ -p 15672:15672 \\ -p 5672:5672 \\ -d \\ rabbitmq:3.8-management 安装DelayExchange插件官方的安装指南地址为：https://blog.rabbitmq.com/posts/2015/04/scheduling-messages-with-rabbitmq 上述文档是基于linux原生安装RabbitMQ，然后安装插件。 因为我们之前是基于Docker安装RabbitMQ，所以下面我们会讲解基于Docker来安装RabbitMQ插件。 下载插件RabbitMQ有一个官方的插件社区，地址为：https://www.rabbitmq.com/community-plugins.html 其中包含各种各样的插件，包括我们要使用的DelayExchange插件： 大家可以去对应的GitHub页面下载3.8.9版本的插件，地址为https://github.com/rabbitmq/rabbitmq-delayed-message-exchange/releases/tag/3.8.9这个对应RabbitMQ的3.8.5以上版本。 上传插件因为我们是基于Docker安装，所以需要先查看RabbitMQ的插件目录对应的数据卷。 我们之前设定的RabbitMQ的数据卷名称为mq-plugins，所以我们使用下面命令查看数据卷： 1docker volume inspect mq-plugins 可以得到下面结果： 接下来，将插件上传到这个目录即可： 安装插件最后就是安装了，需要进入MQ容器内部来执行安装。我的容器名为mq，所以执行下面命令： 1docker exec -it mq bash 执行时，请将其中的 -it 后面的mq替换为你自己的容器名。 进入容器内部后，执行下面命令开启插件： 1rabbitmq-plugins enable rabbitmq_delayed_message_exchange 结果如下： 集群部署接下来，我们看看如何安装RabbitMQ的集群。 集群分类在RabbitMQ的官方文档中，讲述了两种集群的配置方式： 普通模式：普通模式集群不进行数据同步，每个MQ都有自己的队列、数据信息（其它元数据信息如交换机等会同步）。例如我们有2个MQ：mq1，和mq2，如果你的消息在mq1，而你连接到了mq2，那么mq2会去mq1拉取消息，然后返回给你。如果mq1宕机，消息就会丢失。 镜像模式：与普通模式不同，队列会在各个mq的镜像节点之间同步，因此你连接到任何一个镜像节点，均可获取到消息。而且如果一个节点宕机，并不会导致数据丢失。不过，这种方式增加了数据同步的带宽消耗。 我们先来看普通模式集群，我们的计划部署3节点的mq集群： 主机名 控制台端口 amqp通信端口 mq1 8081 —&gt; 15672 8071 —&gt; 5672 mq2 8082 —&gt; 15672 8072 —&gt; 5672 mq3 8083 —&gt; 15672 8073 —&gt; 5672 集群中的节点标示默认都是：rabbit@[hostname]，因此以上三个节点的名称分别为： rabbit@mq1 rabbit@mq2 rabbit@mq3 获取cookieRabbitMQ底层依赖于Erlang，而Erlang虚拟机就是一个面向分布式的语言，默认就支持集群模式。集群模式中的每个RabbitMQ 节点使用 cookie 来确定它们是否被允许相互通信。 要使两个节点能够通信，它们必须具有相同的共享秘密，称为Erlang cookie。cookie 只是一串最多 255 个字符的字母数字字符。 每个集群节点必须具有相同的 cookie。实例之间也需要它来相互通信。 我们先在之前启动的mq容器中获取一个cookie值，作为集群的cookie。执行下面的命令： 1docker exec -it mq cat /var/lib/rabbitmq/.erlang.cookie 可以看到cookie值如下： 1FXZMCVGLBIXZCDEMMVZQ 接下来，停止并删除当前的mq容器，我们重新搭建集群。 1docker rm -f mq 准备集群配置在/tmp目录新建一个配置文件 rabbitmq.conf： 123cd /tmp# 创建文件touch rabbitmq.conf 文件内容如下： 123456loopback_users.guest = falselisteners.tcp.default = 5672cluster_formation.peer_discovery_backend = rabbit_peer_discovery_classic_configcluster_formation.classic_config.nodes.1 = rabbit@mq1cluster_formation.classic_config.nodes.2 = rabbit@mq2cluster_formation.classic_config.nodes.3 = rabbit@mq3 再创建一个文件，记录cookie 1234567cd /tmp# 创建cookie文件touch .erlang.cookie# 写入cookieecho &quot;FXZMCVGLBIXZCDEMMVZQ&quot; &gt; .erlang.cookie# 修改cookie文件的权限chmod 600 .erlang.cookie 准备三个目录,mq1、mq2、mq3： 123cd /tmp# 创建目录mkdir mq1 mq2 mq3 然后拷贝rabbitmq.conf、cookie文件到mq1、mq2、mq3： 123456789# 进入/tmpcd /tmp# 拷贝cp rabbitmq.conf mq1cp rabbitmq.conf mq2cp rabbitmq.conf mq3cp .erlang.cookie mq1cp .erlang.cookie mq2cp .erlang.cookie mq3 启动集群创建一个网络： 1docker network create mq-net docker volume create 运行命令 12345678910docker run -d --net mq-net \\-v ${PWD}/mq1/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf \\-v ${PWD}/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \\-e RABBITMQ_DEFAULT_USER=itcast \\-e RABBITMQ_DEFAULT_PASS=123321 \\--name mq1 \\--hostname mq1 \\-p 8071:5672 \\-p 8081:15672 \\rabbitmq:3.8-management 12345678910docker run -d --net mq-net \\-v ${PWD}/mq2/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf \\-v ${PWD}/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \\-e RABBITMQ_DEFAULT_USER=itcast \\-e RABBITMQ_DEFAULT_PASS=123321 \\--name mq2 \\--hostname mq2 \\-p 8072:5672 \\-p 8082:15672 \\rabbitmq:3.8-management 12345678910docker run -d --net mq-net \\-v ${PWD}/mq3/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf \\-v ${PWD}/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \\-e RABBITMQ_DEFAULT_USER=itcast \\-e RABBITMQ_DEFAULT_PASS=123321 \\--name mq3 \\--hostname mq3 \\-p 8073:5672 \\-p 8083:15672 \\rabbitmq:3.8-management 测试在mq1这个节点上添加一个队列： 如图，在mq2和mq3两个控制台也都能看到： 数据共享测试点击这个队列，进入管理页面： 然后利用控制台发送一条消息到这个队列： 结果在mq2、mq3上都能看到这条消息： 可用性测试我们让其中一台节点mq1宕机： 1docker stop mq1 然后登录mq2或mq3的控制台，发现simple.queue也不可用了： 说明数据并没有拷贝到mq2和mq3。 镜像模式在刚刚的案例中，一旦创建队列的主机宕机，队列就会不可用。不具备高可用能力。如果要解决这个问题，必须使用官方提供的镜像集群方案。 官方文档地址：https://www.rabbitmq.com/ha.html 镜像模式的特征默认情况下，队列只保存在创建该队列的节点上。而镜像模式下，创建队列的节点被称为该队列的主节点，队列还会拷贝到集群中的其它节点，也叫做该队列的镜像节点。 但是，不同队列可以在集群中的任意节点上创建，因此不同队列的主节点可以不同。甚至，一个队列的主节点可能是另一个队列的镜像节点。 用户发送给队列的一切请求，例如发送消息、消息回执默认都会在主节点完成，如果是从节点接收到请求，也会路由到主节点去完成。镜像节点仅仅起到备份数据作用。 当主节点接收到消费者的ACK时，所有镜像都会删除节点中的数据。 总结如下： 镜像队列结构是一主多从（从就是镜像） 所有操作都是主节点完成，然后同步给镜像节点 主宕机后，镜像节点会替代成新的主（如果在主从同步完成前，主就已经宕机，可能出现数据丢失） 不具备负载均衡功能，因为所有操作都会有主节点完成（但是不同队列，其主节点可以不同，可以利用这个提高吞吐量） 镜像模式的配置镜像模式的配置有3种模式： ha-mode ha-params 效果 准确模式exactly 队列的副本量count 集群中队列副本（主服务器和镜像服务器之和）的数量。count如果为1意味着单个副本：即队列主节点。count值为2表示2个副本：1个队列主和1个队列镜像。换句话说：count = 镜像数量 + 1。如果群集中的节点数少于count，则该队列将镜像到所有节点。如果有集群总数大于count+1，并且包含镜像的节点出现故障，则将在另一个节点上创建一个新的镜像。 all (none) 队列在群集中的所有节点之间进行镜像。队列将镜像到任何新加入的节点。镜像到所有节点将对所有群集节点施加额外的压力，包括网络I / O，磁盘I / O和磁盘空间使用情况。推荐使用exactly，设置副本数为（N / 2 +1）。 nodes node names 指定队列创建到哪些节点，如果指定的节点全部不存在，则会出现异常。如果指定的节点在集群中存在，但是暂时不可用，会创建节点到当前客户端连接到的节点。 这里我们以rabbitmqctl命令作为案例来讲解配置语法。 语法示例： exactly模式1rabbitmqctl set_policy ha-two &quot;^two\\.&quot; '{&quot;ha-mode&quot;:&quot;exactly&quot;,&quot;ha-params&quot;:2,&quot;ha-sync-mode&quot;:&quot;automatic&quot;}' rabbitmqctl set_policy：固定写法 ha-two：策略名称，自定义 &quot;^two\\.&quot;：匹配队列的正则表达式，符合命名规则的队列才生效，这里是任何以two.开头的队列名称 '{&quot;ha-mode&quot;:&quot;exactly&quot;,&quot;ha-params&quot;:2,&quot;ha-sync-mode&quot;:&quot;automatic&quot;}': 策略内容 &quot;ha-mode&quot;:&quot;exactly&quot;：策略模式，此处是exactly模式，指定副本数量 &quot;ha-params&quot;:2：策略参数，这里是2，就是副本数量为2，1主1镜像 &quot;ha-sync-mode&quot;:&quot;automatic&quot;：同步策略，默认是manual，即新加入的镜像节点不会同步旧的消息。如果设置为automatic，则新加入的镜像节点会把主节点中所有消息都同步，会带来额外的网络开销 all模式1rabbitmqctl set_policy ha-all &quot;^all\\.&quot; '{&quot;ha-mode&quot;:&quot;all&quot;}' ha-all：策略名称，自定义 &quot;^all\\.&quot;：匹配所有以all.开头的队列名 '{&quot;ha-mode&quot;:&quot;all&quot;}'：策略内容 &quot;ha-mode&quot;:&quot;all&quot;：策略模式，此处是all模式，即所有节点都会称为镜像节点 nodes模式1rabbitmqctl set_policy ha-nodes &quot;^nodes\\.&quot; '{&quot;ha-mode&quot;:&quot;nodes&quot;,&quot;ha-params&quot;:[&quot;rabbit@nodeA&quot;, &quot;rabbit@nodeB&quot;]}' rabbitmqctl set_policy：固定写法 ha-nodes：策略名称，自定义 &quot;^nodes\\.&quot;：匹配队列的正则表达式，符合命名规则的队列才生效，这里是任何以nodes.开头的队列名称 '{&quot;ha-mode&quot;:&quot;nodes&quot;,&quot;ha-params&quot;:[&quot;rabbit@nodeA&quot;, &quot;rabbit@nodeB&quot;]}': 策略内容 &quot;ha-mode&quot;:&quot;nodes&quot;：策略模式，此处是nodes模式 &quot;ha-params&quot;:[&quot;rabbit@mq1&quot;, &quot;rabbit@mq2&quot;]：策略参数，这里指定副本所在节点名称 测试我们使用exactly模式的镜像，因为集群节点数量为3，因此镜像数量就设置为2. 运行下面的命令： 1docker exec -it mq1 rabbitmqctl set_policy ha-two &quot;^two\\.&quot; '{&quot;ha-mode&quot;:&quot;exactly&quot;,&quot;ha-params&quot;:2,&quot;ha-sync-mode&quot;:&quot;automatic&quot;}' 下面，我们创建一个新的队列： 在任意一个mq控制台查看队列： 测试数据共享给two.queue发送一条消息： 然后在mq1、mq2、mq3的任意控制台查看消息： 测试高可用现在，我们让two.queue的主节点mq1宕机： 1docker stop mq1 查看集群状态： 查看队列状态： 发现依然是健康的！并且其主节点切换到了rabbit@mq2上 仲裁队列从RabbitMQ 3.8版本开始，引入了新的仲裁队列，他具备与镜像队里类似的功能，但使用更加方便。 添加仲裁队列在任意控制台添加一个队列，一定要选择队列类型为Quorum类型。 在任意控制台查看队列： 可以看到，仲裁队列的 + 2字样。代表这个队列有2个镜像节点。 因为仲裁队列默认的镜像数为5。如果你的集群有7个节点，那么镜像数肯定是5；而我们集群只有3个节点，因此镜像数量就是3. 测试可以参考对镜像集群的测试，效果是一样的。 集群扩容加入集群1）启动一个新的MQ容器： 123456789docker run -d --net mq-net \\-v ${PWD}/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \\-e RABBITMQ_DEFAULT_USER=itcast \\-e RABBITMQ_DEFAULT_PASS=123321 \\--name mq4 \\--hostname mq5 \\-p 8074:15672 \\-p 8084:15672 \\rabbitmq:3.8-management 2）进入容器控制台： 1docker exec -it mq4 bash 3）停止mq进程 1rabbitmqctl stop_app 4）重置RabbitMQ中的数据： 1rabbitmqctl reset 5）加入mq1： 1rabbitmqctl join_cluster rabbit@mq1 6）再次启动mq进程 1rabbitmqctl start_app 增加仲裁队列副本我们先查看下quorum.queue这个队列目前的副本情况，进入mq1容器： 1docker exec -it mq1 bash 执行命令： 1rabbitmq-queues quorum_status &quot;quorum.queue&quot; 结果： 现在，我们让mq4也加入进来： 1rabbitmq-queues add_member &quot;quorum.queue&quot; &quot;rabbit@mq4&quot; 结果： 再次查看： 1rabbitmq-queues quorum_status &quot;quorum.queue&quot; 查看控制台，发现quorum.queue的镜像数量也从原来的 +2 变成了 +3：","link":"/posts/20220622/rabbitmq-install.html"},{"title":"Redis基础命令用法","text":"基本指令操作指令读写数据： 设置 key，value 数据： 12set key value#set name seazean 根据 key 查询对应的 value，如果不存在，返回空（nil）： 12get key#get name 帮助信息： 获取命令帮助文档 12help [command]#help set 获取组中所有命令信息名称 12help [@group-name]#help @string 退出服务 退出客户端： 12quitexit 退出客户端服务器快捷键： 1Ctrl+C key 指令key 是一个字符串，通过 key 获取 redis 中保存的数据 基本操作 12345678del key #删除指定keyunlink key #非阻塞删除key，真正的删除会在后续异步操作exists key #获取key是否存在type key #获取key的类型sort key [ASC/DESC] #对key中数据排序，默认对数字排序，并不更改集合中的数据位置，只是查询sort key alpha #对key中字母排序rename key newkey #改名renamenx key newkey #改名 时效性控制 123456789expire key seconds #为指定key设置有效期，单位为秒pexpire key milliseconds #为指定key设置有效期，单位为毫秒expireat key timestamp #为指定key设置有效期，单位为时间戳pexpireat key mil-timestamp #为指定key设置有效期，单位为毫秒时间戳ttl key #获取key的有效时间，每次获取会自动变化(减小)，类似于倒计时， #-1代表永久性，-2代表不存在/失效pttl key #获取key的有效时间，单位是毫秒，每次获取会自动变化(减小)persist key #切换key从时效性转换为永久性 查询模式 1keys pattern #查询key 查询模式规则：*匹配任意数量的任意符号；?配合一个任意符号；[]匹配一个指定符号 123456keys * #查询所有keykeys aa* #查询所有以aa开头keys *bb #查询所有以bb结尾keys ??cc #查询所有前面两个字符任意，后面以cc结尾 keys user:? #查询所有以user:开头，最后一个字符任意keys u[st]er:1 #查询所有以u开头，以er:1结尾，中间包含一个字母，s或t DB 指令Redis 在使用过程中，随着操作数据量的增加，会出现大量的数据以及对应的 key，数据不区分种类、类别混在一起，容易引起重复或者冲突，所以 Redis 为每个服务提供 16 个数据库，编码 0-15，每个数据库之间相互独立，**共用 **Redis 内存，不区分大小 基本操作 123select index #切换数据库，index从0-15取值ping #测试数据库是否连接正常，返回PONGecho message #控制台输出信息 扩展操作 1234move key db #数据移动到指定数据库，db是数据库编号dbsize #获取当前数据库的数据总量，即key的个数flushdb #清除当前数据库的所有数据flushall #清除所有数据 通信指令Redis 发布订阅（pub/sub）是一种消息通信模式：发送者（pub）发送消息，订阅者（sub）接收消息。 Redis 客户端可以订阅任意数量的频道 操作命令： 打开一个客户端订阅 channel1：SUBSCRIBE channel1 打开另一个客户端，给 channel1发布消息 hello：publish channel1 hello 第一个客户端可以看到发送的消息 注意：发布的消息没有持久化，所以订阅的客户端只能收到订阅后发布的消息 ACL 指令Redis ACL 是 Access Control List（访问控制列表）的缩写，该功能允许根据可以执行的命令和可以访问的键来限制某些连接 acl cat：查看添加权限指令类别 acl whoami：查看当前用户 acl setuser username on &gt;password ~cached:* +get：设置有用户名、密码、ACL 权限（只能 get） 数据类型注：Redis 中存储的是 key-value 形式的数据，并且 Redis 中的 key 永远都是 String 类型的，因此以下的几种数据类型都是针对 value 的！不要搞混了！ String简介String类型，也就是字符串类型，是Redis中最简单的存储类型。其value是字符串，不过根据字符串的格式不同，又可以分为3类： string：普通字符串 int：整数类型，可以做自增、自减操作 float：浮点类型，可以做自增、自减操作 不管是哪种格式，底层都是字节数组形式存储，只不过是编码方式不同。字符串类型的最大空间不能超过512m。 存储的数据：单个数据，是最简单的数据存储类型，也是最常用的数据存储类型，实质上是存一个字符串。string 类型是二进制安全的，意味着 Redis 的 string 可以包含任何数据，比如图片或者序列化的对象 存储数据的格式：一个存储空间保存一个数据，每一个空间中只能保存一个字符串信息 存储内容：通常使用字符串，如果字符串以整数的形式展示，可以作为数字操作使用 Redis 所有操作都是原子性的，采用单线程机制，命令是单个顺序执行，无需考虑并发带来影响，原子性就是有一个失败则都失败。 操作指令操作： 数据操作： 12345set key value #添加/修改数据添加/修改数据del key #删除数据setnx key value #判定性添加数据，键值为空则添加，如果这个键原先存在就不会添加、不会覆盖mset k1 v1 k2 v2... #添加/修改多个数据，m：Multipleappend key value #追加信息到原始信息后部（如果原始信息存在就追加，否则新建） 查询操作 123get key #获取数据mget key1 key2... #获取多个数据strlen key #获取数据字符个数（字符串长度） 设置数值数据增加/减少指定范围的值 12345incr key #key++incrby key increment #key+incrementincrbyfloat key increment #对小数操作decr key #key--decrby key increment #key-increment 设置数据具有指定的生命周期 12setex key seconds value #设置key-value存活时间，seconds单位是秒psetex key milliseconds value #毫秒级 注意事项： 数据操作不成功的反馈与数据正常操作之间的差异 表示运行结果是否成功(integer) 0 → false 失败 (integer) 1 → true 成功 表示运行结果值(integer) 3 → 3 3个 (integer) 1 → 1 1个 数据未获取到时，对应的数据为（nil），等同于null 数据最大存储量：512MB string 在 Redis 内部存储默认就是一个字符串，当遇到增减类操作 incr，decr 时会转成数值型进行计算 按数值进行操作的数据，如果原始数据不能转成数值，或超越了Redis 数值上限范围，将报错9223372036854775807（java 中 Long 型数据最大值，Long.MAX_VALUE） Redis 可用于控制数据库表主键 ID，为数据库表主键提供生成策略，保障数据库表的主键唯一性 应用主页高频访问信息显示控制，例如新浪微博大 V 主页显示粉丝数与微博数量 在 Redis 中为大 V 用户设定用户信息，以用户主键和属性值作为 key，后台设定定时刷新策略 123set user:id:3506728370:fans 12210947set user:id:3506728370:blogs 6164set user:id:3506728370:focuses 83 使用 JSON 格式保存数据 1user:id:3506728370 → {&quot;fans&quot;:12210947,&quot;blogs&quot;:6164,&quot;focuses&quot;:83} key的设置约定：表名 : 主键名 : 主键值 : 字段名 表名 主键名 主键值 字段名 order id 29437595 name equip id 390472345 type news id 202004150 title 实现Redis 字符串对象底层的数据结构实现主要是 int 和简单动态字符串 SDS，是可以修改的字符串，内部结构实现上类似于 Java 的 ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配 123456789struct sdshdr{ //记录buf数组中已使用字节的数量 //等于 SDS 保存字符串的长度 int len; //记录 buf 数组中未使用字节的数量 int free; //字节数组，用于保存字符串 char buf[];} 内部为当前字符串实际分配的空间 capacity 一般要高于实际字符串长度 len，当字符串长度小于 1M 时，扩容都是双倍现有的空间，如果超过 1M，扩容时一次只会多扩 1M 的空间，需要注意的是字符串最大长度为 512M。 详解请参考文章：https://www.cnblogs.com/hunternet/p/9957913.html Hash简介Hash 类型，也叫散列，类似于 Java 中的 HashMap 结构。String 结构是将对象序列化为 JSON 字符串后存储，当需要修改对象某个字段时很不方便。Hash 结构可以将对象中的每个字段独立存储，可以针对单个字段做 CRUD。 数据存储需求：对一系列存储的数据进行编组，方便管理，典型应用存储对象信息 数据存储结构：一个存储空间保存多个键值对数据 hash 类型：底层使用哈希表结构实现数据存储 Redis 中的 hash 整体类似于 Java 中的 Map&lt;String, Map&lt;Object,object&gt;&gt;，左边是 key，右边是值，中间叫 field 字段，本质上 hash 存了一个 key-value 的存储空间 hash 是指的一个数据类型，并不是一个数据 如果 field 数量较少，存储结构优化为压缩列表结构（有序） 如果 field 数量较多，存储结构使用 HashMap 结构（无序） 操作指令操作： 数据操作 1234hset key field value #添加/修改数据hdel key field1 [field2] #删除数据，[]代表可选hsetnx key field value #设置field的值，如果该field存在则不做任何操作hmset key f1 v1 f2 v2... #添加/修改多个数据 查询操作 12345hget key field #获取指定field对应数据hgetall key #获取指定key所有数据hmget key field1 field2... #获取多个数据hexists key field #获取哈希表中是否存在指定的字段hlen key #获取哈希表中字段的数量 获取哈希表中所有的字段名或字段值 12hkeys key #获取所有的field hvals key #获取所有的value 设置指定字段的数值数据增加指定范围的值 12hincrby key field increment #指定字段的数值数据增加指定的值，increment为负数则减少hincrbyfloat key field increment #操作小数 注意事项 hash 类型中 value 只能存储字符串，不允许存储其他数据类型，不存在嵌套现象，如果数据未获取到，对应的值为（nil） 每个 hash 可以存储 2^32 - 1 个键值对 hash 类型和对象的数据存储形式相似，并且可以灵活添加删除对象属性。但 hash 设计初衷不是为了存储大量对象而设计的，不可滥用，不可将 hash 作为对象列表使用 hgetall 操作可以获取全部属性，如果内部 field 过多，遍历整体数据效率就很会低，有可能成为数据访问瓶颈 123456789101112131415161718192021222324252627282930313233343536373839404142127.0.0.1:6379&gt; hset stu name chan(integer) 1127.0.0.1:6379&gt; hset stu age 22(integer) 1127.0.0.1:6379&gt; hset stu score 98(integer) 1127.0.0.1:6379&gt; hgetall stu1) &quot;name&quot;2) &quot;chan&quot;3) &quot;age&quot;4) &quot;22&quot;5) &quot;score&quot;6) &quot;98&quot;127.0.0.1:6379&gt; hkeys stu1) &quot;name&quot;2) &quot;age&quot;3) &quot;score&quot;127.0.0.1:6379&gt; hvals stu1) &quot;chan&quot;2) &quot;22&quot;3) &quot;98&quot;127.0.0.1:6379&gt; hincrby stu age 2(integer) 24127.0.0.1:6379&gt; hvals stu1) &quot;chan&quot;2) &quot;24&quot;3) &quot;98&quot;127.0.0.1:6379&gt; hsetnx stu name siyu(integer) 0127.0.0.1:6379&gt; hsetnx stu favorite game(integer) 1127.0.0.1:6379&gt; hvals stu1) &quot;chan&quot;2) &quot;24&quot;3) &quot;98&quot;4) &quot;game&quot;127.0.0.1:6379&gt; hkeys stu1) &quot;name&quot;2) &quot;age&quot;3) &quot;score&quot;4) &quot;favorite&quot;127.0.0.1:6379&gt; 应用1user:id:3506728370 → {&quot;name&quot;:&quot;春晚&quot;,&quot;fans&quot;:12210862,&quot;blogs&quot;:83} 对于以上数据，使用单条去存的话，存的条数会很多。但如果用 json 格式，存一条数据就够了。 假如现在只粉丝数量发生了变化，需要修改，使用 json 格式存储的话要把整个字符串替换，但是用单条存就不存在这个问题，只需要改其中粉丝数量就可以。 也可以实现购物车的功能，key 对应着每个用户，存储空间存储购物车的信息 实现底层结构哈希类型的内部编码有两种：ziplist（压缩列表）、hashtable（哈希表、字典） 当存储的数据量比较小的情况下，Redis 才使用压缩列表来实现字典类型，具体需要满足两个条件： 当键值对个数小于 hash-max-ziplist-entries 配置（默认 512 个） 每对键值都小于 hash-max-ziplist-value 配置（默认 64 字节） ziplist 使用更加紧凑的结构实现多个元素的连续存储，所以在节省内存方面比 hashtable 更加优秀，当 ziplist 无法满足哈希类型时，Redis 会使用 hashtable 作为哈希的内部实现，因为数据量过大时 ziplist 的读写效率会下降，而 hashtable 的读写时间复杂度为 O(1) 压缩列表压缩列表（ziplist）是列表和哈希的底层实现之一，压缩列表用来紧凑数据存储，节省内存，有序。 压缩列表是由一系列特殊编码的连续内存块组成的顺序型（sequential）数据结枃，一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。 哈希表Redis 字典使用散列表为底层实现，一个散列表里面有多个散列表节点，每个散列表节点就保存了字典中的一个键值对，发生哈希冲突采用链表法解决，存储无序。 为了避免散列表性能的下降，当装载因子大于 1 的时候，Redis 会触发扩容，将散列表扩大为原来大小的 2 倍左右 当数据动态减少之后，为了节省内存，当装载因子小于 0.1 的时候，Redis 就会触发缩容，缩小为字典中数据个数的 50% 左右 List简介Redis 中的 List 类型与 Java 中的 LinkedList 类似，可以看做是一个双向链表结构。既可以支持正向检索和也可以支持反向检索。 特征也与 LinkedList 类似： 有序 元素可以重复 插入和删除快 查询速度一般 常用来存储一个有序数据，例如：朋友圈点赞列表，评论列表等。 数据存储需求：存储多个数据，并对数据进入存储空间的顺序进行区分 数据存储结构：一个存储空间保存多个数据，且通过数据可以体现进入顺序，允许重复元素 list 类型：保存多个数据，底层使用双向链表存储结构实现，类似于 LinkedList 如果两端都能存取数据的话，这就是双端队列，如果只能从同一端进同一端出，这个模型叫栈 操作指令操作： 数据操作 12345lpush key value1 [value2]... #从左边添加/修改数据rpush key value1 [value2]... #从右边添加/修改数据lpop key #从左边获取并移除第一个数据，类似于出栈/出队，没有则返回nilrpop key #从右边获取并移除第一个数据，没有则返回nillrem key count value #删除指定数据，count=2删除2个，该value可能有多个(重复数据) 查询操作 123lrange key start stop #从左边遍历数据并指定开始和结束索引，0是第一个索引，-1是终索引lindex key index #获取指定索引数据，没有则为nil，没有索引则越界llen key #list中数据长度/个数 规定时间内获取并移除数据 1234b #b代表阻塞blpop key1 [key2] timeout #与LPOP和RPOP类似，只不过在没有元素时等待指定的时间，而不是直接返回nil，超时则为(nil) #可以从其他客户端写数据，当前客户端阻塞读取数据brpop key1 [key2] timeout #从右边操作 复制操作 1brpoplpush source destination timeout #从source获取数据放入destination，假如在指定时间内没有任何元素被弹出，则返回一个nil和等待时长。反之，返回一个含有两个元素的列表，第一个元素是被弹出元素的值，第二个元素是等待时长 注意事项 list 中保存的数据都是 string 类型的，数据总容量是有限的，最多 2^32 - 1 个元素（4294967295） list 具有索引的概念，但操作数据时通常以队列的形式进行入队出队，或以栈的形式进行入栈出栈 获取全部数据操作结束索引设置为 -1 list 可以对数据进行分页操作，通常第一页的信息来自于 list，第 2 页及更多的信息通过数据库的形式加载 练习： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162127.0.0.1:6379&gt; lpush names zhangsan lisi(integer) 2127.0.0.1:6379&gt; keys *1) &quot;name&quot;2) &quot;k2&quot;3) &quot;names&quot;4) &quot;stu&quot;5) &quot;user:1&quot;6) &quot;user:2&quot;127.0.0.1:6379&gt; get names(error) WRONGTYPE Operation against a key holding the wrong kind of value127.0.0.1:6379&gt; lrange names 0 -11) &quot;lisi&quot;2) &quot;zhangsan&quot;127.0.0.1:6379&gt; lpush names chan tom(integer) 4127.0.0.1:6379&gt; lrange names 0 -11) &quot;tom&quot;2) &quot;chan&quot;3) &quot;lisi&quot;4) &quot;zhangsan&quot;127.0.0.1:6379&gt; rpush names jerry(integer) 5127.0.0.1:6379&gt; lrange names 0 -11) &quot;tom&quot;2) &quot;chan&quot;3) &quot;lisi&quot;4) &quot;zhangsan&quot;5) &quot;jerry&quot;127.0.0.1:6379&gt; lpop names&quot;tom&quot;127.0.0.1:6379&gt; lrange names 0 -11) &quot;chan&quot;2) &quot;lisi&quot;3) &quot;zhangsan&quot;4) &quot;jerry&quot;127.0.0.1:6379&gt; rpop names&quot;jerry&quot;127.0.0.1:6379&gt; lrange names 0 -11) &quot;chan&quot;2) &quot;lisi&quot;3) &quot;zhangsan&quot;127.0.0.1:6379&gt; brpop names 51) &quot;names&quot;2) &quot;zhangsan&quot;127.0.0.1:6379&gt; lrange names 0 -11) &quot;chan&quot;2) &quot;lisi&quot;127.0.0.1:6379&gt; brpop names 51) &quot;names&quot;2) &quot;lisi&quot;127.0.0.1:6379&gt; lrange names 0 -11) &quot;chan&quot;127.0.0.1:6379&gt; brpop names 51) &quot;names&quot;2) &quot;chan&quot;127.0.0.1:6379&gt; lrange names 0 -1(empty array)127.0.0.1:6379&gt; brpop names 5(nil)(5.02s)127.0.0.1:6379&gt; 应用企业运营过程中，系统将产生出大量的运营数据，如何保障多台服务器操作日志的统一顺序输出？ 依赖 list 的数据具有顺序的特征对信息进行管理，右进左查或者左近左查 使用队列模型解决多路信息汇总合并的问题 使用栈模型解决最新消息的问题 微信文章订阅公众号： 比如订阅了两个公众号，它们发布了两篇文章，文章 ID 分别为 666 和 888，可以通过执行 LPUSH key 666 888 命令推送给我 实现底层结构在 Redis3.2 版本以前列表类型的内部编码有两种：ziplist（压缩列表）和 linkedlist（链表） 列表中存储的数据量比较小的时候，列表就会使用一块连续的内存存储，采用压缩列表的方式实现： 列表中保存的单个数据（有可能是字符串类型的）小于 64 字节 列表中数据个数少于 512 个 在 Redis3.2 版本以后对列表数据结构进行了改造，使用 quicklist（快速列表）代替了 linkedlist 链表结构Redis 链表为双向无环链表，使用 listNode 结构表示 123456789typedef struct listNode{ // 前置节点 struct listNode *prev; // 后置节点 struct listNode *next; // 节点的值 void *value; } listNode; 双向：链表节点带有前驱、后继指针，获取某个节点的前驱、后继节点的时间复杂度为 O(1) 无环：链表为非循环链表，表头节点的前驱指针和表尾节点的后继指针都指向 NULL，对链表的访问以 NULL 为终点 快速列表quicklist 实际上是 ziplist 和 linkedlist 的混合体，将 linkedlist 按段切分，每一段使用 ziplist 来紧凑存储，多个 ziplist 之间使用双向指针串接起来，既满足了快速的插入删除性能，又不会出现太大的空间冗余 Set简介Redis 的 Set 结构与 Java 中的 HashSet 类似，可以看做是一个 value 为 null 的 HashMap。因为也是一个 hash 表，因此具备与 HashSet 类似的特征： 无序 元素不可重复 查找快 支持交集、并集、差集等功能 数据存储需求：存储大量的数据，在查询方面提供更高的效率 数据存储结构：能够保存大量的数据，高效的内部存储机制，便于查询 set 类型：与 hash 存储结构哈希表完全相同，只是仅存储键不存储值（nil），所以添加，删除，查找的复杂度都是 O(1)，并且值是不允许重复且无序的。 操作指令操作： 数据操作 12sadd key member1 [member2] #添加数据srem key member1 [member2] #删除数据 查询操作 123smembers key #获取全部数据scard key #获取集合数据总量，返回set中数据的个数sismember key member #判断集合中是否包含指定数据 随机操作 12spop key [count] #随机获取集中的某个数据并将该数据移除集合srandmember key [count] #随机获取集合中指定(数量)的数据 集合的交、并、差 1234567sinter key1 [key2...] #两个集合的交集，不存在为(empty list or set)sunion key1 [key2...] #两个集合的并集sdiff key1 [key2...] #两个集合的差集sinterstore destination key1 [key2...] #两个集合的交集并存储到指定集合中sunionstore destination key1 [key2...] #两个集合的并集并存储到指定集合中sdiffstore destination key1 [key2...] #两个集合的差集并存储到指定集合中 复制 1smove source destination member #将指定数据从原始集合中移动到目标集合中 注意事项 set 类型不允许数据重复，如果添加的数据在 set 中已经存在，将只保留一份 set 虽然与 hash 的存储结构相同，但是无法启用 hash 中存储值的空间 练习： 将下列数据用Redis的Set集合来存储： 张三的好友有：李四、王五、赵六；李四的好友有：王五、麻子、二狗 利用Set的命令实现下列功能： 计算张三的好友有几人 计算张三和李四有哪些共同好友 查询哪些人是张三的好友却不是李四的好友 查询张三和李四的好友总共有哪些人 判断李四是否是张三的好友 判断张三是否是李四的好友 将李四从张三的好友列表中移除 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647127.0.0.1:6379&gt; sadd zs lisi wangwu zhaoliu(integer) 3127.0.0.1:6379&gt; sadd ls wangwu mazi ergou(integer) 3127.0.0.1:6379&gt; scard zs(integer) 3127.0.0.1:6379&gt; sinter zs ls1) &quot;wangwu&quot;127.0.0.1:6379&gt; sdiff zs ls1) &quot;zhaoliu&quot;2) &quot;lisi&quot;127.0.0.1:6379&gt; smembers ls1) &quot;ergou&quot;2) &quot;mazi&quot;3) &quot;wangwu&quot;127.0.0.1:6379&gt; smembers zs1) &quot;zhaoliu&quot;2) &quot;lisi&quot;3) &quot;wangwu&quot;127.0.0.1:6379&gt; sunion zs ls1) &quot;lisi&quot;2) &quot;wangwu&quot;3) &quot;ergou&quot;4) &quot;zhaoliu&quot;5) &quot;mazi&quot;127.0.0.1:6379&gt; sismember zs lisi(integer) 1127.0.0.1:6379&gt; sismember ls zhangsan(integer) 0127.0.0.1:6379&gt; smembers zs1) &quot;zhaoliu&quot;2) &quot;lisi&quot;3) &quot;wangwu&quot;127.0.0.1:6379&gt; smembers ls1) &quot;ergou&quot;2) &quot;mazi&quot;3) &quot;wangwu&quot;127.0.0.1:6379&gt; srem zs lisi(integer) 1127.0.0.1:6379&gt; smembers ls1) &quot;ergou&quot;2) &quot;mazi&quot;3) &quot;wangwu&quot;127.0.0.1:6379&gt; smembers zs1) &quot;zhaoliu&quot;2) &quot;wangwu&quot;127.0.0.1:6379&gt; 应用应用场景： 黑名单：资讯类信息类网站追求高访问量，但是由于其信息的价值，往往容易被不法分子利用，通过爬虫技术，快速获取信息，个别特种行业网站信息通过爬虫获取分析后，可以转换成商业机密。 注意：爬虫不一定做摧毁性的工作，有些小型网站需要爬虫为其带来一些流量。 白名单：对于安全性更高的应用访问，仅仅靠黑名单是不能解决安全问题的，此时需要设定可访问的用户群体， 依赖白名单做更为苛刻的访问验证 随机操作可以实现抽奖功能 集合的交并补可以实现微博共同关注的查看，可以根据共同关注或者共同喜欢推荐相关内容 实现集合类型的内部编码有两种： intset（整数集合）：当集合中的元素都是整数且元素个数小于 set-maxintset-entries配置（默认 512 个）时，Redis 会选用 intset 来作为集合的内部实现，从而减少内存的使用 hashtable（哈希表，字典）：当无法满足 intset 条件时，Redis 会使用 hashtable 作为集合的内部实现 整数集合（intset）是 Redis 用于保存整数值的集合抽象数据结构，可以保存类型为 int16_t、int32_t 或者 int64_t 的整数值，并且保证集合中的元素是有序不重复的 SortedSet简介Redis 的 SortedSet 是一个可排序的 set 集合，与 Java 中的 TreeSet 有些类似，但底层数据结构却差别很大。SortedSet 中的每一个元素都带有一个 score 属性（比如分数、票数等业务参数），可以基于 score 属性对元素排序，底层的实现是一个跳表（SkipList）加 hash 表。 SortedSet 具备下列特性： 可排序 元素不重复 查询速度快 因为 SortedSet 的可排序特性，经常被用来实现排行榜这样的功能。 数据存储需求：数据排序有利于数据的有效展示，需要提供一种可以根据自身特征进行排序的方式 数据存储结构：新的存储模型，可以保存可排序的数据 sorted_set 类型：在 set 的存储结构基础上添加可排序字段，类似于 TreeSet 操作指令操作： 数据操作 123456zadd key score1 member1 [score2 member2] #添加数据zrem key member [member ...] #删除数据zremrangebyrank key start stop #删除指定索引范围的数据zremrangebyscore key min max #删除指定分数区间内的数据zscore key member #获取指定值的分数zincrby key increment member #指定值的分数增加increment 查询操作 12345678910zrange key start stop [WITHSCORES] #获取指定范围的数据，升序，WITHSCORES 代表显示分数zrevrange key start stop [WITHSCORES] #获取指定范围的数据，降序zrangebyscore key min max [WITHSCORES] [LIMIT offset count] #按条件获取数据，从小到大zrevrangebyscore key max min [WITHSCORES] [...] #从大到小zcard key #获取集合数据的总量zcount key min max #获取指定分数区间内的数据总量zrank key member #获取数据对应的索引（排名）升序zrevrank key member #获取数据对应的索引（排名）降序 min 与 max 用于限定搜索查询的条件 start 与 stop 用于限定查询范围，作用于索引，表示开始和结束索引 offset 与 count 用于限定查询范围，作用于查询结果，表示开始位置和数据总量 集合的交、并操作 12zinterstore destination numkeys key [key ...] #两个集合的交集并存储到指定集合中zunionstore destination numkeys key [key ...] #两个集合的并集并存储到指定集合中 注意事项： score 保存的数据存储空间是 64 位，如果是整数范围是 -9007199254740992~9007199254740992 score 保存的数据也可以是一个双精度的 double 值，基于双精度浮点数的特征可能会丢失精度，慎重使用 sorted_set 底层存储还是基于 set 结构的，因此数据不能重复，如果重复添加相同的数据，score 值将被反复覆盖，保留最后一次修改的结果。 练习： 将班级的下列学生得分存入Redis的SortedSet中：Jack 85, Lucy 89, Rose 82, Tom 95, Jerry 78, Amy 92, Miles 76，并实现下列功能： 删除Tom同学 获取Amy同学的分数 获取Rose同学的排名 查询80分以下有几个学生 给Amy同学加2分 查出成绩前3名的同学 查出成绩80分以下的所有同学 123456789101112131415161718192021222324127.0.0.1:6379&gt; zadd exam 85 jack 89 lucy 82 rose 95 tom 78 jerry 92 amy 76 miles(integer) 7127.0.0.1:6379&gt; zrank exam jack(integer) 3127.0.0.1:6379&gt; zrem exam tom(integer) 1127.0.0.1:6379&gt; zscore exam amy&quot;92&quot;127.0.0.1:6379&gt; zrank exam rose(integer) 2127.0.0.1:6379&gt; zrevrank exam rose(integer) 3127.0.0.1:6379&gt; zcount exam 0 80(integer) 2127.0.0.1:6379&gt; zincrby exam 2 amy&quot;94&quot;127.0.0.1:6379&gt; zrevrange exam 0 21) &quot;amy&quot;2) &quot;lucy&quot;3) &quot;jack&quot;127.0.0.1:6379&gt; zrangebyscore exam 0 801) &quot;miles&quot;2) &quot;jerry&quot;127.0.0.1:6379&gt; 应用 排行榜 对于基于时间线限定的任务处理，将处理时间记录为 score 值，利用排序功能区分处理的先后顺序 当任务或者消息待处理，形成了任务队列或消息队列时，对于高优先级的任务要保障对其优先处理，采用 score 记录权重 实现底层结构有序集合是由 ziplist（压缩列表）或 skiplist（跳跃表）组成的 当数据比较少时，有序集合使用的是 ziplist 存储的，使用 ziplist 格式存储需要满足以下两个条件： 有序集合保存的元素个数要小于 128 个； 有序集合保存的所有元素大小都小于 64 字节 当元素比较多时，此时 ziplist 的读写效率会下降，时间复杂度是 O(n)，跳表的时间复杂度是 O(logn) 跳跃表Redis 使用跳跃表作为有序集合键的底层实现之一，如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员是比较长的字符串时，Redis 就会使用跳跃表来作为有序集合健的底层实现 跳跃表在链表的基础上增加了多级索引以提升查找的效率，索引是占内存的，所以是一个空间换时间的方案。原始链表中存储的有可能是很大的对象，而索引结点只需要存储关键值和几个指针，并不需要存储对象，因此当节点本身比较大或者元素数量比较多的时候，其优势可以被放大，而缺点则可以忽略 基于单向链表加索引的方式实现 Redis 的跳跃表实现由 zskiplist 和 zskiplistnode 两个结构组成，其中 zskiplist 用于保存跳跃表信息（比如表头节点、表尾节点、长度），而 zskiplistnode 则用于表示跳跃表节点 Redis 每个跳跃表节点的层高都是 1 至 32 之间的随机数（Redis5 之后最大层数为 64） 在同一个跳跃表中，多个节点可以包含相同的分值，但每个节点的成员对象必须是唯一的。跳跃表中的节点按照分值大小进行排序，当分值相同时节点按照成员对象的大小进行排序 个人笔记：JUC → 并发包 → ConcurrentSkipListMap 详解跳跃表 参考文章：https://www.cnblogs.com/hunternet/p/11248192.html BitMap操作BitMap 本身不是一种数据类型， 实际上就是字符串（key-value） ， 但是它可以对字符串的位进行操作 数据结构的详解查看 Java → Algorithm → 位图 指令操作： 获取指定 key 对应偏移量上的 bit 值 1getbit key offset 设置指定 key 对应偏移量上的 bit 值，value 只能是 1 或 0 1setbit key offset value 对指定 key 按位进行交、并、非、异或操作，并将结果保存到 destKey 中 1bitop option destKey key1 [key2...] option：and 交、or 并、not 非、xor 异或 统计指定 key 中1的数量 1bitcount key [start end] 应用 解决 Redis 缓存穿透，判断给定数据是否存在， 防止缓存穿透 垃圾邮件过滤，对每一个发送邮件的地址进行判断是否在布隆的黑名单中，如果在就判断为垃圾邮件 爬虫去重，爬给定网址的时候对已经爬取过的 URL 去重 信息状态统计 HyperLog基数是数据集去重后元素个数，HyperLogLog 是用来做基数统计的，运用了 LogLog 的算法 12{1, 3, 5, 7, 5, 7, 8} 基数集： {1, 3, 5 ,7, 8} 基数：5{1, 1, 1, 1, 1, 7, 1} 基数集： {1,7} 基数：2 相关指令： 添加数据 1pfadd key element [element ...] 统计数据 1pfcount key [key ...] 合并数据 1pfmerge destkey sourcekey [sourcekey...] 应用场景： 用于进行基数统计，不是集合不保存数据，只记录数量而不是具体数据，比如网站的访问量 核心是基数估算算法，最终数值存在一定误差 误差范围：基数估计的结果是一个带有 0.81% 标准错误的近似值 耗空间极小，每个 hyperloglog key 占用了12K的内存用于标记基数 pfadd 命令不是一次性分配12K内存使用，会随着基数的增加内存逐渐增大 Pfmerge 命令合并后占用的存储空间为12K，无论合并之前数据量多少 GEOGeoHash 是一种地址编码方法，把二维的空间经纬度数据编码成一个字符串 添加坐标点 12geoadd key longitude latitude member [longitude latitude member ...]georadius key longitude latitude radius m|km|ft|mi [withcoord] [withdist] [withhash] [count count] 获取坐标点 12geopos key member [member ...]georadiusbymember key member radius m|km|ft|mi [withcoord] [withdist] [withhash] [count count] 计算距离 12geodist key member1 member2 [unit] #计算坐标点距离geohash key member [member ...] #计算经纬度 redis 应用于地理位置计算。","link":"/posts/20220403/redis-basics.html"},{"title":"Netty学习之NIO基础","text":"本博客是根据黑马程序员Netty实战学习时所做的笔记。笔记总结源自 Nyimac：Netty 学习之 NIO 基础 三大组件简介Channel与Buffer Java NIO系统的核心在于：通道(Channel)和缓冲区(Buffer)。通道表示打开到 IO 设备(例如：文件、套接字)的连接。若需要使用 NIO 系统，需要获取用于连接 IO 设备的通道以及用于容纳数据的缓冲区。然后操作缓冲区，对数据进行处理。 简而言之，通道负责传输，缓冲区负责存储。 常见的Channel有以下四种，其中FileChannel主要用于文件传输，其余三种用于网络通信。 FileChannel DatagramChannel SocketChannel ServerSocketChannel Buffer有以下几种，其中使用较多的是ByteBuffer。 ByteBuffer MappedByteBuffer DirectByteBuffer HeapByteBuffer ShortBuffer IntBuffer LongBuffer FloatBuffer DoubleBuffer CharBuffer Selector在使用Selector之前，处理socket连接还有以下两种方法 使用多线程技术 为每个连接分别开辟一个线程，分别去处理对应的socke连接 这种方法存在以下几个问题 内存占用高 每个线程都需要占用一定的内存，当连接较多时，会开辟大量线程，导致占用大量内存 线程上下文切换成本高 只适合连接数少的场景 连接数过多，会导致创建很多线程，从而出现问题 使用线程池技术 使用线程池，让线程池中的线程去处理连接 这种方法存在以下几个问题 阻塞模式下，线程仅能处理一个连接 线程池中的线程获取任务（task）后，只有当其执行完任务之后（断开连接后），才会去获取并执行下一个任务 若socke连接一直未断开，则其对应的线程无法处理其他socke连接 仅适合短连接场景 短连接即建立连接发送请求并响应后就立即断开，使得线程池中的线程可以快速处理其他连接 使用选择器 selector 的作用就是配合一个线程来管理多个 channel（fileChannel因为是阻塞式的，所以无法使用selector），获取这些 channel 上发生的事件，这些 channel 工作在非阻塞模式下，当一个channel中没有执行任务时，可以去执行其他channel中的任务。适合连接数多，但流量较少的场景。 若事件未就绪，调用 selector 的 select() 方法会阻塞线程，直到 channel 发生了就绪事件。这些事件就绪后，select 方法就会返回这些事件交给 thread 来处理。 ByteBuffer使用案例使用方式注：channel.read(buffer)：从 channel 读就是向 buffer 写；如果见到 channel.write(buffer)：向 channel 写就是从 buffer 读。 向 buffer 写入数据，例如调用 channel.read(buffer) 调用 flip() 切换至 读模式 flip会使得buffer中的limit变为position，position变为0 从 buffer 读取数据，例如调用 buffer.get() 调用 clear() 或者compact()切换至 写模式 调用clear()方法时position=0，limit变为capacity 调用compact()方法时，会将缓冲区中的未读数据压缩到缓冲区前面 重复以上步骤 使用ByteBuffer读取文件中的内容 案例1： 1234567891011121314151617181920212223public class TestByteBuffer { public static void main(String[] args) { // 获得FileChannel try (FileChannel channel = new FileInputStream(&quot;stu.txt&quot;).getChannel()) { // 获得缓冲区 ByteBuffer buffer = ByteBuffer.allocate(10); int hasNext = 0; StringBuilder builder = new StringBuilder(); while((hasNext = channel.read(buffer)) &gt; 0) { // 切换模式 limit=position, position=0 buffer.flip(); // 当buffer中还有数据时，获取其中的数据 while(buffer.hasRemaining()) { builder.append((char)buffer.get()); } // 切换模式 position=0, limit=capacity buffer.clear(); } System.out.println(builder.toString()); } catch (IOException e) { } }} 打印结果 10123456789abcdef 案例2： 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.chan.nio.c2;import lombok.extern.slf4j.Slf4j;import java.io.FileInputStream;import java.io.IOException;import java.nio.ByteBuffer;import java.nio.channels.FileChannel;@Slf4j(topic = &quot;TestByteBuffer&quot;)public class TestByteBuffer { public static void main(String[] args) { m1(); } /* ctrl+alt+M */ private static void m1() { //FileChannel3种获得方式 //1.输入输出流，2.RandomAccessFile try (FileChannel channel = new FileInputStream(&quot;data.txt&quot;).getChannel()) { //准备缓冲区 ByteBuffer buffer = ByteBuffer.allocate(10); while (true) { //从channel读取数据，就是向buffer写入 int len = channel.read(buffer); log.debug(&quot;读取到的字节数{}&quot;,len); if (len == -1){//没有内容了 break; } //打印buffer的内容 buffer.flip();//切换至读模式 while (buffer.hasRemaining()){ //是否还有剩余未读的数据 byte b = buffer.get(); System.out.print((char) b); log.debug(&quot;实际字节{}&quot;,(char) b); } //读完了之后buffer要切换为写模式 buffer.clear();//切换为写模式 } } catch (IOException e) { e.printStackTrace(); } }} 打印结果： 11234567890qwer 核心属性字节缓冲区的父类Buffer中有几个核心属性，如下 12345// Invariants: mark &lt;= position &lt;= limit &lt;= capacityprivate int mark = -1;private int position = 0;private int limit;private int capacity; capacity：缓冲区的容量。通过构造函数赋予，一旦设置，无法更改 limit：缓冲区的界限。位于limit 后的数据不可读写。缓冲区的限制不能为负，并且不能大于其容量 position：下一个读写位置的索引（类似PC）。缓冲区的位置不能为负，并且不能大于limit mark：记录当前position的值。position被改变后，可以通过调用reset() 方法恢复到mark的位置。 以上四个属性必须满足以下要求 mark &lt;= position &lt;= limit &lt;= capacity 核心方法put()方法 put()方法可以将一个数据放入到缓冲区中。 进行该操作后，postition的值会+1，指向下一个可以放入的位置。capacity = limit ，为缓冲区容量的值。 flip()方法 flip()方法会切换对缓冲区的操作模式，由写-&gt;读 / 读-&gt;写 进行该操作后 如果是写模式-&gt;读模式，position = 0 ， limit 指向最后一个元素的下一个位置，capacity不变 如果是读-&gt;写，则恢复为put()方法中的值 get()方法 get()方法会读取缓冲区中的一个值 进行该操作后，position会+1，如果超过了limit则会抛出异常 注意：get(i)方法不会改变position的值 rewind()方法 该方法只能在读模式下使用 rewind()方法后，会恢复position、limit和capacity的值，变为进行get()前的值 clean()方法 clean()方法会将缓冲区中的各个属性恢复为最初的状态，position = 0, capacity = limit 此时缓冲区的数据依然存在，处于“被遗忘”状态，下次进行写操作时会覆盖这些数据 mark()和reset()方法 mark()方法会将postion的值保存到mark属性中 reset()方法会将position的值改为mark中保存的值 compact()方法此方法为ByteBuffer的方法，而不是Buffer的方法 compact会把未读完的数据向前压缩，然后切换到写模式 数据前移后，原位置的值并未清零，写时会覆盖之前的值 clear() VS compact()clear只是对position、limit、mark进行重置，而compact在对position进行设置，以及limit、mark进行重置的同时，还涉及到数据在内存中拷贝（会调用arraycopy）。所以compact比clear更耗性能。但compact能保存你未读取的数据，将新数据追加到为读取的数据之后；而clear则不行，若你调用了clear，则未读取的数据就无法再读取到了 所以需要根据情况来判断使用哪种方法进行模式切换 方法调用及演示ByteBuffer调试工具类需要先导入netty依赖：netty-all。 12345&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.51.Final&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174import java.nio.ByteBuffer;import io.netty.util.internal.MathUtil;import io.netty.util.internal.StringUtil;import io.netty.util.internal.MathUtil.*;public class ByteBufferUtil { private static final char[] BYTE2CHAR = new char[256]; private static final char[] HEXDUMP_TABLE = new char[256 * 4]; private static final String[] HEXPADDING = new String[16]; private static final String[] HEXDUMP_ROWPREFIXES = new String[65536 &gt;&gt;&gt; 4]; private static final String[] BYTE2HEX = new String[256]; private static final String[] BYTEPADDING = new String[16]; static { final char[] DIGITS = &quot;0123456789abcdef&quot;.toCharArray(); for (int i = 0; i &lt; 256; i++) { HEXDUMP_TABLE[i &lt;&lt; 1] = DIGITS[i &gt;&gt;&gt; 4 &amp; 0x0F]; HEXDUMP_TABLE[(i &lt;&lt; 1) + 1] = DIGITS[i &amp; 0x0F]; } int i; // Generate the lookup table for hex dump paddings for (i = 0; i &lt; HEXPADDING.length; i++) { int padding = HEXPADDING.length - i; StringBuilder buf = new StringBuilder(padding * 3); for (int j = 0; j &lt; padding; j++) { buf.append(&quot; &quot;); } HEXPADDING[i] = buf.toString(); } // Generate the lookup table for the start-offset header in each row (up to 64KiB). for (i = 0; i &lt; HEXDUMP_ROWPREFIXES.length; i++) { StringBuilder buf = new StringBuilder(12); buf.append(StringUtil.NEWLINE); buf.append(Long.toHexString(i &lt;&lt; 4 &amp; 0xFFFFFFFFL | 0x100000000L)); buf.setCharAt(buf.length() - 9, '|'); buf.append('|'); HEXDUMP_ROWPREFIXES[i] = buf.toString(); } // Generate the lookup table for byte-to-hex-dump conversion for (i = 0; i &lt; BYTE2HEX.length; i++) { BYTE2HEX[i] = ' ' + StringUtil.byteToHexStringPadded(i); } // Generate the lookup table for byte dump paddings for (i = 0; i &lt; BYTEPADDING.length; i++) { int padding = BYTEPADDING.length - i; StringBuilder buf = new StringBuilder(padding); for (int j = 0; j &lt; padding; j++) { buf.append(' '); } BYTEPADDING[i] = buf.toString(); } // Generate the lookup table for byte-to-char conversion for (i = 0; i &lt; BYTE2CHAR.length; i++) { if (i &lt;= 0x1f || i &gt;= 0x7f) { BYTE2CHAR[i] = '.'; } else { BYTE2CHAR[i] = (char) i; } } } /** * 打印所有内容 * @param buffer */ public static void debugAll(ByteBuffer buffer) { int oldlimit = buffer.limit(); buffer.limit(buffer.capacity()); StringBuilder origin = new StringBuilder(256); appendPrettyHexDump(origin, buffer, 0, buffer.capacity()); System.out.println(&quot;+--------+-------------------- all ------------------------+----------------+&quot;); System.out.printf(&quot;position: [%d], limit: [%d]\\n&quot;, buffer.position(), oldlimit); System.out.println(origin); buffer.limit(oldlimit); } /** * 打印可读取内容 * @param buffer */ public static void debugRead(ByteBuffer buffer) { StringBuilder builder = new StringBuilder(256); appendPrettyHexDump(builder, buffer, buffer.position(), buffer.limit() - buffer.position()); System.out.println(&quot;+--------+-------------------- read -----------------------+----------------+&quot;); System.out.printf(&quot;position: [%d], limit: [%d]\\n&quot;, buffer.position(), buffer.limit()); System.out.println(builder); } private static void appendPrettyHexDump(StringBuilder dump, ByteBuffer buf, int offset, int length) { if (MathUtil.isOutOfBounds(offset, length, buf.capacity())) { throw new IndexOutOfBoundsException( &quot;expected: &quot; + &quot;0 &lt;= offset(&quot; + offset + &quot;) &lt;= offset + length(&quot; + length + &quot;) &lt;= &quot; + &quot;buf.capacity(&quot; + buf.capacity() + ')'); } if (length == 0) { return; } dump.append( &quot; +-------------------------------------------------+&quot; + StringUtil.NEWLINE + &quot; | 0 1 2 3 4 5 6 7 8 9 a b c d e f |&quot; + StringUtil.NEWLINE + &quot;+--------+-------------------------------------------------+----------------+&quot;); final int startIndex = offset; final int fullRows = length &gt;&gt;&gt; 4; final int remainder = length &amp; 0xF; // Dump the rows which have 16 bytes. for (int row = 0; row &lt; fullRows; row++) { int rowStartIndex = (row &lt;&lt; 4) + startIndex; // Per-row prefix. appendHexDumpRowPrefix(dump, row, rowStartIndex); // Hex dump int rowEndIndex = rowStartIndex + 16; for (int j = rowStartIndex; j &lt; rowEndIndex; j++) { dump.append(BYTE2HEX[getUnsignedByte(buf, j)]); } dump.append(&quot; |&quot;); // ASCII dump for (int j = rowStartIndex; j &lt; rowEndIndex; j++) { dump.append(BYTE2CHAR[getUnsignedByte(buf, j)]); } dump.append('|'); } // Dump the last row which has less than 16 bytes. if (remainder != 0) { int rowStartIndex = (fullRows &lt;&lt; 4) + startIndex; appendHexDumpRowPrefix(dump, fullRows, rowStartIndex); // Hex dump int rowEndIndex = rowStartIndex + remainder; for (int j = rowStartIndex; j &lt; rowEndIndex; j++) { dump.append(BYTE2HEX[getUnsignedByte(buf, j)]); } dump.append(HEXPADDING[remainder]); dump.append(&quot; |&quot;); // Ascii dump for (int j = rowStartIndex; j &lt; rowEndIndex; j++) { dump.append(BYTE2CHAR[getUnsignedByte(buf, j)]); } dump.append(BYTEPADDING[remainder]); dump.append('|'); } dump.append(StringUtil.NEWLINE + &quot;+--------+-------------------------------------------------+----------------+&quot;); } private static void appendHexDumpRowPrefix(StringBuilder dump, int row, int rowStartIndex) { if (row &lt; HEXDUMP_ROWPREFIXES.length) { dump.append(HEXDUMP_ROWPREFIXES[row]); } else { dump.append(StringUtil.NEWLINE); dump.append(Long.toHexString(rowStartIndex &amp; 0xFFFFFFFFL | 0x100000000L)); dump.setCharAt(dump.length() - 9, '|'); dump.append('|'); } } public static short getUnsignedByte(ByteBuffer buffer, int index) { return (short) (buffer.get(index) &amp; 0xFF); }} 调用ByteBuffer的方法123456789101112public class TestByteBufferAllocate { public static void main(String[] args) { System.out.println(ByteBuffer.allocate(12).getClass()); System.out.println(ByteBuffer.allocateDirect(12).getClass()); /* class java.nio.HeapByteBuffer -java堆内存，读写效率较低，受到GC的影响 class java.nio.DirectByteBuffer -直接内存，读写效率高（少一次拷贝），不会受到GC的影响，分配的效率低 如果使用不当，可能内存泄露 */ }} 1234567891011121314151617181920212223242526272829public class TestByteBuffer { public static void main(String[] args) { ByteBuffer buffer = ByteBuffer.allocate(10); // 向buffer中写入1个字节的数据 buffer.put((byte)97); // 使用工具类，查看buffer状态 ByteBufferUtil.debugAll(buffer); // 向buffer中写入4个字节的数据 buffer.put(new byte[]{98, 99, 100, 101}); ByteBufferUtil.debugAll(buffer); // 获取数据 buffer.flip(); ByteBufferUtil.debugAll(buffer); System.out.println(buffer.get()); System.out.println(buffer.get()); ByteBufferUtil.debugAll(buffer); // 使用compact切换模式 buffer.compact(); ByteBufferUtil.debugAll(buffer); // 再次写入 buffer.put((byte)102); buffer.put((byte)103); ByteBufferUtil.debugAll(buffer); }} 运行结果 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// 向缓冲区写入了一个字节的数据，此时postition为1+--------+-------------------- all ------------------------+----------------+position: [1], limit: [10] +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 61 00 00 00 00 00 00 00 00 00 |a......... |+--------+-------------------------------------------------+----------------+// 向缓冲区写入四个字节的数据，此时position为5+--------+-------------------- all ------------------------+----------------+position: [5], limit: [10] +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 61 62 63 64 65 00 00 00 00 00 |abcde..... |+--------+-------------------------------------------------+----------------+// 调用flip切换模式，此时position为0，表示从第0个数据开始读取+--------+-------------------- all ------------------------+----------------+position: [0], limit: [5] +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 61 62 63 64 65 00 00 00 00 00 |abcde..... |+--------+-------------------------------------------------+----------------+// 读取两个字节的数据 9798 // position变为2 +--------+-------------------- all ------------------------+----------------+position: [2], limit: [5] +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 61 62 63 64 65 00 00 00 00 00 |abcde..... |+--------+-------------------------------------------------+----------------+ // 调用compact切换模式，此时position及其后面的数据被压缩到ByteBuffer前面去了// 此时position为3，会覆盖之前的数据 +--------+-------------------- all ------------------------+----------------+position: [3], limit: [10] +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 63 64 65 64 65 00 00 00 00 00 |cdede..... |+--------+-------------------------------------------------+----------------+ // 再次写入两个字节的数据，之前的 0x64 0x65 被覆盖 +--------+-------------------- all ------------------------+----------------+position: [5], limit: [10] +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 63 64 65 66 67 00 00 00 00 00 |cdefg..... |+--------+-------------------------------------------------+----------------+ 字符串与ByteBuffer的相互转换方法一编码：字符串调用getByte方法获得byte数组，将byte数组放入ByteBuffer中 解码：先调用ByteBuffer的flip方法，然后通过StandardCharsets的decoder方法解码 12345678910111213141516171819202122public class Translate { public static void main(String[] args) { // 准备两个字符串 String str1 = &quot;hello&quot;; String str2 = &quot;&quot;; ByteBuffer buffer1 = ByteBuffer.allocate(16); // 通过字符串的getByte方法获得字节数组，放入缓冲区中 buffer1.put(str1.getBytes()); ByteBufferUtil.debugAll(buffer1); // 将缓冲区中的数据转化为字符串 // 切换模式 buffer1.flip(); // 通过StandardCharsets解码，获得CharBuffer，再通过toString获得字符串 str2 = StandardCharsets.UTF_8.decode(buffer1).toString(); System.out.println(str2); ByteBufferUtil.debugAll(buffer1); }} 运行结果 123456789101112131415+--------+-------------------- all ------------------------+----------------+position: [5], limit: [16] +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 68 65 6c 6c 6f 00 00 00 00 00 00 00 00 00 00 00 |hello...........|+--------+-------------------------------------------------+----------------+hello+--------+-------------------- all ------------------------+----------------+position: [5], limit: [5] +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 68 65 6c 6c 6f 00 00 00 00 00 00 00 00 00 00 00 |hello...........|+--------+-------------------------------------------------+----------------+ 方法二编码：通过StandardCharsets的encode方法获得ByteBuffer，此时获得的ByteBuffer为读模式，无需通过flip切换模式 解码：通过StandardCharsets的decoder方法解码 123456789101112131415161718public class Translate { public static void main(String[] args) { // 准备两个字符串 String str1 = &quot;hello&quot;; String str2 = &quot;&quot;; // 通过StandardCharsets的encode方法获得ByteBuffer // 此时获得的ByteBuffer为读模式，无需通过flip切换模式 ByteBuffer buffer1 = StandardCharsets.UTF_8.encode(str1); ByteBufferUtil.debugAll(buffer1); // 将缓冲区中的数据转化为字符串 // 通过StandardCharsets解码，获得CharBuffer，再通过toString获得字符串 str2 = StandardCharsets.UTF_8.decode(buffer1).toString(); System.out.println(str2); ByteBufferUtil.debugAll(buffer1); }} 运行结果 123456789101112131415+--------+-------------------- all ------------------------+----------------+position: [0], limit: [5] +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 68 65 6c 6c 6f |hello |+--------+-------------------------------------------------+----------------+hello+--------+-------------------- all ------------------------+----------------+position: [5], limit: [5] +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 68 65 6c 6c 6f |hello |+--------+-------------------------------------------------+----------------+ 方法三编码：字符串调用getByte()方法获得字节数组，将字节数组传给ByteBuffer的wrap()方法，通过该方法获得ByteBuffer。同样无需调用flip方法切换为读模式 解码：通过StandardCharsets的decoder方法解码 123456789101112131415161718public class Translate { public static void main(String[] args) { // 准备两个字符串 String str1 = &quot;hello&quot;; String str2 = &quot;&quot;; // 通过StandardCharsets的encode方法获得ByteBuffer // 此时获得的ByteBuffer为读模式，无需通过flip切换模式 ByteBuffer buffer1 = ByteBuffer.wrap(str1.getBytes()); ByteBufferUtil.debugAll(buffer1); // 将缓冲区中的数据转化为字符串 // 通过StandardCharsets解码，获得CharBuffer，再通过toString获得字符串 str2 = StandardCharsets.UTF_8.decode(buffer1).toString(); System.out.println(str2); ByteBufferUtil.debugAll(buffer1); }} 运行结果 123456789101112131415+--------+-------------------- all ------------------------+----------------+position: [0], limit: [5] +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 68 65 6c 6c 6f |hello |+--------+-------------------------------------------------+----------------+hello+--------+-------------------- all ------------------------+----------------+position: [5], limit: [5] +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 68 65 6c 6c 6f |hello |+--------+-------------------------------------------------+----------------+ 整合： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package com.chan.nio.c2;import java.nio.ByteBuffer;import java.nio.charset.StandardCharsets;import static com.chan.nio.c2.ByteBufferUtil.debugAll;public class TestByteBufferString { public static void main(String[] args) { //字符串转为ByteBuffer,三种方式 //1.将字符串转换成字节放入buffer ByteBuffer buffer1 = ByteBuffer.allocate(16); buffer1.put(&quot;hello&quot;.getBytes());//默认是写模式，现在依旧是写模式 有position: [5], limit: [16]可看出 debugAll(buffer1); //输出结果： /* +--------+-------------------- all ------------------------+----------------+ position: [5], limit: [16] +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f | +--------+-------------------------------------------------+----------------+ |00000000| 68 65 6c 6c 6f 00 00 00 00 00 00 00 00 00 00 00 |hello...........| +--------+-------------------------------------------------+----------------+ */ //2.Charset ByteBuffer buffer2 = StandardCharsets.UTF_8.encode(&quot;hello&quot;);//buffer默认是写模式，这种方式会自动切换成读模式 position: [0], limit: [5] debugAll(buffer2); /* +--------+-------------------- all ------------------------+----------------+ position: [0], limit: [5] +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f | +--------+-------------------------------------------------+----------------+ |00000000| 68 65 6c 6c 6f |hello | +--------+-------------------------------------------------+----------------+ */ //3.wrap ByteBuffer buffer3 = ByteBuffer.wrap(&quot;hello&quot;.getBytes());//buffer默认是写模式，这种方式会自动切换成读模式 position: [0], limit: [5] debugAll(buffer3); /* +--------+-------------------- all ------------------------+----------------+ position: [0], limit: [5] +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f | +--------+-------------------------------------------------+----------------+ |00000000| 68 65 6c 6c 6f |hello | +--------+-------------------------------------------------+----------------+ */ //转为字符串 buffer1.flip();//由于前面方式1将字符串的字节写入buffer后不会自动切换成读模式，因此要手动切换才能转换成字符串 String str1 = StandardCharsets.UTF_8.decode(buffer1).toString(); String str2 = StandardCharsets.UTF_8.decode(buffer2).toString(); String str3 = StandardCharsets.UTF_8.decode(buffer3).toString(); System.out.println(&quot;str1:&quot; + str1); System.out.println(&quot;str2:&quot; + str2); System.out.println(&quot;str3:&quot; + str3); }} 粘包与半包现象网络上有多条数据发送给服务端，数据之间使用 \\n 进行分隔但由于某种原因这些数据在接收时，被进行了重新组合，例如原始数据有3条为 Hello,world\\n I’m Nyima\\n How are you?\\n 变成了下面的两个 byteBuffer (粘包，半包) Hello,world\\nI’m Nyima\\nHo w are you?\\n 出现原因粘包 发送方在发送数据时，并不是一条一条地发送数据，而是将数据整合在一起，当数据达到一定的数量后再一起发送。这就会导致多条信息被放在一个缓冲区中被一起发送出去 半包 接收方的缓冲区的大小是有限的，当接收方的缓冲区满了以后，就需要将信息截断，等缓冲区空了以后再继续放入数据。这就会发生一段完整的数据最后被截断的现象 解决办法 通过get(index)方法遍历ByteBuffer，遇到分隔符时进行处理。 注意 ：get(index)不会改变position的值 记录该段数据长度，以便于申请对应大小的缓冲区 将缓冲区的数据通过get()方法写入到target中 调用compact方法切换模式，因为缓冲区中可能还有未读的数据 1234567891011121314151617181920212223242526272829303132333435public class ByteBufferDemo { public static void main(String[] args) { ByteBuffer buffer = ByteBuffer.allocate(32); // 模拟粘包+半包 buffer.put(&quot;Hello,world\\nI'm Nyima\\nHo&quot;.getBytes()); // 调用split函数处理 split(buffer); buffer.put(&quot;w are you?\\n&quot;.getBytes()); split(buffer); } private static void split(ByteBuffer buffer) { // 切换为读模式 buffer.flip(); for(int i = 0; i &lt; buffer.limit(); i++) { // 遍历寻找分隔符 // get(i)不会移动position if (buffer.get(i) == '\\n') { // 缓冲区长度 int length = i+1-buffer.position(); ByteBuffer target = ByteBuffer.allocate(length); // 将前面的内容写入target缓冲区 for(int j = 0; j &lt; length; j++) { // 将buffer中的数据写入target中 target.put(buffer.get()); } // 打印查看结果 ByteBufferUtil.debugAll(target); } } // 切换为写模式，但是缓冲区可能未读完，这里需要使用compact buffer.compact(); }} 运行结果 123456789101112131415161718192021+--------+-------------------- all ------------------------+----------------+position: [12], limit: [12] +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 48 65 6c 6c 6f 2c 77 6f 72 6c 64 0a |Hello,world. |+--------+-------------------------------------------------+----------------++--------+-------------------- all ------------------------+----------------+position: [10], limit: [10] +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 49 27 6d 20 4e 79 69 6d 61 0a |I'm Nyima. |+--------+-------------------------------------------------+----------------++--------+-------------------- all ------------------------+----------------+position: [13], limit: [13] +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 48 6f 77 20 61 72 65 20 79 6f 75 3f 0a |How are you?. |+--------+-------------------------------------------------+----------------+ 文件编程FileChannel工作模式FileChannel只能在阻塞模式下工作，所以无法搭配Selector 获取不能直接打开 FileChannel，必须通过 FileInputStream、FileOutputStream 或者 RandomAccessFile 来获取 FileChannel，它们都有 getChannel 方法 通过 FileInputStream 获取的 channel 只能读 通过 FileOutputStream 获取的 channel 只能写 通过 RandomAccessFile 是否能读写根据构造 RandomAccessFile 时的读写模式决定 读取通过 FileInputStream 获取channel，通过read方法将数据写入到ByteBuffer中 read方法的返回值表示读到了多少字节，若读到了文件末尾则返回-1 1int readBytes = channel.read(buffer); 可根据返回值判断是否读取完毕 1234while(channel.read(buffer) &gt; 0) { // 进行对应操作 ...} 写入因为channel也是有大小的，所以 write 方法并不能保证一次将 buffer 中的内容全部写入 channel。必须需要按照以下规则进行写入 1234// 通过hasRemaining()方法查看缓冲区中是否还有数据未写入到通道中while(buffer.hasRemaining()) { channel.write(buffer);} 关闭通道需要close，一般情况通过try-with-resource进行关闭，最好使用以下方法获取stream以及channel，避免某些原因使得资源未被关闭 12345678910111213public class TestChannel { public static void main(String[] args) throws IOException { try (FileInputStream fis = new FileInputStream(&quot;stu.txt&quot;); FileOutputStream fos = new FileOutputStream(&quot;student.txt&quot;); FileChannel inputChannel = fis.getChannel(); FileChannel outputChannel = fos.getChannel()) { // 执行对应操作 ... } }} 位置position channel也拥有一个保存读取数据位置的属性，即position 1long pos = channel.position(); 可以通过position(int pos)设置channel中position的值 12long newPos = ...;channel.position(newPos); 设置当前位置时，如果设置为文件的末尾 这时读取会返回 -1 这时写入，会追加内容，但要注意如果 position 超过了文件末尾，再写入时在新内容和原末尾之间会有空洞（00） 强制写入操作系统出于性能的考虑，会将数据缓存，不是立刻写入磁盘，而是等到缓存满了以后将所有数据一次性的写入磁盘。可以调用 force(true) 方法将文件内容和元数据（文件的权限等信息）立刻写入磁盘 两个Channel传输数据transferTo方法使用transferTo方法可以快速、高效地将一个channel中的数据传输到另一个channel中，但一次只能传输2G的内容 transferTo底层使用了零拷贝技术 123456789101112131415public class TestChannel { public static void main(String[] args){ try (FileInputStream fis = new FileInputStream(&quot;stu.txt&quot;); FileOutputStream fos = new FileOutputStream(&quot;student.txt&quot;); FileChannel inputChannel = fis.getChannel(); FileChannel outputChannel = fos.getChannel()) { // 参数：inputChannel的起始位置，传输数据的大小，目的channel // 返回值为传输的数据的字节数 // transferTo一次只能传输2G的数据 inputChannel.transferTo(0, inputChannel.size(), outputChannel); } catch (IOException e) { e.printStackTrace(); } }} 当传输的文件大于2G时，需要使用以下方法进行多次传输 123456789101112131415161718public class TestChannel { public static void main(String[] args){ try (FileInputStream fis = new FileInputStream(&quot;stu.txt&quot;); FileOutputStream fos = new FileOutputStream(&quot;student.txt&quot;); FileChannel inputChannel = fis.getChannel(); FileChannel outputChannel = fos.getChannel()) { long size = inputChannel.size(); long capacity = inputChannel.size(); // 分多次传输 while (capacity &gt; 0) { // transferTo返回值为传输了的字节数 capacity -= inputChannel.transferTo(size-capacity, capacity, outputChannel); } } catch (IOException e) { e.printStackTrace(); } }} Path与Paths Path 用来表示文件路径 Paths 是工具类，用来获取 Path 实例 1234567Path source = Paths.get(&quot;1.txt&quot;); // 相对路径 不带盘符 使用 user.dir 环境变量来定位 1.txtPath source = Paths.get(&quot;d:\\\\1.txt&quot;); // 绝对路径 代表了 d:\\1.txt 反斜杠需要转义Path source = Paths.get(&quot;d:/1.txt&quot;); // 绝对路径 同样代表了 d:\\1.txtPath projects = Paths.get(&quot;d:\\\\data&quot;, &quot;projects&quot;); // 代表了 d:\\data\\projects . 代表了当前路径 .. 代表了上一级路径 例如目录结构如下 12345d: |- data |- projects |- a |- b 代码 123Path path = Paths.get(&quot;d:\\\\data\\\\projects\\\\a\\\\..\\\\b&quot;);System.out.println(path);System.out.println(path.normalize()); // 正常化路径 会去除 . 以及 .. 输出结果为 12d:\\data\\projects\\a\\..\\bd:\\data\\projects\\b Files查找检查文件是否存在 12Path path = Paths.get(&quot;helloword/data.txt&quot;);System.out.println(Files.exists(path)); 创建创建一级目录 12Path path = Paths.get(&quot;helloword/d1&quot;);Files.createDirectory(path); 如果目录已存在，会抛异常 FileAlreadyExistsException 不能一次创建多级目录，否则会抛异常 NoSuchFileException 创建多级目录用 12Path path = Paths.get(&quot;helloword/d1/d2&quot;);Files.createDirectories(path); 拷贝及移动拷贝文件 1234Path source = Paths.get(&quot;helloword/data.txt&quot;);Path target = Paths.get(&quot;helloword/target.txt&quot;);Files.copy(source, target); 如果文件已存在，会抛异常 FileAlreadyExistsException 如果希望用 source 覆盖掉 target，需要用 StandardCopyOption 来控制 1Files.copy(source, target, StandardCopyOption.REPLACE_EXISTING); 移动文件 1234Path source = Paths.get(&quot;helloword/data.txt&quot;);Path target = Paths.get(&quot;helloword/data.txt&quot;);Files.move(source, target, StandardCopyOption.ATOMIC_MOVE); StandardCopyOption.ATOMIC_MOVE 保证文件移动的原子性 删除删除文件 123Path target = Paths.get(&quot;helloword/target.txt&quot;);Files.delete(target); 如果文件不存在，会抛异常 NoSuchFileException 删除目录 123Path target = Paths.get(&quot;helloword/d1&quot;);Files.delete(target); 如果目录还有内容，会抛异常 DirectoryNotEmptyException 遍历可以使用Files工具类中的walkFileTree(Path, FileVisitor)方法，其中需要传入两个参数 Path：文件起始路径 FileVisitor：文件访问器， 使用访问者模式 接口的实现类 SimpleFileVisitor 有四个方法 preVisitDirectory：访问目录前的操作 visitFile：访问文件的操作 visitFileFailed：访问文件失败时的操作 postVisitDirectory：访问目录后的操作 1234567891011121314151617181920212223242526272829public class TestWalkFileTree { public static void main(String[] args) throws IOException { Path path = Paths.get(&quot;F:\\\\JDK 8&quot;); // 文件目录数目 AtomicInteger dirCount = new AtomicInteger(); // 文件数目 AtomicInteger fileCount = new AtomicInteger(); Files.walkFileTree(path, new SimpleFileVisitor&lt;Path&gt;(){ @Override public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException { System.out.println(&quot;===&gt;&quot;+dir); // 增加文件目录数 dirCount.incrementAndGet(); return super.preVisitDirectory(dir, attrs); } @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException { System.out.println(file); // 增加文件数 fileCount.incrementAndGet(); return super.visitFile(file, attrs); } }); // 打印数目 System.out.println(&quot;文件目录数:&quot;+dirCount.get()); System.out.println(&quot;文件数:&quot;+fileCount.get()); }} 运行结果如下 12345678910111213141516...===&gt;F:\\JDK 8\\lib\\security\\policy\\unlimitedF:\\JDK 8\\lib\\security\\policy\\unlimited\\local_policy.jarF:\\JDK 8\\lib\\security\\policy\\unlimited\\US_export_policy.jarF:\\JDK 8\\lib\\security\\trusted.librariesF:\\JDK 8\\lib\\sound.propertiesF:\\JDK 8\\lib\\tzdb.datF:\\JDK 8\\lib\\tzmappingsF:\\JDK 8\\LICENSEF:\\JDK 8\\README.txtF:\\JDK 8\\releaseF:\\JDK 8\\THIRDPARTYLICENSEREADME-JAVAFX.txtF:\\JDK 8\\THIRDPARTYLICENSEREADME.txtF:\\JDK 8\\Welcome.html文件目录数:23文件数:279 网络编程阻塞 阻塞模式下，相关方法都会导致线程暂停 ServerSocketChannel.accept 会在没有连接建立时让线程暂停 SocketChannel.read 会在通道中没有数据可读时让线程暂停 阻塞的表现其实就是线程暂停了，暂停期间不会占用 cpu，但线程相当于闲置 单线程下，阻塞方法之间相互影响，几乎不能正常工作，需要多线程支持 但多线程下，有新的问题，体现在以下方面 32 位 jvm 一个线程 320k，64 位 jvm 一个线程 1024k，如果连接数过多，必然导致 OOM，并且线程太多，反而会因为频繁上下文切换导致性能降低 可以采用线程池技术来减少线程数和线程上下文切换，但治标不治本，如果有很多连接建立，但长时间 inactive，会阻塞线程池中所有线程，因此不适合长连接，只适合短连接 服务端代码 12345678910111213141516171819202122232425262728293031323334public class Server { public static void main(String[] args) { // 创建缓冲区 ByteBuffer buffer = ByteBuffer.allocate(16); // 获得服务器通道 try(ServerSocketChannel server = ServerSocketChannel.open()) { // 为服务器通道绑定端口 server.bind(new InetSocketAddress(8080)); // 用户存放连接的集合 ArrayList&lt;SocketChannel&gt; channels = new ArrayList&lt;&gt;(); // 循环接收连接 while (true) { System.out.println(&quot;before connecting...&quot;); // 没有连接时，会阻塞线程 SocketChannel socketChannel = server.accept(); System.out.println(&quot;after connecting...&quot;); channels.add(socketChannel); // 循环遍历集合中的连接 for(SocketChannel channel : channels) { System.out.println(&quot;before reading&quot;); // 处理通道中的数据 // 当通道中没有数据可读时，会阻塞线程 channel.read(buffer); buffer.flip(); ByteBufferUtil.debugRead(buffer); buffer.clear(); System.out.println(&quot;after reading&quot;); } } } catch (IOException e) { e.printStackTrace(); } }} 客户端代码 1234567891011public class Client { public static void main(String[] args) { try (SocketChannel socketChannel = SocketChannel.open()) { // 建立连接 socketChannel.connect(new InetSocketAddress(&quot;localhost&quot;, 8080)); System.out.println(&quot;waiting...&quot;); } catch (IOException e) { e.printStackTrace(); } }} 运行结果 客户端-服务器建立连接前：服务器端因accept阻塞 客户端-服务器建立连接后，客户端发送消息前：服务器端因通道为空被阻塞 客户端发送数据后，服务器处理通道中的数据。再次进入循环时，再次被accept阻塞 之前的客户端再次发送消息，服务器端因为被accept阻塞，无法处理之前客户端发送到通道中的信息 非阻塞 可以通过ServerSocketChannel的configureBlocking(false)方法将获得连接设置为非阻塞的。此时若没有连接，accept会返回null 可以通过SocketChannel的configureBlocking(false)方法将从通道中读取数据设置为非阻塞的。若此时通道中没有数据可读，read会返回-1 服务器代码如下 123456789101112131415161718192021222324252627282930313233343536373839public class Server { public static void main(String[] args) { // 创建缓冲区 ByteBuffer buffer = ByteBuffer.allocate(16); // 获得服务器通道 try(ServerSocketChannel server = ServerSocketChannel.open()) { // 为服务器通道绑定端口 server.bind(new InetSocketAddress(8080)); // 用户存放连接的集合 ArrayList&lt;SocketChannel&gt; channels = new ArrayList&lt;&gt;(); // 循环接收连接 while (true) { // 设置为非阻塞模式，没有连接时返回null，不会阻塞线程 server.configureBlocking(false); SocketChannel socketChannel = server.accept(); // 通道不为空时才将连接放入到集合中 if (socketChannel != null) { System.out.println(&quot;after connecting...&quot;); channels.add(socketChannel); } // 循环遍历集合中的连接 for(SocketChannel channel : channels) { // 处理通道中的数据 // 设置为非阻塞模式，若通道中没有数据，会返回0，不会阻塞线程 channel.configureBlocking(false); int read = channel.read(buffer); if(read &gt; 0) { buffer.flip(); ByteBufferUtil.debugRead(buffer); buffer.clear(); System.out.println(&quot;after reading&quot;); } } } } catch (IOException e) { e.printStackTrace(); } }} 这样写存在一个问题，因为设置为了非阻塞，会一直执行while(true)中的代码，CPU一直处于忙碌状态，会使得性能变低，所以实际情况中不使用这种方法处理请求 Selector多路复用单线程可以配合 Selector 完成对多个 Channel 可读写事件的监控，这称之为多路复用 多路复用仅针对网络 IO，普通文件 IO 无法利用多路复用 如果不用 Selector 的非阻塞模式，线程大部分时间都在做无用功，而 Selector 能够保证 有可连接事件时才去连接 有可读事件才去读取 有可写事件才去写入 限于网络传输能力，Channel 未必时时可写，一旦 Channel 可写，会触发 Selector 的可写事件 使用及Accpet事件要使用Selector实现多路复用，服务端代码如下改进 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class SelectServer { public static void main(String[] args) { ByteBuffer buffer = ByteBuffer.allocate(16); // 获得服务器通道 try(ServerSocketChannel server = ServerSocketChannel.open()) { server.bind(new InetSocketAddress(8080)); // 创建选择器 Selector selector = Selector.open(); // 通道必须设置为非阻塞模式 server.configureBlocking(false); // 将通道注册到选择器中，并设置感兴趣的事件 server.register(selector, SelectionKey.OP_ACCEPT); while (true) { // 若没有事件就绪，线程会被阻塞，反之不会被阻塞。从而避免了CPU空转 // 返回值为就绪的事件个数 int ready = selector.select(); System.out.println(&quot;selector ready counts : &quot; + ready); // 获取所有事件 Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); // 使用迭代器遍历事件 Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); // 判断key的类型 if(key.isAcceptable()) { // 获得key对应的channel ServerSocketChannel channel = (ServerSocketChannel) key.channel(); System.out.println(&quot;before accepting...&quot;); // 获取连接并处理，而且是必须处理，否则需要取消 SocketChannel socketChannel = channel.accept(); System.out.println(&quot;after accepting...&quot;); // 处理完毕后移除 iterator.remove(); } } } } catch (IOException e) { e.printStackTrace(); } }} 步骤解析 获得选择器Selector 1Selector selector = Selector.open(); 将 通道设置为非阻塞模式 ，并注册到选择器中，并设置感兴趣的事件 channel 必须工作在非阻塞模式 FileChannel 没有非阻塞模式，因此不能配合 selector 一起使用 绑定的 事件类型 可以有 connect - 客户端连接成功时触发 accept - 服务器端成功接受连接时触发 read - 数据可读入时触发，有因为接收能力弱，数据暂不能读入的情况 write - 数据可写出时触发，有因为发送能力弱，数据暂不能写出的情况 1234// 通道必须设置为非阻塞模式server.configureBlocking(false);// 将通道注册到选择器中，并设置感兴趣的实践server.register(selector, SelectionKey.OP_ACCEPT); 通过Selector监听事件，并获得就绪的通道个数，若没有通道就绪，线程会被阻塞 阻塞直到绑定事件发生 1int count = selector.select(); 阻塞直到绑定事件发生，或是超时（时间单位为 ms） 1int count = selector.select(long timeout); 不会阻塞，也就是不管有没有事件，立刻返回，自己根据返回值检查是否有事件 1int count = selector.selectNow(); 获取就绪事件并得到对应的通道，然后进行处理 123456789101112131415161718192021// 获取所有事件Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); // 使用迭代器遍历事件Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator();while (iterator.hasNext()) { SelectionKey key = iterator.next(); // 判断key的类型，此处为Accept类型 if(key.isAcceptable()) { // 获得key对应的channel ServerSocketChannel channel = (ServerSocketChannel) key.channel(); // 获取连接并处理，而且是必须处理，否则需要取消 SocketChannel socketChannel = channel.accept(); // 处理完毕后移除 iterator.remove(); }} 事件发生后能否不处理 事件发生后，要么处理，要么取消（cancel），不能什么都不做，否则下次该事件仍会触发，这是因为 nio 底层使用的是水平触发 Read事件 在Accept事件中，若有客户端与服务器端建立了连接，需要将其对应的SocketChannel设置为非阻塞，并注册到选择其中 添加Read事件，触发后进行读取操作 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class SelectServer { public static void main(String[] args) { ByteBuffer buffer = ByteBuffer.allocate(16); // 获得服务器通道 try(ServerSocketChannel server = ServerSocketChannel.open()) { server.bind(new InetSocketAddress(8080)); // 创建选择器 Selector selector = Selector.open(); // 通道必须设置为非阻塞模式 server.configureBlocking(false); // 将通道注册到选择器中，并设置感兴趣的实践 server.register(selector, SelectionKey.OP_ACCEPT); // 为serverKey设置感兴趣的事件 while (true) { // 若没有事件就绪，线程会被阻塞，反之不会被阻塞。从而避免了CPU空转 // 返回值为就绪的事件个数 int ready = selector.select(); System.out.println(&quot;selector ready counts : &quot; + ready); // 获取所有事件 Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); // 使用迭代器遍历事件 Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); // 判断key的类型 if(key.isAcceptable()) { // 获得key对应的channel ServerSocketChannel channel = (ServerSocketChannel) key.channel(); System.out.println(&quot;before accepting...&quot;); // 获取连接 SocketChannel socketChannel = channel.accept(); System.out.println(&quot;after accepting...&quot;); // 设置为非阻塞模式，同时将连接的通道也注册到选择其中 socketChannel.configureBlocking(false); socketChannel.register(selector, SelectionKey.OP_READ); // 处理完毕后移除 iterator.remove(); } else if (key.isReadable()) { SocketChannel channel = (SocketChannel) key.channel(); System.out.println(&quot;before reading...&quot;); channel.read(buffer); System.out.println(&quot;after reading...&quot;); buffer.flip(); ByteBufferUtil.debugRead(buffer); buffer.clear(); // 处理完毕后移除 iterator.remove(); } } } } catch (IOException e) { e.printStackTrace(); } }} 删除事件 当处理完一个事件后，一定要调用迭代器的remove方法移除对应事件，否则会出现错误。原因如下 以我们上面的 Read事件 的代码为例 当调用了 server.register(selector, SelectionKey.OP_ACCEPT)后，Selector中维护了一个集合，用于存放SelectionKey以及其对应的通道 12// WindowsSelectorImpl 中的 SelectionKeyImpl数组private SelectionKeyImpl[] channelArray = new SelectionKeyImpl[8]; 12345public class SelectionKeyImpl extends AbstractSelectionKey { // Key对应的通道 final SelChImpl channel; ...} 当选择器中的通道对应的事件发生后，selecionKey会被放到另一个集合中，但是selecionKey不会自动移除，所以需要我们在处理完一个事件后，通过迭代器手动移除其中的selecionKey。否则会导致已被处理过的事件再次被处理，就会引发错误 断开处理当客户端与服务器之间的连接断开时，会给服务器端发送一个读事件，对异常断开和正常断开需要加以不同的方式进行处理 正常断开 正常断开时，服务器端的channel.read(buffer)方法的返回值为-1，所以当结束到返回值为-1时，需要调用key的cancel方法取消此事件，并在取消后移除该事件 1234567891011int read = channel.read(buffer);// 断开连接时，客户端会向服务器发送一个写事件，此时read的返回值为-1if(read == -1) { // 取消该事件的处理 key.cancel(); channel.close();} else { ...}// 取消或者处理，都需要移除keyiterator.remove(); 异常断开 异常断开时，会抛出IOException异常， 在try-catch的catch块中捕获异常并调用key的cancel方法即可 消息边界不处理消息边界存在的问题 将缓冲区的大小设置为4个字节，发送2个汉字（你好），通过decode解码并打印时，会出现乱码 123ByteBuffer buffer = ByteBuffer.allocate(4);// 解码并打印System.out.println(StandardCharsets.UTF_8.decode(buffer)); 输出如下： 12你��� 这是因为UTF-8字符集下，1个汉字占用3个字节，此时缓冲区大小为4个字节，一次读时间无法处理完通道中的所有数据，所以一共会触发两次读事件。这就导致 你好 的 好 字被拆分为了前半部分和后半部分发送，解码时就会出现问题 处理消息边界 传输的文本可能有以下三种情况 文本大于缓冲区大小 此时需要将缓冲区进行扩容 发生半包现象 发生粘包现象 解决思路大致有以下三种 固定消息长度，数据包大小一样，服务器按预定长度读取，当发送的数据较少时，需要将数据进行填充，直到长度与消息规定长度一致。缺点是浪费带宽 另一种思路是按分隔符拆分，缺点是效率低，需要一个一个字符地去匹配分隔符 TLV 格式，即 Type 类型、Length 长度、Value 数据 （也就是在消息开头 用一些空间存放后面数据的长度 ），如HTTP请求头中的Content-Type与 Content-Length 。类型和长度已知的情况下，就可以方便获取消息大小，分配合适的 buffer，缺点是 buffer 需要提前分配，如果内容过大，则影响 server 吞吐量 Http 1.1 是 TLV 格式 Http 2.0 是 LTV 格式 下文的消息边界处理方式为第二种：按分隔符拆分 附件与扩容 Channel的register方法还有第三个参数：附件，可以向其中放入一个Object类型的对象，该对象会与登记的Channel以及其对应的SelectionKey绑定，可以从SelectionKey获取到对应通道的附件 1public final SelectionKey register(Selector sel, int ops, Object att) 可通过SelectionKey的attachment()方法获得附件 1ByteBuffer buffer = (ByteBuffer) key.attachment(); 我们需要在Accept事件发生后，将通道注册到Selector中时，对每个通道添加一个ByteBuffer附件，让每个通道发生读事件时都使用自己的通道，避免与其他通道发生冲突而导致问题 12345// 设置为非阻塞模式，同时将连接的通道也注册到选择其中，同时设置附件socketChannel.configureBlocking(false);ByteBuffer buffer = ByteBuffer.allocate(16);// 添加通道对应的Buffer附件socketChannel.register(selector, SelectionKey.OP_READ, buffer); 当Channel中的数据大于缓冲区时，需要对缓冲区进行扩容操作。此代码中的扩容的判定方法：Channel调用compact方法后，的position与limit相等，说明缓冲区中的数据并未被读取（容量太小），此时创建新的缓冲区，其大小扩大为两倍。同时还要将旧缓冲区中的数据拷贝到新的缓冲区中，同时调用SelectionKey的attach方法将新的缓冲区作为新的附件放入SelectionKey中 12345678// 如果缓冲区太小，就进行扩容if (buffer.position() == buffer.limit()) { ByteBuffer newBuffer = ByteBuffer.allocate(buffer.capacity()*2); // 将旧buffer中的内容放入新的buffer中 ewBuffer.put(buffer); // 将新buffer作为附件放到key中 key.attach(newBuffer);} 改造后的服务器代码如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public class SelectServer { public static void main(String[] args) { // 获得服务器通道 try(ServerSocketChannel server = ServerSocketChannel.open()) { server.bind(new InetSocketAddress(8080)); // 创建选择器 Selector selector = Selector.open(); // 通道必须设置为非阻塞模式 server.configureBlocking(false); // 将通道注册到选择器中，并设置感兴趣的事件 server.register(selector, SelectionKey.OP_ACCEPT); // 为serverKey设置感兴趣的事件 while (true) { // 若没有事件就绪，线程会被阻塞，反之不会被阻塞。从而避免了CPU空转 // 返回值为就绪的事件个数 int ready = selector.select(); System.out.println(&quot;selector ready counts : &quot; + ready); // 获取所有事件 Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); // 使用迭代器遍历事件 Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); // 判断key的类型 if(key.isAcceptable()) { // 获得key对应的channel ServerSocketChannel channel = (ServerSocketChannel) key.channel(); System.out.println(&quot;before accepting...&quot;); // 获取连接 SocketChannel socketChannel = channel.accept(); System.out.println(&quot;after accepting...&quot;); // 设置为非阻塞模式，同时将连接的通道也注册到选择其中，同时设置附件 socketChannel.configureBlocking(false); ByteBuffer buffer = ByteBuffer.allocate(16); socketChannel.register(selector, SelectionKey.OP_READ, buffer); // 处理完毕后移除 iterator.remove(); } else if (key.isReadable()) { SocketChannel channel = (SocketChannel) key.channel(); System.out.println(&quot;before reading...&quot;); // 通过key获得附件（buffer） ByteBuffer buffer = (ByteBuffer) key.attachment(); int read = channel.read(buffer); if(read == -1) { key.cancel(); channel.close(); } else { // 通过分隔符来分隔buffer中的数据 split(buffer); // 如果缓冲区太小，就进行扩容 if (buffer.position() == buffer.limit()) { ByteBuffer newBuffer = ByteBuffer.allocate(buffer.capacity()*2); // 将旧buffer中的内容放入新的buffer中 buffer.flip(); newBuffer.put(buffer); // 将新buffer放到key中作为附件 key.attach(newBuffer); } } System.out.println(&quot;after reading...&quot;); // 处理完毕后移除 iterator.remove(); } } } } catch (IOException e) { e.printStackTrace(); } } private static void split(ByteBuffer buffer) { buffer.flip(); for(int i = 0; i &lt; buffer.limit(); i++) { // 遍历寻找分隔符 // get(i)不会移动position if (buffer.get(i) == '\\n') { // 缓冲区长度 int length = i+1-buffer.position(); ByteBuffer target = ByteBuffer.allocate(length); // 将前面的内容写入target缓冲区 for(int j = 0; j &lt; length; j++) { // 将buffer中的数据写入target中 target.put(buffer.get()); } // 打印结果 ByteBufferUtil.debugAll(target); } } // 切换为写模式，但是缓冲区可能未读完，这里需要使用compact buffer.compact(); }} ByteBuffer的大小分配 每个 channel 都需要记录可能被切分的消息，因为 ByteBuffer 不能被多个 channel 共同使用，因此需要为每个 channel 维护一个独立的 ByteBuffer ByteBuffer 不能太大，比如一个 ByteBuffer 1Mb 的话，要支持百万连接就要 1Tb 内存，因此需要设计大小可变的 ByteBuffer 分配思路可以参考 一种思路是首先分配一个较小的 buffer，例如 4k，如果发现数据不够，再分配 8k 的 buffer，将 4k buffer 内容拷贝至 8k buffer，优点是消息连续容易处理，缺点是数据拷贝耗费性能 参考实现 http://tutorials.jenkov.com/java-performance/resizable-array.html 另一种思路是用多个数组组成 buffer，一个数组不够，把多出来的内容写入新的数组，与前面的区别是消息存储不连续解析复杂，优点是避免了拷贝引起的性能损耗 案例： 服务端： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.chan.nio.c4;import com.chan.nio.c2.ByteBufferUtil;import lombok.SneakyThrows;import lombok.extern.slf4j.Slf4j;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.ServerSocketChannel;import java.nio.channels.SocketChannel;import java.util.ArrayList;import java.util.List;/** * 有个缺陷就是线程会死循环，导致CPU空转 */@Slf4j(topic = &quot;Server&quot;)public class Server { @SneakyThrows public static void main(String[] args) { ByteBuffer buffer = ByteBuffer.allocate(16); ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.configureBlocking(false); ssc.bind(new InetSocketAddress(8080)); List&lt;SocketChannel&gt; channels = new ArrayList&lt;&gt;(); while (true) { SocketChannel sc = ssc.accept(); if (sc != null) { log.debug(&quot;connected... {}&quot;, sc); sc.configureBlocking(false); channels.add(sc); } for (SocketChannel channel : channels) { int read = channel.read(buffer); if (read &gt; 0) { buffer.flip(); ByteBufferUtil.debugRead(buffer); buffer.clear(); log.debug(&quot;after read... {}&quot;, channel); } } } }} 改进服务端代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889package com.chan.nio.c4;import com.chan.nio.c2.ByteBufferUtil;import lombok.SneakyThrows;import lombok.extern.slf4j.Slf4j;import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.*;import java.util.Iterator;import java.util.Set;/** * 单线程配合选择器完成对多个socketChannel事件的处理 */@Slf4j(topic = &quot;Server2&quot;)public class Server2 { @SneakyThrows public static void main(String[] args) { ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); //更改为非阻塞模式 serverSocketChannel.configureBlocking(false); serverSocketChannel.bind(new InetSocketAddress(8080)); Selector selector = Selector.open(); //将channel注册到selector，并指定事件类型为ACCEPT serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT, null); while (true) { Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); if (iterator.hasNext()) { SelectionKey key = iterator.next(); // 处理key 时，要从 selectedKeys 集合中删除，否则下次处理就会有问题 iterator.remove(); //事件类型为ACCEPT的key if (key.isAcceptable()) { //因为Selector中事件类型为Accept的channel只有一个，因此这个ssc和上面的serverSocketChannel是同一个 ServerSocketChannel ssc = (ServerSocketChannel) key.channel(); SocketChannel socketChannel = ssc.accept(); socketChannel.configureBlocking(false); ByteBuffer buffer = ByteBuffer.allocate(16); //将一个bytebuffer作为附件关联到selectionKey上 SelectionKey scKey = socketChannel.register(selector, SelectionKey.OP_READ, buffer); log.debug(&quot;scKey: {}&quot;, scKey); } else if (key.isReadable()) { try { //因为Selector中事件类型为Read的channel可能有多个，因此这个sc和上面的socketChannel不一定是同一个 SocketChannel sc = (SocketChannel) key.channel();//拿到触发事件的channel // ByteBuffer buffer = ByteBuffer.allocate(16); //获取selectionKey上面关联的附件 ByteBuffer buffer = (ByteBuffer) key.attachment(); int read = sc.read(buffer);// 如果客户端是正常断开，读不到数据了，那么 read 的方法的返回值是 -1 if (read == -1) { key.cancel(); } else { buffer.flip();//将buffer切换为读模式（默认为写） //处理消息的边界问题，比如(黏包，半包问题) for (int i = 0; i &lt; buffer.limit(); i++) { //找到一条完整数据 buffer.get(i)通过索引方式从buffer读数据，position指针不会向后移动 if (buffer.get(i) == '\\n'){ int length = i + 1 - buffer.position(); //将这条完整的数据存入新的buffer ByteBuffer target = ByteBuffer.allocate(length); //从buffer读向target写 for (int j = 0; j &lt; length; j++) { //buffer.get()获取buffer中position位置的下一个，position指针向后移动 target.put(buffer.get()); } ByteBufferUtil.debugAll(target); } } buffer.compact();//将buffer切换为写模式 //需要扩容的话 if (buffer.position() == buffer.limit()) { ByteBuffer newBuffer = ByteBuffer.allocate(buffer.capacity() * 2); buffer.flip(); newBuffer.put(buffer); key.attach(newBuffer); } } } catch (IOException e) { e.printStackTrace(); key.cancel();// 因为客户端断开了,因此需要将 key 取消（从 selector 的 keys 集合中真正删除 key） } } } } }} 客户端： 12345678910111213141516171819202122package com.chan.nio.c4;import lombok.SneakyThrows;import lombok.extern.slf4j.Slf4j;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.SocketChannel;@Slf4j(topic = &quot;Client&quot;)public class Client { @SneakyThrows public static void main(String[] args) { ByteBuffer buffer = ByteBuffer.allocate(16); SocketChannel channel = SocketChannel.open(); channel.connect(new InetSocketAddress(&quot;localhost&quot;, 8080)); log.debug(&quot;waiting...&quot;); buffer.put(&quot;hello...&quot;.getBytes());//写入 buffer.flip(); channel.write(buffer);//通过channel发送 buffer.clear(); }} Write事件服务器通过Buffer向通道中写入数据时，可能因为通道容量小于Buffer中的数据大小，导致无法一次性将Buffer中的数据全部写入到Channel中，这时便需要分多次写入，具体步骤如下 执行一次写操作，向将buffer中的内容写入到SocketChannel中，然后判断Buffer中是否还有数据 若Buffer中还有数据，则需要将SockerChannel注册到Seletor中，并关注写事件，同时将未写完的Buffer作为附件一起放入到SelectionKey中 1234567 int write = socket.write(buffer);// 通道中可能无法放入缓冲区中的所有数据if (buffer.hasRemaining()) { // 注册到Selector中，关注可写事件，并将buffer添加到key的附件中 socket.configureBlocking(false); socket.register(selector, SelectionKey.OP_WRITE, buffer);} 添加写事件的相关操作key.isWritable()，对Buffer再次进行写操作 每次写后需要判断Buffer中是否还有数据（是否写完）。若写完，需要移除SelecionKey中的Buffer附件，避免其占用过多内存，同时还需移除对写事件的关注 1234567891011SocketChannel socket = (SocketChannel) key.channel();// 获得bufferByteBuffer buffer = (ByteBuffer) key.attachment();// 执行写操作int write = socket.write(buffer);System.out.println(write);// 如果已经完成了写操作，需要移除key中的附件，同时不再对写事件感兴趣if (!buffer.hasRemaining()) { key.attach(null); key.interestOps(0);} 整体代码如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class WriteServer { public static void main(String[] args) { try(ServerSocketChannel server = ServerSocketChannel.open()) { server.bind(new InetSocketAddress(8080)); server.configureBlocking(false); Selector selector = Selector.open(); server.register(selector, SelectionKey.OP_ACCEPT); while (true) { selector.select(); Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); // 处理后就移除事件 iterator.remove(); if (key.isAcceptable()) { // 获得客户端的通道 SocketChannel socket = server.accept(); // 写入数据 StringBuilder builder = new StringBuilder(); for(int i = 0; i &lt; 500000000; i++) { builder.append(&quot;a&quot;); } ByteBuffer buffer = StandardCharsets.UTF_8.encode(builder.toString()); // 先执行一次Buffer-&gt;Channel的写入，如果未写完，就添加一个可写事件 int write = socket.write(buffer); System.out.println(write); // 通道中可能无法放入缓冲区中的所有数据 if (buffer.hasRemaining()) { // 注册到Selector中，关注可写事件，并将buffer添加到key的附件中 socket.configureBlocking(false); socket.register(selector, SelectionKey.OP_WRITE, buffer); } } else if (key.isWritable()) { SocketChannel socket = (SocketChannel) key.channel(); // 获得buffer ByteBuffer buffer = (ByteBuffer) key.attachment(); // 执行写操作 int write = socket.write(buffer); System.out.println(write); // 如果已经完成了写操作，需要移除key中的附件，同时不再对写事件感兴趣 if (!buffer.hasRemaining()) { key.attach(null); key.interestOps(0); } } } } } catch (IOException e) { e.printStackTrace(); } }} 案例代码： 服务端： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package com.chan.nio.c4;import lombok.SneakyThrows;import lombok.extern.slf4j.Slf4j;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.*;import java.nio.charset.Charset;import java.util.Iterator;@Slf4j(topic = &quot;WriteServer&quot;)public class WriteServer { @SneakyThrows public static void main(String[] args) { ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.configureBlocking(false); Selector selector = Selector.open(); ssc.register(selector, SelectionKey.OP_ACCEPT, null); // sscKey.interestOps(SelectionKey.OP_ACCEPT); ssc.bind(new InetSocketAddress(8080)); while (true) { selector.select(); Iterator&lt;SelectionKey&gt; iterator = selector.selectedKeys().iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); iterator.remove(); if (key.isAcceptable()) { /* 和上面的ssc其实是一个，因为对于服务器而言，ServerSocketChannel只有一个，所以这个位置也可以ssc.accept()。 但是SocketChannel不行，因为有多个，需要根据触发事件的那个key去找到对应的SocketChannel。 ServerSocketChannel serverSocketChannel = (ServerSocketChannel) key.channel(); SocketChannel socketChannel = serverSocketChannel.accept(); */ SocketChannel socketChannel = ssc.accept(); socketChannel.configureBlocking(false); SelectionKey scKey = socketChannel.register(selector, 0, null); scKey.interestOps(SelectionKey.OP_READ); //向客户端发送大量数据 StringBuilder stringBuilder = new StringBuilder(); for (int i = 0; i &lt; 5000000; i++) { stringBuilder.append(&quot;a&quot;); } //将数据放入buffer并且自动打开buffer的读模式 ByteBuffer buffer = Charset.defaultCharset().encode(stringBuilder.toString()); //返回值代表实际写入的字节数，不一定能一次性写完 int write = socketChannel.write(buffer); System.out.println(write); //判断是否有剩余内容 if (buffer.hasRemaining()) { //关注可写事件 1 4 scKey.interestOps(scKey.interestOps() + SelectionKey.OP_WRITE);//5 表示关注读事件和写事件或下面写法 // scKey.interestOps(scKey.interestOps() | SelectionKey.OP_WRITE); //把未写完的数据挂到scKey上 scKey.attach(buffer); } } else if (key.isWritable()) { ByteBuffer buffer = (ByteBuffer) key.attachment(); SocketChannel channel = (SocketChannel) key.channel(); int write = channel.write(buffer); System.out.println(write); //清理操作 if (!buffer.hasRemaining()) {//如果内容都写完了的话 key.attach(null);//清除buffer key.interestOps(key.interestOps() - SelectionKey.OP_WRITE);//不再关注可写事件 } } } } }} 客户端： 123456789101112131415161718192021222324package com.chan.nio.c4;import lombok.SneakyThrows;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.SocketChannel;public class WriteClient { @SneakyThrows public static void main(String[] args) { SocketChannel socketChannel = SocketChannel.open(); //客户端这边connect一连上，服务端那边selector.select(),就会往下进行，就会发现一个事件类型为ACCEPT的key socketChannel.connect(new InetSocketAddress(&quot;localhost&quot;, 8080)); //接收数据 int count = 0; while (true) { ByteBuffer buffer = ByteBuffer.allocate(1024 * 1024); count = count + socketChannel.read(buffer); System.out.println(count); buffer.clear(); } }} 优化多线程优化充分利用多核CPU，分两组选择器 单线程配一个选择器（Boss），专门处理 accept 事件 创建 cpu 核心数的线程（Worker），每个线程配一个选择器，轮流处理 read 事件 实现思路 创建一个负责处理Accept事件的Boss线程，与多个负责处理Read事件的Worker线程 Boss线程执行的操作 接受并处理Accepet事件，当Accept事件发生后，调用Worker的register(SocketChannel socket)方法，让Worker去处理Read事件，其中需要根据标识robin去判断将任务分配给哪个Worker 123456// 创建固定数量的WorkerWorker[] workers = new Worker[4];// 用于负载均衡的原子整数AtomicInteger robin = new AtomicInteger(0);// 负载均衡，轮询分配Workerworkers[robin.getAndIncrement()% workers.length].register(socket); register(SocketChannel socket)方法会通过同步队列完成Boss线程与Worker线程之间的通信，让SocketChannel的注册任务被Worker线程执行。添加任务后需要调用selector.wakeup()来唤醒被阻塞的Selector 123456789101112131415161718192021public void register(final SocketChannel socket) throws IOException { // 只启动一次 if (!started) { // 初始化操作 } // 向同步队列中添加SocketChannel的注册事件 // 在Worker线程中执行注册事件 queue.add(new Runnable() { @Override public void run() { try { socket.register(selector, SelectionKey.OP_READ); } catch (IOException e) { e.printStackTrace(); } } }); // 唤醒被阻塞的Selector // select类似LockSupport中的park，wakeup的原理类似LockSupport中的unpark selector.wakeup();} Worker线程执行的操作 从同步队列中获取注册任务，并处理Read事件 实现代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117public class ThreadsServer { public static void main(String[] args) { try (ServerSocketChannel server = ServerSocketChannel.open()) { // 当前线程为Boss线程 Thread.currentThread().setName(&quot;Boss&quot;); server.bind(new InetSocketAddress(8080)); // 负责轮询Accept事件的Selector Selector boss = Selector.open(); server.configureBlocking(false); server.register(boss, SelectionKey.OP_ACCEPT); // 创建固定数量的Worker Worker[] workers = new Worker[4]; // 用于负载均衡的原子整数 AtomicInteger robin = new AtomicInteger(0); for(int i = 0; i &lt; workers.length; i++) { workers[i] = new Worker(&quot;worker-&quot;+i); } while (true) { boss.select(); Set&lt;SelectionKey&gt; selectionKeys = boss.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); iterator.remove(); // BossSelector负责Accept事件 if (key.isAcceptable()) { // 建立连接 SocketChannel socket = server.accept(); System.out.println(&quot;connected...&quot;); socket.configureBlocking(false); // socket注册到Worker的Selector中 System.out.println(&quot;before read...&quot;); // 负载均衡，轮询分配Worker workers[robin.getAndIncrement()% workers.length].register(socket); System.out.println(&quot;after read...&quot;); } } } } catch (IOException e) { e.printStackTrace(); } } static class Worker implements Runnable { private Thread thread; private volatile Selector selector; private String name; private volatile boolean started = false; /** * 同步队列，用于Boss线程与Worker线程之间的通信 */ private ConcurrentLinkedQueue&lt;Runnable&gt; queue; public Worker(String name) { this.name = name; } public void register(final SocketChannel socket) throws IOException { // 只启动一次 if (!started) { thread = new Thread(this, name); selector = Selector.open(); queue = new ConcurrentLinkedQueue&lt;&gt;(); thread.start(); started = true; } // 向同步队列中添加SocketChannel的注册事件 // 在Worker线程中执行注册事件 queue.add(new Runnable() { @Override public void run() { try { socket.register(selector, SelectionKey.OP_READ); } catch (IOException e) { e.printStackTrace(); } } }); // 唤醒被阻塞的Selector // select类似LockSupport中的park，wakeup的原理类似LockSupport中的unpark selector.wakeup(); } @Override public void run() { while (true) { try { selector.select(); // 通过同步队列获得任务并运行 Runnable task = queue.poll(); if (task != null) { // 获得任务，执行注册操作 task.run(); } Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); while(iterator.hasNext()) { SelectionKey key = iterator.next(); iterator.remove(); // Worker只负责Read事件 if (key.isReadable()) { // 简化处理，省略细节 SocketChannel socket = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(16); socket.read(buffer); buffer.flip(); ByteBufferUtil.debugAll(buffer); } } } catch (IOException e) { e.printStackTrace(); } } } }} NIO与BIOStream与Channel stream 不会自动缓冲数据，channel 会利用系统提供的发送缓冲区、接收缓冲区（更为底层） stream 仅支持阻塞 API，channel 同时支持阻塞、非阻塞 API，网络 channel 可配合 selector 实现多路复用 二者 均为全双工 ，即读写可以同时进行 虽然Stream是单向流动的，但是它也是全双工的 IO模型 同步 ：线程自己去获取结果（一个线程） 例如：线程调用一个方法后，需要等待方法返回结果 异步 ：线程自己不去获取结果，而是由其它线程返回结果（至少两个线程） 例如：线程A调用一个方法后，继续向下运行，运行结果由线程B返回 当调用一次 channel.read 或 stream.read 后，会由用户态切换至操作系统内核态来完成真正数据读取，而读取又分为两个阶段，分别为： 等待数据阶段 复制数据阶段 根据UNIX 网络编程 - 卷 I，IO模型主要有以下几种 阻塞IO 用户线程进行read操作时，需要等待操作系统执行实际的read操作，此期间用户线程是被阻塞的，无法执行其他操作 非阻塞IO 用户线程 在一个循环中一直调用read方法 ，若内核空间中还没有数据可读，立即返回 只是在等待阶段非阻塞 用户线程发现内核空间中有数据后，等待内核空间执行复制数据，待复制结束后返回结果 多路复用 Java中通过Selector实现多路复用 当没有事件是，调用select方法会被阻塞住 一旦有一个或多个事件发生后，就会处理对应的事件，从而实现多路复用 多路复用与阻塞IO的区别 阻塞IO模式下，若线程因accept事件被阻塞，发生read事件后，仍需等待accept事件执行完成后，才能去处理read事件 多路复用模式下，一个事件发生后，若另一个事件处于阻塞状态，不会影响该事件的执行 异步IO 线程1调用方法后理解返回，不会被阻塞也不需要立即获取结果 当方法的运行结果出来以后，由线程2将结果返回给线程1 零拷贝零拷贝指的是数据无需拷贝到 JVM 内存中，同时具有以下三个优点 更少的用户态与内核态的切换 不利用 cpu 计算，减少 cpu 缓存伪共享 零拷贝适合小文件传输 传统 IO 问题传统的 IO 将一个文件通过 socket 写出 12345678File f = new File(&quot;helloword/data.txt&quot;);RandomAccessFile file = new RandomAccessFile(file, &quot;r&quot;);byte[] buf = new byte[(int)f.length()];file.read(buf);Socket socket = ...;socket.getOutputStream().write(buf); 内部工作流如下 Java 本身并不具备 IO 读写能力，因此 read 方法调用后，要从 Java 程序的用户态切换至内核态，去调用操作系统（Kernel）的读能力，将数据读入内核缓冲区。这期间用户线程阻塞，操作系统使用 DMA（Direct Memory Access）来实现文件读，其间也不会使用 CPU DMA 也可以理解为硬件单元，用来解放 cpu 完成文件 IO 从内核态切换回用户态，将数据从内核缓冲区读入用户缓冲区（即 byte[] buf），这期间 CPU 会参与拷贝，无法利用 DMA 调用 write 方法，这时将数据从用户缓冲区（byte[] buf）写入 socket 缓冲区，CPU 会参与拷贝 接下来要向网卡写数据，这项能力 Java 又不具备，因此又得从用户态切换至内核态，调用操作系统的写能力，使用 DMA 将 socket 缓冲区的数据写入网卡，不会使用 CPU 可以看到中间环节较多，java 的 IO 实际不是物理设备级别的读写，而是缓存的复制，底层的真正读写是操作系统来完成的 用户态与内核态的切换发生了 3 次，这个操作比较重量级 数据拷贝了共 4 次 NIO 优化通过 DirectByteBuf ByteBuffer.allocate(10) 底层对应 HeapByteBuffer，使用的还是 Java 内存 ByteBuffer. allocateDirect (10) 底层对应DirectByteBuffer，使用的是操作系统内存 大部分步骤与优化前相同，唯有一点：Java 可以使用 DirectByteBuffer 将堆外内存映射到 JVM 内存中来直接访问使用 这块内存不受 JVM 垃圾回收的影响，因此内存地址固定，有助于 IO 读写 Java 中的 DirectByteBuf 对象仅维护了此内存的虚引用，内存回收分成两步 DirectByteBuffer 对象被垃圾回收，将虚引用加入引用队列 当引用的对象ByteBuffer被垃圾回收以后，虚引用对象Cleaner就会被放入引用队列中，然后调用Cleaner的clean方法来释放直接内存 DirectByteBuffer 的释放底层调用的是 Unsafe 的 freeMemory 方法 通过专门线程访问引用队列，根据虚引用释放堆外内存 减少了一次数据拷贝，用户态与内核态的切换次数没有减少 进一步优化1以下两种方式都是零拷贝，即无需将数据拷贝到用户缓冲区中（JVM内存中） 底层采用了 linux 2.1 后提供的 sendFile 方法，Java 中对应着两个 channel 调用 transferTo/transferFrom 方法拷贝数据 Java 调用 transferTo 方法后，要从 Java 程序的用户态切换至内核态，使用 DMA将数据读入内核缓冲区，不会使用 CPU 数据从内核缓冲区传输到 socket 缓冲区，CPU 会参与拷贝 最后使用 DMA 将 socket 缓冲区的数据写入网卡，不会使用 CPU 这种方法下 只发生了1次用户态与内核态的切换 数据拷贝了 3 次 进一步优化2linux 2.4 对上述方法再次进行了优化 Java 调用 transferTo 方法后，要从 Java 程序的用户态切换至内核态，使用 DMA将数据读入内核缓冲区，不会使用 CPU 只会将一些 offset 和 length 信息拷入 socket 缓冲区，几乎无消耗 使用 DMA 将 内核缓冲区的数据写入网卡，不会使用 CPU 整个过程仅只发生了1次用户态与内核态的切换，数据拷贝了 2 次 AIOAIO 用来解决数据复制阶段的阻塞问题 同步意味着，在进行读写操作时，线程需要等待结果，还是相当于闲置 异步意味着，在进行读写操作时，线程不必等待结果，而是将来由操作系统来通过回调方式由另外的线程来获得结果 异步模型需要底层操作系统（Kernel）提供支持 Windows 系统通过 IOCP 实现了真正的异步 IO Linux 系统异步 IO 在 2.6 版本引入，但其底层实现还是用多路复用模拟了异步 IO，性能没有优势。","link":"/posts/20220315/netty-nio.html"},{"title":"RabbitMQ学习记录","text":"初级篇。 初识MQ同步和异步通讯微服务间通讯有同步和异步两种方式： 同步通讯：就像打电话，需要实时响应。 异步通讯：就像发邮件，不需要马上回复。 两种方式各有优劣，打电话可以立即得到响应，但是你却不能跟多个人同时通话。发送邮件可以同时与多个人收发邮件，但是往往响应会有延迟。 同步通讯我们熟知的微服务间通信Feign调用就属于同步方式，虽然调用可以实时得到结果，但存在下面的问题： 总结： 同步调用的优点： 时效性较强，可以立即得到结果 同步调用的问题： 耦合度高 性能和吞吐能力下降 有额外的资源消耗 有级联失败问题 异步通讯异步调用则可以避免上述问题： 我们以购买商品为例，用户支付后需要调用订单服务完成订单状态修改，调用物流服务，从仓库分配响应的库存并准备发货。 在事件模式中，支付服务是事件发布者（publisher），在支付完成后只需要发布一个支付成功的事件（event），事件中带上订单id。 订单服务和物流服务是事件订阅者（Consumer），订阅支付成功的事件，监听到事件后完成自己业务即可。 为了解除事件发布者与订阅者之间的耦合，两者并不是直接通信，而是有一个中间人（Broker）。发布者发布事件到Broker，不关心谁来订阅事件。订阅者从Broker订阅事件，不关心谁发来的消息。 Broker 是一个像数据总线一样的东西，所有的服务要接收数据和发送数据都发到这个总线上，这个总线就像协议一样，让服务间的通讯变得标准和可控。 好处： 吞吐量提升：无需等待订阅者处理完成，响应更快速 故障隔离：服务没有直接调用，不存在级联失败问题 调用间没有阻塞，不会造成无效的资源占用 耦合度极低，每个服务都可以灵活插拔，可替换 流量削峰：不管发布事件的流量波动多大，都由Broker接收，订阅者可以按照自己的速度去处理事件 缺点： 架构复杂了，业务没有明显的流程线，不好管理 需要依赖于Broker的可靠、安全、性能 好在现在开源软件或云平台上 Broker 的软件是非常成熟的，比较常见的一种就是我们今天要学习的MQ技术。 技术对比MQ，中文是消息队列（MessageQueue），字面来看就是存放消息的队列。也就是事件驱动架构中的Broker。 比较常见的MQ实现： ActiveMQ RabbitMQ RocketMQ Kafka 几种常见MQ的对比： RabbitMQ ActiveMQ RocketMQ Kafka 公司/社区 Rabbit Apache 阿里 Apache 开发语言 Erlang Java Java Scala&amp;Java 协议支持 AMQP，XMPP，SMTP，STOMP OpenWire,STOMP，REST,XMPP,AMQP 自定义协议 自定义协议 可用性 高 一般 高 高 单机吞吐量 一般 差 高 非常高 消息延迟 微秒级 毫秒级 毫秒级 毫秒以内 消息可靠性 高 一般 高 一般 追求可用性：Kafka、 RocketMQ 、RabbitMQ 追求可靠性：RabbitMQ、RocketMQ 追求吞吐能力：RocketMQ、Kafka 追求消息低延迟：RabbitMQ、Kafka 快速入门安装RabbitMQhttps://chanservy.github.io/posts/20220622/rabbitmq-install.html MQ的基本结构： RabbitMQ中的一些角色： publisher：生产者 consumer：消费者 exchange：交换机，负责消息路由 queue：队列，存储消息 virtualHost：虚拟主机，隔离不同租户的exchange、queue、消息的隔离 RabbitMQ消息模型RabbitMQ官方提供了5个不同的Demo示例，对应了不同的消息模型： Demo案例案例代码地址：https://github.com/ChanServy/rabbitmq-advanced 包括三部分： mq-demo：父工程，管理项目依赖 publisher：消息的发送者 consumer：消息的消费者 common：公共模块 入门案例简单队列模式的模型图： 官方的HelloWorld是基于最基础的消息队列模型来实现的，只包括三个角色： publisher：消息发布者，将消息发送到队列queue queue：消息队列，负责接受并缓存消息 consumer：订阅队列，处理队列中的消息 publisher实现思路： 建立连接 创建Channel 声明队列 发送消息 关闭连接和channel 代码实现： 123456789101112131415161718192021222324252627282930313233343536373839404142package cn.itcast.mq.helloworld;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import org.junit.Test;import java.io.IOException;import java.util.concurrent.TimeoutException;public class PublisherTest { @Test public void testSendMessage() throws IOException, TimeoutException { // 1.建立连接 ConnectionFactory factory = new ConnectionFactory(); // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码 factory.setHost(&quot;192.168.150.101&quot;); factory.setPort(5672); factory.setVirtualHost(&quot;/&quot;); factory.setUsername(&quot;itcast&quot;); factory.setPassword(&quot;123321&quot;); // 1.2.建立连接 Connection connection = factory.newConnection(); // 2.创建通道Channel Channel channel = connection.createChannel(); // 3.创建队列 String queueName = &quot;simple.queue&quot;; channel.queueDeclare(queueName, false, false, false, null); // 4.发送消息 String message = &quot;hello, rabbitmq!&quot;; channel.basicPublish(&quot;&quot;, queueName, null, message.getBytes()); System.out.println(&quot;发送消息成功：【&quot; + message + &quot;】&quot;); // 5.关闭通道和连接 channel.close(); connection.close(); }} consumer实现代码思路： 建立连接 创建Channel 声明队列 订阅消息 代码实现： 1234567891011121314151617181920212223242526272829303132333435363738394041package cn.itcast.mq.helloworld;import com.rabbitmq.client.*;import java.io.IOException;import java.util.concurrent.TimeoutException;public class ConsumerTest { public static void main(String[] args) throws IOException, TimeoutException { // 1.建立连接 ConnectionFactory factory = new ConnectionFactory(); // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码 factory.setHost(&quot;192.168.150.101&quot;); factory.setPort(5672); factory.setVirtualHost(&quot;/&quot;); factory.setUsername(&quot;itcast&quot;); factory.setPassword(&quot;123321&quot;); // 1.2.建立连接 Connection connection = factory.newConnection(); // 2.创建通道Channel Channel channel = connection.createChannel(); // 3.创建队列 String queueName = &quot;simple.queue&quot;; channel.queueDeclare(queueName, false, false, false, null); // 4.订阅消息 channel.basicConsume(queueName, true, new DefaultConsumer(channel){ @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { // 5.处理消息 String message = new String(body); System.out.println(&quot;接收到消息：【&quot; + message + &quot;】&quot;); } }); System.out.println(&quot;等待接收消息。。。。&quot;); }} 总结基本消息队列的消息发送流程： 建立connection 创建channel 利用channel声明队列 利用channel向队列发送消息 基本消息队列的消息接收流程： 建立connection 创建channel 利用channel声明队列 定义consumer的消费行为handleDelivery() 利用channel将消费者与队列绑定 SpringAMQPSpringAMQP是基于RabbitMQ封装的一套模板，并且还利用SpringBoot对其实现了自动装配，使用起来非常方便。 SpringAmqp的官方地址：https://spring.io/projects/spring-amqp SpringAMQP提供了三个功能： 自动声明队列、交换机及其绑定关系 基于注解的监听器模式，异步接收消息 封装了RabbitTemplate工具，用于发送消息 Basic Queue 简单队列模型在父工程中引入依赖 12345&lt;!--AMQP依赖，包含RabbitMQ--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 消息发送首先配置MQ地址，在publisher服务的application.yml中添加配置： 1234567spring: rabbitmq: host: localhost # 主机名 port: 5672 # 端口 virtual-host: / # 虚拟主机 username: root # 用户名 password: 123456 # 密码 然后在publisher服务中编写测试类SpringAmqpTest，并利用RabbitTemplate实现消息发送： 123456789101112131415161718192021222324252627282930313233343536373839@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringAmqpTest { @Autowired private RabbitTemplate rabbitTemplate; /** * basic queue 简单队列模型 * 利用RabbitTemplate实现向指定队列中发送消息。 * 一个生产者向队列中推送消息，一个消费者监听队列消费消息。 */ @Test public void testSimpleQueue() { // 队列名称 String queueName = &quot;simple.queue&quot;; // 消息 String message = &quot;hello, spring amqp!&quot;; // 发送消息 rabbitTemplate.convertAndSend(queueName, message); }}@RestController@Slf4jpublic class MqController { @Resource RabbitTemplate rabbitTemplate; @RequestMapping(&quot;/simple&quot;) public R simpleSendToQueue() { Book book = new Book(); book.setName(&quot;蛤蟆先生去看心理医生&quot;); book.setAuthor(&quot;罗伯特&quot;); String bookJson = JSONUtil.toJsonStr(book); rabbitTemplate.convertAndSend(&quot;simple.queue&quot;, bookJson); return R.ok(); }} 消息接收首先配置MQ地址，在consumer服务的application.yml中添加配置： 1234567spring: rabbitmq: host: localhost # 主机名 port: 5672 # 端口 virtual-host: / # 虚拟主机 username: root # 用户名 password: 123456 # 密码 新建一个类SimpleQueueListener，代码如下： 注：@RabbitListener注解监听的队列在MQ服务器中如果不存在，会报错。 发送消息，如果发送的消息是个对象，我们会使用序列化机制将对象写出去，对象必须实现 Serializable。 123456789101112131415/** * 生产者消费者服务间传递的消息是对象时，对象的引用路径必须一致 * 这样就得将这个对象抽取出来放到公共模块 * 如果不这样，那么在发送消息之前，生产者可以将这个对象变成JSON字符串 * 然后再发送，那么在消费者收到消息之后，需要将JSON字符串再转成对象。 * * @author CHAN * @since 2022/7/7 */@Datapublic class Book implements Serializable { private String name; private String author;} 1234567891011121314151617181920212223242526272829303132333435363738394041package com.chan.mq.consumer.listener;import com.chan.mq.common.pojo.Book;import com.chan.mq.common.pojo.Movie;import org.springframework.amqp.rabbit.annotation.RabbitHandler;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Component;/** * 监听消息：使用@RabbitListener * @RabbitListener ：加在类或者方法上（监听哪些队列即可）queues：声明需要监听的所有队列。 * @RabbitHandler ：加在方法上（区分不同类型的消息） * 区分的不同类型消息： * 可能是listener监听两个队列的消息，两个队列中的消息类型可能不同，String、Book。 * 也可能是listener监听一个队列中的消息，发送到这个队列的多条消息类型可能不同，String、Book。 * * @author CHAN * @since 2022/7/7 */// @RabbitListener(queues = {&quot;simple.queue&quot;, &quot;work.queue&quot;})@Component@RabbitListener(queues = {&quot;simple.queue&quot;})public class SimpleQueueListener { /** * 监听simple.queue队列中的消息，如果simple.queue不存在会报错。 * // @RabbitListener(queues = &quot;simple.queue&quot;) * // public void listenSimpleQueueMessage(String msg) throws InterruptedException { * // System.out.println(&quot;spring 消费者接收到消息：【&quot; + msg + &quot;】&quot;); * // } */ @RabbitHandler public void listenSimpleQueueMessage(String msg) { System.out.println(&quot;spring 消费者接收到String类型的消息：【&quot; + msg + &quot;】&quot;); } @RabbitHandler public void listenSimpleQueueMessage(Book book) { System.out.println(&quot;spring 消费者接收到Book类型的消息：【&quot; + book + &quot;】&quot;); }} @RabbitListener ：加在类或者方法上，queues：声明需要监听的所有队列。 @RabbitHandler ：加在方法上（区分不同类型的消息） 区分的不同类型消息： 可能是listener监听两个队列的消息，两个队列中的消息类型可能不同，String、Book。 也可能是listener监听一个队列中的消息，发送到这个队列的多条消息类型可能不同，String、Book。 参数可以写以下类型： 1、Message message：原生消息详细信息。头 + 体 2、T&lt;发送的消息的类型&gt; ：例如 Book 3、Channel channel：当前传输数据的通道。注：如果消费者需要手动 ACK，那么就得传 channel，channel 可以调用相关 API。 Queue：可以多个消费者都来监听，只要消息被收到，队列删除消息，而且在正常情况下，同一条消息只能有一个消费者收到。 场景： 订单服务启动多个，但是对于同一条消息只能有一个客户端收到。 只有一个消息完全处理完，方法运行结束，我们才可以接收到下一条消息。 测试启动consumer服务，然后在publisher服务中运行测试代码，发送MQ消息。 注意： RabbitMQ一共五种消息队列。基本消息队列和工作消息队列的情况下，生产者是直接向队列中发送消息，消费者监听队列就可以。创建队列的代码写在消费者微服务里面，生产者服务只需要知道队列的名字，发送消息时指定队列名和消息就可以。创建队列的方式我们使用@Bean的方式。 在广播（Fanout）、路由（Direct）、主题（Topic）的情况下，生产者是向交换机（Exchange）中发送消息，然后绑定队列和交换机，绑定之后交换机将消息传递给队列，消费者依然是监听队列。创建交换机、队列以及绑定的代码写在消费者微服务里面，生产者服务需要知道交换机的名字、交换机和队列间传递消息的routing key，发送消息时指定交换机名和key就可以。创建交换机、队列以及绑定的代码我们可以使用@Bean的方式，也可以直接在@RabbitListener注解中声明交换机并指定交换机类型、队列以及绑定关系。 WorkQueueWork queues，也被称为（Task queues），任务模型。简单来说就是让多个消费者绑定到一个队列，共同消费队列中的消息。 当消息处理比较耗时的时候，可能生产消息的速度会远远大于消息的消费速度。长此以往，消息就会堆积越来越多，无法及时处理。 此时就可以使用work 模型，多个消费者共同处理消息处理，速度就能大大提高了。 消息发送这次我们循环发送，模拟大量消息堆积现象。 在publisher服务中的SpringAmqpTest类中添加一个测试方法： 1234567891011121314151617/** * WorkQueues，也被称为（Task queues），任务模型 * 向队列中不停发送消息，模拟消息堆积。 * 一个生产者向队列中推送消息，让多个消费者绑定到一个队列，共同消费队列中的消息。避免消息堆积。 */@Testpublic void testWorkQueue() throws InterruptedException { // 队列名称 String queueName = &quot;work.queue&quot;; // 消息 String message = &quot;hello, message_&quot;; for (int i = 0; i &lt; 10; i++) { // 发送消息 rabbitTemplate.convertAndSend(queueName, message + i); Thread.sleep(20); }} 消息接收要模拟多个消费者绑定同一个队列，我们在consumer服务的WorkQueueListener中添加2个新的方法： 1234567891011121314@Componentpublic class WorkQueueListener { @RabbitListener(queues = &quot;work.queue&quot;) public void listenWorkQueue1(String msg) throws InterruptedException { System.out.println(&quot;消费者1接收到消息：【&quot; + msg + &quot;】&quot; + LocalTime.now()); Thread.sleep(20); } @RabbitListener(queues = &quot;work.queue&quot;) public void listenWorkQueue2(String msg) throws InterruptedException { System.err.println(&quot;消费者2......接收到消息：【&quot; + msg + &quot;】&quot; + LocalTime.now()); Thread.sleep(200); }} 注意到这个消费者sleep了200毫秒，模拟任务耗时，两个消费者任务耗时不一致。 测试启动ConsumerApplication后，在执行publisher服务中刚刚编写的发送测试方法testWorkQueue。 可以看到消费者1很快完成了自己的25条消息。消费者2却在缓慢的处理自己的25条消息。 也就是说消息是平均分配给每个消费者，并没有考虑到消费者的处理能力。这样显然是有问题的。 能者多劳在spring中有一个简单的配置，可以解决这个问题。我们修改consumer服务的application.yml文件，添加配置： 12345spring: rabbitmq: listener: simple: prefetch: 1 # 每次只能获取一条消息，处理完成才能获取下一个消息 总结Work模型的使用： 多个消费者绑定到一个队列，同一条消息只会被一个消费者处理 通过设置prefetch来控制消费者预取的消息数量 发布/订阅发布订阅的模型如图： 可以看到，在订阅模型中，多了一个exchange角色，而且过程略有变化： Publisher：生产者，也就是要发送消息的程序，但是不再发送到队列中，而是发给交换机 Exchange：交换机。一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange的类型。Exchange有以下3种类型： Fanout：广播，将消息交给所有绑定到交换机的队列 Direct：定向，把消息交给符合指定routing key 的队列 Topic：通配符，把消息交给符合routing pattern（路由模式） 的队列 Consumer：消费者，与以前一样，订阅队列，没有变化 Queue：消息队列也与以前一样，接收消息、缓存消息。 Exchange（交换机）只负责转发消息，不具备存储消息的能力，因此如果没有任何队列与Exchange绑定，或者没有符合路由规则的队列，那么消息会丢失！ FanoutFanout，英文翻译是扇出，我觉得在MQ中叫广播更合适。 在广播模式下，消息发送流程是这样的： 1） 可以有多个队列 2） 每个队列都要绑定到Exchange（交换机） 3） 生产者发送的消息，只能发送到交换机，交换机来决定要发给哪个队列，生产者无法决定 4） 交换机把消息发送给绑定过的所有队列 5） 订阅队列的消费者都能拿到消息 我们的计划是这样的： 创建一个交换机 itcast.fanout，类型是Fanout 创建两个队列fanout.queue1和fanout.queue2，绑定到交换机itcast.fanout 声明队列和交换机Spring提供了一个接口Exchange，来表示所有不同类型的交换机： 在consumer中创建一个类，声明队列和交换机： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * @author CHAN * @since 2022/7/8 */@Configurationpublic class FanoutConfig { /** * 声明交换机，默认情况下，由SpringAMQP声明的交换机都是持久化的。 * @return Fanout类型交换机 */ @Bean public FanoutExchange fanoutExchange(){ // 三个参数：交换机名称、是否持久化、当没有queue与其绑定时是否自动删除 return new FanoutExchange(&quot;fanout.exchange&quot;, true, false); } /** * 默认情况下，由SpringAMQP声明的队列都是持久化的。 * 第1个队列 */ @Bean public Queue fanoutQueue1(){ return new Queue(&quot;fanout.queue1&quot;); // 使用QueueBuilder构建队列，durable就是持久化的 // return QueueBuilder.durable(&quot;fanout.queue1&quot;).build(); } /** * 绑定队列和交换机 */ @Bean public Binding bindingQueue1(){ return BindingBuilder.bind(fanoutQueue1()).to(fanoutExchange()); } /** * 第2个队列 */ @Bean public Queue fanoutQueue2(){ return new Queue(&quot;fanout.queue2&quot;); } /** * 绑定队列和交换机 */ @Bean public Binding bindingQueue2(){ return BindingBuilder.bind(fanoutQueue2()).to(fanoutExchange()); }} 消息发送123456789@RequestMapping(&quot;/fanout&quot;)public R fanoutSendToExchange() { // 交换机名称 String exchangeName = &quot;fanout.exchange&quot;; // 消息 String message = &quot;hello, Rabbit FanoutExchange!&quot;; rabbitTemplate.convertAndSend(exchangeName, &quot;&quot;, message); return R.ok();} 消息接收在consumer服务的WithExchangeListener中添加两个方法，作为消费者： 1234567891011121314151617/** * @author CHAN * @since 2022/7/8 */@Componentpublic class WithExchangeListener { @RabbitListener(queues = &quot;fanout.queue1&quot;) public void listenFanoutQueue1(String msg) { int i = 1 / 0;// test error msg System.out.println(&quot;消费者1接收到Fanout消息：【&quot; + msg + &quot;】&quot;); } @RabbitListener(queues = &quot;fanout.queue2&quot;) public void listenFanoutQueue2(String msg) { System.out.println(&quot;消费者2接收到Fanout消息：【&quot; + msg + &quot;】&quot;); }} 总结交换机的作用是什么？ 接收publisher发送的消息 将消息按照规则路由到与之绑定的队列 不能缓存消息，路由失败，消息丢失 FanoutExchange的会将消息路由到每个绑定的队列 声明队列、交换机、绑定关系的Bean是什么？ Queue FanoutExchange Binding Direct在Fanout模式中，一条消息，会被所有订阅的队列都消费。但是，在某些场景下，我们希望不同的消息被不同的队列消费。这时就要用到Direct类型的Exchange。 在Direct模型下： 队列与交换机的绑定，不能是任意绑定了，而是要指定一个RoutingKey（路由key） 消息的发送方在 向 Exchange发送消息时，也必须指定消息的 RoutingKey。 Exchange不再把消息交给每一个绑定的队列，而是根据消息的Routing Key进行判断，只有队列的Routingkey与消息的 Routing key完全一致，才会接收到消息 案例需求如下： 利用@RabbitListener声明Exchange、Queue、RoutingKey 在consumer服务中，编写两个消费者方法，分别监听direct.queue1和direct.queue2 在publisher中编写测试方法，向itcast. direct发送消息 基于注解声明队列和交换机基于@Bean的方式声明队列和交换机比较麻烦，Spring还提供了基于注解方式来声明。 在consumer的WithExchangeListener中添加两个消费者，同时基于注解来声明队列和交换机： 123456789101112131415161718// 上面的fanout类型的交换机测试的时候我们是使用@Bean的方式创建的交换机和队列以及绑定关系，下面使用注解的方式@RabbitListener(bindings = @QueueBinding( value = @Queue(name = &quot;direct.queue1&quot;), exchange = @Exchange(name = &quot;direct.exchange&quot;, type = ExchangeTypes.DIRECT/*交换机类型默认DIRECT*/), key = {&quot;red&quot;, &quot;blue&quot;}))public void listenDirectQueue1(String msg) { System.out.println(&quot;消费者接收到direct.queue1的消息：【&quot; + msg + &quot;】&quot;);}@RabbitListener(bindings = @QueueBinding( value = @Queue(name = &quot;direct.queue2&quot;), exchange = @Exchange(name = &quot;direct.exchange&quot;, type = ExchangeTypes.DIRECT), key = {&quot;red&quot;, &quot;yellow&quot;}))public void listenDirectQueue2(String msg) { System.out.println(&quot;消费者接收到direct.queue2的消息：【&quot; + msg + &quot;】&quot;);} 消息发送在publisher服务中添加测试方法： 12345678910@RequestMapping(&quot;/direct&quot;)public R directSendToExchange() { // 交换机名称 String exchangeName = &quot;direct.exchange&quot;; // 消息 String message = &quot;红色警报！日本乱排核废水，导致海洋生物变异，惊现哥斯拉！&quot;; // 发送消息 rabbitTemplate.convertAndSend(exchangeName, &quot;blue&quot;, message); return R.ok();} 总结描述下Direct交换机与Fanout交换机的差异？ Fanout交换机将消息路由给每一个与之绑定的队列 Direct交换机根据RoutingKey判断路由给哪个队列 如果多个队列具有相同的RoutingKey，则与Fanout功能类似 基于@RabbitListener注解声明队列和交换机有哪些常见注解？ @Queue @Exchange Topic说明Topic类型的Exchange与Direct相比，都是可以根据RoutingKey把消息路由到不同的队列。只不过Topic类型Exchange可以让队列在绑定Routing key 的时候使用通配符！ Routingkey 一般都是有一个或多个单词组成，多个单词之间以”.”分割，例如： item.insert 通配符规则： #：匹配一个或多个词 *：匹配不多不少恰好1个词 举例： item.#：能够匹配item.spu.insert 或者 item.spu item.*：只能匹配item.spu ​ 图示： 解释： Queue1：绑定的是china.# ，因此凡是以 china.开头的routing key 都会被匹配到。包括china.news和china.weather Queue4：绑定的是#.news ，因此凡是以 .news结尾的 routing key 都会被匹配。包括china.news和japan.news 案例需求： 实现思路如下： 利用@RabbitListener声明Exchange、Queue、RoutingKey 在consumer服务中，编写两个消费者方法，分别监听topic.queue1和topic.queue2 在publisher中编写测试方法，向itcast. topic发送消息 消息发送在publisher服务中添加测试方法： 12345678910@RequestMapping(&quot;/topic&quot;)public R topicSendToExchange() { // 交换机名称 String exchangeName = &quot;topic.exchange&quot;; // 消息 String message = &quot;喜报！孙悟空大战哥斯拉，胜!&quot;; // 发送消息 rabbitTemplate.convertAndSend(exchangeName, &quot;china.news&quot;, message); return R.ok();} 消息接收在consumer服务的WithExchangeListener中添加方法： 1234567891011121314151617@RabbitListener(bindings = @QueueBinding( value = @Queue(name = &quot;topic.queue1&quot;), exchange = @Exchange(name = &quot;topic.exchange&quot;, type = ExchangeTypes.TOPIC), key = &quot;china.#&quot;))public void listenTopicQueue1(String msg) { System.out.println(&quot;消费者接收到topic.queue1的消息：【&quot; + msg + &quot;】&quot;);}@RabbitListener(bindings = @QueueBinding( value = @Queue(name = &quot;topic.queue2&quot;), exchange = @Exchange(name = &quot;topic.exchange&quot;, type = ExchangeTypes.TOPIC), key = &quot;#.news&quot;))public void listenTopicQueue2(String msg) { System.out.println(&quot;消费者接收到topic.queue2的消息：【&quot; + msg + &quot;】&quot;);} 总结描述下Direct交换机与Topic交换机的差异？ Topic交换机接收的消息RoutingKey必须是多个单词，以 **.** 分割 Topic交换机与队列绑定时的bindingKey可以指定通配符 #：代表0个或多个词 *：代表1个词 消息转换器之前说过，Spring会把你发送的消息序列化为字节发送给MQ（前提是对象类型实现序列化接口），接收消息的时候，还会把字节反序列化为Java对象。 只不过，默认情况下Spring采用的序列化方式是JDK序列化。众所周知，JDK序列化存在下列问题： 数据体积过大 有安全漏洞 可读性差 我们来测试一下。 测试默认转换器我们修改消息发送的代码，发送一个Map对象： 123456789@Testpublic void testSendMap() throws InterruptedException { // 准备消息 Map&lt;String,Object&gt; msg = new HashMap&lt;&gt;(); msg.put(&quot;name&quot;, &quot;Jack&quot;); msg.put(&quot;age&quot;, 21); // 发送消息 rabbitTemplate.convertAndSend(&quot;simple.queue&quot;,&quot;&quot;, msg);} 停止consumer服务 发送消息后查看控制台： 配置JSON转换器显然，JDK序列化方式并不合适。我们希望消息体的体积更小、可读性更高，因此可以使用JSON方式来做序列化和反序列化。 在publisher和consumer两个服务中都引入依赖： 1234&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;&lt;/dependency&gt; 配置消息转换器。 在启动类中添加一个Bean即可： 1234@Beanpublic MessageConverter messageConverter() { return new Jackson2JsonMessageConverter();} 但是我个人还是更倾向于自己手动将对象类型转成一个JSON字符串，然后再发送到MQ Server，消费者接收JSON字符串后再手动转成对象。不想用这个。 高级篇。 消息队列在使用过程中，面临着很多实际问题需要思考： 消息可靠性消息从发送，到消费者接收，会经理多个过程： 其中的每一步都可能导致消息丢失，常见的丢失原因包括： 发送时丢失： 生产者发送的消息未送达exchange 消息到达exchange后未到达queue MQ宕机，queue将消息丢失 consumer接收到消息后未消费就宕机 针对这些问题，RabbitMQ分别给出了解决方案： 生产者确认机制 mq持久化 消费者确认机制 失败重试机制 下面通过案例来演示每一个步骤。案例代码地址：https://github.com/ChanServy/rabbitmq-advanced 生产者消息确认RabbitMQ提供了publisher confirm机制来避免消息发送到MQ过程中丢失。这种机制必须给每个消息指定一个唯一ID。消息发送到MQ以后，会返回一个结果给发送者，表示消息是否处理成功。 返回结果有两种方式： publisher-confirm，发送者确认 消息成功投递到交换机，返回ack 消息未投递到交换机，返回nack publisher-return，发送者回执 消息投递到交换机了，但是没有路由到队列。返回ACK，及路由失败原因。 注意： 修改配置首先，修改publisher服务中的application.yml文件，添加下面的内容： 1234567spring: rabbitmq: publisher-confirm-type: correlated publisher-returns: true template: mandatory: true 说明： publish-confirm-type：开启publisher-confirm，这里支持两种类型： simple：同步等待confirm结果，直到超时 correlated：异步回调，定义ConfirmCallback，MQ返回结果时会回调这个ConfirmCallback publish-returns：开启publish-return功能，同样是基于callback机制，不过是定义ReturnCallback template.mandatory：定义消息路由失败时的策略。true，则调用ReturnCallback；false：则直接丢弃消息 定义Return回调每个RabbitTemplate只能配置一个ReturnCallback，因此需要在项目加载时配置： 修改publisher服务，添加一个： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.chan.mq.producer.config;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.beans.BeansException;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.context.annotation.Configuration;/** * 每个RabbitTemplate只能配置一个ReturnCallback，因此需要在项目加载时配置 * @author CHAN * @since 2022/7/7 */@Slf4j@Configurationpublic class MyRabbitConfig implements ApplicationContextAware { // @Bean // public MessageConverter messageConverter() { // return new Jackson2JsonMessageConverter(); // } @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { // 获取RabbitTemplate RabbitTemplate rabbitTemplate = applicationContext.getBean(RabbitTemplate.class); // 设置ReturnCallback rabbitTemplate.setReturnCallback((message, replyCode, replyText, exchange, routingKey) -&gt; { // 判断是否是延迟消息 Integer receivedDelay = message.getMessageProperties().getReceivedDelay(); if (receivedDelay != null &amp;&amp; receivedDelay &gt; 0) { // 是一个延迟消息，忽略这个错误提示 return; } // 投递失败，记录日志 log.info(&quot;消息发送失败，应答码{}，原因{}，交换机{}，路由键{},消息{}&quot;, replyCode, replyText, exchange, routingKey, message.toString()); // 如果有业务需要，可以重发消息 // ... }); }} 定义ConfirmCallbackConfirmCallback可以在发送消息时指定，因为每个业务处理confirm成功或失败的逻辑不一定相同。 common服务中： 123456@Datapublic class Movie implements Serializable { private int id; private String name; private String author;} 在publisher服务中，定义一个测试方法： 123456789101112131415161718192021222324252627282930313233@RequestMapping(&quot;/confirm&quot;)public R testSendWithConfirmCallback() { // 消息体 Movie movie = new Movie(); movie.setId(1); movie.setName(&quot;复仇者联盟&quot;); movie.setAuthor(&quot;漫威&quot;); // String movieJson = JSONUtil.toJsonStr(movie); // 全局唯一的消息ID，需要封装到CorrelationData中 CorrelationData correlationData = new CorrelationData(String.valueOf(movie.getId())); // 添加callback correlationData.getFuture().addCallback( result -&gt; { // 判断结果 if (Objects.requireNonNull(result).isAck()) { // ACK log.debug(&quot;消息成功投递到交换机！消息ID: {}&quot;, correlationData.getId()); } else { // NACK log.error(&quot;消息投递到交换机失败！消息ID：{}，原因：{}&quot;, correlationData.getId(), result.getReason()); // 重发消息 } }, exception -&gt; { // 记录日志 log.error(&quot;消息发送异常, 消息ID：{}，原因：{}&quot;, correlationData.getId(), exception.getMessage()); // 重发消息... } ); // 发送消息 rabbitTemplate.convertAndSend(&quot;simple.queue&quot;, movie, correlationData); return R.ok();} 消费者： 1234567891011121314151617@Component@RabbitListener(queues = {&quot;simple.queue&quot;})public class SimpleQueueListener { @RabbitHandler public void listenSimpleQueueMessage(Movie movie, Message message, Channel channel) throws IOException { System.out.println(&quot;spring 消费者接收到Movie类型的消息：【&quot; + movie + &quot;】&quot;); byte[] body = message.getBody();// 获取消息体 MessageProperties properties = message.getMessageProperties();// 获取消息头属性信息 long deliveryTag = properties.getDeliveryTag();// channel内按顺序自增的 System.out.println(&quot;deliveryTag===&gt;&quot; + deliveryTag); channel.basicAck(deliveryTag, false);// 消费者手动ACK，false：只手动ACK当前这条消息 // requeue=false 丢弃；requeue=true 重新发回MQ服务器，重新入队 channel.basicNack(deliveryTag, false, false);// 消费者手动NACK，false：只手动NACK当前这条消息，false：设置NACK这条消息不重新入队 channel.basicReject(deliveryTag, false);// 和NACK1个意思，只不过不能设置批量参数 }} 参数可以写以下类型： 1、Message message：原生消息详细信息。头 + 体 2、T&lt;发送的消息的类型&gt; ：例如 Book 3、Channel channel：当前传输数据的通道。注：如果消费者需要手动 ACK，那么就得传 channel，channel 可以调用相关 API。 后面详细说消费者端消息安全性的问题。 消息持久化生产者确认可以确保消息投递到RabbitMQ的队列中，但是消息发送到RabbitMQ以后，如果突然宕机，也可能导致消息丢失。 要想确保消息在RabbitMQ中安全保存，必须开启消息持久化机制。 交换机持久化 队列持久化 消息持久化 交换机持久化RabbitMQ中交换机默认是非持久化的，mq重启后就丢失。 SpringAMQP中可以通过代码指定交换机持久化： 12345@Beanpublic DirectExchange simpleExchange(){ // 三个参数：交换机名称、是否持久化、当没有queue与其绑定时是否自动删除 return new DirectExchange(&quot;simple.direct&quot;, true, false);} 事实上，默认情况下，由SpringAMQP声明的交换机都是持久化的。 可以在RabbitMQ控制台看到持久化的交换机都会带上D的标示： 队列持久化RabbitMQ中队列默认是非持久化的，mq重启后就丢失。 SpringAMQP中可以通过代码指定交换机持久化： 12345@Beanpublic Queue simpleQueue(){ // 使用QueueBuilder构建队列，durable就是持久化的 return QueueBuilder.durable(&quot;simple.queue&quot;).build();} 事实上，默认情况下，由SpringAMQP声明的队列都是持久化的。 可以在RabbitMQ控制台看到持久化的队列都会带上D的标示： 消息持久化利用SpringAMQP发送消息时，可以设置消息的属性（MessageProperties），指定delivery-mode： 1：非持久化 2：持久化 用java代码指定： 默认情况下，SpringAMQP发出的任何消息都是持久化的，不用特意指定。 消费者消息确认RabbitMQ是阅后即焚机制，RabbitMQ确认消息被消费者消费后会立刻删除。 而RabbitMQ是通过消费者回执来确认消费者是否成功处理消息的：消费者获取消息后，应该向RabbitMQ发送ACK回执，表明自己已经处理消息。 设想这样的场景： 1）RabbitMQ投递消息给消费者 2）消费者获取消息后，返回ACK给RabbitMQ 3）RabbitMQ删除消息 4）消费者宕机，消息尚未处理 这样，消息就丢失了。因此消费者返回ACK的时机非常重要。 而SpringAMQP则允许配置三种确认模式： manual：手动ack，需要在业务代码结束后，调用api发送ack。 auto：自动ack，由spring监测listener代码是否出现异常，没有异常则返回ack；抛出异常则返回nack none：关闭ack，MQ假定消费者获取消息后会成功处理，因此消息投递后立即被删除 由此可知： none模式下，消息投递是不可靠的，可能丢失 auto模式类似事务机制，出现异常时返回nack，消息回滚到mq；没有异常，返回ack manual：自己根据业务情况，判断什么时候该ack 一般，我们都是使用默认的auto即可。 演示none模式修改consumer服务的application.yml文件，添加下面内容： 12345spring: rabbitmq: listener: simple: acknowledge-mode: none # 关闭ack 修改consumer服务中的方法，模拟一个消息处理异常： 1234567@RabbitListener(queues = &quot;simple.queue&quot;)public void listenSimpleQueue(String msg) { log.info(&quot;消费者接收到simple.queue的消息：【{}】&quot;, msg); // 模拟异常 System.out.println(1 / 0); log.debug(&quot;消息处理完成！&quot;);} 测试可以发现，当消息处理抛异常时，消息依然被RabbitMQ删除了。 演示auto模式再次把确认机制修改为auto: 12345spring: rabbitmq: listener: simple: acknowledge-mode: auto # 自动ack 在异常位置打断点，再次发送消息，程序卡在断点时，可以发现此时消息状态为unack（未确定状态）： 抛出异常后，因为Spring会自动返回nack，所以消息恢复至Ready状态，并且没有被RabbitMQ删除： 消费失败重试机制当消费者出现异常后，消息会不断requeue（重入队）到队列，再重新发送给消费者，然后再次异常，再次requeue，无限循环，导致mq的消息处理飙升，带来不必要的压力： 怎么办呢？ 本地重试我们可以利用Spring的retry机制，在消费者收到消息后，运行过程中消费者出现异常时利用本地重试，而不是无限制的requeue到mq队列。 修改consumer服务的application.yml文件，添加内容： 12345678910spring: rabbitmq: listener: simple: retry: enabled: true # 开启消费者失败重试 initial-interval: 1000 # 初始的失败等待时长为1秒 multiplier: 1 # 失败的等待时长倍数，下次等待时长 = multiplier * last-interval max-attempts: 3 # 最大重试次数 stateless: true # true无状态；false有状态。如果业务中包含事务，这里改为false 重启consumer服务，重复之前的测试。可以发现： 在重试3次后，SpringAMQP会抛出异常AmqpRejectAndDontRequeueException，说明本地重试触发了 查看RabbitMQ控制台，发现消息被删除了，说明最后SpringAMQP返回的是ack，mq删除消息了 结论： 开启本地重试时，消息处理过程中抛出异常，不会requeue到队列，而是在消费者本地重试 重试达到最大次数后，Spring会返回ack，消息会被丢弃 失败策略在之前的测试中，达到最大重试次数后，消息会被丢弃，这是由Spring内部机制决定的。 在开启重试模式后，重试次数耗尽，如果消息依然失败，则需要有MessageRecovery接口来处理，它包含三种不同的实现： RejectAndDontRequeueRecoverer：重试耗尽后，直接reject，丢弃消息。默认就是这种方式 ImmediateRequeueMessageRecoverer：重试耗尽后，返回nack，消息重新入队 RepublishMessageRecoverer：重试耗尽后，将失败消息投递到指定的交换机 比较优雅的一种处理方案是RepublishMessageRecoverer，失败后将消息投递到一个指定的，专门存放异常消息的队列，后续由人工集中处理。 1）在consumer服务中定义处理失败消息的交换机和队列 123456789101112@Beanpublic DirectExchange errorMessageExchange(){ return new DirectExchange(&quot;error.direct&quot;);}@Beanpublic Queue errorQueue(){ return new Queue(&quot;error.queue&quot;, true);}@Beanpublic Binding errorBinding(Queue errorQueue, DirectExchange errorMessageExchange){ return BindingBuilder.bind(errorQueue).to(errorMessageExchange).with(&quot;error&quot;);} 2）定义一个RepublishMessageRecoverer，关联队列和交换机 1234@Beanpublic MessageRecoverer republishMessageRecoverer(RabbitTemplate rabbitTemplate){ return new RepublishMessageRecoverer(rabbitTemplate, &quot;error.direct&quot;, &quot;error&quot;);} 完整代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package com.chan.mq.consumer.config;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.DirectExchange;import org.springframework.amqp.core.Queue;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.amqp.rabbit.retry.MessageRecoverer;import org.springframework.amqp.rabbit.retry.RepublishMessageRecoverer;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * 消费者自动ACK的情况下，当消费者有异常，Spring会感知到RabbitListener中的异常，不会ACK并且会将消息requeue回原来的队列中。 * 但是requeue回队列中就又会立刻被消费者收到并且异常，这样就会一直requeue，从而降低MQ的吞吐量。因此我们配置了Spring本地重试， * 这样本地重试一定次数（我们可以配置）后，SpringAMQP会抛出AmqpRejectAndDontRequeueException（说明本地重试触发了消息不会requeue了） * 并且SpringAMQP会返回ACK给RabbitMQ服务器将消息删除。 * * 结论： * 开启本地重试时，消息处理过程中抛出异常，不会requeue到队列，而是在消费者本地重试 * 重试达到最大次数后，Spring会返回ack，相当于Spring默认本地重试一定次数后消息一定会被成功消费，消息会被丢弃 * * 这个丢弃策略是默认的，但是这样就会造成消息丢失，并不好，因此我们需要有一个MessageRecovery接口来处理，这个接口包含3种实现： * RejectAndDontRequeueRecoverer：重试耗尽后，直接reject，丢弃消息。默认就是这种方式 * ImmediateRequeueMessageRecoverer：重试耗尽后，返回nack，消息重新入队 * RepublishMessageRecoverer：重试耗尽后，将失败消息投递到指定的交换机 * * 我们选择RepublishMessageRecoverer，处理消息失败后将消息投递到一个指定的，专门存放异常消息的队列，后续由人工集中处理。 * 配置就是本类。 * * 当消费者出现异常了，异常消息的处理方案可以使用这种，也可以使用死信交换机那种。 * * @author CHAN * @since 2022/7/8 */@Configurationpublic class RepublishMessageRecovererConfig { /** * 专门存放处理失败的消息的交换机 * @return */ @Bean public DirectExchange errorMessageExchange(){ return new DirectExchange(&quot;error.direct&quot;); } /** * 存放异常消息的队列 * @return */ @Bean public Queue errorQueue(){ return new Queue(&quot;error.queue&quot;, true); } /** * 绑定 * @return */ @Bean public Binding errorBinding(){ return BindingBuilder.bind(errorQueue()).to(errorMessageExchange()).with(&quot;error&quot;); } /** * 定义一个RepublishMessageRecoverer，关联队列和交换机 */ @Bean public MessageRecoverer republishMessageRecoverer(RabbitTemplate rabbitTemplate){ return new RepublishMessageRecoverer(rabbitTemplate, &quot;error.direct&quot;, &quot;error&quot;); }} 总结如何确保RabbitMQ消息的可靠性？ 开启生产者确认机制，确保生产者的消息能到达队列 开启持久化功能，确保消息未消费前在队列中不会丢失 开启消费者确认机制为auto，由spring确认消息处理成功后完成ack 开启消费者失败重试机制，并设置MessageRecoverer，多次重试失败后将消息投递到异常交换机，交由人工处理 死信交换机初识死信交换机什么是死信交换机什么是死信？ 当一个队列中的消息满足下列情况之一时，可以成为死信（dead letter）： 消息被消费者使用reject拒绝（丢弃）了或使用nack声明消费失败了，并且消息的requeue参数设置为false 情况一：比如收到消息后消费者出现异常，本地重试相应次数后的默认策略（上面介绍过），消息reject情况。 情况二：比如设置了手动ACK机制。消费者端手动NACK了，并且requeue参数设置为了false。消息requeue=false情况。 消息是一个过期消息，超时无人消费 要投递的队列消息满了，无法投递 如果这个包含死信的队列配置了dead-letter-exchange属性和dead-letter-routingkey属性，也就是说这个包含死信的队列指定了一个死信交换机，那么队列中的死信就会投递到这个交换机中，而这个交换机称为死信交换机（Dead Letter Exchange，检查DLX）。 队列将死信投递给死信交换机时，必须知道两个信息： 死信交换机名称 死信交换机与死信队列绑定的RoutingKey 如图，一个消息被消费者拒绝了，变成了死信： 因为simple.queue绑定了死信交换机 dl.direct，因此死信会投递给这个交换机： 如果这个死信交换机也绑定了一个队列，则消息最终会进入这个存放死信的队列： 另外，队列将死信投递给死信交换机时，必须知道两个信息： 死信交换机名称 死信交换机与死信队列绑定的RoutingKey 这样才能确保投递的消息能到达死信交换机，并且正确的路由到死信队列。 利用死信交换机接收死信（拓展）在失败重试策略中，默认的RejectAndDontRequeueRecoverer会在本地重试次数耗尽后，发送reject给RabbitMQ，消息变成死信，被丢弃。 我们可以给simple.queue添加一个死信交换机，给死信交换机绑定一个队列。这样消息变成死信后也不会丢弃，而是最终投递到死信交换机，路由到与死信交换机绑定的队列。 我们在consumer服务中，定义一组死信交换机、死信队列： 1234567891011121314151617181920212223242526272829303132333435363738package com.chan.mq.consumer.config;import org.springframework.amqp.core.*;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @author CHAN 注：与图中不一致。图只是思路，这个类是我自己配置的。 * @since 2022/7/8 */@Configurationpublic class DeadLetterConfig { // 声明普通的queue队列，并且为其指定死信交换机：dl.direct // 这样这个普通的队列中如果有死信，那么死信就会进到这个死信交换机 @Bean public Queue normalQueue() { return QueueBuilder.durable(&quot;normal.queue&quot;)// 指定队列名称，并持久化 .deadLetterExchange(&quot;dl.direct&quot;)// 指定死信交换机 .deadLetterRoutingKey(&quot;dl&quot;)// 指定死信交换机和死信队列绑定的key .build(); } // 声明死信交换机 dl.direct @Bean public DirectExchange dlExchange(){ return new DirectExchange(&quot;dl.direct&quot;, true, false); } // 声明存储死信的队列 dl.queue @Bean public Queue dlQueue(){ return new Queue(&quot;dl.queue&quot;, true); } // 将死信队列 与 死信交换机绑定 @Bean public Binding dlBinding(){ return BindingBuilder.bind(dlQueue()).to(dlExchange()).with(&quot;dl&quot;); }} 总结什么样的消息会成为死信？ 消息被消费者reject或者返回nack 消息超时未消费 队列满了 如何给队列指定死信交换机？ 给队列设置dead-letter-exchange属性，指定一个交换机 给队列设置dead-letter-routing-key属性，设置死信交换机与死信队列的RoutingKey 死信交换机的使用场景是什么？ 如果队列绑定了死信交换机，死信会投递到死信交换机； 可以利用死信交换机收集所有消费者处理失败的消息（死信），交由人工处理，进一步提高消息队列的可靠性。 TTL一个队列中的消息如果超时未消费，则会变为死信，超时分为两种情况： 消息所在的队列设置了超时时间 消息本身设置了超时时间 接收超时死信的死信交换机在consumer服务中，定义一个新的消费者，并且声明死信交换机、死信队列，这个消费者消费死信队列中的死信，也就是正常队列超时或者正常队列中的消息超时从而进到死信交换机（前提是这个正常队列创建时指定了死信交换机），进而进到死信队列中的消息，业务中可看做延迟消息。 注解方式声明死信交换机和死信队列： 12345678@RabbitListener(bindings = @QueueBinding( value = @Queue(name = &quot;dl.ttl.queue&quot;, durable = &quot;true&quot;), exchange = @Exchange(name = &quot;dl.ttl.direct&quot;), key = &quot;dl.ttl&quot;))public void listenDlQueue(String msg){ log.info(&quot;接收到 dl.ttl.queue的延迟消息：{}&quot;, msg);} 声明一个队列，并且指定TTL要给队列设置超时时间，需要在声明队列时配置x-message-ttl属性： 12345678@Beanpublic Queue ttlQueue(){ return QueueBuilder.durable(&quot;ttl.queue&quot;) // 指定普通队列名称，并持久化 .ttl(10000) // 设置队列的超时时间，10秒 .deadLetterExchange(&quot;dl.ttl.direct&quot;) // 指定死信交换机 .deadLetterRoutingKey(&quot;dl.ttl&quot;)// 指定死信交换机和死信队列绑定的key .build();} 注意，这个队列设定了死信交换机为dl.ttl.direct 声明交换机，将ttl.queue与交换机绑定： 12345678@Beanpublic DirectExchange ttlExchange(){ return new DirectExchange(&quot;ttl.direct&quot;);}@Beanpublic Binding ttlBinding(){ return BindingBuilder.bind(ttlQueue()).to(ttlExchange()).with(&quot;ttl&quot;);} 或者使用@Bean的方式声明死信交换机和死信队列也可。 下面是使用@Bean的方式声明死信交换机和死信队列并且使用@Bean的方式创建可超时的普通队列的整体代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.chan.mq.consumer.config;import org.springframework.amqp.core.*;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * TTL延时消息也是基于死信交换机和死信队列实现 * * @author CHAN * @since 2022/7/8 */@Configurationpublic class TTLMessageWithDLConfig { // 声明一个队列，并且指定TTL，这个队列设定了死信交换机为dl.ttl.direct @Bean public Queue ttlQueue() { return QueueBuilder.durable(&quot;ttl.queue&quot;)// 指定普通队列名称，并持久化 .ttl(10000)// 设置队列的超时时间，10秒，普通队列超时，其中的消息就会变为死信进入死信交换机，我们只需要监听死信队列就可以实现延迟消息的效果 .deadLetterExchange(&quot;dl.ttl.direct&quot;)// 指定死信交换机 .deadLetterRoutingKey(&quot;dl.ttl&quot;)// 指定死信交换机和死信队列绑定的key .build(); } // 声明交换机，将ttl.queue与交换机绑定 @Bean public DirectExchange ttlExchange() { return new DirectExchange(&quot;ttl.direct&quot;); } @Bean public Binding ttlBinding() { return BindingBuilder.bind(ttlQueue()).to(ttlExchange()).with(&quot;ttl&quot;); } // 声明死信交换机 @Bean public DirectExchange dlTTLExchange() { return new DirectExchange(&quot;dl.ttl.direct&quot;); } // 声明死信队列 @Bean public Queue dlTTLQueue() { return new Queue(&quot;dl.ttl.queue&quot;, true); } // 绑定死信队列到死信交换机 @Bean public Binding dlTTLBinding() { return BindingBuilder.bind(dlTTLQueue()).to(dlTTLExchange()).with(&quot;dl.ttl&quot;); }} 12345678@Component@Slf4jpublic class DlTtlQueueListener { @RabbitListener(queues = {&quot;dl.ttl.queue&quot;}) public void listenDlQueue(String msg){ log.info(&quot;接收到 dl.ttl.queue的延迟消息：{}&quot;, msg); }} 发送消息，但是不要指定TTL： 123456789101112@RequestMapping(&quot;/ttlqueue&quot;)public R testSendToTTLQueue() { // 创建消息 String message = &quot;hello, ttl queue&quot;; // 消息ID，需要封装到CorrelationData中 CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString()); // 发送消息 rabbitTemplate.convertAndSend(&quot;ttl.direct&quot;, &quot;ttl&quot;, message, correlationData); // 记录日志 log.debug(&quot;发送消息成功&quot;); return R.ok();} 发送消息的日志： 查看下接收消息的日志： 因为队列的TTL值是10000ms，也就是10秒。可以看到消息发送与接收之间的时差刚好是10秒。 发送消息时，设定TTL123456789101112131415161718192021222324252627@Configurationpublic class DeadLetterConfig { // 声明普通的queue队列，并且为其指定死信交换机：dl.direct // 这样这个普通的队列中如果有死信，那么死信就会进到这个死信交换机 @Bean public Queue normalQueue() { return QueueBuilder.durable(&quot;normal.queue&quot;)// 指定队列名称，并持久化 .deadLetterExchange(&quot;dl.direct&quot;)// 指定死信交换机 .deadLetterRoutingKey(&quot;dl&quot;)// 指定死信交换机和死信队列绑定的key .build(); } // 声明死信交换机 dl.direct @Bean public DirectExchange dlExchange(){ return new DirectExchange(&quot;dl.direct&quot;, true, false); } // 声明存储死信的队列 dl.queue @Bean public Queue dlQueue(){ return new Queue(&quot;dl.queue&quot;, true); } // 将死信队列 与 死信交换机绑定 @Bean public Binding dlBinding(){ return BindingBuilder.bind(dlQueue()).to(dlExchange()).with(&quot;dl&quot;); }} 12345678@Component@Slf4jpublic class DlQueueListener { @RabbitListener(queues = {&quot;dl.queue&quot;}) public void listenDlQueue(String msg){ log.info(&quot;接收到 dl.queue的延迟消息：{}&quot;, msg); }} 在发送消息时，也可以指定TTL： 12345678910111213141516171819202122232425/** * 由于我们需要设置消息的TTL超时时间，因此需要使用MessageBuilder的方式发送消息。当使用MessageBuilder发送消息到MQ时，会有一个问题： * 就是当我们项目中同时配置了Jackson2JsonMessageConverter(将对象类型的消息序列化成JSON)，消息序列化时会出错导致异常。 * 取消这个序列化配置，就不会出错了，但是取消序列化配置之后，发送对象类型的消息（比如消息体是一个Book类型）时又会报错。 * 显示SimpleMessageConverter只能转换String、字节数组等基本类型，因此我们可以让这个对象实现Serializable； * 但是不配置JSON序列化，而使用Java的Serializable序列化的话，将对象消息发送到MQ服务器时可读性太差。 * 因此，最好的方式是我们自己将对象序列化成JSON字符串之后，再将对象的JSON字符串发送到MQ，消费者收到JSON之后再将JSON序列化成对象包装类。 * 简单来说就是如果我们想发送一个我们自己的对象类型到MQ，我们自己完成JSON序列化和反序列化，不用通过配置让MQ帮我们完成。 * @return R */@RequestMapping(&quot;/ttlmsg&quot;)public R testSendTTLMsgToQueue() { // 创建消息 Message message = MessageBuilder .withBody(&quot;hello, ttl message&quot;.getBytes(StandardCharsets.UTF_8)) .setDeliveryMode(MessageDeliveryMode.PERSISTENT) .setExpiration(&quot;5000&quot;) .build(); // 消息ID，需要封装到CorrelationData中 CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString()); // 发送消息 rabbitTemplate.convertAndSend(&quot;normal.queue&quot;, message, correlationData); log.debug(&quot;发送消息成功&quot;); return R.ok();} 注：消息生产者发送的消息类型和消息消费者接收的消息类型要一致！ 这次，发送与接收的延迟只有5秒。说明当队列、消息都设置了TTL时，任意一个到期就会成为死信。 总结消息超时的两种方式是？ 给队列设置ttl属性，进入队列后超过ttl时间的消息变为死信 给消息设置ttl属性，队列接收到消息超过ttl时间后变为死信 如何实现发送一个消息20秒后消费者才收到消息？ 给消息的目标队列指定死信交换机 将消费者监听的队列绑定到死信交换机 发送消息时给消息设置超时时间为20秒 延迟队列利用TTL结合死信交换机，我们实现了消息发出后，消费者延迟收到消息的效果。这种消息模式就称为延迟队列（Delay Queue）模式。 延迟队列的使用场景包括： 延迟发送短信 用户下单，如果用户在15 分钟内未支付，则自动取消 预约工作会议，20分钟后自动通知所有参会人员 因为延迟队列的需求非常多，所以RabbitMQ的官方也推出了一个插件，原生支持延迟队列效果。 这个插件就是DelayExchange插件。参考RabbitMQ的插件列表页面：https://www.rabbitmq.com/community-plugins.html 使用方式可以参考官网地址：https://blog.rabbitmq.com/posts/2015/04/scheduling-messages-with-rabbitmq 安装DelayExchange插件https://chanservy.github.io/posts/20220622/rabbitmq-install.html DelayExchange原理DelayExchange需要将一个交换机声明为delayed类型。当我们发送消息到delayExchange时，流程如下： 接收消息 判断消息是否具备x-delay属性 如果有x-delay属性，说明是延迟消息，持久化到硬盘，读取x-delay值，作为延迟时间 返回routing not found结果给消息发送者 x-delay时间到期后，重新投递消息到指定队列 使用DelayExchange插件的使用也非常简单：声明一个交换机，交换机的类型可以是任意类型，只需要设定delayed属性为true即可，然后声明队列与其绑定即可。 1）声明DelayExchange交换机基于注解方式（推荐）： 1234567891011121314151617181920/** * 创建并监听延迟队列 * * 延时队列可以使用这种，也可以使用死信交换机那种。 * * @author CHAN * @since 2022/7/8 */@Component@Slf4jpublic class DelayQueueListener { @RabbitListener(bindings = @QueueBinding( value = @Queue(name = &quot;delay.queue&quot;, durable = &quot;true&quot;), exchange = @Exchange(name = &quot;delay.direct&quot;, delayed = &quot;true&quot;), key = &quot;delay&quot; )) public void listenDelayExchange(String msg) { log.info(&quot;消费者接收到了delay.queue的延迟消息:{}&quot;, msg); }} 也可以基于@Bean的方式： 2）发送消息发送消息时，一定要携带x-delay属性，指定延迟的时间： 1234567891011121314151617181920@RequestMapping(&quot;/delay&quot;)public R testDelayQueue() { // 1.准备消息 Book book = new Book(); book.setName(&quot;蛤蟆先生去看心理医生&quot;); book.setAuthor(&quot;罗伯特&quot;); String bookJson = JSONUtil.toJsonStr(book); Message message = MessageBuilder .withBody(bookJson.getBytes(StandardCharsets.UTF_8)) .setDeliveryMode(MessageDeliveryMode.PERSISTENT) .setHeader(&quot;x-delay&quot;, 5000) .build(); // 2.准备CorrelationData CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString()); // 3.发送消息 rabbitTemplate.convertAndSend(&quot;delay.direct&quot;, &quot;delay&quot;, message, correlationData); log.info(&quot;发送消息成功&quot;); return R.ok();} 总结延迟队列插件的使用步骤包括哪些？ 声明一个交换机，添加delayed属性为true 发送消息时，添加x-delay头，值为超时时间 惰性队列消息堆积问题当生产者发送消息的速度超过了消费者处理消息的速度，就会导致队列中的消息堆积，直到队列存储消息达到上限。之后发送的消息就会成为死信，可能会被丢弃，这就是消息堆积问题。 解决消息堆积有两种思路： 增加更多消费者，提高消费速度。也就是我们之前说的work queue模式 扩大队列容积，提高堆积上限 要提升队列容积，把消息保存在内存中显然是不行的。 惰性队列从RabbitMQ的3.6.0版本开始，就增加了Lazy Queues的概念，也就是惰性队列。惰性队列的特征如下： 接收到消息后直接存入磁盘而非内存 消费者要消费消息时才会从磁盘中读取并加载到内存 支持数百万条的消息存储 基于命令行设置lazy-queue而要设置一个队列为惰性队列，只需要在声明队列时，指定x-queue-mode属性为lazy即可。可以通过命令行将一个运行中的队列修改为惰性队列： 1rabbitmqctl set_policy Lazy &quot;^lazy-queue$&quot; '{&quot;queue-mode&quot;:&quot;lazy&quot;}' --apply-to queues 命令解读： rabbitmqctl ：RabbitMQ的命令行工具 set_policy ：添加一个策略 Lazy ：策略名称，可以自定义 &quot;^lazy-queue$&quot; ：用正则表达式匹配队列的名字 '{&quot;queue-mode&quot;:&quot;lazy&quot;}' ：设置队列模式为lazy模式 --apply-to queues ：策略的作用对象，是所有的队列 基于@Bean声明lazy-queue 基于@RabbitListener声明LazyQueue 总结消息堆积问题的解决方案？ 队列上绑定多个消费者，提高消费速度 使用惰性队列，可以再mq中保存更多消息 惰性队列的优点有哪些？ 基于磁盘存储，消息上限高 没有间歇性的page-out，性能比较稳定 惰性队列的缺点有哪些？ 基于磁盘存储，消息时效性会降低 性能受限于磁盘的IO MQ集群集群分类RabbitMQ的是基于Erlang语言编写，而Erlang又是一个面向并发的语言，天然支持集群模式。RabbitMQ的集群有两种模式： •普通集群：是一种分布式集群，将队列分散到集群的各个节点，从而提高整个集群的并发能力。 •镜像集群：是一种主从集群，普通集群的基础上，添加了主从备份功能，提高集群的数据可用性。 镜像集群虽然支持主从，但主从同步并不是强一致的，某些情况下可能有数据丢失的风险。因此在RabbitMQ的3.8版本以后，推出了新的功能：仲裁队列来代替镜像集群，底层采用Raft协议确保主从的数据一致性。 普通集群集群结构和特征普通集群，或者叫标准集群（classic cluster），具备下列特征： 会在集群的各个节点间共享部分数据，包括：交换机、队列元信息。不包含队列中的消息。 当访问集群某节点时，如果队列不在该节点，会从数据所在节点传递到当前节点并返回 队列所在节点宕机，队列中的消息就会丢失 结构如图： 部署https://chanservy.github.io/posts/20220622/rabbitmq-install.html 镜像集群集群结构和特征镜像集群：本质是主从模式，具备下面的特征： 交换机、队列、队列中的消息会在各个mq的镜像节点之间同步备份。 创建队列的节点被称为该队列的主节点，备份到的其它节点叫做该队列的镜像节点。 一个队列的主节点可能是另一个队列的镜像节点 所有操作都是主节点完成，然后同步给镜像节点 主宕机后，镜像节点会替代成新的主 结构如图： 部署https://chanservy.github.io/posts/20220622/rabbitmq-install.html 仲裁队列集群特征仲裁队列：仲裁队列是3.8版本以后才有的新功能，用来替代镜像队列，具备下列特征： 与镜像队列一样，都是主从模式，支持主从数据同步 使用非常简单，没有复杂的配置 主从同步基于Raft协议，强一致 部署https://chanservy.github.io/posts/20220622/rabbitmq-install.html Java代码创建仲裁队列1234567@Beanpublic Queue quorumQueue() { return QueueBuilder .durable(&quot;quorum.queue&quot;) // 持久化 .quorum() // 仲裁队列 .build();} SpringAMQP连接MQ集群注意，这里用address来代替host、port方式 123456spring: rabbitmq: addresses: 192.168.150.105:8071, 192.168.150.105:8072, 192.168.150.105:8073 username: itcast password: 123321 virtual-host: /","link":"/posts/20220622/rabbitmq-study.html"},{"title":"共享模型之不可变","text":"不可变类的使用？不可变类的设计？无状态类的设计？ 日期转换的问题当我们在多线程中使用 SimpleDateFormat 类来转换日期格式的时候，会出现线程安全问题，因为 SimpleDateFormat 类并不是线程安全的。 123456789101112131415@Slf4j(topic = &quot;c.Test&quot;)public class Test { public static void main(String[] args) { SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); for (int i = 0; i &lt; 10; i++) { new Thread(() -&gt; { try { log.debug(&quot;{}&quot;, sdf.parse(&quot;1951-04-21&quot;)); } catch (Exception e) { log.error(&quot;{}&quot;, e); } }).start(); } }} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535413:12:02 [Thread-3] c.Test - Wed Apr 21 00:00:00 CST 119913:12:02 [Thread-9] c.Test - Sat Apr 21 00:00:00 CST 195113:12:02 [Thread-7] c.Test - Sun Jun 21 00:00:00 CST 213313:12:02 [Thread-5] c.Test - Sun Oct 08 00:00:00 CST 588156113:12:02 [Thread-1] c.Test - {}java.lang.NumberFormatException: multiple points at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1890) at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110) at java.lang.Double.parseDouble(Double.java:538) at java.text.DigitList.getDouble(DigitList.java:169) at java.text.DecimalFormat.parse(DecimalFormat.java:2087) at java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:1869) at java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1514) at java.text.DateFormat.parse(DateFormat.java:364) at com.chan.concurrent.unableChange.Test.lambda$main$0(Test.java:14) at java.lang.Thread.run(Thread.java:748)13:12:02 [Thread-4] c.Test - Sun Sep 21 00:00:00 CST 195213:12:02 [Thread-6] c.Test - Sun Jun 21 00:00:00 CST 213313:12:02 [Thread-2] c.Test - {}java.lang.NumberFormatException: multiple points at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1890) at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110) at java.lang.Double.parseDouble(Double.java:538) at java.text.DigitList.getDouble(DigitList.java:169) at java.text.DecimalFormat.parse(DecimalFormat.java:2087) at java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:1869) at java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1514) at java.text.DateFormat.parse(DateFormat.java:364) at com.chan.concurrent.unableChange.Test.lambda$main$0(Test.java:14) at java.lang.Thread.run(Thread.java:748)13:12:02 [Thread-0] c.Test - {}java.lang.NumberFormatException: For input string: &quot;95121E.495121&quot; at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043) at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110) at java.lang.Double.parseDouble(Double.java:538) at java.text.DigitList.getDouble(DigitList.java:169) at java.text.DecimalFormat.parse(DecimalFormat.java:2087) at java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:2162) at java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1514) at java.text.DateFormat.parse(DateFormat.java:364) at com.chan.concurrent.unableChange.Test.lambda$main$0(Test.java:14) at java.lang.Thread.run(Thread.java:748)13:12:02 [Thread-8] c.Test - {}java.lang.NumberFormatException: For input string: &quot;95121E.495121E4&quot; at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043) at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110) at java.lang.Double.parseDouble(Double.java:538) at java.text.DigitList.getDouble(DigitList.java:169) at java.text.DecimalFormat.parse(DecimalFormat.java:2087) at java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:1869) at java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1514) at java.text.DateFormat.parse(DateFormat.java:364) at com.chan.concurrent.unableChange.Test.lambda$main$0(Test.java:14) at java.lang.Thread.run(Thread.java:748) 这里是说当我们将日期的格式转换一种形式的时候，也就是使用 SimpleDateFormat 类的 parse() 方法的时候，会有线程安全问题。 注意线程安全问题并不是使用这个类的 format() 方法将 Date 类型的变量格式化成字符串的时候，而是使用 parse() 方法将字符串类型的变量转换成 Date 类型的情况。 思路-同步锁123456789101112131415161718@Slf4j(topic = &quot;c.Test&quot;)public class Test { public static void main(String[] args) { SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); for (int i = 0; i &lt; 10; i++) { new Thread(() -&gt; { synchronized (sdf) { try { Date parse = sdf.parse(&quot;1951-04-21&quot;); log.debug(&quot;{}&quot;, parse); } catch (Exception e) { log.error(&quot;{}&quot;, e); } } }).start(); } }} 1234567891013:18:40 [Thread-0] c.Test - Sat Apr 21 00:00:00 CST 195113:18:40 [Thread-9] c.Test - Sat Apr 21 00:00:00 CST 195113:18:40 [Thread-8] c.Test - Sat Apr 21 00:00:00 CST 195113:18:40 [Thread-7] c.Test - Sat Apr 21 00:00:00 CST 195113:18:40 [Thread-6] c.Test - Sat Apr 21 00:00:00 CST 195113:18:40 [Thread-5] c.Test - Sat Apr 21 00:00:00 CST 195113:18:40 [Thread-4] c.Test - Sat Apr 21 00:00:00 CST 195113:18:40 [Thread-3] c.Test - Sat Apr 21 00:00:00 CST 195113:18:40 [Thread-2] c.Test - Sat Apr 21 00:00:00 CST 195113:18:40 [Thread-1] c.Test - Sat Apr 21 00:00:00 CST 1951 这样虽能解决问题，但带来的是性能上的损失，并不算很好。 思路-不可变如果一个对象再也不能够修改其内部状态（属性），那么它就是线程安全的，因为不存在并发修改啊！这样的对象在Java 中有很多，例如在 Java 8 后，提供了一个新的日期格式化类： 123456789101112@Slf4j(topic = &quot;c.Test&quot;)public class Test { public static void main(String[] args) { DateTimeFormatter dtf = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;); for (int i = 0; i &lt; 10; i++) { new Thread(() -&gt; { LocalDate date = dtf.parse(&quot;2018-10-01&quot;, LocalDate::from); log.debug(&quot;{}&quot;, date); }).start(); } }} 1234567891013:23:20 [Thread-2] c.Test - 2018-10-0113:23:20 [Thread-4] c.Test - 2018-10-0113:23:20 [Thread-5] c.Test - 2018-10-0113:23:20 [Thread-9] c.Test - 2018-10-0113:23:20 [Thread-3] c.Test - 2018-10-0113:23:20 [Thread-7] c.Test - 2018-10-0113:23:20 [Thread-0] c.Test - 2018-10-0113:23:20 [Thread-6] c.Test - 2018-10-0113:23:20 [Thread-8] c.Test - 2018-10-0113:23:20 [Thread-1] c.Test - 2018-10-01 可以看 DateTimeFormatter 的文档： 12@implSpecThis class is immutable and thread-safe . 由此可见，不可变对象，实际是另一种避免竞争，保护线程安全的方式。 不可变设计另一个大家更为熟悉的 String 类也是不可变的，以它为例，说明一下不可变设计的要素 12345678910public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence { /** The value is used for character storage. */ private final char value[]; /** Cache the hash code for the string */ private int hash; // Default to 0 // ... } 从代码中，我们可以看到，所谓 String 类的状态，也就是类中的属性，我们可以看到 value[] 和 hash 两个都是 private 的。 value[] 是个字符数组，在它的前面有 final，也就是代表它不可变，每次有新的值不是在它的基础上做改动，而是新建一个新的字符数组，把旧的复制过来，旧的还是不变的。 hash 属性也没有 set 方法。 final 的使用发现该类，类中所有的属性都是 final 的。 属性用 final 修饰保证了该属性是只读的，不能修改的 类用 final 修饰保证了该类中的方法不能被覆盖，防止子类无意间破坏不可变性。 保护性拷贝12345678910public String substring(int beginIndex) { if (beginIndex &lt; 0) { throw new StringIndexOutOfBoundsException(beginIndex); } int subLen = value.length - beginIndex; if (subLen &lt; 0) { throw new StringIndexOutOfBoundsException(subLen); } return (beginIndex == 0) ? this : new String(value, beginIndex, subLen);} 发现其内部是调用 String 的构造方法创建了一个新字符串，再进入这个构造看看，是否对 final char[] value 做出了修改： 123456789101112131415161718public String(char value[], int offset, int count) { if (offset &lt; 0) { throw new StringIndexOutOfBoundsException(offset); } if (count &lt;= 0) { if (count &lt; 0) { throw new StringIndexOutOfBoundsException(count); } if (offset &lt;= value.length) { this.value = &quot;&quot;.value; return; } } if (offset &gt; value.length - count) { throw new StringIndexOutOfBoundsException(offset + count); } this.value = Arrays.copyOfRange(value, offset, offset+count);} 结果发现并没有做出修改。 构造新字符串对象时，会生成新的 char[] value，对内容进行复制 。这种通过创建副本对象来避免共享的手段称之为【保护性拷贝（defensive copy）】 设计模式之享元模式简介定义 英文名称：Flyweight pattern。 当需要重用数量有限的同一类对象时。 体现包装类在JDK中 Boolean，Byte，Short，Integer，Long，Character 等包装类提供了 valueOf 方法，例如 Long 的 valueOf 会缓存 -128~127 之间的 Long 对象，在这个范围之间会重用对象，大于这个范围，才会新建 Long 对象： 源码： 1234567public static Long valueOf(long l) { final int offset = 128; if (l &gt;= -128 &amp;&amp; l &lt;= 127) { // will cache return LongCache.cache[(int)l + offset]; } return new Long(l);} 注意： Byte，Short，Long 缓存的范围都是 -128~127 Character 缓存的范围是 0~127 Integer的默认范围是 -128~127 最小值不能变 但最大值可以通过调整虚拟机参数-Djava.lang.Integer.IntegerCache.high 来改变 Boolean 缓存了 true 和 false 还有 String 串池和 BigDecimal。 DIY例如：一个线上商城应用，QPS 达到数千，如果每次都重新创建和关闭数据库连接，性能会受到极大影响。 这时预先创建好一批连接，放入连接池。一次请求到达后，从连接池获取连接，使用完毕后再还回连接池，这样既节约了连接的创建和关闭时间，也实现了连接的重用，不至于让庞大的连接数压垮数据库。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public class Test1 { public static void main(String[] args) { Pool pool = new Pool(2); for (int i = 0; i &lt; 5; i++) { new Thread(new Runnable() { @Override public void run() { // 从连接池中拿连接 Connection borrowConn = pool.borrow(); try { // 模拟程序运行 TimeUnit.SECONDS.sleep(new Random().nextInt(1)); } catch (InterruptedException e) { e.printStackTrace(); } finally { pool.free(borrowConn); } } }, &quot;线程&quot; + i).start(); } }}/** * 享元模式: 模拟数据库连接池 */@Slf4j(topic = &quot;c.Pool&quot;)class Pool { // 连接池大小 private final int poolSize; // 连接对象容器 private Connection[] connections; // 连接状态数组 0表示空闲;1表示繁忙 private AtomicIntegerArray states; public Pool(int poolSize) { this.poolSize = poolSize; this.connections = new Connection[poolSize]; this.states = new AtomicIntegerArray(new int[poolSize]); for (int i = 0; i &lt; poolSize; i++) { connections[i] = new MockConnection(&quot;连接: &quot; + (i + 1)); } } /** * 拿连接 * * @return connection */ public Connection borrow() { while (true) { for (int i = 0; i &lt; poolSize; i++) { // 如果连接空闲 if (states.get(i) == 0) { // cas保证线程安全 if (states.compareAndSet(i, 0, 1)) { log.debug(&quot;从池中得到连接: {}&quot;, connections[i]); return connections[i]; } } } synchronized (this) { try { log.debug(&quot;池中没有空闲连接, wait...&quot;); this.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } } /** * 归还连接 * * @param conn 连接 */ public void free(Connection conn) { for (int i = 0; i &lt; poolSize; i++) { if (connections[i] == conn) { states.set(i, 0); synchronized (this) { log.debug(&quot;释放连接: {}&quot;, conn); this.notifyAll(); } break; } } }}class MockConnection implements Connection { // ...} 1234567891017:54:00 [线程1] c.Pool - 从池中得到连接: com.chan.concurrent.unableChange.MockConnection@6e1c8eb617:54:00 [线程1] c.Pool - 释放连接: com.chan.concurrent.unableChange.MockConnection@6e1c8eb617:54:00 [线程0] c.Pool - 从池中得到连接: com.chan.concurrent.unableChange.MockConnection@7f3707a617:54:00 [线程0] c.Pool - 释放连接: com.chan.concurrent.unableChange.MockConnection@7f3707a617:54:00 [线程2] c.Pool - 从池中得到连接: com.chan.concurrent.unableChange.MockConnection@7f3707a617:54:00 [线程2] c.Pool - 释放连接: com.chan.concurrent.unableChange.MockConnection@7f3707a617:54:00 [线程3] c.Pool - 从池中得到连接: com.chan.concurrent.unableChange.MockConnection@7f3707a617:54:00 [线程3] c.Pool - 释放连接: com.chan.concurrent.unableChange.MockConnection@7f3707a617:54:00 [线程4] c.Pool - 从池中得到连接: com.chan.concurrent.unableChange.MockConnection@7f3707a617:54:00 [线程4] c.Pool - 释放连接: com.chan.concurrent.unableChange.MockConnection@7f3707a6 以上实现没有考虑： 连接的动态增长与收缩 连接保活（可用性检测） 等待超时处理 分布式 hash 对于关系型数据库，有比较成熟的连接池实现，例如c3p0，druid等，对于更通用的对象池，可以考虑使用apache commons pool，例如redis连接池可以参考jedis中关于连接池的实现。 无状态在 web 阶段学习时，设计 Servlet 时为了保证其线程安全，都会有这样的建议，不要为 Servlet 设置成员变量，这种没有任何成员变量的类是线程安全的。 因为成员变量保存的数据也可以称为状态信息，因此没有成员变量就称之为【无状态】 阶段总结 不可变类的使用 不可变类的设计 原理方面 final 模式方面 享元模式","link":"/posts/20211123/java-concurrent-5.html"},{"title":"共享模型之内存","text":"前言：上一章讲解的 Monitor 主要关注的是访问共享变量时，保证临界区代码的【原子性】，这一章我们进一步深入学习共享变量在多线程间的【可见性】问题与多条指令执行时的【有序性】问题。 Java内存模型JMM 即 Java Memory Model，它定义了主存、工作内存抽象概念，底层对应着 CPU 寄存器、缓存、硬件内存、CPU 指令优化等。 主内存：所有共享信息放的位置。 工作内存：每个线程的私有信息存放的位置。 JMM 体现在以下几个方面： 原子性：保证指令不会受到线程上下文切换的影响。 可见性：保证指令不会受 cpu 缓存的影响。 有序性：保证指令不会受 cpu 指令并行优化的影响。 可见性退不出的循环：先来看一个现象，main 线程对 run 变量的修改对于 t 线程不可见，导致了 t 线程无法停止： 1234567891011static boolean run = true;public static void main(String[] args) throws InterruptedException { Thread t = new Thread(()-&gt;{ while(run){ // .... } }); t.start(); sleep(1); run = false; // 线程t不会如预想的停下来} 为什么呢？分析一下： 初始状态， t 线程刚开始从主内存读取了 run 的值到工作内存。 因为 t 线程要频繁从主内存中读取 run 的值，JIT 编译器会将 run 的值缓存至自己的工作内存中的高速缓存中，减少对主存中 run 的访问，提高效率。 1 秒之后，main 线程修改了 run 的值，并同步至主存，而 t 是从自己工作内存中的高速缓存中读取这个变量的值，结果永远是旧值。 解决办法： volatile（易变关键字）：它可以用来修饰成员变量和静态成员变量，它可以避免线程从自己的工作内存中查找变量的值，必须到主存中获取它的值，线程操作 volatile 变量都是直接操作主存。 可见性 vs 原子性volatile只能保证可见性，不能保证原子性！ volatile只能保证主内存中“此时此刻最新”的共享变量值在多个线程中的可见性，但是不能保证原子性！ synchronized 语句块既可以保证代码块的原子性，也同时保证代码块内变量的可见性。但缺点是synchronized（隐式锁）是属于重量级操作，性能相对更低。 如果在前面示例的死循环中加入 System.out.println() 会发现即使不加 volatile 修饰符，线程 t 也能正确看到对 run 变量的修改了，想一想为什么？ 模式之两阶段终止停止标记用 volatile 是为了保证该变量在多个线程之间的可见性。 我们的例子中，即主线程把它修改为 true 对 thread 线程可见。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.chan.concurrent.TwoPhaseTermination;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;@Slf4j(topic = &quot;c.TPTVolatile&quot;)public class TPTVolatile { private Thread thread; private volatile boolean stop = false; public void start() { thread = new Thread(new Runnable() { @Override public void run() { while (true) { if (stop) { log.debug(&quot;打断之后要做的事...&quot;);//优雅永不过时 break; } try { TimeUnit.SECONDS.sleep(1); log.debug(&quot;将结果保存...&quot;); } catch (InterruptedException e) { } } } },&quot;监控线程&quot;); thread.start(); } public void stop() { stop = true; thread.interrupt(); } public static void main(String[] args) throws InterruptedException { TPTVolatile tptVolatile = new TPTVolatile(); tptVolatile.start(); Thread.sleep(4000); log.debug(&quot;stop&quot;); tptVolatile.stop(); }} 设计模式之犹豫模式Balking （犹豫）模式用在一个线程发现另一个线程或本线程已经做了某一件相同的事，那么本线程就无需再做了，直接结束返回。 下面的案例就是一个监控线程的案例，我们想要实现监控线程之启动一次，因此符合犹豫模式的思想。 设置一个启动标记，每次启动之前都检查一次之前是否启动过，启动过就直接返回不再重新启动了。 并且下面的例子也能说明，volatile关键字只能保证可见性，并不能保证原子性，因为如果不加synchronized的话，多个线程并发执行的时候，可能线程1执行到if的时候判断starting为false，然后还没执行到将true赋值给starting的时候，线程2并发来执行，加了volatile从主内存中读取此刻最新的starting值，依然是false，然后又启动一遍监控线程，就不能保证我们的需求。 1234567891011121314151617@Slf4j(topic = &quot;c.MonitorService&quot;)public class MonitorService { // 用来表示是否已经有线程已经在执行启动了，设置初始值为false private volatile boolean starting = false; public void start() { log.info(&quot;尝试启动监控线程...&quot;); synchronized (this) { if (starting) { return; } starting = true; } // 真正启动监控线程的代码... }} Balking还经常用在线程安全的单例 12345678910111213public class Singleton { private Singleton() { } private static Singleton INSTANCE = null;//懒汉 public static synchronized Singleton getInstance() { if (INSTANCE != null) { return INSTANCE; } INSTANCE = new Singleton(); return INSTANCE; }} 对比一下保护性暂停模式：保护性暂停模式用在一个线程等待另一个线程的执行结果，当条件不满足时线程等待。 有序性JVM 会在不影响正确性的前提下，可以调整语句的执行顺序，思考下面一段代码： 12345static int i;static int j;// 在某个线程内执行如下赋值操作i = ...; j = ...; 可以看到，至于是先执行 i 还是 先执行 j ，对最终的结果不会产生影响。所以，上面代码真正执行时，既可以是： 12i = ...; j = ...; 也可以是： 12j = ...;i = ...; 这种特性称之为『指令重排』，上面的例子是在某个线程内，单线程倒是没啥影响，但是多线程下『指令重排』会影响正确性。为什么要有重排指令这项优化呢？从 CPU执行指令的原理来理解一下吧。 名词Clock Cycle Time主频的概念大家接触的比较多，而 CPU 的 Clock Cycle Time（时钟周期时间），等于主频的倒数，意思是 CPU 能够识别的最小时间单位，比如说 4G 主频的 CPU 的 Clock Cycle Time 就是 0.25 ns，作为对比，我们墙上挂钟的Cycle Time 是 1s。 例如，运行一条加法指令一般需要一个时钟周期时间。 CPI有的指令需要更多的时钟周期时间，所以引出了 CPI （Cycles Per Instruction）指令平均时钟周期数。 IPCIPC（Instruction Per Clock Cycle） 即 CPI 的倒数，表示每个时钟周期能够运行的指令数。 CPU 执行时间程序的 CPU 执行时间，即我们前面提到的 user + system 时间，可以用下面的公式来表示： 1程序 CPU 执行时间 = 指令数 * CPI * Clock Cycle Time 鱼罐头的故事加工一条鱼需要 50 分钟，只能一条鱼、一条鱼顺序加工。。。这五个一起就好比一条指令的流程： 可以将每个鱼罐头的加工流程细分为 5 个步骤： 去鳞清洗 10分钟 蒸煮沥水 10分钟 加注汤料 10分钟 杀菌出锅 10分钟 真空封罐 10分钟 即使只有一个工人，最理想的情况是：他能够在 10 分钟内同时做好这 5 件事，因为对第一条鱼的真空装罐，不会影响对第二条鱼的杀菌出锅。 指令重排序优化事实上，现代处理器会设计为一个时钟周期完成一条执行时间最长的 CPU 指令。为什么这么做呢？可以想到指令还可以再划分成一个个更小的阶段，例如，每条指令都可以分为：取指令，指令译码，执行指令，内存访问，数据写回这 5 个阶段： 术语参考：instruction fetch (IF)instruction decode (ID)execute (EX)memory access (MEM)register write back (WB) 在不改变程序结果的前提下，这些指令的各个阶段可以通过重排序和组合来实现指令级并行。 指令重排的前提是，重排指令不能影响结果，例如： 1234567// 可以重排的例子int a = 10; // 指令1int b = 20; // 指令2System.out.println( a + b );// 不能重排的例子int a = 10; // 指令1int b = a - 5; // 指令2 支持流水线的处理器现代 CPU 支持多级指令流水线，例如支持同时执行 取指令 - 指令译码 - 执行指令 - 内存访问 - 数据写回 的处理器，就可以称之为五级指令流水线。这时 CPU 可以在一个时钟周期内，同时运行五条指令的不同阶段（相当于一条执行时间最长的复杂指令），IPC = 1，本质上，流水线技术并不能缩短单条指令的执行时间，但它变相地提高了指令地吞吐率。 SuperScalar 处理器大多数处理器包含多个执行单元，并不是所有计算功能都集中在一起，可以再细分为整数运算单元、浮点数运算单元等，这样可以把多条指令也可以做到并行获取、译码等，CPU 可以在一个时钟周期内，执行多于一条指令，IPC &gt; 1。 诡异的结果12345678910111213141516int num = 0;boolean ready = false;// 线程1 执行此方法public void actor1(I_Result r) { if(ready) { r.r1 = num + num; } else { r.r1 = 1; }}// 线程2 执行此方法public void actor2(I_Result r) { num = 2; ready = true; } I_Result 是一个对象，有一个属性 r1 用来保存结果，问，可能的结果有几种？ 情况1：线程1 先执行，这时 ready = false，所以进入 else 分支结果为 1 情况2：线程2 先执行 num = 2，但没来得及执行 ready = true，线程1 执行，还是进入 else 分支，结果为1 情况3：线程2 执行到 ready = true，线程1 执行，这回进入 if 分支，结果为 4（因为 num 已经执行过了） 但我告诉你，结果还有可能是 0 😁😁😁，信不信吧！ 这种情况下是：线程2 执行 ready = true，切换到线程1，进入 if 分支，相加为 0，再切回线程2 执行 num = 2。 这种现象叫做指令重排，是 JIT 编译器在运行时的一些优化，这个现象需要通过大量测试才能复现。 解决方案： volatile 修饰的变量，可以禁用指令重排 1234567891011121314151617public class ConcurrencyTest { int num = 0; volatile boolean ready = false; public void actor1(I_Result r) { if(ready) { r.r1 = num + num; } else { r.r1 = 1; } } public void actor2(I_Result r) { num = 2; ready = true; }} 原理之volatile内存屏障内存屏障 Memory Barrier（Memory Fence） 可见性 写屏障（sfence）保证在该屏障之前的，对共享变量的改动，都同步到主存当中 读屏障（lfence）保证在该屏障之后，对共享变量的读取，加载的是主存中最新数据 有序性 写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后 读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前 volatile 原理volatile 的底层实现原理是内存屏障，Memory Barrier（Memory Fence） 对 volatile 变量的写指令之后会加入写屏障 对 volatile 变量的读指令之前会加入读屏障 如何保证可见性 写屏障（sfence）保证在该屏障之前的，对共享变量的改动，都同步到主存当中 12345public void actor2(I_Result r) { num = 2; // 同步到主存中了 num变量即使没有使用volatile也可以在线程间可见 ready = true; // ready 是 volatile 赋值带写屏障 使用volatile可以在线程间可见 // 写屏障} 而读屏障（lfence）保证在该屏障之后，对共享变量的读取，加载的是主存中最新数据 123456789public void actor1(I_Result r) { // 读屏障 // ready 是 volatile 读取值带读屏障 if(ready) { r.r1 = num + num; } else { r.r1 = 1; }} 如何保证有序性 写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后 读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前 还是那句话，不能解决指令交错！ 写屏障仅仅是保证之后的读能够读到最新的结果。 而有序性的保证也只是保证了本线程内相关代码不被重排序，只是禁止本线程内的指令重排。 小总结： 对于加了volatile的成员变量赋值就是一道写屏障，写屏障防止在它之前的代码排到它后面，实现了有序性的保证但只是保证了本线程内相关代码不被重排序。 并且写屏障会将它之前的所有的操作都同步到主存。 对于加了volatile的成员变量读取就是一道读屏障，读屏障防止在它之后的代码排到它前面。 并且读屏障保证在它之后对共享变量的读取，加载的是主存中的最新数据。 volatile只可保证可见性和有序性，不保证原子性，并且有序性只是禁止本线程内的指令重排，线程间的执行顺序保证不了，线程间依然是由CPU的时间片决定。 synchronized可保证原子性，可见性，有序性，但是保证有序性有前提，必须将共享变量的变化都完全包裹在synchronized块中，都交给synchronized管理。 double-checked locking 问题以著名的 double-checked locking 单例模式为例 12345678910111213public final class Singleton { private Singleton() { } private static Singleton INSTANCE = null; public static synchronized Singleton getInstance() { if (INSTANCE == null) { // t1 INSTANCE = new Singleton(); } return INSTANCE; }} 上面的写法虽可以实现线程安全的单例，但是无疑每次都会进入synchronized中，效率低下。 下面做了改进，也就是双检的思想，进入synchronized之前先判断单例是否为空，为空才进同步块，不为空直接返回提升效率。 那为什么两次if判断单例是否存在呢？因为要避免并发带来的问题，比如多线程并发，线程1执行到第一个if判断完之后，发现为空，进入同步块，上锁了，这时，还没等线程1将INSTANCE赋值完成，也就是还未执行到INSTANCE = new Singleton();的时候，线程2来了，第一个if判断发现此时此刻INSTANCE是空的，然后阻塞，等待线程1执行完将线程2唤醒，线程2又赋值了一遍INSTANCE，违反了单例的初衷。 123456789101112131415161718public final class Singleton { private Singleton() { } private static Singleton INSTANCE = null; public static Singleton getInstance() { if (INSTANCE == null) { // t2 // 只有首次访问会同步，而之后的使用没有 synchronized synchronized (Singleton.class) { if (INSTANCE == null) { // t1 INSTANCE = new Singleton(); } } } return INSTANCE; }} 以上的实现特点是： 懒惰实例化 首次使用 getInstance() 才使用 synchronized 加锁，后续使用时无需加锁 有隐含的，但很关键的一点：第一个 if 使用了 INSTANCE 变量，是在同步块之外 但在多线程环境下，上面的代码依然是有问题的：INSTANCE = new Singleton(); 这段代码其实是两条指令。 构造方法的指令和前面的赋值指令。 我们操作的是INSTANCE，INSTANCE并没有被完全包裹在synchronized块中，因此，synchronized不能保证它的有序性，那么这两条指令就可能会发生指令重排，也就是先对INSTANCE进行赋值，而后再创建构造对象，这样就出问题了，INSTANCE被赋值了一个不完整的对象，这样其它线程来了拿到了一个未初始化完毕的单例对象，就会出现问题。 double-checked locking 解决12345678910111213141516171819public final class Singleton { private Singleton() { } private static volatile Singleton INSTANCE = null; public static Singleton getInstance() { // 实例没创建，才会进入内部的 synchronized代码块 if (INSTANCE == null) { synchronized (Singleton.class) { // t2 // 也许有其它线程已经创建实例，所以再判断一次 if (INSTANCE == null) { // t1 INSTANCE = new Singleton(); } } } return INSTANCE; }} happens-beforehappens-before 规定了对共享变量的写操作对其它线程的读操作可见，它是可见性与有序性的一套规则总结，抛开以下 happens-before 规则，JMM 并不能保证一个线程对共享变量的写，对于其它线程对该共享变量的读可见。 变量都是指成员变量或静态成员变量 线程解锁 m 之前对变量的写，对于接下来对 m 加锁的其它线程对该变量的读可见 1234567891011121314151617181920212223package com.chan.concurrent.happensBefore;/** * 1 线程解锁 m 之前对变量的写，对于接下来对 m 加锁的其它线程对该变量的读可见 * synchronized的可见性的体现 */public class HappensBefore01 { static int x; static final Object m = new Object(); public static void main(String[] args) { new Thread(() -&gt; { synchronized (m) { x = 10; } }, &quot;t1&quot;).start(); new Thread(() -&gt; { synchronized (m) { System.out.println(x); } }, &quot;t2&quot;).start(); }} 线程对 volatile 变量的写，对接下来其它线程对该变量的读可见 123456789101112131415161718package com.chan.concurrent.happensBefore;/** * 2 线程对 volatile 变量的写，对接下来其它线程对该变量的读可见 * volatile的可见性的体现 */public class HappensBefore02 { volatile static int x; public static void main(String[] args) { new Thread(() -&gt; { x = 10; }, &quot;t1&quot;).start(); new Thread(() -&gt; { System.out.println(x); }, &quot;t2&quot;).start(); }} 线程 start 前对变量的写，对该线程开始后对该变量的读可见 12345678910111213141516package com.chan.concurrent.happensBefore;/** * 线程 start 前对变量的写，对该线程开始后对该变量的读可见 */public class HappensBefore03 { static int x; public static void main(String[] args) { x = 10; new Thread(() -&gt; { System.out.println(x); }, &quot;t2&quot;).start(); }} 线程结束前对变量的写，对其它线程得知它结束后的读可见（比如其它线程调用 t1.isAlive() 或 t1.join()等待它结束） 123456789101112131415161718package com.chan.concurrent.happensBefore;/** * 线程结束前对变量的写，对其它线程得知它结束后的读可见（比如其它线程调用 t1.isAlive() 或 t1.join()等待它结束） * 因为线程在结束之前就会将自己工作内存中的对于共享变量修改的值同步到主内存中，供其它线程看得到。 */public class HappensBefore04 { static int x; public static void main(String[] args) throws InterruptedException { Thread t1 = new Thread(() -&gt; { x = 10; }, &quot;t1&quot;); t1.start(); t1.join(); System.out.println(x); }} 线程 t1 打断 t2（interrupt）前对变量的写，对于其他线程得知 t2 被打断后对变量的读可见（通过t2.interrupted 或 t2.isInterrupted） 12345678910111213141516171819202122232425262728293031323334353637383940package com.chan.concurrent.happensBefore;import java.util.concurrent.TimeUnit;/** * 线程 t1 打断 t2（interrupt）前对变量的写，对于其他线程得知 t2 被打断后对变量的读可见（通过t2.interrupted 或 t2.isInterrupted） * 线程在被打断之前对共享变量修改的值，在得知这个线程被打断以后(就是判断打断标记以后)，其它线程对这个共享变量的读取是可见的 */public class HappensBefore05 { static int x; public static void main(String[] args) { Thread t2 = new Thread(() -&gt; { while (true) { if (Thread.currentThread().isInterrupted()) { System.out.println(x); break; } } }, &quot;t2&quot;); t2.start(); new Thread(() -&gt; { try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } x = 10; t2.interrupt(); }, &quot;t1&quot;).start(); // while (!t2.isInterrupted()) { Thread.yield(); } System.out.println(x); }} 对变量默认值（0，false，null）的写，对其它线程对该变量的读可见。 x=20写屏障前面的共享变量都会存到主存，其它线程可见; 并且x=20前面的代码不会排到它的后面 12345678910111213141516171819202122package com.chan.concurrent.happensBefore;/** * x=20写屏障前面的共享变量都会存到主存，其它线程可见; 并且x=20前面的代码不会排到它的后面 */public class HappensBefore07 { volatile static int x; static int y; public static void main(String[] args) { new Thread(()-&gt;{ y = 10; x = 20; //写屏障，写屏障前面的共享变量都会存到主存，其它线程可见; 并且x=20前面的代码不会排到它的后面 },&quot;t1&quot;).start(); new Thread(()-&gt;{ // x=20 对 t2 可见，同时 y=10 也对 t2 可见 System.out.println(x); },&quot;t2&quot;).start(); }} Balking模式习题希望 doInit() 方法仅被调用一次，下面的实现是否有问题，为什么？ 1234567891011121314151617181920/** * 需求是希望doInit()方法仅被调用一次，下面的实现是否有问题? 为什么? */public class TestVolatile { // 是否被调用过的标志 默认为false private volatile boolean initialized = false; public void init() { if (initialized) { // 被调用过，直接返回 return; } doInit(); initialized = true; } private void doInit() { // 调用 }} 上面的代码是有问题的。 上面的代码没有保证原子性，因为volatile是不能保证原子性的，只能保证可见性和有序性，有序性也就是会禁止本线程内的指令重排。 但是它不能保证原子性，也就是不能避免指令交错，指令交错是多个线程并发的问题。 上面的例子如果是多线程并发的话可能会造成多次调用doInit方法，比如现在有两个线程，线程1和线程2，线程1进行到判断的位置，判断完了之后执行doInit方法，但是当线程1还没执行到将true赋值到initialized的时候，线程2来了从主内存中取到此时此刻最新的值，依然是false，那么又调用一遍方法，并不能保证只被调用一次。 因此要加上锁，改正如下： 12345678910111213141516171819202122232425package com.chan.concurrent.balking;/** * 需求是希望doInit()方法仅被调用一次，下面的实现是否有问题? 为什么? */public class TestVolatile { // 是否被调用过的标志 默认为false private volatile boolean initialized = false; public void init() { synchronized (this) { if (initialized) { // 被调用过，直接返回 return; } doInit(); initialized = true; } } private void doInit() { // 调用 }} volatile只适用于1个线程写，其它线程读的情况，用它保证可见性的场景，还有一种就是它可用作double-check locking双检时，保证在synchronized代码块外那个共享变量不会发生指令重排的问题。 线程安全单例习题单例模式有很多实现方法，饿汉、懒汉、静态内部类、枚举类，试分析每种实现下获取单例对象（即调用getInstance）时的线程安全，并思考注释中的问题： 饿汉式：类加载就会导致该单实例对象被创建 懒汉式：类加载不会导致该单实例对象被创建，而是首次使用该对象时才会创建 单例实现1 123456789101112131415161718package com.chan.concurrent.singleton;import java.io.Serializable;// 问题1：为什么加 final// 问题2：如果实现了序列化接口，还要做什么来防止反序列化破坏单例public final class Singleton01 implements Serializable { // 问题3：为什么设置为私有? 是否能防止反射创建新的实例? private Singleton01() {} // 问题4：这样初始化是否能保证单例对象创建时的线程安全? private static final Singleton01 INSTANCE = new Singleton01(); // 问题5：为什么提供静态方法而不是直接将 INSTANCE 设置为 public，说出你知道的理由 public static Singleton01 getInstance() { return INSTANCE; } public Object readResolve() { return INSTANCE; }} 问题1答案：为了防止类被继承，子类中重写覆盖从而破坏单例 问题2答案：单例类如果实现了序列化接口，为了防止反序列化破坏单例，我们固定的解决方案就是在类中写入一个readResolve方法并且返回我们的单例对象，因为当反序列化创建对象时，会调用readResolve方法，因此我们重写这个方法，让它返回我们创建的单例对象，从而解决了反序列化破坏我们的单例的问题。 问题3答案：因为共有的构造方法，谁都可以调用构造创建对象，就不是单例了; 不能防止反射创建新的实例，因为反射通过类可以得到构造器，进行暴力反射。 问题4答案：能。 静态成员变量的初始化操作是在类的加载阶段完成的，类加载的阶段由JVM来保证代码的线程安全性。 类加载阶段对于静态成员变量的赋值都是线程安全的。 问题5答案：有更好的封装性，有需要的时候可以内部改进实现懒惰初始化，并且有需要的时候可以实现泛型的需求。 单例实现2 1234567891011package com.chan.concurrent.singleton;// 问题1：枚举单例是如何限制实例个数的// 问题2：枚举单例在创建时是否有并发问题// 问题3：枚举单例能否被反射破坏单例// 问题4：枚举单例能否被反序列化破坏单例// 问题5：枚举单例属于懒汉式还是饿汉式// 问题6：枚举单例如果希望加入一些单例创建时的初始化逻辑该如何做enum Singleton02 { INSTANCE;} 问题1答案：定义几个就有几个(相当于类中的静态成员变量)，是单实例的。 问题2答案：无并发问题。 因为都相当于是静态的，在类加载的时候赋值，有JVM来完成并且由JVM来保证线程安全。 问题3答案：不会被反射破坏单例 问题4答案：不能被序列化反序列化破坏单例，因为enum的底层对反序列化做了封装 问题5答案：饿汉式，都是相当于静态成员变量，并且伴随着类的加载就初始化了，由JVM保证线程安全性 问题6答案：加构造方法，将一些初始化的逻辑加在它的构造方法中就可以了。 单例实现3 123456789101112public class Singleton03 { private Singleton03() { } private static Singleton03 INSTANCE = null;//懒汉式 懒汉式的线程安全性就需要自己来保证了 // 分析这里的线程安全，并说明有什么缺点 public static synchronized Singleton03 getInstance() { if( INSTANCE != null ){ return INSTANCE; } INSTANCE = new Singleton03(); return INSTANCE; }} 答：性能低，每次不管单例对象是否被创建过都需要进入到synchronized中去执行判断逻辑。 单例实现4：DDL→double-check locking 双检，这样提出来提前判断一次，如果前面创建过了单例那么就不会进入synchronized了。 1234567891011121314151617181920public class Singleton04 { private Singleton04() { } // 问题1：解释为什么要加 volatile ? private static volatile Singleton04 INSTANCE = null; // 问题2：对比实现3，说出这样做的意义 public static Singleton04 getInstance() { if (INSTANCE != null) { return INSTANCE; } synchronized (Singleton04.class) { // 问题3：为什么还要在这里加为空判断，之前不是判断过了吗 if (INSTANCE != null) { // t2 return INSTANCE; } INSTANCE = new Singleton04(); return INSTANCE; } }} 问题1答案：首先保证可见性，INSTANCE的值在所有线程间可见。 然后保证有序性，因为INSTANCE = new Singleton04();实际是两部操作，先创建构造对象再赋值，由于JVM在并行优化的时候可能出现指令交错从而导致指令重排，这两部操作需要保证顺序性，并且INSTANCE不是被完全包裹在synchronized中的，因此synchronized没法保证有序性，因此加上volatile来禁止本线程内的指令重排。 从而保证有序性。 问题2答案：这样提出来提前判断一次，如果前面创建过了单例那么就不会进入synchronized了，效率高，避免每次都进入到 synchronized。 问题3答案：考虑到首次创建单例对象时，可能多个线程并发的问题。 比如多线程并发，线程1执行到第一个if判断完之后，发现为空，进入同步块，上锁了，这时，还没等线程1将INSTANCE赋值完成，也就是还未执行到INSTANCE = new Singleton();的时候，线程2来了，第一个if判断发现此时此刻INSTANCE是空的，然后阻塞，等待线程1执行完将线程2唤醒，线程2又赋值了一遍INSTANCE，违反了单例的初衷，因此即使进入到synchronized中也应该在判断一遍。 单例实现5 1234567891011public class Singleton05 { private Singleton05() { } // 问题1：属于懒汉式还是饿汉式 private static class LazyHolder { static final Singleton05 INSTANCE = new Singleton05(); } // 问题2：在创建时是否有并发问题 public static Singleton05 getInstance() { return LazyHolder.INSTANCE; }} 问题1答案：懒汉式，因为静态内部类对外不可见。 类加载的时候不会加载内部类，只有在调用方法的时候，用到内部类了，内部类才会进行类加载并且创建实例对象。 问题2答案：无并发问题。 因为是在静态内部类的静态成员变量位置，在静态内部类进行类加载的时候会直接赋值静态成员变量，伴随着类加载而诞生的单例对象，不会有线程安全问题，因为JVM会保证线程安全。 阶段总结本章重点讲解了 JMM 中的 可见性：由 JVM 缓存优化引起 有序性：由 JVM 指令重排序优化引起 happens-before 规则 原理方面 CPU 指令并行 volatile 模式方面 两阶段终止模式的 volatile 改进 同步模式之 balking","link":"/posts/20211121/java-concurrent-3.html"},{"title":"JVM 学习笔记","text":"什么是 JVM定义Java Virtual Machine，JAVA程序的运行环境（JAVA二进制字节码的运行环境）也就是 Java 虚拟机。 好处 一次编写，到处运行 自动内存管理，垃圾回收机制 数组下标越界检查 多态，面向对象 比较JVM、JRE、JDK的区别 内存结构整体架构 JVM 大致上可分为： 类加载器模块 JVM 内存结构 执行引擎 JVM被分为三个主要的子系统：类加载器子系统、运行时数据区和执行引擎 。 首先，大致概述一下整个流程： 一个类从 Java 源代码编译成了二进制字节码以后，必须经过类加载器才能被加载到 JVM 中运行。类都是放在方法区的部分，类将来创建的实例对象放在堆，而堆中的对象在调用方法时，又会用到虚拟机栈、程序计数器以及本地方法栈。 方法执行时，每行代码是由执行引擎中的解释器逐行进行执行，方法中的一些热点代码（被频繁调用的代码）会由一个 JIT 即时编译器来编译，优化执行。执行引擎中还有一个很重要的模块：GC 垃圾回收。GC 会对堆中的一些不再引用的对象进行垃圾回收。当然这里还会有一些 Java 代码不方便实现的功能必须调用底层操作系统的功能，所以我们要和操作系统的一些功能打交道的话，就需要借用本地方法接口来调用操作系统的一些方法，这就是整个 JVM 的组成。 程序计数器作用是记住下一条jvm指令的执行地址。 特点 线程私有，每个线程都有自己的程序计数器 ，随着线程的创建而创建，随着线程的销毁而销毁 CPU会为每个线程分配时间片，当当前线程的时间片使用完以后，CPU就会去执行另一个线程中的代码 程序计数器是每个线程所私有的，当另一个线程的时间片用完，又返回来执行当前线程的代码时，通过程序计数器可以知道应该执行哪一句指令 不会存在内存溢出（程序计数器在 JVM 规范中是唯一一个不会存在内存溢出的区域） 计数器是 java 对物理硬件的屏蔽和抽象；计数器在物理上是通过寄存器来实现的。 寄存器是整个 CPU 的组件里读取速度最快的一个单元，因为我们读写指令地址的动作是非常频繁的，所以 Java 虚拟机在设计的时候，就将 CPU 中的寄存器当做了程序计数器，用它来存储地址，将来从寄存器读取地址。 Java 是支持多线程的，多线程运行时，CPU 会有一个调度器组件，给线程们分配时间片。比如线程 1 和线程 2，线程 1 先分到了时间片，在时间内代码未执行完，执行到了一定程度，然后会将线程 1 的状态进行一个暂存，切换到线程 2 执行，等线程 2 执行到一定程度，线程 2 的时间片用尽，再切换回来，再继续执行线程 1 剩余的代码。这便是时间片的概念。 线程切换的过程中，我们的程序计数器会记住下一条指令执行到哪里了，程序计数器是线程私有的，每个线程都有自己的程序计数器。 虚拟机栈定义 每个线程运行需要的内存空间，称为虚拟机栈 每个栈由多个栈帧组成，对应着每次调用方法时所占用的内存 每个线程只能有一个活动栈帧，对应着当前正在执行的方法 符合数据结构栈内存的特点，先进后出。其实栈就是线程运行时需要的内存空间。一个线程就需要一个栈，多个线程就需要多个栈。 一个栈内是由多个栈帧组成的。一个栈帧对应一次方法的调用。线程最终的目的是为了执行代码的，代码都是由一个个的方法来组成的，所以在线程运行时，每个方法它需要的内存，我们便称之为栈帧。那么方法需要的内存指的是什么呢？参数、局部变量、返回地址这些都需要占用内存。 栈帧与栈是如何联系起来的？比如调用第一个方法时，会给这个方法划分一段栈帧空间，并且压入栈内，当这个方法执行完了，就会将这个方法对应的栈帧让它出栈，也就是释放这个方法所占用的内存，这就是栈与栈帧的联系。 一个栈内可能有多个栈帧。比如调用方法 1，方法 1 间接调用方法 2，方法 2 就会产生一个新的栈帧，方法 2 执行完，会将方法 2 对应的栈帧出栈，最后方法 1 执行完，也是将方法 1 对应的栈帧出栈。 演示代码 1234567891011121314public class Main { public static void main(String[] args) { method1(); } private static void method1() { method2(1, 2); } private static int method2(int a, int b) { int c = a + b; return c; }} 在控制台中可以看到，主类中的方法在进入虚拟机栈的时候，符合栈的特点 问题辨析 垃圾回收是否涉及栈内存？ 不需要。因为虚拟机栈中是由一个个栈帧组成的，而栈帧内存对应着每一次方法的调用，在方法执行完毕后，对应的栈帧就会被弹出栈，也就是会自动的被回收掉。所以无需通过垃圾回收机制去回收栈内存，垃圾回收只是回收堆内存中的无用对象。 栈内存的分配越大越好吗？ 不是。因为物理内存是一定的，栈内存越大，虽然可以支持更多的递归调用，但是可执行的线程数就会越少。 方法内的局部变量是否是线程安全的？ 如果方法内局部变量没有逃离方法的作用范围，则是线程安全的 如果如果局部变量引用了对象，并逃离了方法的作用范围，则需要考虑线程安全问题 内存溢出Java.lang.stackOverflowError 栈内存溢出 发生原因 虚拟机栈中，栈帧过多（无限递归） 每个栈帧所占用过大 线程运行诊断CPU占用过高 Linux环境下运行某些程序的时候，可能导致CPU的占用过高，这时需要定位占用CPU过高的线程 top命令，查看是哪个进程占用CPU过高 ps H -eo pid, tid（线程id）, %cpu | grep 刚才通过top查到的进程id 通过ps命令进一步查看是哪个线程占用CPU过高 jstack 进程id 通过查看进程中线程的nid，与刚才通过ps命令看到的tid来对比定位，进一步定位到问题代码的源码行号。注意jstack查找出的线程id是16进制的，需要转换 本地方法栈一些带有native关键字的方法就是需要JAVA去调用本地的C或者C++方法，因为JAVA有时候没法直接和操作系统底层交互，所以需要用到本地方法 堆定义通过new关键字创建的对象都会被放在堆内存 特点 所有线程共享，堆内存中的对象都需要考虑线程安全问题 有垃圾回收机制 堆内存溢出java.lang.OutofMemoryError ：java heap space. 堆内存溢出 堆内存诊断jps：查看当前系统中有哪些 java 进程 jmap：查看堆内存占用情况 jmap - heap 进程id jconsole：jconsole 是 jdk 自带的堆诊断工具，在 bin 目录下，或者在 idea 控制台旁边的 Terminal 输入 jconsole 就打开了。图形界面的，多功能的监测工具，可以连续监测。 jvirsalvm：也是可以进行堆内存诊断的，并且 jvisualvm 有堆 Dump 的功能，就是可以抓取堆的当前快照，我们可以进一步的对堆的一些详细内容进行分析。查找保留前 20 个最大的对象。在 idea 控制台旁边的 Terminal 输入 jvisualvm 就打开了。 jstat：查看jvm的GC情况。jstat命令查看jvm的GC情况 （以Linux为例） 方法区和堆一样也是线程共享的区域。方法区中存储了跟类的结构相关的一些信息，比如有成员变量，成员方法以及构造器方法。在虚拟机启动时被创建。 结构 方法区内存溢出 1.8以前会导致永久代内存溢出 12* 演示永久代内存溢出 java.lang.OutOfMemoryError: PermGen space* -XX:MaxPermSize=8m 1.8以后会导致元空间内存溢出 12* 演示元空间内存溢出 java.lang.OutOfMemoryError: Metaspace* -XX:MaxMetaspaceSize=8m 常量池二进制字节码的组成：类的基本信息、常量池、类的方法定义（包含了虚拟机指令） 常量池的作用就是给我们的这些指令提供一些常量符号，根据常量符号找到下一步的指令。 eg： 123456789101112package com.chan.concurrent.lianxi;public class Test { public static void main(String[] args) { String a = &quot;a&quot;; String b = &quot;b&quot;; String ab = &quot;ab&quot;; String ab2 = a+b; //使用拼接字符串的方法创建字符串 String ab3 = &quot;a&quot; + &quot;b&quot;; }} 通过反编译来查看类的信息 获得对应类的.class文件 在JDK对应的bin目录下运行cmd，也可以在IDEA控制台输入 javac 对应类的绝对路径输入完成后，对应的目录下就会出现类的.class文件 在控制台输入 javap -v 类的绝对路径 然后能在控制台看到反编译以后类的信息了 类的基本信息 常量池 虚拟机中执行编译的方法（框内的是真正编译执行的内容，**#号的内容需要在常量池中查找**） 运行时常量池 常量池 就是一张表（如上图中的constant pool），虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、字面量信息 运行时常量池 常量池是*.class文件中的，当该类被加载以后，它的常量池信息就会放入运行时常量池，并把里面的符号地址变为真实地址 常量池与串池的关系串池StringTable特征 常量池中的字符串仅是符号，只有在被用到时才会转化为对象 利用串池的机制，来避免重复创建字符串对象 字符串变量拼接的原理是StringBuilder 字符串常量拼接的原理是编译器优化 可以使用intern方法，主动将串池中还没有的字符串对象放入串池中 注意：无论是串池还是堆里面的字符串，都是对象 用来放字符串对象且里面的元素不重复 1234567public class StringTableStudy { public static void main(String[] args) { String a = &quot;a&quot;; String b = &quot;b&quot;; String ab = &quot;ab&quot;; }} 常量池中的信息，都会被加载到运行时常量池中，但这是a b ab 仅是常量池中的符号，还没有成为java字符串 12345670: ldc #2 // String a2: astore_13: ldc #3 // String b5: astore_26: ldc #4 // String ab8: astore_39: return 当执行到 ldc #2 时，会把符号 a 变为 “a” 字符串对象，并放入串池中（hashtable结构 不可扩容） 当执行到 ldc #3 时，会把符号 b 变为 “b” 字符串对象，并放入串池中 当执行到 ldc #4 时，会把符号 ab 变为 “ab” 字符串对象，并放入串池中 最终StringTable [“a”, “b”, “ab”] 注意：字符串对象的创建都是懒惰的，只有当运行到那一行字符串且在串池中不存在的时候（如 ldc #2）时，该字符串才会被创建并放入串池中。 使用拼接字符串变量对象创建字符串的过程 123456789public class StringTableStudy { public static void main(String[] args) { String a = &quot;a&quot;; String b = &quot;b&quot;; String ab = &quot;ab&quot;; //拼接字符串对象来创建新的字符串 String ab2 = a+b; }} 反编译后的结果 123456789101112131415161718192021 Code: stack=2, locals=5, args_size=1 0: ldc #2 // String a 2: astore_1 3: ldc #3 // String b 5: astore_2 6: ldc #4 // String ab 8: astore_3 9: new #5 // class java/lang/StringBuilder 12: dup 13: invokespecial #6 // Method java/lang/StringBuilder.&quot;&lt;init&gt;&quot;:()V 16: aload_1 17: invokevirtual #7 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 20: aload_2 21: invokevirtual #7 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 24: invokevirtual #8 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 27: astore 4 29: return 通过拼接的方式来创建字符串的过程是：StringBuilder().append(“a”).append(“b”).toString() 也就是 new String(“ab”)，因为 StringBuilder 的 toString 方法的底层就是 new String。 123456// StringBuilder类中的方法@Overridepublic String toString() { // Create a copy, don't share the array return new String(value, 0, count);} 最后的toString方法的返回值是一个新的字符串，但字符串的值和拼接的字符串一致，但是两个不同的字符串，一个存在于串池之中，一个存在于堆内存之中 1234String ab = &quot;ab&quot;;String ab2 = a+b;//结果为false,因为ab是存在于串池之中，ab2是由StringBuffer的toString方法所返回的一个对象，存在于堆内存之中System.out.println(ab == ab2); 使用拼接字符串常量对象的方法创建字符串 12345678910public class StringTableStudy { public static void main(String[] args) { String a = &quot;a&quot;; String b = &quot;b&quot;; String ab = &quot;ab&quot;; String ab2 = a+b; //使用拼接字符串的方法创建字符串 String ab3 = &quot;a&quot; + &quot;b&quot;; }} 反编译后的结果 123456789101112131415161718192021222324 Code: stack=2, locals=6, args_size=1 0: ldc #2 // String a 2: astore_1 3: ldc #3 // String b 5: astore_2 6: ldc #4 // String ab 8: astore_3 9: new #5 // class java/lang/StringBuilder 12: dup 13: invokespecial #6 // Method java/lang/StringBuilder.&quot;&lt;init&gt;&quot;:()V 16: aload_1 17: invokevirtual #7 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 20: aload_2 21: invokevirtual #7 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 24: invokevirtual #8 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 27: astore 4 //ab3初始化时直接从串池中获取字符串 29: ldc #4 // String ab 31: astore 5 33: returnCopy 使用拼接字符串常量的方法来创建新的字符串时，因为内容是常量，javac在编译期会进行优化，结果已在编译期确定为ab，而创建ab的时候已经在串池中放入了“ab”，所以ab3直接从串池中获取值，所以进行的操作和 ab = “ab” 一致。 使用拼接字符串变量的方法来创建新的字符串时，因为内容是变量，只能在运行期确定它的值，所以需要使用StringBuilder来创建，在堆中 intern方法 1.8调用字符串对象的intern方法，会将该字符串对象尝试放入到串池中 如果串池中没有该字符串对象，则放入成功 如果有该字符串对象，则放入失败 无论放入是否成功，都会返回串池中的字符串对象 注意：此时如果调用intern方法成功，堆内存与串池中的字符串对象是同一个对象；如果失败，则不是同一个对象 例1 12345678910111213public class Main { public static void main(String[] args) { //&quot;a&quot; &quot;b&quot; 被放入串池中，str则存在于堆内存之中 String str = new String(&quot;a&quot;) + new String(&quot;b&quot;); //调用str的intern方法，这时串池中没有&quot;ab&quot;，则会将该字符串对象str放入到串池中，并且返回&quot;ab&quot; String st2 = str.intern(); //给str3赋值，因为此时串池中已有&quot;ab&quot;，则直接将串池中的内容返回 String str3 = &quot;ab&quot;; //因为str被放入了串池，所以以下两条语句打印的都为true System.out.println(str == st2); System.out.println(str == str3); }} 例2 12345678910111213141516public class Main { public static void main(String[] args) { //此处创建字符串对象&quot;ab&quot;，因为串池中还没有&quot;ab&quot;，所以将其放入串池中 String str3 = &quot;ab&quot;; //&quot;a&quot; &quot;b&quot; 被放入串池中，str则存在于堆内存之中 String str = new String(&quot;a&quot;) + new String(&quot;b&quot;); //此时因为在创建str3时，&quot;ab&quot;已存在于串池中，所以str放入串池失败，但是会返回串池中的&quot;ab&quot; String str2 = str.intern(); //false str是堆中的,str2是串池中的 System.out.println(str == str2); //false str是堆中的,str3是串池中的 System.out.println(str == str3); //true System.out.println(str2 == str3); }} intern方法 1.6调用字符串对象的intern方法，会将该字符串对象尝试放入到串池中 如果串池中没有该字符串对象，会将该字符串对象复制一份，再将副本放入到串池中 如果有该字符串对象，则放入失败 无论放入是否成功，都会返回串池中的字符串对象 面试题 123456789101112131415161718String s1 = &quot;a&quot;; //&quot;a&quot;放入串池String s2 = &quot;b&quot;; //&quot;b&quot;放入串池String s3 = &quot;a&quot; + &quot;b&quot;;//&quot;ab&quot;放入串池String s4 = s1 + s2;//s4为&quot;ab&quot;,但是在堆中String s5 = &quot;ab&quot;;//直接从串池中拿到&quot;ab&quot;String s6 = s4.intern();//将s4放入串池,但是串池中有了&quot;ab&quot;因此放入失败,因此s4仍然在堆中// 问System.out.println(s3 == s4);//falseSystem.out.println(s3 == s5);//trueSystem.out.println(s3 == s6);//falseString x2 = new String(&quot;c&quot;) + new String(&quot;d&quot;);//&quot;c&quot;和&quot;d&quot;放入串池,x2为&quot;cd&quot;在堆中String x1 = &quot;cd&quot;;//将&quot;cd&quot;放入串池x2.intern();//将x2放入串池,但是串池中有了&quot;cd&quot;因此放入失败,因此x2仍在堆中System.out.println(x1 == x2);//false// 问，如果调换了【倒数2,3行代码】的位置呢?// 答:x2能放入串池,返回true// 问: 如果是jdk1.6呢// 答:肯定是false,因为1.6中,如果串池中没有那么会复制一份x2的副本,将副本放入串池 x1==x2返回false,如果串池中之前就有也返回false 总结 StringTable 特性： 常量池中的字符串仅是符号，第一次用到时才变为对象 利用串池的机制，来避免重复创建字符串对象 字符串变量拼接的原理是 StringBuilder （1.8） 字符串常量拼接的原理是编译期优化 可以使用 intern 方法，主动将串池中还没有的字符串对象放入串池 1.8 将这个字符串对象尝试放入串池，如果有则并不会放入，如果没有则放入串池， 会把串池中的对象返回 1.6 将这个字符串对象尝试放入串池，如果有则并不会放入，如果没有会把此对象复制一份，放入串池， 会把串池中的对象返回 StringTable 垃圾回收StringTable在内存紧张时，会发生垃圾回收 StringTable调优 因为StringTable是由HashTable实现的，所以可以适当增加HashTable桶的个数，来减少字符串放入串池所需要的时间 1-XX:StringTableSize=xxxxCopy 考虑是否需要将字符串对象入池 可以通过intern方法减少重复入池 StringTable 的底层是类似于 Hashtable 的实现，也就是哈希表，数组加链表的结构，数组上的每个索引的位置称为桶，它是以哈希表的结构来存储数据的。 适当的将 StringTable 的桶的总个数调大也就可以理解为让数组长度适当变长，让它有一个更好的哈希分布，减少哈希冲突，让我们的 StringTable 串池字符串常量池的性能得到提升。 如果你的应用里有大量的字符串，而且这些字符串可能会存在重复的问题，那么我们可以让字符串入池来减少字符串对象的个数，节约我们的堆内存的使用。 直接内存 属于操作系统，常见于NIO操作时，用于数据缓冲区 分配回收成本较高，但读写性能高 不属于 JVM 内存结构中，不受 JVM 内存回收管理 文件读写流程普通的 IO 操作： 使用了DirectBuffer： 直接内存是操作系统和Java代码都可以访问的一块区域，无需将代码从系统内存复制到Java堆内存，少了一次 copy 操作，从而提高了效率。 释放原理直接内存的回收不是通过 JVM 的垃圾回收来释放的，而底层是通过 unsafe.freeMemory 来释放 通过 12345//通过ByteBuffer申请分配1G的直接内存ByteBuffer byteBuffer = ByteBuffer.allocateDirect(_1G);// ... 一些操作// 显式回收 ByteBufferSystem.gc(); 上面代码中使用了 System.gc() ，让 JVM 回收了 ByteBuffer。此时我们查看电脑的内存占用，发现直接内存没了。。。wtf？？不是说 JVM 不能回收直接内存吗？那调用了 gc() 之后为何会释放直接内存？ 这就要从底层一步一步解释了。。。 allocateDirect的源码实现 123public static ByteBuffer allocateDirect(int capacity) { return new DirectByteBuffer(capacity);} DirectByteBuffer类 源码中的 unsafe 对象解析：这个对象通过反射可以得到，是极其底层的，记得 cas 中也用到了 unsafe 对象。其实直接内存的分配和释放，核心就是靠这个 unsafe 对象。 12345678910111213141516171819202122232425262728DirectByteBuffer(int cap) { // package-private super(-1, 0, cap, cap); boolean pa = VM.isDirectMemoryPageAligned(); int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); Bits.reserveMemory(size, cap); long base = 0; try { // 底层：直接内存的申请必须依靠unsafe base = unsafe.allocateMemory(size); //申请内存 返回直接内存的内存地址 } catch (OutOfMemoryError x) { Bits.unreserveMemory(size, cap); throw x; } unsafe.setMemory(base, size, (byte) 0);// 这行代码和前面的try中的代码必须组合到一起使用才可完成直接内存的分配 if (pa &amp;&amp; (base % ps != 0)) { // Round up to page boundary address = base + ps - (base &amp; (ps - 1)); } else { address = base; } // Cleaner是一个虚引用类型，this就为虚引用的实际对象，在此也就是ByteBuffer // 在此可以看到 cleaner 有一个回调函数Deallocator，这个回调函数其实是一个任务，因为底层实现了Runnable，在run方法中主动调用了unsafe的freeMemory方法。注：直接内存的释放必须主动调用unsafe的freeMemory方法！！ cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); //通过虚引用，来实现直接内存的释放，this为虚引用的实际对象 att = null;} 这里就解释了为何调用了 gc() ，不受 JVM 内存管理的直接内存会释放：当调用了 gc 后，不被引用的 ByteBuffer 对象会被 JVM 垃圾回收，当它被回收掉时，它就会触发虚引用对象 cleaner 中的 clean 方法，clean() 方法中又调用了 run 方法，run 方法中又主动调用了 unsafe 的 freeMemory 方法，进而直接内存会释放。 123456789101112131415161718public void clean() { if (remove(this)) { try { this.thunk.run(); //调用run方法 } catch (final Throwable var2) { AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() { public Void run() { if (System.err != null) { (new Error(&quot;Cleaner terminated abnormally&quot;, var2)).printStackTrace(); } System.exit(1); return null; } }); } }} 这个 clean 方法不是在主线程中被执行的，它是在后台的一个叫 ReferenceHandler 的这个线程中执行的，这个线程是专门去检测虚引用对象的，一旦虚引用对象所关联的那个实际对象也就是那个 ByteBuffer 被 gc 回收掉之后，它就会调用到虚引用对象里的 clean 方法，然后去执行任务对象也就是 run 方法里的内容，run 方法里面就会主动调用 unsafe 的 freeMemory 方法，从而释放直接内存。 对应对象的run方法 123456789public void run() { if (address == 0) { // Paranoia return; } unsafe.freeMemory(address); //释放直接内存中占用的内存 address = 0; Bits.unreserveMemory(size, capacity);} 直接内存的回收机制总结 使用了Unsafe类来完成直接内存的分配回收，回收需要主动调用freeMemory方法 ByteBuffer的实现内部使用了Cleaner（虚引用）来检测ByteBuffer。一旦ByteBuffer被垃圾回收，那么ReferenceHandler线程会检测到，并且调用Cleaner的clean方法，clean方法又调用run方法，然后run中又调用freeMemory来释放内存。 所以直接内存的释放借助 Java 中的虚引用机制（四大引用之一）。 禁用显式回收在涉及到 JVM 调优时，经常会在运行前在 idea 中加入-XX:+DisableExplicitGC，这个参数的作用就是禁用显式回收，也就是让代码中的System.gc() 无效。因为 System.gc() 是显式的垃圾回收，触发的是 Full GC，是比较影响性能的一种回收，因为 Full GC 不光回收新生代还要回收老年代，会造成程序的暂停时间较长。因此加这个参数，加这个参数的话对别的代码影响倒不大，但是会影响到直接内存的回收机制。 如果我们不能显式的回收掉 ByteBuffer 的话，那么 ByteBuffer 只能等到真正的垃圾回收时才会被清理，所以造成了直接内存不能及时被释放，会让直接内存占用较大，长时间得不到回收释放。 解决：直接用 unsafe 的 freeMemory() 来手动释放直接内存 Direct Memory，不等 ReferenceHandler 检测，直接手动管理。 垃圾回收如何判断对象可以回收引用计数法是指只要一个对象被其它变量所引用，那就让这个对象的计数 +1，如果被引用两次，那么它的计数就会加到 2，如果某个变量不再引用它了，那么让它的计数 -1，当这个对象的引用计数变为 0 的时候，就可以作为垃圾被回收。 弊端：循环引用时，两个对象的计数都为1，导致两个对象都无法被释放 可达性分析算法JVM 采用了这种算法进行垃圾回收。这种算法首先会确定一系列的根对象（GC root），也就是肯定不能当成垃圾被回收的对象。在垃圾回收之前，会先对堆内存中的所有对象进行扫描，看每一个对象是否被根对象所直接或间接的引用，如果是，则不能被回收；反之，可作为垃圾将来被回收。 1234567891011121314151617// 在我么当前活动线程的执行过程中，局部变量所引用的对象可作为根对象// 方法参数中引用的字符串数组对象也是一个根对象public class Demo { public static void main(String[] args) throws IOException { // list 为局部对象，存在于栈帧中，它引用的new ArrayList&lt;&gt;()在堆中。 List&lt;Object&gt; list = new ArrayList&lt;&gt;(); list.add(&quot;a&quot;); list.add(&quot;b&quot;); System.out.println(1); System.in.read();// 让程序暂停运行 按enter继续 list = null; System.out.println(2); System.in.read(); System.out.println(&quot;end...&quot;); }} 总结： JVM中的垃圾回收器通过可达性分析来探索所有存活的对象 扫描堆中的对象，看能否沿着GC Root对象为起点的引用链找到该对象，如果找不到，则表示可以回收 可以作为GC Root的对象 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI（即一般说的Native方法）引用的对象 五种引用下图中实线代表强引用。 B、C 对象都是根对象。 软引用、弱引用、虚引用、终结器引用也都是对象。 A2 是被软引用对象引用的对象。 A3 是被弱引用对象引用的对象。 ByteBuffer 是被虚引用对象引用的对象。 强引用只有所有 GC Roots 对象都不通过【强引用】引用该对象，该对象才能被垃圾回收。 如上图B、C对象都不引用A1对象时，A1对象才能被回收 软引用当GC Root指向软引用对象时，在内存不足时，会回收软引用对象所引用的对象。 如上图如果B对象不再引用A2对象且内存不足时，软引用所引用的A2对象就会被回收。 软引用的使用123456789101112131415161718192021222324252627public class Demo { private static final int _4MB = 4 * 1024 * 1024; public static void main(String[] args) throws IOException { soft(); } /** * 软引用 */ public static void soft() { // list--&gt;SoftReference--&gt;byte[] //使用软引用对象 list和SoftReference是强引用，而SoftReference和byte数组则是软引用 List&lt;SoftReference&lt;byte[]&gt;&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 5; i++) { SoftReference&lt;byte[]&gt; reference = new SoftReference&lt;&gt;(new byte[_4MB]); System.out.println(reference.get()); list.add(reference); System.out.println(list.size()); } System.out.println(&quot;循环结束：&quot; + list.size()); for (SoftReference&lt;byte[]&gt; reference : list) { System.out.println(reference.get()); } }} 如果在垃圾回收时发现内存不足，在回收软引用所指向的对象时，软引用本身不会被清理 如果想要清理软引用，需要使用引用队列 1234567891011121314151617181920212223242526272829303132333435363738394041public class Demo { private static final int _4MB = 4 * 1024 * 1024; public static void main(String[] args) throws IOException { soft(); } /** * 软引用配合引用队列 */ public static void soft() { // list--&gt;SoftReference--&gt;byte[] List&lt;SoftReference&lt;byte[]&gt;&gt; list = new ArrayList&lt;&gt;(); // 使用引用队列，用于移除引用为空的软引用对象 ReferenceQueue&lt;byte[]&gt; queue = new ReferenceQueue&lt;&gt;(); for (int i = 0; i &lt; 5; i++) { // 关联了引用队列，当软引用所关联的 byte[] 被回收时，软引用自己会加入到 queue 中去 SoftReference&lt;byte[]&gt; reference = new SoftReference&lt;&gt;(new byte[_4MB], queue); System.out.println(reference.get()); list.add(reference); System.out.println(list.size()); } // poll 方法：取到队列中最先放入的元素 将它移出队列 // 遍历引用队列，如果有元素，则移除 Reference&lt;? extends byte[]&gt; poll = queue.poll(); while (poll != null) { // 引用队列不为空，则从集合中移除该元素 list.remove(poll); // 移动到引用队列中的下一个元素 poll = queue.poll(); } for (SoftReference&lt;byte[]&gt; reference : list) { System.out.println(reference.get()); } }} 大概思路为：查看引用队列中有无软引用，如果有，则将该软引用从存放它的集合中移除（这里为一个list集合） 弱引用只有弱引用引用该对象时，在垃圾回收时，无论内存是否充足，都会回收弱引用所引用的对象 如上图如果B对象不再引用A3对象，则A3对象会被回收 弱引用的使用和软引用类似，只是将 SoftReference 换为了 WeakReference 123456789101112131415161718192021222324252627public class Demo { private static final int _4MB = 4 * 1024 * 1024; public static void main(String[] args) throws IOException { weak(); } /** * 弱引用 */ public static void weak() { // list--&gt;WeakReference--&gt;byte[] List&lt;WeakReference&lt;byte[]&gt;&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 5; i++) { WeakReference&lt;byte[]&gt; reference = new WeakReference&lt;&gt;(new byte[_4MB]); System.out.println(reference.get()); list.add(reference); System.out.println(list.size()); } System.out.println(&quot;循环结束：&quot; + list.size()); for (WeakReference&lt;byte[]&gt; reference : list) { System.out.println(reference.get()); } }} 小总结：软引用本身也是一个对象，也占用内存，软引用可以关联一个引用队列（可选），如果软引用对象引用的对象被垃圾回收了，软引用对象本身不会被回收，而是进入一个引用队列（如果这个软引用关联了引用队列的话）。如果想对软引用对象占用的内存进行释放，要结合引用队列，从队列中遍历并找到，然后进一步判断软引用对象是否被强引用引用，如果没有的话可回收释放。弱引用也是一样的道理，弱引用和软引用很相似，唯一的不同就是：软引用引用的对象（该对象没有被强引用），会在内存不足的时候被回收；而弱引用引用的对象（该对象没有被强引用），无论内存是否充足，都会回收弱引用所引用的对象。 虚引用必须关联一个引用队列。虚引用的一个典型案例就是直接内存的释放。 对于虚引用对象，前面直接内存的地方就提到过。申请直接内存的时候，创建 ByteBuffer 的实现类对象时，就会创建一个名为 cleaner 的虚引用对象，ByteBuffer 会被分配一块直接内存，并且会将直接内存的内存地址传递给虚引用对象，这样的一个操作是为何？将来我的 ByteBuffer 一旦没有强引用所引用它了，ByteBuffer 自己会被垃圾回收掉，但是只有它被垃圾回收了还不够，因为分配给它的直接内存并不能被垃圾回收管理，所以我们要在 ByteBuffer 被回收时，让虚引用对象进入到引用队列，而虚引用所在的引用队列由一个叫做 ReferenceHandler 的线程来定时的到这个引用队列中找有无一个新入队的 cleaner，如果有，这个线程就会调用虚引用对象 cleaner 的 clean() 方法，clean 方法就会根据前面记录的直接内存的地址，调用 unsafe.freeMemory()，将直接内存释放掉，这样就保证不会造成因为直接内存一直不释放而导致的内存泄漏。 当虚引用对象所引用的对象被回收以后，虚引用对象就会被放入引用队列中，调用虚引用的方法 虚引用的一个体现是释放直接内存所分配的内存，当引用的对象ByteBuffer被垃圾回收以后，虚引用对象Cleaner就会被放入引用队列中，然后调用Cleaner的clean方法来释放直接内存 如上图，B对象不再引用ByteBuffer对象，ByteBuffer就会被回收。但是直接内存中的内存还未被回收。这时需要将虚引用对象Cleaner放入引用队列中，然后调用它的clean方法来释放直接内存 总结：在虚引用引用的对象（比如 ByteBuffer）被垃圾回收时，虚引用对象（比如 cleaner）自己就会进入到引用队列，从而间接地由一个线程（ReferenceHandler）来调用虚引用对象 cleaner 的 clean 方法，然后调用 unsafe.freeMemory() 来释放直接内存。 终结器引用所有的类都继承自Object类，Object类有一个finalize方法。当某个对象不再被其他的对象所引用时，会先将终结器引用对象放入引用队列中，然后根据终结器引用对象找到它所引用的对象，然后调用该对象的finalize方法。调用以后，该对象就可以被垃圾回收了 如上图，B对象不再引用A4对象。这是终结器对象就会被放入引用队列中，引用队列会根据它，找到它所引用的对象。然后调用被引用对象的finalize方法。调用以后，该对象就可以被垃圾回收了 总结：终结器引用回收的效率低，因为在第一次回收时，不能真正的回收掉 A4 对象，而是先将终结器引用加入到引用队列，并且处理这个引用队列的线程优先级很低，被执行的机会很少，所以会造成 A4 对象的 finalize() 方法迟迟不被调用，这个队列占的内存也迟迟得不到释放，这也是为何我们不推荐使用 finalize() 来释放资源的原因。 引用队列 软引用和弱引用可以配合引用队列 在弱引用和虚引用所引用的对象被回收以后，会将这些引用放入引用队列中，方便一起回收这些软/弱引用对象 虚引用和终结器引用必须配合引用队列 虚引用和终结器引用在使用时会关联一个引用队列 大总结： 强引用 只有所有 GC Roots 对象都不通过【强引用】引用该对象，该对象才能被垃圾回收 软引用（SoftReference） 仅有软引用引用该对象时，在垃圾回收后，内存仍不足时会再次出发垃圾回收，回收软引用对象 可以配合引用队列来释放软引用自身 弱引用（WeakReference） 仅有弱引用引用该对象时，在垃圾回收时，无论内存是否充足，都会回收弱引用对象 可以配合引用队列来释放弱引用自身 虚引用（PhantomReference） 必须配合引用队列使用，主要配合 ByteBuffer 使用，被引用对象回收时，会将虚引用入队，由 Reference Handler 线程调用虚引用相关方法释放直接内存 终结器引用（FinalReference） 无需手动编码，但其内部配合引用队列使用，在垃圾回收时，终结器引用入队（被引用对象暂时没有被回收），再由 Finalizer 线程通过终结器引用找到被引用对象并调用它的 finalize 方法，第二次 GC 时才能回收被引用对象。 垃圾回收算法标记-清除 定义：标记清除算法顾名思义，是指在虚拟机执行垃圾回收的过程中，先采用标记算法确定可回收对象，然后垃圾收集器根据标识清除相应的内容，给堆内存腾出相应的空间 这里的腾出内存空间并不是将内存空间的字节清0，而是记录下这段内存的起始结束地址，下次分配内存的时候，会直接覆盖这段内存 缺点：容易产生大量的内存碎片，可能无法满足大对象的内存分配，一旦导致无法分配对象，那就会导致jvm启动gc，一旦启动gc，我们的应用程序就会暂停，这就导致应用的响应速度变慢 标记-整理 标记-整理 会将不被GC Root引用的对象回收，清楚其占用的内存空间。然后整理剩余的对象，可以有效避免因内存碎片而导致的问题，但是因为整体需要消耗一定的时间，所以效率较低 复制 大致流程： 将内存分为等大小的两个区域，FROM和TO（TO中为空）。先将被GC Root引用的对象从FROM放入TO中，再回收不被GC Root引用的对象。然后交换FROM和TO。这样也可以避免内存碎片的问题，但是会占用双倍的内存空间。 分代回收前面说的几种垃圾回收算法，并不是单独工作的，它们是协同工作的，具体实现是 JVM 中的分代垃圾回收机制，它将整个堆内存大区域划分成 2 块：新生代、老年代，不同区域的不同的垃圾回收算法就可以更有效的进行垃圾回收。其中新生代一般存放一些用完了就可以丢掉的对象；老年代一般存放一些长时间使用的对象，这里的长时间就是指那些经历了新生代阈值次数的垃圾回收还幸存下来的对象，阈值一般为 15，但是有时候可能会不到 15 就提前放入老年代。新生代中又分了三个区域，分别为伊甸园，幸存区 From、幸存区 To，它们仨的默认比例为 8 : 1 : 1，新创建的对象都被放在了新生代的伊甸园中，当伊甸园的内存不足的时候，就会进行一次垃圾回收，这时的回收叫做 Minor GC，Minor GC 触发后，会采用可达性分析算法沿着 GC root（根对象）的引用链找，看这些对象是有引用的还是可以作为垃圾进行一次标记动作的，标记成功之后，采用复制算法，将伊甸园和幸存区 From 中存活的对象复制到幸存区 To 中，并且让幸存的对象寿命 +1（最开始的时候寿命为 0）。然后将伊甸园和幸存区 From 中的垃圾清除。现在的状况就是：伊甸园是干净的，幸存区 From 是干净的，幸存区 To 中存放了 Minor GC 之后存活的对象，然后将幸存区 From 和幸存区 To 的位置调换。这就是复制回收算法的思想。这样新创建的对象就可以继续放入伊甸园了。 注：minor gc 会引发 stop the world，暂停其它用户的线程，等垃圾回收结束，用户线程才恢复运行。原因就是一个线程在垃圾回收过程中，会涉及到对象的复制，可能对象的地址会发生变化，如果其它线程不阻塞的话就可能得到一个错误的地址。 但是如果经过了几轮的垃圾回收，达到了一定的阈值，仍然幸存的对象，那么这些对象就会放入老年代中，等对象越来越多老年代内存满了，当老年代空间不足，会先尝试触发 minor gc，如果之后空间仍不足，那么触发 full gc，STW 的时间更长。 回收流程新创建的对象都被放在了新生代的伊甸园中 当伊甸园中的内存不足时，就会进行一次垃圾回收，这时的回收叫做 Minor GC Minor GC 会将伊甸园和幸存区FROM存活的对象先复制到幸存区 TO中， 并让其寿命加1，再交换两个幸存区 再次创建对象，若新生代的伊甸园又满了，则会再次触发 Minor GC（会触发 stop the world， 暂停其他用户线程，只让垃圾回收线程工作），这时不仅会回收伊甸园中的垃圾，还会回收幸存区中的垃圾，再将活跃对象复制到幸存区TO中。回收以后会交换两个幸存区，并让幸存区中的对象寿命加1。 如果幸存区中的对象的寿命超过某个阈值（最大为15，4bit），就会被放入老年代中 总结： 对象首先分配在伊甸园区域 新生代空间不足时，触发 minor gc，伊甸园和 from 存活的对象使用 copy 复制到 to 中，存活的对象年龄加 1并且交换 from to minor gc 会引发 stop the world，暂停其它用户的线程，等垃圾回收结束，用户线程才恢复运行 当对象寿命超过阈值时，会晋升至老年代，最大寿命是15（4bit） 当老年代空间不足，会先尝试触发 minor gc，如果之后空间仍不足，那么触发 full gc，STW 的时间更长 老年代空间分配担保规则参考原文：https://blog.csdn.net/qq_21588061/article/details/114290212 如果年轻代里大量对象存活，确实自己的Survivor区放不下了，必须转移到老年代去 但是如果老年代里空间也不够放这些对象，改怎么办呢？ 首先，在执行任何一次Minor GC之前，JVM都会先检查一些老年代可用的内存空间，是否大于年轻代所有对象的总大小，为什么呢？因为最极端的情况下，可能年轻代Minor GC之后，所有对象都存活下来了，那岂不是年轻代所有对象全部进入老年代 如果说发现老年代内存大小是大于年轻代所有对象的，此时就可以放心大胆地对年轻代发起一次Minor GC了，因为即使 Minor GC 之后所有对象都存活，Survivor 区放不下了，也可以转移到老年代去。 但是假如执行Minor GC之前，发现老年代的可用内存已经小于了年轻代的全部对象大小了。 这个时候是不是有可能在Minor GC之后年轻代的对象全部存活下来，全部需要转移到老年代中去，但是老年代内存空间又不够？理论上是有可能的。 所以假如Minor GC之前，发现老年代的可用内存已经小于了年轻代的全部对象大小，就会看一个“-XX:-HandlePromotionFailure”的参数是否设置了 如果设置了这个参数，那么就会继续尝试进行下一步判断。下一步判断，就会看看老年代的内存大小，是否大于之前每一次Minor GC后进去老年代对象的平均大小。 但是如果上面步骤判断失败了，或者是“-XX:-HandlePromotionFailure”参数没设置，此时就会直接触发一次“Full GC”， 就是对老年代进行垃圾回收，尽量腾出来一些内存空间，然后再执行Minor GC。 如果上面两个步骤都判断成功，那么就可以冒点风险尝试一下Minor GC，此时进行Minor GC有几种可能： ①Minor GC过后，剩余的存活对象的大小，小于Survivor区的大小，那么此时存活对象进入Survivor区即可 ②Minor GC过后，剩余的存活对象的大小，大于Survivor区的大小，但是小于老年代可用内存大小，就直接进入老年代即可 ③Minor GC过后，剩余的存活对象的大小，大于Survivor区的大小，同时大于老年代可用内存大小，就是比以往Minor GC之后剩余对象大小的平均值大，此时就会发生“Handle Promotion Failure”的情况，这个时候就会出发一次“Full GC”。 Full GC就是对老年代进行垃圾回收，同时也一般会对年轻代进行垃圾回收。 如果Full GC之后，老年代还是没有足够空间存放Minor GC过后的剩余存活对象，此时就会导致所谓的“OOM”内存溢出了。 所以，所谓的JVM优化，就是尽可能的让对象都在年轻代里分配和回收，尽量别让太多对象频繁进入老年代，避免频繁对老年代进行垃圾回收，同时给系统充足的内存大小，避免年轻代频繁的进行垃圾回收。 GC 分析大对象处理策略当遇到一个较大的对象时，就算新生代的伊甸园为空，也无法容纳该对象时，会将该对象直接晋升为老年代，这就是阈值 15 的例外情况。 线程内存溢出某个线程的内存溢出了而抛异常（out of memory），不会让其他的线程结束运行 这是因为当一个线程抛出OOM异常后，它所占据的内存资源会全部被释放掉，从而不会影响其他线程的运行，进程依然正常 垃圾回收器相关概念并行收集：指多条垃圾收集线程并行工作，但此时用户线程仍处于等待状态。 并发收集：指用户线程与垃圾收集线程同时工作（在同一时间段内交替执行）。用户程序在继续运行，而垃圾收集程序运行在另一个CPU上 吞吐量：即CPU用于运行用户代码的时间与CPU总消耗时间的比值（吞吐量 = 运行用户代码时间 / ( 运行用户代码时间 + 垃圾收集时间 )），也就是。例如：虚拟机共运行100分钟，垃圾收集器花掉1分钟，那么吞吐量就是99% 串行串行指的是垃圾回收线程和用户工作线程串行，在垃圾回收的时候，工作线程全部暂停。 单线程 内存较小，个人电脑（CPU核数较少） -XX:+UseSerialGC = Serial + SerialOld 安全点：让其他线程都在这个点停下来，以免垃圾回收时移动对象地址，使得其他线程找不到被移动的对象 因为是串行的，所以只有一个垃圾回收线程。且在该线程执行回收工作时，其他线程进入阻塞状态 Serial 收集器Serial收集器是最基本的、发展历史最悠久的收集器 特点：单线程、简单高效（与其他收集器的单线程相比），采用复制算法。对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程手机效率。收集器进行垃圾回收时，必须暂停其他所有的工作线程，直到它结束（Stop The World） ParNew 收集器ParNew收集器其实就是Serial收集器的多线程版本 特点：多线程、ParNew收集器默认开启的收集线程数与CPU的数量相同，在CPU非常多的环境中，可以使用-XX:ParallelGCThreads参数来限制垃圾收集的线程数。和Serial收集器一样存在Stop The World问题 Serial Old 收集器Serial Old是Serial收集器的老年代版本 特点：同样是单线程收集器，采用标记-整理算法 吞吐量优先 多线程垃圾回收 堆内存较大，多核CPU 单位时间内，STW（stop the world，停掉其他所有工作线程）时间最短 JDK1.8默认使用的垃圾回收器 -XX:+UseParallelGC ~ -XX:+UseParallelOldGC -XX:+UseAdaptiveSizePolicy -XX:GCTimeRatio=ratio -XX:MaxGCPauseMillis=ms -XX:ParallelGCThreads=n Parallel Scavenge 收集器与吞吐量关系密切，故也称为吞吐量优先收集器 特点：属于新生代收集器也是采用复制算法的收集器（用到了新生代的幸存区），又是并行的多线程收集器（与ParNew收集器类似） 该收集器的目标是达到一个可控制的吞吐量。还有一个值得关注的点是：GC自适应调节策略（与ParNew收集器最重要的一个区别） GC自适应调节策略：Parallel Scavenge收集器可设置-XX:+UseAdptiveSizePolicy参数。当开关打开时不需要手动指定新生代的大小（-Xmn）、Eden与Survivor区的比例（-XX:SurvivorRation）、晋升老年代的对象年龄（-XX:PretenureSizeThreshold）等，虚拟机会根据系统的运行状况收集性能监控信息，动态设置这些参数以提供最优的停顿时间和最高的吞吐量，这种调节方式称为GC的自适应调节策略。 Parallel Scavenge收集器使用两个参数控制吞吐量： XX:MaxGCPauseMillis 控制最大的垃圾收集停顿时间 XX:GCRatio 直接设置吞吐量的大小 Parallel Old 收集器是Parallel Scavenge收集器的老年代版本 特点：多线程，采用标记-整理算法（老年代没有幸存区） 响应时间优先 多线程 堆内存较大，多核CPU 尽可能让单次STW时间变短（尽量不影响其他线程运行） -XX:+UseConcMarkSweepGC ~ -XX:+UseParNewGC ~ SerialOld -XX:ParallelGCThreads=n ~ -XX:ConcGCThreads=threads -XX:CMSInitiatingOccupancyFraction=percent -XX:+CMSScavengeBeforeRemark CMS 收集器Concurrent Mark Sweep，一种以获取最短回收停顿时间为目标的老年代收集器 特点：基于标记-清除算法实现。并发收集、低停顿，但是会产生内存碎片 应用场景：适用于注重服务的响应速度，希望系统停顿时间最短，给用户带来更好的体验等场景下。如web程序、b/s服务 CMS收集器的运行过程分为下列4步： 初始标记：标记GC Roots能直接到的对象。速度很快但是仍存在Stop The World问题 并发标记：进行GC Roots Tracing 的过程，找出存活对象且用户线程可并发执行 重新标记：为了修正并发标记期间因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录。仍然存在Stop The World问题 并发清除：对标记的对象进行清除回收 CMS为了减轻STW带来的影响，采用了如上四个阶段来进行垃圾回收，其中初始标记和重新标记的耗时很短，会STW但是影响不大，然后并发标记和并发清理阶段的耗时很长，但是可以和工作线程并发运行的，因此对系统的影响不大。这就是CMS的大致的工作原理。 CMS收集器的垃圾回收过程（垃圾回收线程）是与用户线程一起并发执行的。 但是CMS的问题也显而易见： 并发回收垃圾导致CPU资源紧张。 Concurrent Mode Failure问题：就是CMS由于是允许垃圾回收线程和工作线程并发执行的，因此需要给工作线程预留一定的内存，因此CMS并不是等到老年代满了才开始回收垃圾的，而是当老年代中的占用内存达到了老年代内存总大小的92%时就会自动开始使用标记清理算法回收垃圾，因此，还剩8%的剩余空间，预留8%的空间给并发清理期间，系统程序将一些新对象放入老年代中，但如果工作线程生成的对象经过Minor GC晋升到老年代的速度太快（大于并行清除阶段垃圾回收的速度并且占满剩余的8%内存）的极端情况发生，也就是说如果CMS并发清理期间，系统程序要放入老年代的对象大于了此时老年代的可用内存空间，这个时候会发生Concurrent Mode Failure，会造成 CMS 垃圾回收器并发失败，就是说并发垃圾回收失败了，我一边回收，你一边把对象放入老年代，内存都不够了，从而导致 CMS 垃圾回收器不能正常工作，会退化为 Serial Old 串行的老年代垃圾回收器。这样效率会很低，强行把系统程序STW，重新进行长时间的GC Roots追踪，标记出全部的存活对象，不允许新的对象产生。响应时间变长。 在并发清理阶段，CMS是回收之前没标记的对象，也就是回收之前的垃圾，但是由于并发清理阶段，工作线程和垃圾回收线程并行运行，工作线程会产生新的对象和新的垃圾，这些新产生的可能也进入到老年代了，但是本轮GC不管。因此不必担心没被标记的新对象到了老年代中被误清理的情况，但是这也意味着可能也会产生新的垃圾到老年代中，也即是我们提到的“浮动垃圾”。 为什么说本轮GC不管？是因为并发清理阶段新晋升到老年代的对象会被分配在FreeList中指定的合适区域，因此不会参与本轮的清理。因为CMS内部维护着一个数据结构，用来记录可以安全分配新对象的内存空间地址。 内存碎片问题：CMS的标记清理算法会造成大量的内存碎片，这样容易因为内存不连贯而频繁触发Full GC，因此CMS不是完全就仅仅用标记清理算法的，CMS有一个参数是“-XX:+UseCMSCompactAtFullCollection”，默认就是打开的。它的意思是在Full GC之后要再次进行“Stop the World”，停止工作线程，然后进行碎片整理，就是将存活的对象挪到一起，空出来大片连续的内存空间，避免内存碎片。 还有一个参数是“-XX:CMSFullGCsBeforeCompaction”，这个意思是执行多少次Full GC之后再执行一次内存碎片整理的工作，默认是0，意思就是每次Full GC之后都会进行一次内存整理。 内存碎片整理完之后，存活的对象都放在一起，然后空出来大片连续的内存空间可供使用。 G1定义Garbage First JDK 9以后默认使用，而且替代了CMS 收集器 适用场景 同时注重吞吐量和低延迟（响应时间） 超大堆内存（内存大的），会将堆内存划分为多个大小相等的区域 整体上是标记-整理算法，两个区域之间是复制算法 相关参数：JDK8 并不是默认开启的，所需要参数开启 123-XX:+UseG1GC-XX:G1HeapRegionSize=size-XX:MaxGCPauseMillis=time G1垃圾回收阶段 Young Collection分区算法region：分代是按对象的生命周期划分，分区是将堆空间划分连续几个不同小区间，每一个小区间独立回收，可以控制一次回收多少个小区间，方便控制 GC 产生的停顿时间 E：伊甸园 S：幸存区 O：老年代 会 STW Young Collection + CM注：CM：ConcurrentMark，并发标记 在 Young GC 时会对 GC Root 进行初始标记 在老年代占用堆内存的比例达到阈值时，对进行并发标记（不会 STW），阈值可以根据用户来进行设定 Mixed Collection会对 E、S、O 进行全面的回收，优先回收垃圾最多的区域。 最终标记：因为垃圾回收线程和工作线程可并发执行，垃圾回收时不会阻塞工作线程，所以可能会有浮动垃圾，因此需要最终标记 拷贝存活 -XX:MaxGCPauseMills:xxx 用于指定最长的停顿时间 问：为什么有的老年代被拷贝了，有的没拷贝？ 因为指定了最大停顿时间，如果对所有老年代都进行回收，耗时可能过高。为了保证时间不超过设定的停顿时间，会回收最无价值的老年代（回收后，能够得到更多内存） 垃圾回收器总结 SerialGC（垃圾回收线程串行，其它线程阻塞） 新生代内存不足发生的垃圾收集 - minor gc 老年代内存不足发生的垃圾收集 - full gc ParallelGC（垃圾回收线程并行，其它线程阻塞） 新生代内存不足发生的垃圾收集 - minor gc 老年代内存不足发生的垃圾收集 - full gc CMS（垃圾回收线程和用户的工作线程并发交替运行） 新生代内存不足发生的垃圾收集 - minor gc 老年代内存不足 G1（垃圾回收线程和用户的工作线程并发交替运行） 新生代内存不足发生的垃圾收集 - minor gc 老年代内存不足的时候，触发的垃圾回收要分两种情况： G1在老年代内存不足时（老年代所占内存超过阈值） 如果垃圾产生速度慢于垃圾回收速度，不会触发Full GC 如果垃圾产生速度快于垃圾回收速度，便会触发Full GC 看完儒猿技术窝JVM专栏中这部分的内容，对G1简单总结一下： 首先强调一下，前面学习的几种垃圾回收器需要搭配使用，比如ParNew和CMS搭配使用，并且需要设置堆内存的大小（Xms和Xmx，一般设置成一样的值）和指定新生代的大小，那么剩下的就是老年代的大小。现在我们了解的G1垃圾回收器，是不需要设置新生代的大小的，只需要设置堆内存的大小就行，关于堆内存中的新生代和老年代，G1可以自动计算和设置，当然也可以手动更改，但是一般都用默认值就好。 其实G1垃圾回收器设计的思想，主要是将堆内存拆分为很多个小的Region，然后新生代和老年代各自对应一些Region，回收的时候尽可能的挑选停顿时间最短以及回收对象最多的Region，尽量保证达到我们指定的垃圾回收系统停顿时间。其实大家通过之前的学习，有关JVM的优化思路，都明白一点，我们对内存的合理分配，优化一些参数，就是为了尽可能的减少Minor GC和Full GC，尽量减少GC带来的系统停顿，避免影响系统处理请求。但是现在我们可以直接给G1指定，在一个时间内，垃圾回收导致的系统卡顿时间不能超过多久，由G1全权给你负责保证达到这个目标。G1怎么做到垃圾回收导致的系统停顿可控的呢？就是G1会追踪每个Region里的回收价值，G1会搞清楚每个Region里的对象有多少是垃圾，如果对这个Region进行垃圾回收需要耗费多长时间，可以回收掉多少垃圾。因此简单来说，G1可以做到让我们自己设定垃圾回收对系统的影响，G1通过将内存拆分为大量的小Region，以及追踪每个Region中可以回收的对象大小和预估时间，最后在垃圾回收的时候，尽量把垃圾回收对系统造成的影响控制在我们指定的时间范围内，同时在有限的时间内尽量回收尽可能多的垃圾。这就是G1的核心设计思路。 可以使用“-XX:+UseG1GC”来指定使用G1垃圾回收器，然后JVM启动的时候一旦发现使用的是G1垃圾回收器，此时就会自动用堆内存大小除以2048。因为JVM最多可以有2048个Region，并且Region的大小必须是2的倍数，比如说2M、4M之类的。当然可以通过手动方式设定，则是“-XX:G1HeapRegionSize”。刚开始的时候，默认新生代在堆内存的占比是5%，可以通过“-XX:G1NewSizePrecent”来设置新生代的初始占比的，维持默认即可。在系统运行中，JVM会不停的给新生代增加更多的Region，但是最多新生代的占比不会超过60%，可以通过“-XX:G1MaxNewSizePercent”来设置。一旦Region进行了垃圾回收，此时新生代的Region数量还会减少，这些其实都是动态的。 其实在G1中虽然将内存划分为了很多的Region，但是其实还是有新生代、老年代之分的，并且在新生代中还是有Eden和Survivor划分的。其实前面学习的很多的技术原理在G1时期都是有用的。并且Eden和Survivor的默认比依然是8：1：1。只不过前面是按照内存大小来比，现在是依靠Region的数量来比值。随着系统运行，不停地在新生代的Eden对应的Region中放对象，JVM就会不停的给新生代加入更多的Region，直到新生代占据堆大小的最大比例60%，一旦占了60%，并且Eden区还占满了对象，那么就会触发新生代的GC（Minor GC），这时只是回收新生代的垃圾对象。G1会用复制算法来进行垃圾回收，同时系统进入STW状态。这个过程和之前的区别就是G1可以设定目标GC停顿时间，也就是G1指定GC的时候最多允许系统停顿多长时间，可以通过“-XX:MaxGCPauseMills”参数来设定，默认值是200ms。 按照前面的推算，新生代最大占60%，那么老年代就是40%，在G1中对象从新生代进入老年代的条件和前面几乎一样，对象在新生代躲过了几次的垃圾回收，到达一定年龄了；或者根据动态年龄判定的规则，一旦发现某次新生代的GC过后，存活对象超过了Survivor的50%，此时就会判断一下，比如年龄为1、2、3、4岁的对象的大小总和超过了Survivor的50%，此时4岁以上的老对象全部会进入到老年代，这就是动态年龄判定规则。这时候又会有人想起大对象，大对象不是直接进入到老年代吗，是的没错，但是只有在G1的这套内存模式下是特别的。因为G1专门提供了Region来存放大对象，而不是让大对象直接进入到老年代中。在G1中，大对象的判定规则是如果一个对象大小超过了一个Region大小的50%，那就会被放入大对象专门的Region中。而且一个对象如果太太大，也可能会横跨多个Region来存放。有人会问，不是新生代60%老年代40%吗，那√8还有哪些Region给大对象？其实前面提到了，在G1里面，新生代和老年代的Region是动态的是不停变化的。比如说现在新生代占据了1200个Region，但是一次垃圾回收之后，就让里面的1000个Region都空了，那么此时那1000个空着的Region就可以不属于新生代了，里面的很多Region可以用来存放大对象。那还会有人问：既然大对象不属于新生代也不属于老年代，那什么时候会触发垃圾回收呢？也很简单，其实新生代、老年代在回收的时候，会顺带带着大对象Region一起回收。所以这就是在G1内存模型下对大对象的分配和回收策略。 G1垃圾回收的过程： 初始标记阶段，会STW，仅仅标记GC Roots直接能引用的对象，速度快。 类的静态变量可以作为根对象 方法中的局部变量可以作为根对象 类的成员变量不可 并发标记阶段，允许系统程序运行，不会STW，从GC Roots开始沿着引用链追踪所有的存活对象，耗时但是影响不大因为可以和用户线程并行。 最终标记阶段，会STW，因为并发标记阶段垃圾回收线程和工作线程可并发执行，垃圾回收时不会阻塞工作线程，所以可能会有浮动垃圾，因此需要最终标记，和CMS垃圾回收器中的重新标记阶段类似。会根据并发标记阶段记录的那些对象的修改，最终标记一下有哪些存活的对象，有哪些是垃圾对象。 混合回收阶段，是最后一个阶段，这个阶段会计算新生代、老年代、大对象中每个Region中的存活对象数量，存活对象占比，还有执行垃圾回收的预期性能和效率，接着会STW，然后全力以赴尽快进行垃圾回收，此时它可能会从新生代、老年代、大对象里各自挑选部分的Region进行回收，因为必须让垃圾回收的停顿时间控制在我们指定的范围内。这里会STW，虽然会停止系统程序，但是不必担心，因为在这个阶段中，G1是允许执行多次混合回收的，每次混合回收虽然会让系统STW，但不会让系统停顿时间过长。 什么时候触发新生代+老年代的混合垃圾回收？G1有一个参数，是“-XX:InitiatingHeapOccupancyPercent”，它的默认值是45%，意思就是说：如果老年代占据了堆内存的45%的Region的时候（新生代最大已经达不到占堆内存60%），此时就会尝试触发一个新生代+老年代+大对象一起回收的混合回收阶段，也就是说，此时垃圾回收不仅仅是回收老年代，还会回收新生代，以及大对象。那么到底是回收这些区域的哪些Region呢？那就要看情况了。因为我们设定了对GC停顿时间的目标，因此它会从新生代、老年代、大对象里面各自挑选一些Region，保证用指定的时间（比如默认的200ms）回收尽可能多的垃圾，这就是混合回收Mixed GC，在最后一个阶段（混合回收）的时候，其实会停止所有程序运行，所以说G1是允许执行多次混合回收的。比如先停止工作，执行一次混合回收回收掉一些Region，接着恢复系统运行，然后再次停止系统运行，再执行一次混合回收回收掉一些Region，接着恢复系统运行。 有些参数可以控制这个，比如： “-XX:G1MixedGCCountTarget”参数，就是在一次混合回收的过程中，这个阶段执行几次混合回收，默认值是8次。先停止系统运行，执行一次混合回收回收掉一些Region，接着恢复系统运行，然后再次停止系统运行，再执行一次混合回收回收掉一些Region，反复8次。这样可以不让系统停顿时间过长。 “-XX:G1HeapWastePercent”参数，默认值是5%。意思是，在混合回收的时候，对Region回收都是基于复制算法进行的，不会出现碎片问题，都是将要回收的Region中存活的对象放入其它的Region，然后这个Region中的垃圾对象全部清理掉。这样的话就会不断的空出来新的Region，一旦空闲出来的Region数量达到了堆内存的5%，此时就会立刻停止混合回收。意味着本次混合回收结束。 “-XX:G1MixedGCLiveThresholdPercent”参数，默认值是85%，意思是确定要回收的Region的时候，必须是存活对象低于85%的Region才可以进行回收。否则还回收干什么？人家里面的存活对象那么多，还要把85%的对象都拷贝到别的Region，成本很高。 回收失败时的Full GC：在进行混合回收的时候，无论是年轻代还是老年代都是基于复制算法进行回收，都要把各个Region的存活对象拷贝到别的Region里，此时万一出现拷贝过程中发现没有空闲的Region可以承载自己的存活对象了，就会触发一次失败。一旦失败立马就会切换为停止系统程序，然后采用单线程进行标记、清理和压缩整理，空闲出来一批Region，这个过程极慢。stop the world 的时间变长。 G1和ParNew+CMS调优原则都是尽可能Minor GC，不做老年代的Full GC，G1相对来说更加智能，但也意味着JVM要用更多的资源去判断每个region的使用情况，而ParNew+CMS更加纯粹和直接。虽然G1在GC的时候不会产生内存碎片（复制算法），但是由于每个region存在存活对象85%不清理机制，会导致内存没有被充分释放的问题，而CMS虽然会有内存碎片（标记-清理），但是清理完之后后面会有一个对内存空间的压缩（由两个默认的参数设置决定，可以调节在多少次清理之后进行内存压缩，默认为0，每次都压缩），以减少内存碎片，是空间更加连贯。 因此对于CPU性能高的、内存容量大的、对应用响应度要求高的系统更推荐使用G1，而内存小一些的、CPU性能相对一般的甚至低下的更推荐使用ParNew+CMS。 我们知道，新创建的对象都是优先在伊甸园中的，那么伊甸园Eden区快满了的时候，会触发Minor GC，在触发Minor GC之前，会根据空间担保机制判断是否需要先进行Full GC，那么我们知道理论上，当老年代快占满了的时候，会触发Full GC。但是要知道：在使用ParNew+CMS的时候，老年代垃圾回收触发的时机有所变化，因为CMS是并发垃圾回收器，意思是CMS允许垃圾回收线程和用户工作线程并发执行，在CMS回收垃圾的同时，工作线程可能会在老年代中产生新的对象以及浮动垃圾，因此老年代需要预留一些空间，所以CMS中规定老年代占满92%就开始使用CMS进行老年代的垃圾回收，也就是说老年代可用空间只有原来的92%，8%预留给并发运行的工作线程，CMS本轮不会清理新晋升到老年代中的对象和垃圾。当8%内存不够用时，意思是晋升新对象以及浮动垃圾的速度大于垃圾回收线程回收垃圾的速度，并且已经占满了8%，导致放不下了，那么CMS并发回收失败，并且此时老年代的垃圾回收器从CMS退化为 Serial Old 串行的老年代垃圾回收器。这样效率会很低，强行把系统程序STW，重新进行长时间的GC Roots追踪，标记出全部的存活对象，不允许新的对象产生。响应时间变长。对于G1，有了region的概念，G1是在新生代region占了整个堆内存的60%（可调节），并且Eden满了的情况下才会触发Minor GC（复制算法）。在老年代region占了整个堆内存的45%，开始进行Mixed GC，混合回收阶段会回收新生代、老年代、大对象的region（复制算法），当Mixed GC时，没有新的空闲region用来装存活的对象时，会触发Full GC，Mixed GC就会切换为采用单线程进行标记、清理和压缩整理，空闲出来一批Region，这个过程极慢。stop the world 的时间变长。 Young Collection 跨代引用 新生代回收的跨代引用（老年代引用新生代）问题 卡表与Remembered Set Remembered Set 存在于E中，用于保存新生代对象对应的脏卡 脏卡：O被划分为多个区域（一个区域512K），如果该区域引用了新生代对象，则该区域被称为脏卡 在引用变更时通过post-write barried + dirty card queue concurrent refinement threads 更新 Remembered Set 跨代引用的总结： 对于新生代垃圾回收时的跨代引用问题，首先我们要回忆新生代的垃圾回收，第一步就是找根对象（GC root），然后根据可达性分析算法，找到根对象的引用链，从而确定幸存下来的对象。那么我们要知道，根对象有一部分是来自于老年代的，也就是需要从老年代中找，但是老年代中通常存活的对象非常多，遍历整个老年代及其耗时，所以 JVM 会采用一种卡表（cardTable）的方式，将老年代区域再划分成一个个的 card，每个大约 512k。这样如果老年代中的某一个对象是引用了新生代对象的根对象（例子：可能集合中插入新对象，集合在老年代，新对象在新生代。），那么就标记这个根对象所在的 card 为 dirty card（脏对象）。这样在新生代垃圾回收的时候，查找根对象的时候，就不用遍历老年代中所有的对象了，而是去找那个标记为 dirty card 的小区域，只遍历小区域中的对象。 这时就会有人问了：如何知道这个 card 中有引用了新生代对象的根对象呢，标记 dirty card 不是也需要遍历整个老年代吗？ 其实是不用的！因为在进行对象引用的创建时，会有一个查找过程，查找该引用是否是被其它区域的对象所引用，如果是，则在 Remembered Set （注：新生代这边有一个 Remembered Set，其中会记录外部对我的一些引用，也就是记录都有哪些 dirty card。）中集中标注，也就是这里的标记脏 card。所以说，引用的时候就自动标记了。 将来对新生代伊甸区做垃圾回收时，先通过 Remember Set 知道它对应哪些 dirty card，再到这些 dirty card 区域遍历查找 GC root，减少了 GC root 的查找时间。 那么具体如何标记脏卡的？ 标记脏卡是通过一个叫 post-write barrier 的写屏障，在每次对象的引用发生变更时，都要去更新脏卡，将卡表中的卡标记为脏卡的动作是异步操作，不会立刻去完成卡表的更新，它会将更新的指令放在一个 dirty card queue 中，将来由一个线程去完成脏卡的更新操作。 Remark重新标记阶段 在垃圾回收时，收集器处理对象的过程中 黑色：已被处理，需要保留的 灰色：正在处理中的 白色：还未处理的 但是在并发标记过程中，有可能A被处理了以后未引用C，但该处理过程还未结束，在处理过程结束之前A引用了C，这时就会用到remark 过程如下 之前C未被引用，这时A引用了C，就会给C加一个写屏障，写屏障的指令会被执行，将C放入一个队列当中，并将C变为 处理中 状态 在并发标记阶段结束以后，重新标记阶段会STW，然后将放在该队列中的对象重新处理，发现有强引用引用它，就会处理它 Remark 总结： 在说 CMS 和 G1 这种并发垃圾回收器时，对于标记动作而言，有两个不同的阶段：并发标记阶段和重新标记阶段，后者也就是所谓的 Remark 阶段。并发标记阶段意味着在垃圾回收线程进行垃圾回收时，用户线程不会阻塞，也可以运行，所以当某个对象被当做垃圾进行清理但还未清理的时候，可能同时会有用户线程在对这个对象的引用做修改。意思就是可能已经被并发标记为可作为垃圾回收的对象，又有了新的引用，所以我们需要重新标记阶段。注意不要和最终标记弄混了，最终标记针对的是并发时可能出现的浮动垃圾的标记。 重新标记阶段的具体做法： 当我的对象的引用发生改变时，JVM 会给它加入一个写屏障 pre-write barrier ，只要对象的引用发生了改变，这个写屏障的指令就会被执行，这指令会将引用发生改变的这个对象加入到一个队列中 satb_mark_queue，并且将这个对象标记为未处理完，等到整个并发标记阶段结束了，接下来进入重新标记阶段，会 STW，这时重新标记阶段的线程会将对象从队列中取出再做一次检查。 JDK 8u20 字符串去重过程 将所有新分配的字符串（底层是char[]）放入一个队列 当新生代回收时，G1并发检查是否有重复的字符串 如果字符串的值一样，就让他们引用同一个字符串对象 注意，其与String.intern的区别 intern 方法关注的是字符串对象本身，让字符串本身不重复，因为串池的底层就是 HashTable。 字符串去重关注的是char[] 在JVM内部，使用了不同的字符串标 优点与缺点 节省了大量内存 新生代回收时间略微增加，导致略微多占用CPU JDK 8u40 并发标记类卸载在并发标记阶段结束以后，就能知道哪些类不再被使用。如果一个类加载器的所有类都不在使用，则卸载它所加载的所有类 JDK 8u60 回收巨型对象 一个对象大于region的一半时，就称为巨型对象 G1不会对巨型对象进行拷贝 回收时被优先考虑 G1会跟踪老年代所有incoming引用，如果老年代incoming引用为0的巨型对象就可以在新生代垃圾回收时处理掉 GC 调优查看虚拟机参数命令 1&quot;F:\\JAVA\\JDK8.0\\bin\\java&quot; -XX:+PrintFlagsFinal -version | findstr &quot;GC&quot;Copy 可以根据参数去查询具体的信息 调优领域 内存（GC） 锁竞争 CPU占用 IO 确定目标低延迟/高吞吐量？ 选择合适的GC CMS G1 ZGC ParallelGC Zing 最快的GC是不发生GC首先排除减少因为自身编写的代码而引发的内存问题 查看Full GC前后的内存占用，考虑以下几个问题 数据是不是太多？ 数据表示是否太臃肿 对象图 对象大小 是否存在内存泄漏 新生代调优 新生代的特点 所有的new操作分配内存都是非常廉价的 TLAB：每个线程都会在伊甸园中分配一块私有区域，也就是 TLAB（Thread-local allocation buffer）缓冲区，是每个线程局部的、私有的。当线程中 new 一个对象的时候，首先会检查这个 TLAB 缓冲区中有没有可用的内存，如果有，优先会在 TLAB 中进行对象的分配，原因是因为堆内存是线程间共享的区域，我们对象的分配可能会有线程安全问题，所以在做对象的分配的时候，也要做个线程并发安全的保护，这个操作就是 JVM 帮我们做的，所以 TLAB 的作用就是每个线程用自己私有的这块伊甸园内存来进行对象的分配。 死亡对象回收零代价 大部分对象用过即死（朝生夕死） MInor GC 所用时间远小于Full GC 新生代内存越大越好么？ 不是 新生代内存太小：频繁触发Minor GC，会STW，会使得吞吐量下降 新生代内存太大：因为堆内存大小固定，所以老年代内存占比有所降低，会更频繁地触发Full GC。而且触发Minor GC时，清理新生代所花费的时间会更长 新生代内存设置为内容纳[并发量*(请求-响应)]的数据为宜 随着新生代的内存空间变大，吞吐量变大，因为新生代内存空间大了，新生代垃圾回收占整个 CPU 计算的时间比例就会变小，这就代表吞吐量会变大，但是并不是新生代内存空间一直变大，吞吐量也会一直变大，反而是达到了一个点之后吞吐量会逐渐变小，因为老年代内存占比有所降低，会更频繁地触发Full GC。而且触发Minor GC时，清理新生代所花费的时间会更长 幸存区调优 幸存区需要能够保存 当前活跃对象+需要晋升的对象！ 晋升阈值配置得当，让长时间存活的对象尽快晋升 幸存区的晋升规则：如果幸存区分配的比较小，它就会由 JVM 动态的去调整晋升阈值，这个时候阈值就不一定为默认的 15 了，也许本来轮不到晋升的对象，但是由于幸存区的内存不够，导致 JVM 会提前将一些对象晋升到老年代，也就是有可能存活时间较短的对象提前进入了老年代，那么问题来了，如果一个本来存活时间短的对象被提前晋升到老年代的话，那么可能它得等到老年代的内存不足的时候，（暂且不考虑 CMS 和 G1 中 Full GC 之前的并发标记以及回收。）触发 Full GC 的时候才能把它回收，这是不好的，白白占用老年代的宝贵内存资源。所以我们要尽量保证存活时间短的对象在下次新生代垃圾回收的时候就回收掉，那些真正需要长时间存活的对象才晋升到老年代。 老年代调优以 CMS 并发垃圾回收器为例：CMS 是一种低响应时间的，并发的垃圾回收器，垃圾回收线程在工作的同时，其它的用户线程也能并发地执行。这样虽然减少了前面几种收集器阻塞线程时而浪费的时间，但是有个缺点，因为在垃圾回收线程回收垃圾的同时，用户线程可能会产生新的垃圾，也就是浮动垃圾。如果浮动垃圾产生的速度大于垃圾回收线程清理垃圾的速度，也就是如果浮动垃圾的产生又导致内存不足，这时会造成 CMS 垃圾回收器并发失败，从而导致 CMS 垃圾回收器不能正常工作，会退化为 Serial Old 串行的老年代垃圾回收器。这样效率会很低，STW，响应时间变长。所以我们在给老年代规划内存大小的时候，需要把它规划的大一些，避免浮动垃圾引起的并发失败，从而导致 Full GC 严重影响效率。 类加载与字节码技术 类文件结构一个简单的 HelloWorld.java 123456// HelloWorld 示例public class HelloWorld { public static void main(String[] args) { System.out.println(&quot;hello world&quot;); }} 执行 javac -parameters -d . HellowWorld.java 编译为 HelloWorld.class 后是这个样子的： 以下是字节码文件 123456789101112131415161718192021222324252627282930313233343536373839[root@localhost ~]# od -t xC HelloWorld.class0000000 ca fe ba be 00 00 00 34 00 23 0a 00 06 00 15 090000020 00 16 00 17 08 00 18 0a 00 19 00 1a 07 00 1b 070000040 00 1c 01 00 06 3c 69 6e 69 74 3e 01 00 03 28 290000060 56 01 00 04 43 6f 64 65 01 00 0f 4c 69 6e 65 4e0000100 75 6d 62 65 72 54 61 62 6c 65 01 00 12 4c 6f 630000120 61 6c 56 61 72 69 61 62 6c 65 54 61 62 6c 65 010000140 00 04 74 68 69 73 01 00 1d 4c 63 6e 2f 69 74 630000160 61 73 74 2f 6a 76 6d 2f 74 35 2f 48 65 6c 6c 6f0000200 57 6f 72 6c 64 3b 01 00 04 6d 61 69 6e 01 00 160000220 28 5b 4c 6a 61 76 61 2f 6c 61 6e 67 2f 53 74 720000240 69 6e 67 3b 29 56 01 00 04 61 72 67 73 01 00 130000260 5b 4c 6a 61 76 61 2f 6c 61 6e 67 2f 53 74 72 690000300 6e 67 3b 01 00 10 4d 65 74 68 6f 64 50 61 72 610000320 6d 65 74 65 72 73 01 00 0a 53 6f 75 72 63 65 460000340 69 6c 65 01 00 0f 48 65 6c 6c 6f 57 6f 72 6c 640000360 2e 6a 61 76 61 0c 00 07 00 08 07 00 1d 0c 00 1e0000400 00 1f 01 00 0b 68 65 6c 6c 6f 20 77 6f 72 6c 640000420 07 00 20 0c 00 21 00 22 01 00 1b 63 6e 2f 69 740000440 63 61 73 74 2f 6a 76 6d 2f 74 35 2f 48 65 6c 6c0000460 6f 57 6f 72 6c 64 01 00 10 6a 61 76 61 2f 6c 610000500 6e 67 2f 4f 62 6a 65 63 74 01 00 10 6a 61 76 610000520 2f 6c 61 6e 67 2f 53 79 73 74 65 6d 01 00 03 6f0000540 75 74 01 00 15 4c 6a 61 76 61 2f 69 6f 2f 50 720000560 69 6e 74 53 74 72 65 61 6d 3b 01 00 13 6a 61 760000600 61 2f 69 6f 2f 50 72 69 6e 74 53 74 72 65 61 6d0000620 01 00 07 70 72 69 6e 74 6c 6e 01 00 15 28 4c 6a0000640 61 76 61 2f 6c 61 6e 67 2f 53 74 72 69 6e 67 3b0000660 29 56 00 21 00 05 00 06 00 00 00 00 00 02 00 010000700 00 07 00 08 00 01 00 09 00 00 00 2f 00 01 00 010000720 00 00 00 05 2a b7 00 01 b1 00 00 00 02 00 0a 000000740 00 00 06 00 01 00 00 00 04 00 0b 00 00 00 0c 000000760 01 00 00 00 05 00 0c 00 0d 00 00 00 09 00 0e 000001000 0f 00 02 00 09 00 00 00 37 00 02 00 01 00 00 000001020 09 b2 00 02 12 03 b6 00 04 b1 00 00 00 02 00 0a0001040 00 00 00 0a 00 02 00 00 00 06 00 08 00 07 00 0b0001060 00 00 00 0c 00 01 00 00 00 09 00 10 00 11 00 000001100 00 12 00 00 00 05 01 00 10 00 00 00 01 00 13 000001120 00 00 02 00 14 根据 JVM 规范，类文件结构如下 123456789101112131415161718ClassFile { u4 magic; u2 minor_version; u2 major_version; u2 constant_pool_count; cp_info constant_pool[constant_pool_count-1]; u2 access_flags; u2 this_class; u2 super_class; u2 interfaces_count; u2 interfaces[interfaces_count]; u2 fields_count; field_info fields[fields_count]; u2 methods_count; method_info methods[methods_count]; u2 attributes_count; attribute_info attributes[attributes_count];} 魔数u4 magic 对应字节码文件的0~3个字节 0000000 ca fe ba be 00 00 00 34 00 23 0a 00 06 00 15 09 版本u2 minor_version; u2 major_version; 0000000 ca fe ba be 00 00 00 34 00 23 0a 00 06 00 15 09 4~7 字节，表示类的版本 00 34（52） 表示是 Java 8 字节码指令可参考 https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-6.html#jvms-6.5 javap工具Oracle 提供了 javap 工具来反编译 class 文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364Classfile /home/chanservy/idea/projects/concurrent/src/main/java/com/chan/jvm/HelloWorld.class Last modified 2021-10-27; size 438 bytes MD5 checksum 5ab6bab2c9d3036ba334e71f619ace9a Compiled from &quot;HelloWorld.java&quot;public class com.chan.jvm.HelloWorld minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #6.#15 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Fieldref #16.#17 // java/lang/System.out:Ljava/io/PrintStream; #3 = String #18 // hello world #4 = Methodref #19.#20 // java/io/PrintStream.println:(Ljava/lang/String;)V #5 = Class #21 // com/chan/jvm/HelloWorld #6 = Class #22 // java/lang/Object #7 = Utf8 &lt;init&gt; #8 = Utf8 ()V #9 = Utf8 Code #10 = Utf8 LineNumberTable #11 = Utf8 main #12 = Utf8 ([Ljava/lang/String;)V #13 = Utf8 SourceFile #14 = Utf8 HelloWorld.java #15 = NameAndType #7:#8 // &quot;&lt;init&gt;&quot;:()V #16 = Class #23 // java/lang/System #17 = NameAndType #24:#25 // out:Ljava/io/PrintStream; #18 = Utf8 hello world #19 = Class #26 // java/io/PrintStream #20 = NameAndType #27:#28 // println:(Ljava/lang/String;)V #21 = Utf8 com/chan/jvm/HelloWorld #22 = Utf8 java/lang/Object #23 = Utf8 java/lang/System #24 = Utf8 out #25 = Utf8 Ljava/io/PrintStream; #26 = Utf8 java/io/PrintStream #27 = Utf8 println #28 = Utf8 (Ljava/lang/String;)V{ public com.chan.jvm.HelloWorld(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 3: 0 public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=1, args_size=1 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #3 // String hello world 5: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return LineNumberTable: line 6: 0 line 7: 8}SourceFile: &quot;HelloWorld.java&quot; 图解方法执行流程1）原始 java 代码 注意：当一段 Java 代码（.Java）被执行的时候，先编译成字节码文件，也就是我们熟知的 .class 文件，然后会由 Java 虚拟机的类加载器把我们刚才 main 方法所在的类进行一个类加载的操作，类加载实际上是将刚才的这些 class 的字节数据读取到内存中，其中常量池的这部分数据会放入运行时常量池（运行时常量池：之前我们说内存结构的时候，说过整个 JVM 分为堆、栈、方法区三部分，运行时常量池从某种意义上讲其实就属于方法区。），就是把我们 class 文件常量池中的数据都放入运行时常量池。 1234567891011/** * 演示 字节码指令 和 操作数栈、常量池的关系 */public class Demo3_1 { public static void main(String[] args) { int a = 10; int b = Short.MAX_VALUE + 1; int c = a + b; System.out.println(c); }} 在 Java 源代码中，像 a 那样比较小的数字，其实并不是存在于常量池中的，而是跟着方法的字节码指令存放在一起，而一旦数字的范围超过了整数的最大值，比如 b ，则会存在于常量池中，也就是说：在 short 范围内的数字，都和字节码指令存放在一起，一旦超过了 short 整数的范围则会存在于常量池中，short 的最大值为 32767。 2）编译后的字节码文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475Classfile /home/chanservy/idea/projects/concurrent/src/main/java/com/chan/jvm/Demo3_1.class Last modified 2021-10-27; size 445 bytes MD5 checksum 3e7e729c66dad33e41c46dc43bb1bc81 Compiled from &quot;Demo3_1.java&quot;public class com.chan.jvm.Demo3_1 minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #7.#16 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Class #17 // java/lang/Short #3 = Integer 32768 #4 = Fieldref #18.#19 // java/lang/System.out:Ljava/io/PrintStream; #5 = Methodref #20.#21 // java/io/PrintStream.println:(I)V #6 = Class #22 // com/chan/jvm/Demo3_1 #7 = Class #23 // java/lang/Object #8 = Utf8 &lt;init&gt; #9 = Utf8 ()V #10 = Utf8 Code #11 = Utf8 LineNumberTable #12 = Utf8 main #13 = Utf8 ([Ljava/lang/String;)V #14 = Utf8 SourceFile #15 = Utf8 Demo3_1.java #16 = NameAndType #8:#9 // &quot;&lt;init&gt;&quot;:()V #17 = Utf8 java/lang/Short #18 = Class #24 // java/lang/System #19 = NameAndType #25:#26 // out:Ljava/io/PrintStream; #20 = Class #27 // java/io/PrintStream #21 = NameAndType #28:#29 // println:(I)V #22 = Utf8 com/chan/jvm/Demo3_1 #23 = Utf8 java/lang/Object #24 = Utf8 java/lang/System #25 = Utf8 out #26 = Utf8 Ljava/io/PrintStream; #27 = Utf8 java/io/PrintStream #28 = Utf8 println #29 = Utf8 (I)V{ public com.chan.jvm.Demo3_1(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 3: 0 public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=4, args_size=1 0: bipush 10 2: istore_1 3: ldc #3 // int 32768 5: istore_2 6: iload_1 7: iload_2 8: iadd 9: istore_3 10: getstatic #4 // Field java/lang/System.out:Ljava/io/PrintStream; 13: iload_3 14: invokevirtual #5 // Method java/io/PrintStream.println:(I)V 17: return LineNumberTable: line 5: 0 line 6: 3 line 7: 6 line 8: 10 line 9: 17}SourceFile: &quot;Demo3_1.java&quot; 3）字节码中的常量池载入到运行时常量池 我们都知道，方法区是概念，在 java7 中，方法区的具体实现就是永久代，常量池存在于永久带中，永久带存在于方法区中；而在 java8 中，方法区的具体实现就是元空间，常量池存在于元空间中，虽然元空间独立存在与本地内存，但是也叫方法区的实现，因此从某种意义上讲，常量池也属于方法区，只不过这里单独提出来说明了。 4）方法字节码载入方法区 5）main 线程开始运行，分配栈帧内存 栈帧中有局部变量表和操作数栈 （stack=2，locals=4） 对应操作数栈有2个空间（每个空间4个字节），局部变量表中有4个槽位 6）执行引擎开始执行字节码 bipush 10 将一个 byte 压入操作数栈（操作数栈大小都为 4 字节，其长度会补齐 4 个字节），类似的指令还有 sipush 将一个 short 压入操作数栈（其长度会补齐 4 个字节） ldc 将一个 int 压入操作数栈 ldc2_w 将一个 long 压入操作数栈（分两次压入，因为 long 是 8 个字节） 这里小的数字都是和字节码指令存在一起，超过 short 范围的数字存入了常量池 istore 1 将操作数栈栈顶元素弹出，放入局部变量表的slot 1中 对应代码中的 1a = 10Copy ldc #3 读取运行时常量池中 #3 数据到操作数栈，即32768(超过short最大值范围的数会被放到运行时常量池中)，将其加载到操作数栈中 注意 Short.MAX_VALUE 是 32767，所以 32768 = Short.MAX_VALUE + 1 实际是在编译期间计算好的 istore 2 将操作数栈中的元素弹出，放到局部变量表的2号位置 iload1 iload2 将局部变量表中1号位置和2号位置的元素放入操作数栈中 因为只能在操作数栈中执行运算操作 iadd 将操作数栈中的两个元素弹出栈并相加，结果在压入操作数栈中 istore 3 将操作数栈中的元素弹出，放入局部变量表的3号位置 getstatic #4 在运行时常量池中找到#4，发现是一个对象，它存在于堆内存中 在堆内存中找到该对象，并将其引用放入操作数栈中 iload 3 将局部变量表中3号位置的元素压入操作数栈中 invokevirtual 5 找到常量池 #5 项 定位到方法区 java/io/PrintStream.println:(I)V 方法 生成新的栈帧（分配 locals、stack等） 传递参数，执行新栈帧中的字节码 执行完毕，弹出栈帧 清除 main 操作数栈内容 return完成 main 方法调用，弹出 main 栈帧，程序结束 练习： 1234567891011/** * 从字节码角度分析 a++ 相关题目 */public class Demo3_1 { public static void main(String[] args) { int a = 10; int b = a++ + ++a + a--; System.out.println(a);// 11 System.out.println(b);// 34 }} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778Classfile /home/chanservy/idea/projects/concurrent/src/main/java/com/chan/jvm/Demo3_1.class Last modified 2021-10-27; size 434 bytes MD5 checksum fd4b0448bd8dd4239c5e5119332ffe79 Compiled from &quot;Demo3_1.java&quot;public class com.chan.jvm.Demo3_1 minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #5.#14 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Fieldref #15.#16 // java/lang/System.out:Ljava/io/PrintStream; #3 = Methodref #17.#18 // java/io/PrintStream.println:(I)V #4 = Class #19 // com/chan/jvm/Demo3_1 #5 = Class #20 // java/lang/Object #6 = Utf8 &lt;init&gt; #7 = Utf8 ()V #8 = Utf8 Code #9 = Utf8 LineNumberTable #10 = Utf8 main #11 = Utf8 ([Ljava/lang/String;)V #12 = Utf8 SourceFile #13 = Utf8 Demo3_1.java #14 = NameAndType #6:#7 // &quot;&lt;init&gt;&quot;:()V #15 = Class #21 // java/lang/System #16 = NameAndType #22:#23 // out:Ljava/io/PrintStream; #17 = Class #24 // java/io/PrintStream #18 = NameAndType #25:#26 // println:(I)V #19 = Utf8 com/chan/jvm/Demo3_1 #20 = Utf8 java/lang/Object #21 = Utf8 java/lang/System #22 = Utf8 out #23 = Utf8 Ljava/io/PrintStream; #24 = Utf8 java/io/PrintStream #25 = Utf8 println #26 = Utf8 (I)V{ public com.chan.jvm.Demo3_1(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 3: 0 public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=3, args_size=1 0: bipush 10 2: istore_1 3: iload_1 4: iinc 1, 1 7: iinc 1, 1 10: iload_1 11: iadd 12: iload_1 13: iinc 1, -1 16: iadd 17: istore_2 18: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 21: iload_1 22: invokevirtual #3 // Method java/io/PrintStream.println:(I)V 25: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 28: iload_2 29: invokevirtual #3 // Method java/io/PrintStream.println:(I)V 32: return LineNumberTable: line 5: 0 line 6: 3 line 7: 18 line 8: 25 line 9: 32}SourceFile: &quot;Demo3_1.java&quot; 分析： 注意 iinc 指令是直接在局部变量表 slot 上进行运算 a++ 和 ++a 的区别是先执行 iload 还是先执行 iinc 通过字节码指令来分析问题代码 12345678910111213141516public class Demo2 { public static void main(String[] args) { // 0号槽位放的是args int i=0;// 局部变量表1号槽位 int x=0;// 局部变量表2号槽位 while(i&lt;10) { // 这里的 x++,是先 iload x,结果就是把局部变量表中的0读进操作数栈 // 后 iinc x 1:注意这里是将局部变量表中 x 槽位的值 +1 // 这里的++操作的是局部变量表中的值 // 赋值操作“=” 是将操作数栈中的值弹出赋值到x x = x++; i++; } System.out.println(x); //结果为0 }} 为什么最终的x结果为0呢？ 其实不管循环多少次，最终 x 的结果都是 0。通过分析字节码指令即可知晓： 123456789101112131415161718Code: stack=2, locals=3, args_size=1 //操作数栈分配2个空间，局部变量表分配3个空间 0: iconst_0 //准备一个常数0 1: istore_1 //将常数0放入局部变量表的1号槽位 i=0 2: iconst_0 //准备一个常数0 3: istore_2 //将常数0放入局部变量的2号槽位 x=0 4: iload_1 //将局部变量表1号槽位的数放入操作数栈中 5: bipush 10 //将数字10放入操作数栈中，此时操作数栈中有2个数 7: if_icmpge 21 //比较操作数栈中的两个数，如果下面的数大于上面的数，就跳转到21。这里的比较是将两个数做减法。因为涉及运算操作，所以会将两个数弹出操作数栈来进行运算。运算结束后操作数栈为空 10: iload_2 //将局部变量2号槽位的数放入操作数栈中，放入的值是0 11: iinc 2, 1 //将局部变量2号槽位的数加1，自增后，槽位中的值为1 14: istore_2 //将操作数栈中的数放入到局部变量表的2号槽位，2号槽位的值又变为了0 15: iinc 1, 1 //1号槽位的值自增1 18: goto 4 //跳转到第4条指令 21: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 24: iload_2 25: invokevirtual #3 // Method java/io/PrintStream.println:(I)V 28: return 构造方法cinit()V123456789101112131415public class Demo3 { static int i = 10; static { i = 20; } static { i = 30; } public static void main(String[] args) { System.out.println(i); //结果为30 }} 编译器会按从上至下的顺序，收集所有 static 静态代码块和静态成员赋值的代码，合并为一个特殊的方法 cinit()V ： 12345678stack=1, locals=0, args_size=0 0: bipush 10 2: putstatic #3 // Field i:I 5: bipush 20 7: putstatic #3 // Field i:I 10: bipush 30 12: putstatic #3 // Field i:I 15: return init()V123456789101112131415161718192021222324public class Demo4 { private String a = &quot;s1&quot;; { b = 20; } private int b = 10; { a = &quot;s2&quot;; } public Demo4(String a, int b) { this.a = a; this.b = b; } public static void main(String[] args) { Demo4 d = new Demo4(&quot;s3&quot;, 30); System.out.println(d.a); System.out.println(d.b); }} 编译器会按从上至下的顺序，收集所有 {} 代码块和成员变量赋值的代码，形成新的构造方法，但原始构造方法内的代码总是在后 123456789101112131415161718192021222324Code: stack=2, locals=3, args_size=3 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: aload_0 5: ldc #2 // String s1 7: putfield #3 // Field a:Ljava/lang/String; 10: aload_0 11: bipush 20 13: putfield #4 // Field b:I 16: aload_0 17: bipush 10 19: putfield #4 // Field b:I 22: aload_0 23: ldc #5 // String s2 25: putfield #3 // Field a:Ljava/lang/String; //原始构造方法在最后执行 28: aload_0 29: aload_1 30: putfield #3 // Field a:Ljava/lang/String; 33: aload_0 34: iload_2 35: putfield #4 // Field b:I 38: return 静态代码块 &gt; 普通代码块 &gt; 构造方法，初始化。 总结：从字节码层面分析，编译器会按照从上至下的顺序，收集所有初始化代码块和成员变量赋值的代码，最后合并成一个新的构造方法。原始的构造方法里的代码也会附加到新的构造方法中，不过是放在最后的位置。 方法调用1234567891011121314151617181920212223242526272829public class Demo5 { public Demo5() { } private void test1() { } private final void test2() { } public void test3() { } public static void test4() { } public static void main(String[] args) { Demo5 demo5 = new Demo5(); demo5.test1(); demo5.test2(); demo5.test3(); Demo5.test4(); }} 不同方法在调用时，对应的虚拟机指令有所区别 私有、构造、被final修饰的方法，在调用时都使用invokespecial指令 普通成员方法在调用时，使用invokespecial指令。因为编译期间无法确定该方法的内容，只有在运行期间才能确定 静态方法在调用时使用invokestatic指令 1234567891011121314Code: stack=2, locals=2, args_size=1 0: new #2 // class com/nyima/JVM/day5/Demo5 3: dup 4: invokespecial #3 // Method &quot;&lt;init&gt;&quot;:()V 7: astore_1 8: aload_1 9: invokespecial #4 // Method test1:()V 12: aload_1 13: invokespecial #5 // Method test2:()V 16: aload_1 17: invokevirtual #6 // Method test3:()V 20: invokestatic #7 // Method test4:()V 23: returnCopy new 是创建【对象】，给对象分配堆内存，执行成功会将【对象引用】压入操作数栈 dup 是赋值操作数栈栈顶的内容，本例即为【对象引用】，为什么需要两份引用呢，一个是要配合 invokespecial 调用该对象的构造方法 “init”:()V （会消耗掉栈顶一个引用），另一个要 配合 astore_1 赋值给局部变量 终方法（ﬁnal），私有方法（private），构造方法都是由 invokespecial 指令来调用，属于静态绑定 普通成员方法是由 invokevirtual 调用，属于动态绑定，即支持多态 成员方法与静态方法调用的另一个区别是，执行方法前是否需要【对象引用】 多态原理因为普通成员方法需要在运行时才能确定具体的内容，所以虚拟机需要调用invokevirtual指令 在执行invokevirtual指令时，经历了以下几个步骤 先通过栈帧中对象的引用找到对象 分析对象头，找到对象实际的Class Class结构中有vtable 查询vtable找到方法的具体地址 执行方法的字节码 异常处理try-catch12345678910public class Demo1 { public static void main(String[] args) { int i = 0; try { i = 10; }catch (Exception e) { i = 20; } }} 对应字节码指令 123456789101112131415Code: stack=1, locals=3, args_size=1 0: iconst_0 1: istore_1 2: bipush 10 4: istore_1 5: goto 12 8: astore_2 9: bipush 20 11: istore_1 12: return //多出来一个异常表 Exception table: from to target type 2 5 8 Class java/lang/Exception 可以看到多出来一个 Exception table 的结构，[from, to) 是前闭后开（也就是检测2~4行）的检测范围，一旦这个范围内的字节码执行出现异常，则通过 type 匹配异常类型，如果一致，进入 target 所指示行号 8行的字节码指令 astore_2 是将异常对象引用存入局部变量表的2号位置（为e） 多个single-catch123456789101112public class Demo1 { public static void main(String[] args) { int i = 0; try { i = 10; }catch (ArithmeticException e) { i = 20; }catch (Exception e) { i = 30; } }} 对应的字节码 12345678910111213141516171819Code: stack=1, locals=3, args_size=1 0: iconst_0 1: istore_1 2: bipush 10 4: istore_1 5: goto 19 8: astore_2 9: bipush 20 11: istore_1 12: goto 19 15: astore_2 16: bipush 30 18: istore_1 19: return Exception table: from to target type 2 5 8 Class java/lang/ArithmeticException 2 5 15 Class java/lang/Exception 因为异常出现时，只能进入 Exception table 中一个分支，所以局部变量表 slot 2 位置被共用 finally123456789101112public class Demo2 { public static void main(String[] args) { int i = 0; try { i = 10; } catch (Exception e) { i = 20; } finally { i = 30; } }} 对应字节码 12345678910111213141516171819202122232425262728293031Code: stack=1, locals=4, args_size=1 0: iconst_0 1: istore_1 //try块 2: bipush 10 4: istore_1 //try块执行完后，会执行finally 5: bipush 30 7: istore_1 8: goto 27 //catch块 11: astore_2 //异常信息放入局部变量表的2号槽位 12: bipush 20 14: istore_1 //catch块执行完后，会执行finally 15: bipush 30 17: istore_1 18: goto 27 //出现异常，但未被Exception捕获，会抛出其他异常，这时也需要执行finally块中的代码 21: astore_3 22: bipush 30 24: istore_1 25: aload_3 26: athrow //抛出异常 27: return Exception table: from to target type 2 5 11 Class java/lang/Exception 2 5 21 any 11 15 21 any 可以看到 ﬁnally 中的代码被复制了 3 份，分别放入 try 流程，catch 流程以及 catch剩余的异常类型流程 所以在字节码层面，finally 块中的代码会复制一式三份，会被复制到 try 分支的末尾；会被复制到 catch 分支的末尾；会被复制到 catch 分支未捕获到的异常分支的末尾。 注意：虽然从字节码指令看来，每个块中都有finally块，但是finally块中的代码只会被执行一次 finally中的return123456789101112131415161718public class Demo3 { public static void main(String[] args) { int i = Demo3.test(); //结果为20 System.out.println(i); } public static int test() { int i; try { i = 10; return i; } finally { i = 20; return i; } }} 对应字节码 12345678910111213141516171819Code: stack=1, locals=3, args_size=0 0: bipush 10 2: istore_0 3: iload_0 4: istore_1 //暂存返回值 5: bipush 20 7: istore_0 8: iload_0 9: ireturn //ireturn会返回操作数栈顶的整型值20 //如果出现异常，还是会执行finally块中的内容，没有抛出异常 10: astore_2 11: bipush 20 13: istore_0 14: iload_0 15: ireturn //这里没有athrow了，也就是如果在finally块中如果有返回操作的话，且try块中出现异常，会吞掉异常！ Exception table: from to target type 0 5 10 any 由于 ﬁnally 中的 ireturn 被插入了所有可能的流程，因此返回结果肯定以ﬁnally的为准 至于字节码中第 2 行，似乎没啥用，且留个伏笔，看下个例子 跟上例中的 ﬁnally 相比，发现没有 athrow 了，这告诉我们：如果在 ﬁnally 中出现了 return，会吞掉异常 所以不要在finally中进行返回操作 被吞掉的异常1234567891011121314151617181920public class Demo3 { public static void main(String[] args) { int i = Demo3.test(); //最终结果为20 System.out.println(i); } public static int test() { int i; try { i = 10; //这里应该会抛出异常 i = i/0; return i; } finally { i = 20; return i; } }} 会发现打印结果为20，并未抛出异常 finally不带return12345678910111213141516public class Demo4 { public static void main(String[] args) { int i = Demo4.test(); System.out.println(i); } public static int test() { int i = 10; try { return i; } finally { i = 20; } }}// 结果为 10 返回的结果一定是 10，因为 finally 块中的代码会复制到 try 块的末尾，也就是 return i 的后面，那 i 的值已经返回了 10，因此 finally 中无论对 i 如何赋值返回的结果都是 10。finally 块中不要写 return 返回操作，否则会捕获不到异常。 对应字节码 123456789101112131415161718Code: stack=1, locals=3, args_size=0 0: bipush 10 2: istore_0 //赋值给i 10 3: iload_0 //加载到操作数栈顶 4: istore_1 //加载到局部变量表的1号位置 5: bipush 20 7: istore_0 //赋值给i 20 8: iload_1 //加载局部变量表1号位置的数10到操作数栈 9: ireturn //返回操作数栈顶元素 10 10: astore_2 11: bipush 20 13: istore_0 14: aload_2 //加载异常 15: athrow //抛出异常 Exception table: from to target type 3 5 10 any Synchronized1234567891011public class Demo5 { public static void main(String[] args) { int i = 10; Lock lock = new Lock(); synchronized (lock) { System.out.println(i); } }}class Lock{} 对应字节码 1234567891011121314151617181920212223242526272829303132Code: stack=2, locals=5, args_size=1 0: bipush 10 2: istore_1 3: new #2 // class com/nyima/JVM/day06/Lock 6: dup //复制一份，放到操作数栈顶，用于构造函数消耗 7: invokespecial #3 // Method com/nyima/JVM/day06/Lock.&quot;&lt;init&gt;&quot;:()V 10: astore_2 //剩下的一份放到局部变量表的2号位置 11: aload_2 //加载到操作数栈 12: dup //复制一份，放到操作数栈，用于加锁时消耗 13: astore_3 //将操作数栈顶元素弹出，暂存到局部变量表的三号槽位。这时操作数栈中有一份对象的引用 14: monitorenter //加锁 //锁住后代码块中的操作 15: getstatic #4 // Field java/lang/System.out:Ljava/io/PrintStream; 18: iload_1 19: invokevirtual #5 // Method java/io/PrintStream.println:(I)V //加载局部变量表中三号槽位对象的引用，用于解锁 22: aload_3 23: monitorexit //解锁 24: goto 34 //异常操作 27: astore 4 29: aload_3 30: monitorexit //解锁 31: aload 4 33: athrow 34: return //可以看出，无论何时出现异常，都会跳转到27行，将异常放入局部变量中，并进行解锁操作，然后加载异常并抛出异常。 Exception table: from to target type 15 24 27 any 27 31 27 any 编译期处理所谓的 语法糖 ，其实就是指 java 编译器把 *.java 源码编译为 *.class 字节码的过程中，自动生成和转换的一些代码，主要是为了减轻程序员的负担，算是 java 编译器给我们的一个额外福利 注意，以下代码的分析，借助了 javap 工具，idea 的反编译功能，idea 插件 jclasslib 等工具。另外， 编译器转换的结果直接就是 class 字节码，只是为了便于阅读，给出了 几乎等价 的 java 源码方式，并不是编译器还会转换出中间的 java 源码，切记。 默认构造函数123public class Candy1 {} 经过编译期优化后 1234567public class Candy1 { //这个无参构造器是java编译器帮我们加上的 public Candy1() { //即调用父类 Object 的无参构造方法，即调用 java/lang/Object.&quot; &lt;init&gt;&quot;:()V super(); }} 语法糖一：当自己的类没有实现任何构造器的情况下，编译器会帮我们默认实现一个无参构造，也就是调用父类 Object 的无参构造 super()。 自动拆装箱基本类型和其包装类型的相互转换过程，称为拆装箱 在JDK 5以后，它们的转换可以在编译期自动完成 123456public class Demo2 { public static void main(String[] args) { Integer x = 1; int y = x; }} 转换过程如下 12345678public class Demo2 { public static void main(String[] args) { //基本类型赋值给包装类型，称为装箱 Integer x = Integer.valueOf(1); //包装类型赋值给基本类型，称谓拆箱 int y = x.intValue(); }} 泛型集合取值泛型也是在 JDK 5 开始加入的特性，但 java 在编译泛型代码后会执行 泛型擦除 的动作，即泛型信息在编译为字节码之后就丢失了，实际的类型都当做了 Object 类型来处理： 1234567public class Demo3 { public static void main(String[] args) { List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); list.add(10);// 实际调用的是 List.add(Object e) Integer x = list.get(0);// 实际调用的是 Object obj = List.get(int index); }} 所以调用get函数取值时，编译器真正生成的字节码中，还要额外做一个类型转换的操作： 12// 需要将 Object 转为 IntegerInteger x = (Integer) list.get(0); 如果要将返回结果赋值给一个int类型的变量，则还有自动拆箱的操作 12// 需要将 Object 转为 Integer, 并执行拆箱操作int x = ((Integer)list.get(0)).intValue(); 还好这些麻烦事都不用自己做。 擦除的是字节码上的泛型信息，可以看到 LocalVariableTypeTable 仍然保留了方法参数泛型的信息 对应字节码 1234567891011121314151617181920Code: stack=2, locals=3, args_size=1 0: new #2 // class java/util/ArrayList 3: dup 4: invokespecial #3 // Method java/util/ArrayList.&quot;&lt;init&gt;&quot;:()V 7: astore_1 8: aload_1 9: bipush 10 11: invokestatic #4 // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer; //这里进行了泛型擦除，实际调用的是add(Objcet o) 14: invokeinterface #5, 2 // InterfaceMethod java/util/List.add:(Ljava/lang/Object;)Z 19: pop 20: aload_1 21: iconst_0 22: invokeinterface #6, 2 // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;//这里进行了类型转换，将Object转换成了Integer 27: checkcast #7 // class java/lang/Integer 30: astore_2 31: returnCopy 可变参数1234567891011public class Demo4 { public static void foo(String... args) { //将args赋值给arr，可以看出String...实际就是String[] String[] arr = args; System.out.println(arr.length); } public static void main(String[] args) { foo(&quot;hello&quot;, &quot;world&quot;); }} 可变参数 String… args 其实是一个 String[] args ，从代码中的赋值语句中就可以看出来。 同 样 java 编译器会在编译期间将上述代码变换为： 12345678910111213public class Demo4 { public Demo4 {} public static void foo(String[] args) { String[] arr = args; System.out.println(arr.length); } public static void main(String[] args) { foo(new String[]{&quot;hello&quot;, &quot;world&quot;}); }} 注意，如果调用的是foo()，即未传递参数时，等价代码为foo(new String[]{})，创建了一个空数组，而不是直接传递的null foreach123456789public class Demo5 { public static void main(String[] args) { //数组赋初值的简化写法也是一种语法糖。 int[] arr = {1, 2, 3, 4, 5}; for(int x : arr) { System.out.println(x); } }} 编译器会帮我们转换为 1234567891011public class Demo5 { public Demo5 {} public static void main(String[] args) { int[] arr = new int[]{1, 2, 3, 4, 5}; for(int i=0; i&lt;arr.length; ++i) { int x = arr[i]; System.out.println(x); } }} 如果是集合使用foreach 12345678public class Demo5 { public static void main(String[] args) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5); for (Integer x : list) { System.out.println(x); } }} 集合要使用foreach，需要该集合类实现了Iterable接口，因为集合的遍历需要用到迭代器Iterator 12345678910111213public class Demo5 { public Demo5 {} public static void main(String[] args) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5); //获得该集合的迭代器 Iterator&lt;Integer&gt; iterator = list.iterator(); while(iterator.hasNext()) { Integer x = iterator.next(); System.out.println(x); } }} switch字符串123456789101112131415public class Demo6 { public static void main(String[] args) { String str = &quot;hello&quot;; switch (str) { case &quot;hello&quot; : System.out.println(&quot;h&quot;); break; case &quot;world&quot; : System.out.println(&quot;w&quot;); break; default: break; } }} 在编译器中执行的操作 123456789101112131415161718192021222324252627282930313233343536373839public class Demo6 { public Demo6() { } public static void main(String[] args) { String str = &quot;hello&quot;; int x = -1; //通过字符串的hashCode+value来判断是否匹配 switch (str.hashCode()) { //hello的hashCode case 99162322 : //再次比较，因为字符串的hashCode有可能相等 if(str.equals(&quot;hello&quot;)) { x = 0; } break; //world的hashCode case 11331880 : if(str.equals(&quot;world&quot;)) { x = 1; } break; default: break; } //用第二个switch在进行输出判断 switch (x) { case 0: System.out.println(&quot;h&quot;); break; case 1: System.out.println(&quot;w&quot;); break; default: break; } }} 过程说明： 在编译期间，单个的switch被分为了两个 第一个用来匹配字符串，并给x赋值 字符串的匹配用到了字符串的hashCode，还用到了equals方法 使用hashCode是为了提高比较效率，使用equals是防止有hashCode冲突（如BM和C.） 第二个用来根据x的值来决定输出语句 switch枚举12345678910111213141516171819public class Demo7 { public static void main(String[] args) { SEX sex = SEX.MALE; switch (sex) { case MALE: System.out.println(&quot;man&quot;); break; case FEMALE: System.out.println(&quot;woman&quot;); break; default: break; } }}enum SEX { MALE, FEMALE;} 编译器中执行的代码如下 12345678910111213141516171819202122232425262728293031323334353637public class Demo7 { /** * 定义一个合成类（仅 jvm 使用，对我们不可见） * 用来映射枚举的 ordinal 与数组元素的关系 * 枚举的 ordinal 表示枚举对象的序号，从 0 开始 * 即 MALE 的 ordinal()=0，FEMALE 的 ordinal()=1 */ static class $MAP { //数组大小即为枚举元素个数，里面存放了case用于比较的数字 static int[] map = new int[2]; static { //ordinal即枚举元素对应所在的位置，MALE为0，FEMALE为1 map[SEX.MALE.ordinal()] = 1; map[SEX.FEMALE.ordinal()] = 2; } } public static void main(String[] args) { SEX sex = SEX.MALE; //将对应位置枚举元素的值赋给x，用于case操作 int x = $MAP.map[sex.ordinal()]; switch (x) { case 1: System.out.println(&quot;man&quot;); break; case 2: System.out.println(&quot;woman&quot;); break; default: break; } }}enum SEX { MALE, FEMALE;} 枚举类123enum SEX { MALE, FEMALE;} 转换后的代码 1234567891011121314151617181920212223242526public final class Sex extends Enum&lt;Sex&gt; { //对应枚举类中的元素 public static final Sex MALE; public static final Sex FEMALE; private static final Sex[] $VALUES; static { //调用构造函数，传入枚举元素的值及ordinal MALE = new Sex(&quot;MALE&quot;, 0); FEMALE = new Sex(&quot;FEMALE&quot;, 1); $VALUES = new Sex[]{MALE, FEMALE}; } //调用父类中的方法 private Sex(String name, int ordinal) { super(name, ordinal); } public static Sex[] values() { return $VALUES.clone(); } public static Sex valueOf(String name) { return Enum.valueOf(Sex.class, name); } } 匿名内部类12345678910blic class Candy11 { public static void main(String[] args) { Runnable runnable = new Runnable() { @Override public void run() { System.out.println(&quot;ok&quot;); } }; }} 转换后的代码 1234567891011121314// 额外生成的类final class Candy11$1 implements Runnable { Candy11$1() { } public void run() { System.out.println(&quot;ok&quot;); }}public class Candy11 { public static void main(String[] args) { Runnable runnable = new Candy11$1(); }} 引用局部变量的匿名内部类，源代码： 12345678910public class Candy11 { public static void test(final int x) { Runnable runnable = new Runnable() { @Override public void run() { System.out.println(&quot;ok:&quot; + x); } }; }} 转化后代码 12345678910111213141516// 额外生成的类final class Candy11$1 implements Runnable { int val$x; Candy11$1(int x) { this.val$x = x; } public void run() { System.out.println(&quot;ok:&quot; + this.val$x); }}public class Candy11 { public static void test(final int x) { Runnable runnable = new Candy11$1(x); }} 注意：这同时解释了为什么匿名内部类引用局部变量时，局部变量必须是 final 的：因为在创建 Candy11$1 对象时，将 x 的值赋值给了 Candy11$1 对象的 val，如果不是 final 的话，那么可能局部变量发生变化，但是 Candy11$1 对象的 val$x 没办法随着变化，不一致会出现问题。我感觉这点和 lambda 中用的参数不能是一个变量是一个道理。 try-with-resourcesJDK 7 开始新增了对需要关闭的资源处理的特殊语法 try-with-resources：它的主要作用就是帮助简化资源关闭的，原来写一个资源关闭的代码都需要自己写一个 finally 块来确保资源一定会关闭，在 JDK7 和之后的版本中，有了 try-with-resources，就不用那么麻烦了。只需要按照它的语法格式（如下代码块）去创建资源对象，可以省略 finally 的书写。 格式： 12345try(资源变量 = 创建资源对象){ } catch( ) { } 但是这个简化，有个前提，就是我们的这个资源对象必须要实现一个叫 AutoCloseable 的接口。例如 InputStream、OutputStream、Connection、Statement 、 ResultSet 等接口都实现了 AutoCloseable，使用 try-with-resources 的格式创建它们的资源对象就可以不用写 finally 语句块，编译器会帮助生成关闭资源代码，例如： 123456789public class Candy9 { public static void main(String[] args) { try(InputStream is = new FileInputStream(&quot;d:\\\\1.txt&quot;)) { System.out.println(is); } catch (IOException e) { e.printStackTrace(); } }} 会被转换为： 1234567891011121314151617181920212223242526272829303132333435public class Candy9 { public Candy9() { } public static void main(String[] args) { try { InputStream is = new FileInputStream(&quot;d:\\\\1.txt&quot;); Throwable t = null; try { System.out.println(is); } catch (Throwable e1) { // t 是我们代码出现的异常 t = e1; throw e1; } finally { // 判断了资源不为空 if (is != null) { // 如果我们代码有异常 if (t != null) { try { is.close(); } catch (Throwable e2) { // 如果 close 出现异常，作为被压制异常添加 t.addSuppressed(e2); } } else { // 如果我们代码没有异常，close 出现的异常就是最后 catch 块中的 e is.close(); } } } } catch (IOException e) { e.printStackTrace(); } }} 为什么要设计一个 addSuppressed(Throwable e) （添加被压制异常）的方法呢？是为了防止异常信息的丢失！这个方法也是 JDK7 中新的方法，为了在释放资源的时候，希望 try 块中我们自己写的代码的异常和关闭资源的异常都保留下来，不要丢失掉。（代码中出现的异常、关闭资源出现的异常全部都捕获到。） 想想 try-with-resources 生成的 fianlly 中如果抛出了异常： 1234567891011121314public class Test6 { public static void main(String[] args) { try (MyResource resource = new MyResource()) { int i = 1/0; } catch (Exception e) { e.printStackTrace(); } }}class MyResource implements AutoCloseable { public void close() throws Exception { throw new Exception(&quot;close 异常&quot;); }} 输出： 12345java.lang.ArithmeticException: / by zeroat test.Test6.main(Test6.java:7)Suppressed: java.lang.Exception: close 异常at test.MyResource.close(Test6.java:18)at test.Test6.main(Test6.java:6) 方法重写时的桥接方法我们都知道，方法重写时对返回值分两种情况： 父子类的返回值完全一致 子类返回值可以是父类返回值的子类（比较绕口，见下面的例子） 123456789101112class A { public Number m() { return 1; }}class B extends A { @Override // 子类 m 方法的返回值是 Integer 是父类 m 方法返回值 Number 的子类 public Integer m() { return 2; }} 对于子类，java 编译器会做如下处理： 12345678910class B extends A { public Integer m() { return 2; } // 此方法才是真正重写了父类 public Number m() 方法 public synthetic bridge Number m() { // 调用 public Integer m() return m(); }} 其中桥接方法比较特殊，仅对 java 虚拟机可见，并且与原来的 public Integer m() 没有命名冲突，可以用下面反射代码来验证： 123for (Method m : B.class.getDeclaredMethods()) { System.out.println(m);} 会输出： 12public java.lang.Integer test.candy.B.m()public java.lang.Number test.candy.B.m() 类加载阶段java类的生命周期： 指一个class文件从加载到卸载的全过程，类的完整生命周期包括7个部分：加载——验证——准备——解析——初始化——使用——卸载，如下图所示： 其中，验证——准备——解析 称为连接阶段，除了解析外，其他阶段是顺序发生的，而解析可以与这些阶段交叉进行，因为Java支持动态绑定（晚期绑定），需要运行时才能确定具体类型；在使用阶段实例化对象。 类的初始化： 是完成程序执行的准备工作。在这个阶段，静态的（变量，方法，代码块）会被执行。同时在会开辟一块存储空间用来存放静态的数据。初始化只在类加载的时候执行一次 类的实例化（实例化对象）： 是指创建（new）一个对象的过程。这个过程中会在堆中开辟内存，将一些非静态的 new 出的对象存放在里面。在程序执行的过程中，可以创建多个对象，既多次实例化。每次实例化都会开辟一块新的内存。（就是调用构造函数） 在每个类初始化使用前，都会先对该类进行加载。 类加载有几个步骤，加载 -&gt; 链接-验证 -&gt; 链接-准备 -&gt; 链接-解析 -&gt; 初始化 在编译过程会把常量的值放入类的常量池中，在准备过程会对类变量（static修饰的变量）赋初始值，也就是零值，同时会将常量的值赋予常量；在初始化过程会按照类文件中的声明顺序执行类变量的赋值和静态语句块（static{}块），如果父类还没有初始化会先进行父类的初始化，完成后才会进行子类的初始化。 可以看到在初始化阶段就会执行 static{} 块的语句，而每一个类在运行过程中一般只会被加载一次，只会完成一次初始化的过程，因此也就只会执行 static{} 块一次。 加载通过类名获取类的二进制字节码，这是通过类加载器来完成的。其加载过程使用“双亲委派模型”。 将类的字节码载入方法区（1.8后为元空间，在本地内存中）中，内部采用 C++ 的 instanceKlass 描述 java 类，它的重要 ﬁeld 有： _java_mirror 即 java 的类镜像，例如对 String 来说，它的镜像类就是 String.class，作用是把 klass 暴露给 java 使用 _super 即父类 _ﬁelds 即成员变量 _methods 即方法 _constants 即常量池 _class_loader 即类加载器 _vtable 虚方法表 _itable 接口方法 如果这个类还有父类没有加载，先加载父类 加载和链接（解析）可能是交替运行的 instanceKlass保存在方法区。JDK 8以后，方法区位于元空间中，而元空间又位于本地内存中 _java_mirror则是保存在堆内存中 InstanceKlass和*.class(JAVA镜像类)互相保存了对方的地址 类的对象在对象头中保存了*.class的地址。让对象可以通过其找到方法区中的instanceKlass，从而获取类的各种信息 链接验证当一个类被加载之后，必须要验证一下这个类是否合法，验证类是否符合 JVM规范，安全性检查，比如这个类是不是符合字节码的格式、变量与方法是不是有重复、数据类型是不是有效、继承与实现是否合乎标准等等。总之，这个阶段的目的就是保证加载的类是能够被 jvm 所运行。 准备为类变量（静态变量）在方法区分配内存，并设置零值。注意：这里是类变量，不是实例变量，实例变量是对象分配到堆内存时根据运行时动态生成的。 为 static 变量分配空间，设置默认值 static变量在JDK 7以前是存储与instanceKlass末尾。但在JDK 7以后就存储在_java_mirror末尾了 static变量在分配空间和赋值是在两个阶段完成的。分配空间在准备阶段完成，赋值在初始化阶段完成 如果 static 变量是 ﬁnal 的基本类型，以及字符串常量，那么编译阶段值就确定了，就是说赋值在准备阶段完成 如果 static 变量是 ﬁnal 的，但属于引用类型，那么赋值也会在初始化阶段完成 解析把常量池中的符号引用解析为直接引用：根据符号引用所作的描述，在内存中找到符合描述的目标并把目标指针指针返回。因为仅仅是符号的话，并不知道类、方法、属性到底在内存的何处，解析之后就知道它们在内存中的位置了。 HSDB的使用 先获得要查看的进程ID 1jps 打开HSDB 1java -cp F:\\JAVA\\JDK8.0\\lib\\sa-jdi.jar sun.jvm.hotspot.HSDB 运行时可能会报错，是因为缺少一个.dll的文件，我们在JDK的安装目录中找到该文件，复制到缺失的文件下即可 定位需要的进程 解析的含义 将常量池中的符号引用解析为直接引用 未解析时，常量池中的看到的对象仅是符号，未真正的存在于内存中 1234567891011121314151617public class Demo1 { public static void main(String[] args) throws IOException, ClassNotFoundException { ClassLoader loader = Demo1.class.getClassLoader(); //只加载不解析 Class&lt;?&gt; c = loader.loadClass(&quot;com.nyima.JVM.day8.C&quot;); //用于阻塞主线程 System.in.read(); }}class C { D d = new D();}class D {} 打开HSDB 可以看到此时只加载了类C 查看类C的常量池，可以看到类D未被解析，只是存在于常量池中的符号 解析以后，会将常量池中的符号引用解析为直接引用 可以看到，此时已加载并解析了类C和类D 初始化类的初始化过程是这样的：按照顺序自上而下运行类中的变量赋值语句和静态语句，如果有父类，则首先按照顺序运行父类中的变量赋值语句和静态语句。在类的初始化阶段，只会初始化与类相关的静态赋值语句和静态语句，也就是有static关键字修饰的信息，而没有static修饰的赋值语句和执行语句在实例化对象的时候才会运行。执行类构造器clinit()方法的过程，虚拟机会保证这个类的『构造方法』的线程安全（clinit是class initialize的简写） clinit()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{}块）中的语句合并产生的 实例化：在堆区分配内存空间，执行实例对象初始化，设置引用变量a指向刚分配的内存地址 注意 编译器收集的顺序是由语句在源文件中出现的顺序决定的，静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句块可以赋值，但是不能访问，如 发生时机类的初始化的懒惰的，以下情况会初始化 main 方法所在的类，总会被首先初始化 首次访问这个类的静态变量或静态方法时 子类初始化，如果父类还没初始化，会引发 子类访问父类的静态变量，只会触发父类的初始化 Class.forName new 会导致初始化 以下情况不会初始化 访问类的 static ﬁnal 静态常量（基本类型和字符串） 类对象.class 不会触发初始化 创建该类对象的数组 类加载器的.loadClass方法 Class.forNamed的参数2为false时 验证类是否被初始化，可以看改类的静态代码块是否被执行 类加载器Java虚拟机设计团队有意把类加载阶段中的“通过一个类的全限定名来获取描述该类的二进制字节流”这个动作放到Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需的类。实现这个动作的代码被称为“类加载器”（ClassLoader） 以JDK 8为例 名称 加载的类 说明 Bootstrap ClassLoader（启动类加载器） JAVA_HOME/jre/lib 无法直接访问 Extension ClassLoader(拓展类加载器) JAVA_HOME/jre/lib/ext 上级为Bootstrap，显示为null Application ClassLoader(应用程序类加载器) classpath 上级为Extension 自定义类加载器 自定义 上级为Application 注：下面的描述中将 Bootstrap ClassLoader 简写为 B，Extension ClassLoader 简写为 E，Application ClassLoader 简写为 A。 它们几个实际上是有层级关系的。并且它们各司其职。B 只负责加载 JAVA_HOME/jre/lib 目录下的所有的类，不在这个目录下的类它不闻不问。同理 E 只加载 JAVA_HOME/jre/lib/ext ，A 只加载 classpath（类路径下的类，比如我们自定义的类，jdk 中没有的类） 当类加载器加载一个类的时候，首先经过 A ，A 会查找该类是否已经被自己曾经加载过，会有个缓存，如果自己没有加载过，那么 A 就会找到它的上级 E，问 E 是否加载过这个类，这个时候 E 也会查看缓存，看看自己曾经是否加载过这个类，如果 E 也没有加载过，那么 A 会让 E 再去问 B，看 B 有没有加载过这个类，如果 B 也没有加载过这个类，也就是说 A 的两个上级都没有加载过这个类，那么才轮到 A 自己去加载这个类。 比如加载 String 类，先 A ，A没加载过，A 问 E，E 没加载过，E 问 B ，因为 String 类就在 JAVA_HOME/jre/lib 目录下，所以 B 加载了 String 类，A 和 E 就都不用操心了。如果是一个自定义的 Student 类的话，那么问了一圈，最后还是 A 来加载。 可以看出双亲委派模式，就是先从下到上询问，再从上到下加载。 启动类加载器可通过在控制台输入指令，使得类被启动类加器加载 拓展类加载器如果classpath和JAVA_HOME/jre/lib/ext 下有同名类，加载时会使用拓展类加载器加载。当应用程序类加载器发现拓展类加载器已将该同名类加载过了，则不会再次加载 双亲委派模式双亲委派模式，即调用类加载器ClassLoader 的 loadClass 方法时，查找类的规则 loadClass源码 12345678910111213141516171819202122232425262728293031323334353637383940414243protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException{ synchronized (getClassLoadingLock(name)) { // 1.首先查找该类是否已经被当前类加载器加载过了，这里查一个缓存，加载器加载过的类的缓存记录。 Class&lt;?&gt; c = findLoadedClass(name); //如果没有被加载过 if (c == null) { long t0 = System.nanoTime(); try { if (parent != null) { // 2. 有上级的话，委派上级 loadClass c = parent.loadClass(name, false); } else { // 3. 如果没有上级了（到ExtClassLoader了），则委派BootstrapClassLoader，这里解释一下，ExtClassLoader的上级其实是BootstrapClassLoader，但是这显示为null，原因是BootstrapClassLoader底层是c++，不是java，因此java访问不到，所以为null c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader //捕获异常，但不做任何处理 } if (c == null) { // 4. 每一层都找不到，调用 findClass 方法（每个类加载器自己扩展）来加载 //先让拓展类加载器调用findClass方法去找到该类，如果还是没找到，就抛出异常，抛出的异常会在应用类加载器中catch到 //然后让应用类加载器去找classpath我们的类路径下找该类 long t1 = System.nanoTime(); c = findClass(name); // 5.记录时间 sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; }} 例如： 1234567public class Load5_3 { public static void main(String[] args) throws ClassNotFoundException { Class&lt;?&gt; aClass = Load5_3.class.getClassLoader() .loadClass(&quot;cn.itcast.jvm.t3.load.H&quot;); System.out.println(aClass.getClassLoader()); }} 执行流程为： sun.misc.Launcher$AppClassLoader //1 处， 开始查看已加载的类，结果没有 sun.misc.Launcher$AppClassLoader // 2 处，委派上级 sun.misc.Launcher$ExtClassLoader.loadClass() sun.misc.Launcher$ExtClassLoader // 1 处，查看已加载的类，结果没有 sun.misc.Launcher$ExtClassLoader // 3 处，没有上级了，则委派 BootstrapClassLoader 查找 BootstrapClassLoader 是在 JAVA_HOME/jre/lib 下找 H 这个类，显然没有 sun.misc.Launcher$ExtClassLoader // 4 处，调用自己的 findClass 方法，是在 JAVA_HOME/jre/lib/ext 下找 H 这个类，显然没有，回到 sun.misc.Launcher$AppClassLoader 的 // 2 处 继续执行到 sun.misc.Launcher$AppClassLoader // 4 处，调用它自己的 findClass 方法，在 classpath 下查找，找到了 线程上下文类加载器我们在使用 JDBC 时，都需要加载 Driver 驱动，不知道你注意到没有，不写 1Class.forName(&quot;com.mysql.jdbc.Driver&quot;) 也是可以让 com.mysql.jdbc.Driver 正确加载的，你知道是怎么做的吗？ 让我们追踪一下源码： 1234567891011public class DriverManager { // 注册驱动的集合 private final static CopyOnWriteArrayList&lt;DriverInfo&gt; registeredDrivers = new CopyOnWriteArrayList&lt;&gt;(); // 初始化驱动 static { loadInitialDrivers(); println(&quot;JDBC DriverManager initialized&quot;); } ...} 先不看别的，看看 DriverManager 的类加载器： 1System.out.println(DriverManager.class.getClassLoader()); 打印 null，表示它的类加载器是 Bootstrap ClassLoader，会到 JAVA_HOME/jre/lib 下搜索类，但 JAVA_HOME/jre/lib 下显然没有 mysql-connector-java-5.1.47.jar 包，这样问题来了，在 DriverManager 的静态代码块中，怎么能正确加载 com.mysql.jdbc.Driver 呢？ 继续看核心 loadInitialDrivers() 方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445private static void loadInitialDrivers() { String drivers; try { drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() { public String run() { return System.getProperty(&quot;jdbc.drivers&quot;); } }); } catch (Exception ex) { drivers = null; } // 1）使用 ServiceLoader 机制加载驱动，即 SPI AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() { public Void run() { ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); try{ while(driversIterator.hasNext()) { driversIterator.next(); } } catch(Throwable t) { // Do nothing } return null; } }); println(&quot;DriverManager.initialize: jdbc.drivers = &quot; + drivers); // 2）使用 jdbc.drivers 定义的驱动名加载驱动 if (drivers == null || drivers.equals(&quot;&quot;)) { return; } String[] driversList = drivers.split(&quot;:&quot;); println(&quot;number of Drivers:&quot; + driversList.length); for (String aDriver : driversList) { try { println(&quot;DriverManager.Initialize: loading &quot; + aDriver); // 这里的 ClassLoader.getSystemClassLoader() 就是应用程序类加载器 Class.forName(aDriver, true, ClassLoader.getSystemClassLoader()); } catch (Exception ex) { println(&quot;DriverManager.Initialize: load failed: &quot; + ex); } }} 我们看到，loadInitialDrivers() 方法中，实现类加载的方式有两个： 使用 ServiceLoader 机制加载驱动，即 SPI 使用 jdbc.drivers 定义的驱动名加载驱动 先看 2 发现它最后是使用 Class.forName 完成类的加载和初始化， 1Class.forName(aDriver, true, ClassLoader.getSystemClassLoader()); 其中用 ClassLoader.getSystemClassLoader() 就代表关联的是应用程序类加载器来加载，也就是说，JDK 打破了双亲委派模式，其实 JDK 在某些情况下确实需要打破双亲委派模式。因此可以顺利完成类加载。 再看 1 它就是大名鼎鼎的 Service Provider Interface （SPI）使用 ServiceLoader 机制加载驱动，面向接口编程 + 解耦。 SPI 的使用规则：要在 jar 包下建一个 META-INF/services 包，包里新建一个文件，文件的命名就是接口的全限定名，是一个普通的文本文件，文件内部的内容就是这个接口的实现类，只要按照这个约定去设计 jar 包，那么将来我们便可以配合 ServiceLoader 机制，来根据接口找到它的实现类并加以实例化，实现解耦。 约定：在 jar 包的 META-INF/services 包下，以接口全限定名名为文件，文件内容是实现类名称。 这样就可以使用 12345ServiceLoader&lt;接口类型&gt; allImpls = ServiceLoader.load(接口类型.class);Iterator&lt;接口类型&gt; iter = allImpls.iterator();while(iter.hasNext()) { iter.next();} 来得到实现类，体现的是【面向接口编程+解耦】的思想，在下面一些框架中都运用了此思想： JDBC Servlet Spring 容器 Dubbo（但是 Dubbo 中对 SPI 进行了扩展） 接着看 ServiceLoader.load 方法： 123456public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) { // 获取线程上下文类加载器 // 通过如下这种方式获得的加载器称为线程上下文加载器，其实就是每个当前线程的应用程序类加载器A，说到底也是用A实现的类加载 ClassLoader cl = Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl);} 线程上下文类加载器是当前线程使用的类加载器，默认就是应用程序类加载器，它内部又是由 Class.forName 调用了线程上下文类加载器完成类加载，具体代码在 ServiceLoader 的内部类 LazyIterator 中： 123456789101112131415161718192021222324252627private S nextService() { if (!hasNextService()) throw new NoSuchElementException(); String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try { c = Class.forName(cn, false, loader); } catch (ClassNotFoundException x) { fail(service, &quot;Provider &quot; + cn + &quot; not found&quot;); } if (!service.isAssignableFrom(c)) { fail(service, &quot;Provider &quot; + cn + &quot; not a subtype&quot;); } try { S p = service.cast(c.newInstance()); providers.put(cn, p); return p; } catch (Throwable x) { fail(service, &quot;Provider &quot; + cn + &quot; could not be instantiated&quot;, x); } throw new Error(); // This cannot happen} 自定义类加载器使用场景 想加载非 classpath 随意路径中的类文件 通过接口来使用实现，希望解耦时，常用在框架设计 这些类希望予以隔离，不同应用的同名类都可以加载，不冲突，常见于 tomcat 容器 步骤 继承ClassLoader父类 要遵从双亲委派机制，重写 ﬁndClass 方法 不是重写loadClass方法，否则不会走双亲委派机制 读取类文件的字节码 调用父类的 deﬁneClass 方法来加载类 使用者调用该类加载器的 loadClass 方法 破坏双亲委派模式 双亲委派模型的第一次“被破坏”其实发生在双亲委派模型出现之前——即JDK1.2面世以前的“远古”时代 建议用户重写findClass()方法，在类加载器中的loadClass()方法中也会调用该方法 双亲委派模型的第二次“被破坏”是由这个模型自身的缺陷导致的 如果有基础类型又要调用回用户的代码，此时也会破坏双亲委派模式 双亲委派模型的第三次“被破坏”是由于用户对程序动态性的追求而导致的 这里所说的“动态性”指的是一些非常“热”门的名词：代码热替换（Hot Swap）、模块热部署（Hot Deployment）等 运行期优化分层编译JVM 将执行状态分成了 5 个层次： 0层：解释执行，用解释器将字节码翻译为机器码 1层：使用 C1 即时编译器编译执行（不带 proﬁling） 2层：使用 C1 即时编译器编译执行（带基本的profiling） 3层：使用 C1 即时编译器编译执行（带完全的profiling） 4层：使用 C2 即时编译器编译执行 proﬁling 是指在运行过程中收集一些程序执行状态的数据，例如【方法的调用次数】，【循环的回边次数】等。 JVM 将整个字节码执行分为 5 个层次。解释执行：就是字节码被加载到 JVM 后，靠一个解释器一个字节一个字节解释执行。解释器就是会将字节码解释为真正的机器码，从而让 CPU 可以识别并执行。注意，当字节码被反复调用的时候，反复调用达到一定的阈值后，它就会启用即时编译器对字节码进行编译，编译为机器码并存入 Code Cache，下次遇到相同的代码，直接执行，无需再编译，提升效率。 即时编译器（JIT）与解释器的区别 解释器 将字节码解释为机器码，下次即使遇到相同的字节码，仍会执行重复的解释 是将字节码解释为针对所有平台都通用的机器码 即时编译器 将一些字节码编译为机器码，并存入 Code Cache，下次遇到相同的代码，直接执行，无需再编译 根据平台类型，生成平台特定的机器码 对于大部分的不常用的代码，我们无需耗费时间将其编译成机器码，而是采取解释执行的方式运行；另一方面，对于仅占据小部分的热点代码，我们则可以将其编译成机器码，以达到理想的运行速度。 执行效率上简单比较一下 Interpreter &lt; C1 &lt; C2，总的目标是发现热点代码（hotspot名称的由来），并优化这些热点代码。 上面的优化手段 C2 可以称之为【逃逸分析】，发现新建的对象是否逃逸。可以使用 -XX:-DoEscapeAnalysis 关闭逃逸分析。 参考资料 逃逸分析逃逸分析（Escape Analysis）简单来讲就是，Java Hotspot 虚拟机可以分析新创建对象的使用范围，并决定是否在 Java 堆上分配内存的一项技术。 逃逸分析的 JVM 参数如下： 开启逃逸分析：-XX:+DoEscapeAnalysis 关闭逃逸分析：-XX:-DoEscapeAnalysis 显示分析结果：-XX:+PrintEscapeAnalysis 逃逸分析技术在 Java SE 6u23+ 开始支持，并默认设置为启用状态，可以不用额外加这个参数 对象逃逸状态 全局逃逸（GlobalEscape） 即一个对象的作用范围逃出了当前方法或者当前线程，有以下几种场景： 对象是一个静态变量 对象是一个已经发生逃逸的对象 对象作为当前方法的返回值 参数逃逸（ArgEscape） 即一个对象被作为方法参数传递或者被参数引用，但在调用过程中不会发生全局逃逸，这个状态是通过被调方法的字节码确定的 没有逃逸 即方法中的对象没有发生逃逸 逃逸分析优化 针对上面第三点，当一个对象没有逃逸时，可以得到以下几个虚拟机的优化 锁消除 我们知道线程同步锁是非常牺牲性能的，当编译器确定当前对象只有当前线程使用，那么就会移除该对象的同步锁 例如，StringBuffer 和 Vector 都是用 synchronized 修饰线程安全的，但大部分情况下，它们都只是在当前线程中用到，这样编译器就会优化移除掉这些锁操作 锁消除的 JVM 参数如下： 开启锁消除：-XX:+EliminateLocks 关闭锁消除：-XX:-EliminateLocks 锁消除在 JDK8 中都是默认开启的，并且锁消除都要建立在逃逸分析的基础上 标量替换 首先要明白标量和聚合量，基础类型和对象的引用可以理解为标量，它们不能被进一步分解。而能被进一步分解的量就是聚合量，比如：对象 对象是聚合量，它又可以被进一步分解成标量，将其成员变量分解为分散的变量，这就叫做标量替换。 这样，如果一个对象没有发生逃逸，那压根就不用创建它，只会在栈或者寄存器上创建它用到的成员标量，节省了内存空间，也提升了应用程序性能 标量替换的 JVM 参数如下： 开启标量替换：-XX:+EliminateAllocations 关闭标量替换：-XX:-EliminateAllocations 显示标量替换详情：-XX:+PrintEliminateAllocations 标量替换同样在 JDK8 中都是默认开启的，并且都要建立在逃逸分析的基础上 栈上分配 当对象没有发生逃逸时，该对象就可以通过标量替换分解成成员标量分配在栈内存中，和方法的生命周期一致，随着栈帧出栈时销毁，减少了 GC 压力，提高了应用程序性能 方法内联内联函数内联函数就是在程序编译时，编译器将程序中出现的内联函数的调用表达式用内联函数的函数体来直接进行替换 JVM内联函数C++是否为内联函数由自己决定，Java由编译器决定。Java不支持直接声明为内联函数的，如果想让他内联，你只能够向编译器提出请求: 关键字final修饰 用来指明那个函数是希望被JVM内联的，如 123public final void doSomething() { // to do something } 总的来说，一般的函数都不会被当做内联函数，只有声明了final后，编译器才会考虑是不是要把你的函数变成内联函数 JVM内建有许多运行时优化。首先短方法更利于JVM推断。流程更明显，作用域更短，副作用也更明显。如果是长方法JVM可能直接就跪了。 第二个原因则更重要：方法内联 如果JVM监测到一些小方法被频繁的执行，它会把方法的调用替换成方法体本身，如： 12345678private int add4(int x1, int x2, int x3, int x4) { //这里调用了add2方法 return add2(x1, x2) + add2(x3, x4); } private int add2(int x1, int x2) { return x1 + x2; } 方法调用被替换后 1234private int add4(int x1, int x2, int x3, int x4) { //被替换为了方法本身 return x1 + x2 + x3 + x4; } 反射优化123456789101112public class Reflect1 { public static void foo() { System.out.println(&quot;foo...&quot;); } public static void main(String[] args) throws NoSuchMethodException, InvocationTargetException, IllegalAccessException { Method foo = Demo3.class.getMethod(&quot;foo&quot;); for(int i = 0; i&lt;=16; i++) { foo.invoke(null); } }} foo.invoke 前面 0 ~ 15 次调用使用的是 MethodAccessor 的 NativeMethodAccessorImpl 实现 invoke方法源码 123456789101112131415161718@CallerSensitivepublic Object invoke(Object obj, Object... args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException{ if (!override) { if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) { Class&lt;?&gt; caller = Reflection.getCallerClass(); checkAccess(caller, clazz, obj, modifiers); } } //MethodAccessor是一个接口，有3个实现类，其中有一个是抽象类 MethodAccessor ma = methodAccessor; // read volatile if (ma == null) { ma = acquireMethodAccessor(); } return ma.invoke(obj, args);} 会由DelegatingMehodAccessorImpl去调用NativeMethodAccessorImpl NativeMethodAccessorImpl源码 1234567891011121314151617181920212223242526class NativeMethodAccessorImpl extends MethodAccessorImpl { private final Method method; private DelegatingMethodAccessorImpl parent; private int numInvocations; NativeMethodAccessorImpl(Method var1) { this.method = var1; } //每次进行反射调用，会让numInvocation与ReflectionFactory.inflationThreshold的值（15）进行比较，并使使得numInvocation的值加一 //如果numInvocation&gt;ReflectionFactory.inflationThreshold，则会调用本地方法invoke0方法 public Object invoke(Object var1, Object[] var2) throws IllegalArgumentException, InvocationTargetException { if (++this.numInvocations &gt; ReflectionFactory.inflationThreshold() &amp;&amp; !ReflectUtil.isVMAnonymousClass(this.method.getDeclaringClass())) { MethodAccessorImpl var3 = (MethodAccessorImpl)(new MethodAccessorGenerator()).generateMethod(this.method.getDeclaringClass(), this.method.getName(), this.method.getParameterTypes(), this.method.getReturnType(), this.method.getExceptionTypes(), this.method.getModifiers()); this.parent.setDelegate(var3); } return invoke0(this.method, var1, var2); } void setParent(DelegatingMethodAccessorImpl var1) { this.parent = var1; } private static native Object invoke0(Method var0, Object var1, Object[] var2);} 12//ReflectionFactory.inflationThreshold()方法的返回值private static int inflationThreshold = 15; 一开始if条件不满足，就会调用本地方法invoke0 随着numInvocation的增大，当它大于ReflectionFactory.inflationThreshold的值16时，就会本地方法访问器替换为一个运行时动态生成的访问器，来提高效率 这时会从反射调用变为正常调用，即直接调用 Reflect1.foo() 内存模型内存模型内容详见 JAVA并发：共享模型之内存","link":"/posts/20211225/jvm.html"},{"title":"Redis实战经验积累","text":"回顾 Redis 基础篇的一些命令redis 主要有以下几种数据类型 string hash list set sorted set string这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。 1set college szu hash这个是类似 map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是这个对象没嵌套其他的对象）给缓存在 redis 里，然后每次读写缓存的时候，可以就操作 hash 里的某个字段。 123456789hset person name bingohset person age 20hset person id 1hget person nameperson = { &quot;name&quot;: &quot;bingo&quot;, &quot;age&quot;: 20, &quot;id&quot;: 1} listlist 是有序列表，这个可以玩儿出很多花样。 比如可以通过 list 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。 比如可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 list 实现分页查询，这个是很棒的一个功能，基于 redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。 12# 0开始位置，-1结束位置，结束位置为-1时，表示列表的最后一个位置，即查看所有。lrange mylist 0 -1 比如可以搞个简单的消息队列，从 list 头怼进去，从 list 尾巴那里弄出来。 123456lpush mylist 1lpush mylist 2lpush mylist 3 4 5# 1rpop mylist 比如微博，某个大 V 的粉丝，就可以使用 list 的格式放在 redis 中去缓存。 key = 某大 V value = [zhangsan, lisi, wangwu, …] setset 是无序集合，自动去重。 直接基于 set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 jvm 内存里的 HashSet 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于 redis 进行全局的 set 去重。 可以基于 set 玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁？对吧。 把两个大 V 的粉丝都放在两个 set 中，对两个 set 做交集。 1234567891011121314151617181920212223242526272829303132#-------操作一个set-------# 添加元素sadd mySet 1# 查看全部元素smembers mySet# 判断是否包含某个值sismember mySet 3# 删除某个/些元素srem mySet 1srem mySet 2 4# 查看元素个数scard mySet# 随机删除一个元素spop mySet#-------操作多个set-------# 将一个set的元素移动到另外一个setsmove yourSet mySet 2# 求两set的交集sinter yourSet mySet# 求两set的并集sunion yourSet mySet# 求在yourSet中而不在mySet中的元素sdiff yourSet mySet sorted setsorted set 是排序的 set，去重并可以排序，写进去的时候给一个分数，自动根据分数排序。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889# 排行榜：将每个用户以及其对应的什么分数写入进去，# 命令：zadd key score value 注：score是sortedset中特有的概念，sortedset因此便可排序，在score位置放入数值，便会以此数值排序。# 比如：zadd board score usernamezadd board 85 zhangsanzadd board 72 lisizadd board 96 wangwuzadd board 63 zhaoliu# 获取排名前三的用户（默认是升序，所以需要 rev 改为降序）# zrange是升序排的，zrevrange是降序排的zrevrange board 0 2# 查询结果：#1) &quot;wangwu&quot;#2) &quot;zhangsan&quot;#3) &quot;lisi&quot;#4) &quot;zhaoliu&quot;# 查询时附带“score”zrevrange board 0 3 withscores# 查询结果#1) &quot;wangwu&quot;#2) &quot;96&quot;#3) &quot;zhangsan&quot;#4) &quot;85&quot;#5) &quot;lisi&quot;#6) &quot;72&quot;#7) &quot;zhaoliu&quot;#8) &quot;63&quot;# 上面 “zrevrange key 起始位置 结束位置” 是按照排位范围查询# =======================================================# 按照score范围+offset机制查询# 命令：ZREVRANGEBYSCORE key MaxScore MinScore LIMIT offset countZREVRANGEBYSCORE board 100 0 withscores limit 0 2# 解析：score在0-100（包含0和100）范围内，查询score排名前二的，第一页的数据# 按照key为board查询，查询的score范围是0-100，查询结果附加score值，limit分页查，0表示从第一个开始查（左闭右开），count表示每页条数# 查询结果；#1) &quot;wangwu&quot;#2) &quot;96&quot;#3) &quot;zhangsan&quot;#4) &quot;85&quot;ZREVRANGEBYSCORE board 85 0 withscores limit 1 2# 解析：score在0-85（包含0和85）范围内，查询score排名前二的，第二页的数据# 查询结果#1) &quot;lisi&quot;#2) &quot;72&quot;#3) &quot;zhaoliu&quot;#4) &quot;63&quot;# 上面两条查询语句中，MaxScore和offset变化了。可以看到，第二次查询时，将第一次查询的最小分数作为第二次查询的最大分数；并且offset变成1，原因是：如果还是0的话，那么由于左闭右开，第二次查询时会将85分的人再查一遍，因此从1开始，offset变成1.zadd board 96 csyzrevrange board 0 4 withscores#1) &quot;wangwu&quot;#2) &quot;96&quot;#3) &quot;csy&quot;#4) &quot;96&quot;#5) &quot;zhangsan&quot;#6) &quot;85&quot;#7) &quot;lisi&quot;#8) &quot;72&quot;#9) &quot;zhaoliu&quot;#10) &quot;63&quot;ZREVRANGEBYSCORE board 100 0 withscores limit 0 2#1) &quot;wangwu&quot;#2) &quot;96&quot;#3) &quot;csy&quot;#4) &quot;96&quot;ZREVRANGEBYSCORE board 96 0 withscores limit 1 2 #错#1) &quot;csy&quot;#2) &quot;96&quot;#3) &quot;zhangsan&quot;#4) &quot;85&quot;# 显然，重复查询了csy，这不是我们想要的，为何呢？问题出在score有相等的情况，offset需要变化。#ZREVRANGEBYSCORE key max min limit offset countZREVRANGEBYSCORE board 96 0 withscores limit 2 2 #对#1) &quot;zhangsan&quot;#2) &quot;85&quot;#3) &quot;lisi&quot;#4) &quot;72&quot;# 显然，这才是我们想要的，这两个标注了对错的查询语句，很鲜明的体现了问题，在score有相等的情况，offset需要变化。# 如何变化？offset的值应为：上一次查询的结果中，score最小值出现的次数。# 比如上上面的例子：96、85，score的最小值为85，出现了一次，那么下次查询的时候offset为1；# 比如上面的例子：96、96，score的最小值为96，出现了两次，那么下次查询的时候offset为2，这样才不会重复查询。# 对于使用redis做分页查询，其实zrange和zrangebyscore都是可以的，但是要区分场景，zrange的排序是按照排位角标的传统排序，传统的分页在feed流是不适用的，因为Feed流中的数据会不断更新，所以数据的排位角标也在变化，因此不能采用传统的分页模式。因此Feed流需要使用的是滚动分页。我们需要记录每次操作的最后一条，然后从这个位置开始去读取数据。由此可见，zrangebyscore可以实现滚动分页。# 获取某用户的排名zrank board zhaoliu 短信登录基于 Session 登录业务流程1、发送短信验证码 2、短信验证码登录或注册 3、校验登录状态 基于 Session 实现登录的原理，其实就是 Session 的原理，Session 的原理为 Cookie。每一个 Session 都会有一个唯一的 sessionid，在你访问 tomcat 的时候，sessionid 就已经自动的被写到你的 cookie 中了，你以后的请求会携带 Cookie，那么 Cookie 中就会有这个 JSESSIONID，就能自动的通过这个 JSESSIONID 找到对应的 Session，进而找到 session 中的数据。程序中 session 都有一个默认的过期时间，其中 tomcat 中的默认时间为 30 分钟。 注：这里要注意的是 Session 的过期时间，Session 默认 30min 内一直无操作的话就过期，如果有操作就会刷新 Session 的过期时间，重新计时 30min。如果 Session 过期的话，那么保存在 Session 中的登录状态自然也就过期了。 Session 共享问题Session 在单体项目下尚且可以使用来记录登录状态，但是当我们将服务集群的方式部署的时候，那么多个服务也就意味着多台 tomcat 服务器，多台 tomcat 之间并不共享 session 的存储空间，因此当请求切换到不同的 tomcat 服务器时就会导致数据丢失的问题，也就是登录状态的丢失，比如说用户第一次的请求到达了 tomcat1 做了登录操作，然后后续的操作请求到达了 tomcat2，这时 tomcat2 中的 session 中并没有这个用户的登录状态，那就意味着这个用户需要重新登录，这显然是不合理的。 解决方案使用 Redis + 随机 Tokensession 的替代方案应该满足 3 点：数据共享、内存存储、key-value 结构。 原理解析之前基于 session 来做登录校验，是因为 tomcat 会自动的将你的 sessionid 写到浏览器的 cookie 中，以后每次请求带着 cookie，则带着 JSESSIONID 来了，进而找到 session 进而找到 session 中保存的登录状态，也就是用户信息，因此这里的 sessionid 相当于一个登录凭证，这个 sessionid 是由 tomcat 维护的。但是我们现在不用这套了，我们用 token，这个 token 是我们在服务端通过代码随机生成的，但是浏览器不会自动帮我们将 token 写入到浏览器的 cookie 中，因此需要我们手动将生成的 token 写回前端浏览器，前端人员将 token 保存到请求头，让以后每次请求都携带这个 token，服务端我们通过 token 到 redis 中取用户信息，从而校验登录状态。并且 token 在 redis 中设置过期时间，模拟 session 的过期特性。注，当用户在 token 有效期内进行操作了，要重新刷新 token 的有效时间，从头开始重新计时。 业务流程1、发送短信验证码 2、短信验证码登录或注册 3、校验登录状态 拦截器的应用。注，单体 SpringBoot 项目这样使用，如果是微服务项目，可以在网关那块拦截。 使用 Spring Session + Redis前面说了，session 是啥？浏览器有个 cookie，在一段时间内这个 cookie 都存在，然后每次发请求过来都带上一个特殊的 jsessionid cookie，就根据这个东西，在服务端可以维护一个对应的 session 域，里面可以放点数据。 虽然 session 自动过期时间是 30min，但是一般的话只要你没关掉浏览器，cookie 还在，那么对应的那个 session 就在，因为 session 会自动续期，但是如果 cookie 没了，session 也就没了。常见于什么购物车之类的东西，还有登录状态保存之类的。 原理图 当所有 Tomcat 需要往 Session 中写数据时，都往 Redis 中写，当所有 Tomcat 需要读数据时，都从 Redis 中读。这样，不同的服务就可以使用相同的 Session 数据了。可以使用 Spring Session 来实现这一功能，Spring Session 就是使用 Spring 中的代理过滤器，将所有的 Session 操作拦截下来，自动的将数据同步到 Redis 中，或者自动的从 Redis 中读取数据。 对于开发者来说，所有关于 Session 同步的操作都是透明的，开发者使用 Spring Session，一旦配置完成后，具体的用法就像使用一个普通的 Session 一样。下面列一个简易的 demo。 创建工程首先，创建一个 Spring Boot 工程，引入 Web、Spring Session 以及 Redis: 创建成功之后，pom.xml 文件如下： 1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 注意： 这里我使用的 Spring Boot 版本是 2.1.4 ，如果使用 Spring Boot2.1.5 的话，除了上面这些依赖之外，需要额外添加 Spring Security 依赖（其他操作不受影响，仅仅只是多了一个依赖，当然也多了 Spring Security 的一些默认认证流程）。 配置 Redis1234567spring.redis.host=192.168.66.128spring.redis.port=6379spring.redis.password=123spring.redis.database=0spring.session.store-type=REDISserver.servlet.session.timeout=30m 并且在微服务的启动类上添加 @EnableRedisHttpSession 注解，代表整合 redis 作为 session 存储。store-type 的类型除了 REDIS，还有 NONE、JDBC、MONGODB 可供选择，根据公司存储架构和需求选择合适的存储渠道，但是大部分应该使用的是 redis。 使用配置完成后，就可以使用 Spring Session 了，其实就是使用普通的 HttpSession ，其他的 Session 同步到 Redis 等操作，框架已经自动帮你完成了： 1234567891011121314@RestControllerpublic class HelloController { @Value(&quot;${server.port}&quot;) Integer port; @GetMapping(&quot;/set&quot;) public String set(HttpSession session) { session.setAttribute(&quot;user&quot;, &quot;javaboy&quot;); return String.valueOf(port); } @GetMapping(&quot;/get&quot;) public String get(HttpSession session) { return session.getAttribute(&quot;user&quot;) + &quot;:&quot; + port; }} 考虑到一会 Spring Boot 将以集群的方式启动 ，为了获取每一个请求到底是哪一个 Spring Boot 提供的服务，需要在每次请求时返回当前服务的端口号，因此这里我注入了 server.port 。 接下来 ，项目打包： 打包之后，启动项目的两个实例： 12java -jar sessionshare-0.0.1-SNAPSHOT.jar --server.port=8080java -jar sessionshare-0.0.1-SNAPSHOT.jar --server.port=8081 然后先访问 localhost:8080/set 向 8080 这个服务的 Session 中保存一个变量，访问完成后，数据就已经自动同步到 Redis 中了： 然后，再调用 localhost:8081/get 接口，就可以获取到 8080 服务的 session 中的数据： 此时关于 session 共享的配置就已经全部完成了，session 共享的效果我们已经看到了，但是每次访问都是我自己手动切换服务实例，因此，接下来我们来引入 Nginx ，实现服务实例自动切换。 引入 Nginx很简单，进入 Nginx 的安装目录的 conf 目录下（默认是在 /usr/local/nginx/conf），编辑 nginx.conf 文件： 在这段配置中： upstream 表示配置上游服务器 javaboy.org 表示服务器集群的名字，这个可以随意取名字 upstream 里边配置的是一个个的单独服务 weight 表示服务的权重，意味者将有多少比例的请求从 Nginx 上转发到该服务上 location 中的 proxy_pass 表示请求转发的地址，/ 表示拦截到所有的请求，转发转发到刚刚配置好的服务集群中 proxy_redirect 表示设置当发生重定向请求时，nginx 自动修正响应头数据（默认是 Tomcat 返回重定向，此时重定向的地址是 Tomcat 的地址，我们需要将之修改使之成为 Nginx 的地址）。 配置完成后，将本地的 Spring Boot 打包好的 jar 上传到 Linux ，然后在 Linux 上分别启动两个 Spring Boot 实例： 12nohup java -jar sessionshare-0.0.1-SNAPSHOT.jar --server.port=8080 &amp;nohup java -jar sessionshare-0.0.1-SNAPSHOT.jar --server.port=8081 &amp; 其中 nohup 表示当终端关闭时，Spring Boot 不要停止运行 &amp; 表示让 Spring Boot 在后台启动 配置完成后，重启 Nginx： 1/usr/local/nginx/sbin/nginx -s reload Nginx 启动成功后，我们首先手动清除 Redis 上的数据，然后访问 192.168.66.128/set 表示向 session 中保存数据，这个请求首先会到达 Nginx 上，再由 Nginx 转发给某一个 Spring Boot 实例： 如上，表示端口为 8081 的 Spring Boot 处理了这个 /set 请求，再访问 /get 请求： 可以看到，/get 请求是被端口为 8080 的服务所处理的。 本案例我已经上传到码云： https://gitee.com/erdochan/sessionshare。注意配置文件的修改！ 关于 Spring Session 其它的一些问题： 我们第一次使用 session 时，浏览器会自动帮我们保存一个 cookie，也就是 JSESSIONID，事实上，它就是个 cookie。之后浏览器访问哪个网站就会带上这个网站的 cookie。 域名之间：比如父域 mall.com，它的子域 auth.mall.com，比如我们现在就是在 auth 这个微服务上做鉴权，使用到 session 保存用户的登录状态，那么这个时候 session 的作用域就是当前域，也就是 auth.mall.com，那么如果鉴权服务这里鉴权成功，登录成功到首页的话，首页的域名就是 mall.com，那么则会出现子域 session 的共享问题，针对这个问题，解决方案就是配置放大 session 的作用域。 另外，如果存入 Redis 的 session 是个对象的话，默认是使用 JDK 的方式序列化后存入的，这样在 Redis 中的数据的可读性不高，因此我们可以配置 Spring Session 将 session 存入 redis 的时候使用 JSON 的序列化方式。 配置类如下： 123456789101112131415161718@Configurationpublic class MallSessionConfig { @Bean public CookieSerializer cookieSerializer() { DefaultCookieSerializer cookieSerializer = new DefaultCookieSerializer(); //放大作用域 cookieSerializer.setDomainName(&quot;mall.com&quot;); cookieSerializer.setCookieName(&quot;MALL-SESSION&quot;); cookieSerializer.setCookieMaxAge(60*60*24*7); return cookieSerializer; } // 使用 JSON 的序列化方式 @Bean public RedisSerializer&lt;Object&gt; springSessionDefaultRedisSerializer() { return new GenericJackson2JsonRedisSerializer(); }} 最后，一级域名也就是顶级域名不同的话，是不能共用 cookie 的，就比如说，一个公司有多款产品，但是顶级域名并不相同，例如：sina.cn.com 和 weibo.com，这种虽然都是新浪公司的但是父域名不同，这样就不能使用 spring session 解决共享登录状态的问题。那么在这种情况下，我想要保证共享登录状态的话，就需要使用单点登录了，一处登录，处处可用，单点登录案例。单点登录核心：三个系统即使域名不一样，想办法给三个系统同步同一个用户的票据； 中央认证服务器，ssoserver.com； 其他系统，想要登录去 ssoserver.com 登录，登录成功跳转回来； 只要有一个系统已经登录，其它系统都不需要登录； 所有系统统一一个 sso-sessionid；所有系统可能域名都不相同。 总的来说，使用 Spring Session 解决分布式 session 问题，实现共享登录状态，是指在父子域名的情况下共享，也就是不同的微服务之间共享和相同的微服务（可能是微服务集群部署）之间共享，而使用单点登录实现共享登录状态，是在父域名不同的情况下共享。 最后介绍一下，有一种基于 JWT 的无状态登录方案，就是不使用 session，使用 token 的一种方式，因为不涉及 cookie 和 session，因此称为无状态。JWT，全称是Json Web Token， 是JSON风格轻量级的授权和身份认证规范，可实现无状态、分布式的Web应用授权；官网。之前写过一篇博客，就是大致介绍了一下 JWT，以及在项目中的简单使用，博客地址：https://chanservy.github.io/2021/04/09/auth-center.html。 总结我们写了一些代码，也做了一些配置，但是基本上都和 Spring Session 无关，配置是配置 Redis，代码就是普通的 HttpSession，和 Spring Session 没有任何关系！和 Spring Session 相关的，就是一开始引入了 Spring Session 的依赖，添加了 session 存储类型的配置以及 @EnableRedisHttpSession 注解。其它的就是正常使用 HttpSession ，只不过在没配置 Spring Session 之前，我们的 session 是基于 web 服务器存储的，配置了之后 session 就是基于 Redis 存储了，对于 session 的操作也是一样的。 Spring Session 核心原理： 我们加入了 @EnableRedisHttpSession 注解，@EnableRedisHttpSession 导入了 RedisHttpSessionConfiguration 配置，那么这个配置做了什么？ 给容器中添加了一个组件：SessionRepository —&gt; RedisOperationsSessionRepository —&gt; redis 操作 session。session 的增删改查封装类。 SessionRepositoryFilter —&gt; Filter：session 存储过滤器；每个请求过来都必须经过 filter。 创建的时候，就自动从容器中获取到了 SessionRepository 原始的 request，response 都被包装。SessionRepositoryRequestWrapper，SessionRepositoryResponseWrapper 以后获取 session 时，依然是 request.getSession(); 注：这里是 SessionRepositoryRequestWrapper 的 request，也就是被包装后的 request，并非原生的 HttpServletRequest。 wrappedRequest.getSession(); —&gt; SessionRepository 中获取到的。 这便是装饰者模式。 使用 ip_hash 指令在负载均衡系统中，如果客户端已经在某台服务器中登陆，如果我们在访问系统，Nginx 会给客户端重新分配一台服务器，这台服务器很有可能不是原先的那台服务器，这显然是不妥的，因为这样就意味着客户端又要重新登陆一次系统。所以需要通过 ip_hash 指令来解决这个问题。 ip_hash 指令的原理Nginx 通过哈希算法（键值对）给每个客户端指定一个对应的服务器，当一个用户已经在一台服务器上登陆，当它再次访问 Nginx 服务器时，Nginx 会从哈希集合中拿到用户上次登陆的那个服务器，然后跳转到相应的服务器。从而解决 session 丢失的问题，ip_hash 会自动运算对应的 ip 访问的地址，可以提高命中率，Nginx 可以自动发现上游服务是不是挂了，如果挂了 Nginx 会自动分配其他的，当挂掉的服务重新又启动起来了，又自动的回去找原来的服务了。 使用 ip_hash 解决 session 共享保证一个 ip 地址永远的访问一台 web 服务器，就不存在 session 共享的问题了。在 Nginx 的配置文件中的 upstream 中添加 ip_hash。 商户查询缓存用缓存，主要有两个用途：高性能、高并发。 缓存更新策略其实这主要是说数据库和缓存的数据双写不一致的问题，该怎样解决。 内存淘汰 超时剔除 主动更新 说明 不用自己维护，利用Redis的内存淘汰机制，当内存不足时自动淘汰部分数据。下次查询时更新缓存。 给缓存数据添加TTL时间，到期后自动删除缓存。下次查询时更新缓存。 编写业务逻辑，在修改数据库的同时，更新缓存。 一致性 差 一般 好 维护成本 无 低 高 业务场景： 低一致性需求：使用内存淘汰机制。例如店铺类型的查询缓存 高一致性需求：主动更新，并以超时剔除作为兜底方案。例如店铺详情查询的缓存 关于内存淘汰机制 往 redis 写入的数据怎么没了？ 啥叫缓存？用内存当缓存。内存是无限的吗，内存是很宝贵而且是有限的，磁盘是廉价而且是大量的。可能一台机器就几十个 G 的内存，但是可以有几个 T 的硬盘空间。redis 主要是基于内存来进行高性能、高并发的读写操作的。 那既然内存是有限的，比如 redis 就只能用 10G，你要是往里面写了 20G 的数据，会咋办？当然会干掉 10G 的数据，然后就保留 10G 的数据了。那干掉哪些数据？保留哪些数据？当然是干掉不常用的数据，保留常用的数据了。触发了内存淘汰机制。 数据明明过期了，怎么还占用着内存？ 这是由 redis 的过期策略来决定。定期删除时随机抽取的设置了过期时间的那些 key 可能有一部分暂时并没有过期，当然过期的会被删除掉，但是并不是所有的过期的 key 都会被抽取到，没抽取到的过期的 key 如果没有被查询，那就不能触发惰性删除，因此可能会出现数据明明过期了但是内存依然被占用着这种情况。 redis 过期策略redis 过期策略是：定期删除+惰性删除。 所谓定期删除，指的是 redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。 假设 redis 里放了 10w 个 key，都设置了过期时间，你每隔几百毫秒，就检查 10w 个 key，那 redis 基本上就死了，cpu 负载会很高的，消耗在你的检查过期 key 上了。注意，这里可不是每隔 100ms 就遍历所有的设置过期时间的 key，那样就是一场性能上的灾难。实际上 redis 是每隔 100ms 随机抽取一些 key 来检查和删除的。 但是问题是，定期删除可能会导致很多过期 key 到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。这就是说，在你获取某个 key 的时候，redis 会检查一下 ，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。 获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。 但是实际上这还是有问题的，如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期 key 堆积在内存里，导致 redis 内存块耗尽了，咋整？ 答案是：走内存淘汰机制。 内存淘汰机制redis 内存淘汰机制有以下几个： noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。 allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。 volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 key（这个一般不太合适）。 volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 key。 volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 key 优先移除。 手写一个 LRU 算法不求自己纯手工从底层开始打造出自己的 LRU，但是起码要知道如何利用已有的 JDK 数据结构实现一个 Java 版的 LRU。 1234567891011121314151617181920class LRUCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; { private final int CACHE_SIZE; /** * 传递进来的参数是最多能缓存多少数据 * * @param cacheSize 缓存大小 */ public LRUCache(int cacheSize) { // 这块就是设置一个 hashmap 的初始大小，最后的 true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。 super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true); CACHE_SIZE = cacheSize; } @Override protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) { // 当 map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。 return size() &gt; CACHE_SIZE; }} 主动更新策略Cache Aside Pattern由缓存的调用者，在更新数据库的同时更新缓存。 操作缓存和数据库时有三个问题需要考虑： 删除缓存还是更新缓存？ 更新缓存：每次更新数据库都更新缓存，无效写操作较多 删除缓存：更新数据库时让缓存失效，查询时再更新缓存 举个栗子：比如一个缓存涉及到的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，对于缓存的无效写操作较多。实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。用到缓存才去算缓存。其实删除缓存，而不是更新缓存，就是一个 lazy 加载的思想，是让它到需要被使用的时候再重新加载。 如何保证缓存与数据库的操作的同时成功或失败？ 单体系统，将缓存与数据库操作放在一个事务 分布式系统，利用 TCC 等分布式事务方案 先操作缓存还是先操作数据库？ 先删除缓存，再更新数据库 分析：先删除缓存，再更新数据库，如果更新数据库失败了，那么再查的时候缓存中没有，进而到数据库中取到旧数据放入缓存，可能有脏数据的情况，不会造成缓存数据库中的数据不一致。但是在对一个数据并发的进行读写的时候，可能会造成缓存数据库中的数据不一致的情况。众所周知，数据库的操作相比缓存的操作效率要低很多，耗时更长；另外如果数据库是主从架构部署，主写从读，数据库的数据修改之后，数据从主节点同步到从节点也需要耗时。如果写请求到来，先删除了缓存，更新数据库的操作还未完成时，读请求到来，这时缓存中无数据，查询数据库从节点，然后将数据写回缓存，在这之后数据库才更新并同步成功，这个时候缓存中和数据库中的数据不一致。 解决：更新数据的时候，根据数据的唯一标识，比如商品的 id ，对这个 id 进行 hash 取值，然后得到的值再对内存队列的数量进行取模，这样针对每个商品操作都可以路由到某一个内存队列中，也就是 hash 算法。将这个 id 的商品更新操作路由之后，发送到一个 jvm 内部队列中。读取这个 id 的商品的数据的时候，如果发现数据不在缓存中，根据唯一标识路由之后，也发送同一个 jvm 内部队列中。一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，如果没有读到缓存，那么可以先将查询数据库并更新缓存的操作发送到队列中，此时会在队列中积压，然后同步等待数据库数据更新完成之后再进行查询数据库。 优化点：一个队列中，其实多个查询请求（包含查库+更新缓存）串在一起是没意义的，因此可以做过滤，如果发现队列中已经有一个查询的请求了，那么就不用再放个查询请求操作进去了，直接等待前面的更新操作请求和查询请求完成即可。如果请求还在等待时间范围内，不断轮询发现缓存中可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。 高并发场景下该解决方案要考虑的问题： 读请求长时阻塞 读请求并发量过高 服务集群式部署的请求路由 热点商品的路由问题，导致请求的倾斜 先更新数据库，再删除缓存 分析：这种情况，如果数据库更新成功，但是缓存更新失败，那么缓存中就是旧数据，而数据库中是新数据，这样造成了数据库和缓存的数据不一致。 解决：首先一定要确保操作数据库与操作缓存两个动作的原子性，要么一起成功，要么一起失败！单体系统，将缓存与数据库操作放在一个事务中；分布式系统，利用 TCC 等分布式事务方案。其次缓存中写入数据的时候设置一个过期淘汰时间作为兜底方案，即使事务操作失误了，数据库更新了，缓存删除失败了，那缓存中的数据到期之后也会过期淘汰掉，下次在查询的时候先查数据库然后将数据写入缓存。 综上，我觉得选择“先更新数据库，再删除缓存”方案更好。 单体项目中： 123456789101112@Transactionalpublic Result update(Shop shop) { Long id = shop.getId(); if (id == null) { return Result.fail(&quot;店铺id不能为空&quot;); } // 1.更新数据库 updateById(shop); // 2.删除缓存 stringRedisTemplate.delete(CACHE_SHOP_KEY + id); return Result.ok();} 总结缓存更新策略的最佳实践方案： 低一致性需求：使用 Redis 自带的内存淘汰机制 高一致性需求：主动更新，并以超时剔除作为兜底方案 读操作：缓存命中则直接返回；缓存未命中则查询数据库，并写入缓存，设定超时时间，最后返回 写操作：先更新数据库，然后再删除缓存，一定要确保操作数据库与操作缓存两个动作的原子性，要么一起成功，要么一起失败！ 单体系统，将缓存与数据库操作放在一个事务中 分布式系统，利用 TCC 等分布式事务方案 缓存雪崩 对于系统 A，假设每天高峰期的时候每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，缓存查不到任何数据了，那么此时 1 秒 5000 个请求在缓存中都查不到数据，自然全部落到数据库，数据库必然扛不住，它会报一下警，然后就挂了。 或者是指在同一时段大量的缓存 key 同时失效，导致大量请求到达数据库，带来巨大压力。 其实都差不多，这就是缓存雪崩。 缓存雪崩的事前事中事后的解决方案如下： 事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。 事中：系统 A 中开启本地 ehcache 缓存 + hystrix 限流&amp;降级，避免 MySQL 被打死。给不同的 Key 的 TTL 添加随机值。 事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。 用户发送一个请求，系统 A 收到请求后，先查本地 ehcache 缓存，如果没查到再查 redis。如果 ehcache 和 redis 都没有，限流之后再查数据库，将数据库中的结果，写入 ehcache 和 redis 中。 限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？走降级！可以返回一些默认的值，或者友情提示，或者空白的值。 好处： 数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过。 只要数据库不死，就是说，对用户来说，2/5 的请求都是可以被处理的。 只要有 2/5 的请求可以被处理，就意味着你的系统没死，对用户来说，可能就是点击几次刷不出来页面，但是多点几次，就可以刷出来一次。 缓存穿透缓存穿透是指客户端请求的数据在缓存中和数据库中都不存在，这样缓存永远不会生效，这些请求都会打到数据库。 图解： 解决方案： 以数据库和缓存同步主键的方式来解决缓存穿透 首先，主键会分为两种情况：自增和非自增。 自增：如果数据库中的数据都是自增的主键，则将最大值的主键存放到 Redis 中。在高并发请求到来的时候，缓存中没有数据的情况下，先判断查询的主键是否小于等于缓存中主键的最大值，如果小于，则继续查询数据库，如果不小于，那么就没必要查询数据库了，因为数据肯定不在数据库中，从而减小数据库的压力。 非自增：如果数据库中的主键非自增的话，则将数据库中所有的主键都取出来放到 Redis 的 set 中，按照的步骤，缓存中没有数据的时候先判断当前查询的主键在不在 set 中，在的话则代表数据在数据库中，进而查询数据库，不在的话就证明数据不在数据库中，就不用查询数据库了。 以缓存空值的方式来解决缓存穿透 解析：如果请求来了，先查询缓存，缓存没查到，然后查询数据库，数据库中也查不到，这个时候向缓存中存入一个空值，并且设置一个过期时间，然后返回 null 或者错误信息提示，按业务需求，下次相同的请求就能到缓存中查到空值。 优点：实现简单，维护方便。 缺点：额外的内存消耗，另外如果前端发来不重复的请求，请求数据库不存在数据，那这样设置 null 值方案就等于失效的，这些请求还是会打到数据库，请求并发量过高使数据库宕机。 流程图：以查询商铺为例： 12345678910111213141516171819202122232425public Shop queryByIdWithPassThroughBySetNil(Long id) { //从redis中查询商铺缓存 String shopJson = stringRedisTemplate.opsForValue().get(RedisConstants.CACHE_SHOP_KEY + id); //判断是否存在 if (StrUtil.isNotBlank(shopJson)) { //存在，直接返回 return JSONUtil.toBean(shopJson, Shop.class); } //有效解决缓存穿透 if (Objects.equals(shopJson, &quot;&quot;)) { return null; } //缓存中不存在，根据id查询数据库 Shop shop = shopMapper.selectById(id); //数据库中不存在，在redis中给这个键设置一个空值，防止缓存穿透，并返回错误 if (shop == null) { stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY + id, &quot;&quot;, RedisConstants.CACHE_NULL_TTL, TimeUnit.MINUTES); return null; } //数据库中存在，将数据写入redis，这里设置一个超时时间，是为双写一致性方案可能会出现的纰漏兜底 //即使极端情况发生导致数据库和缓存的数据不一致，那么到达超时时间之后缓存会清空，数据再被访问时会同步新数据 stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY + id, JSONUtil.toJsonStr(shop), RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); //返回 return shop;} 以布隆过滤器的方式来解决缓存穿透 优点：内存占用较少，没有多余 key 缺点：实现复杂、存在误判的可能。 总结缓存穿透产生的原因是什么？ 用户请求的数据在缓存中和数据库中都不存在，不断发起这样的请求，给数据库带来巨大压力。 缓存穿透的解决方案有哪些？ 数据库和缓存同步主键 缓存null值 布隆过滤 增强id的复杂度，避免被猜测id规律 做好数据的基础格式校验 加强用户权限校验 做好热点参数的限流 缓存击穿缓存击穿也叫热点 Key 问题，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，大量请求高并发查询某个高热度 key 的数据，大量请求到达应用服务器集群，首先查询 Redis 集群，但是这个 key 突然失效了，大量的访问请求会在瞬间给数据库带来巨大的冲击。 解决方式： 可以将热点数据设置为永远不过期； 或者基于 redis or zookeeper 实现互斥锁，等待第一个请求查询完数据库得到数据并且构建完缓存之后，再释放锁，进而其它请求才能通过该 key 访问数据，这样一来，释放锁之后，后面的请求就通过 key 直接去缓存中取数据 在将数据存入缓存的时候不设置 TTL，并且多存入一个字段，用它来表示 key 的过期时间。那么实质上，缓存中的这条数据就永远不会过期，当查询到这条缓存的时候，我们在程序中通过逻辑，根据这个字段来决定是否需要缓存重建。 解决方案 优点 缺点 互斥锁 没有额外的内存消耗；保证一致性 线程需要等待，性能受影响；可能有死锁的风险 逻辑过期 线程无需等待，性能较好；高可用性 一致性稍差；有额外内存消耗；实现较复杂 基于互斥锁方式解决缓存击穿问题核心在于加锁，加锁的时机就是访问数据库之前，加锁的效果就是在缓存中查不到热点 key 的数据的情况下，需要访问数据库时不让这高并发的请求都打到数据库，只放进去一个线程，查询数据库、构建缓存，然后释放锁。剩下的请求去缓存中取数据，保护数据库。这里说的就是分布式锁。 1234567891011121314151617181920212223242526272829303132public Shop queryByIdWithBreakDownByMutex(Long id) { String shopJson = stringRedisTemplate.opsForValue().get(RedisConstants.CACHE_SHOP_KEY + id); if (StrUtil.isNotBlank(shopJson)) { return JSONUtil.toBean(shopJson, Shop.class); } if (Objects.equals(shopJson, &quot;&quot;)) { return null; } //缓存中拿不到数据，需要查询数据库，涉及到数据要考虑缓存穿透和缓存击穿的问题 try { if (!getLock(id)) { TimeUnit.SECONDS.sleep(1); //递归调用，重新尝试到缓存中取数据，没有数据则尝试获取锁，拿不到锁就再次进到这个代码块 queryByIdWithBreakDownByMutex(id); } else { Shop shop = shopMapper.selectById(id); //模拟查询数据库的延时 TimeUnit.MILLISECONDS.sleep(200); if (shop == null) { stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY + id, &quot;&quot;, RedisConstants.CACHE_NULL_TTL, TimeUnit.MINUTES); return null; } stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY + id, JSONUtil.toJsonStr(shop), RedisConstants.CACHE_SHOP_TTL, TimeUnit.MINUTES); return shop; } } catch (Exception e) { e.printStackTrace(); } finally { releaseLock(id); } return null;} 基于逻辑过期方式解决缓存击穿问题互斥锁方案的数据一致性更强，是因为一个线程拿到锁，其它线程都阻塞，同步等待到这个线程查询数据库、构建缓存完成之后。 逻辑过期方案的一致性显然差一些，即使逻辑判断过期也不等待，而是直接返回旧数据，查询数据库、构建缓存操作是在获取互斥锁后开启一个独立线程异步去执行的，这大大提升了性能，可用性提高。可以看到，此方案在开启独立线程之前，也就是操作数据库之前依然获取了互斥锁，目的就是不让所有请求的线程都开启独立线程去操作，最主要也起到了保护数据库的作用。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public Shop queryByIdWithBreakDownByLogicalExpiration(Long id) { String redisDataJson = stringRedisTemplate.opsForValue().get(RedisConstants.CACHE_SHOP_KEY + id); if (StrUtil.isNotBlank(redisDataJson)) { RedisData redisData = JSONUtil.toBean(redisDataJson, RedisData.class); Object data = redisData.getData(); LocalDateTime expireTime = redisData.getExpireTime(); Shop shop = JSONUtil.toBean((JSONObject) data, Shop.class); if (LocalDateTime.now().isBefore(expireTime)) { //返回的数据没过期 return shop; } else { //过期了，需要缓存重建，要先从数据库中查询，加一个互斥锁保护mysql的安全 if (getLock(id)) { //异步去刷新redis的数据 CACHE_REBUILD_POOL.submit(() -&gt; { try { saveShopToRedis(id, 20L); TimeUnit.MILLISECONDS.sleep(200); } catch (InterruptedException e) { e.printStackTrace(); } finally { releaseLock(id); } }); } //没拿到锁。不等，直接返回一个过期的数据，但这个数据不一定就是错的 return shop; } } if (Objects.equals(redisDataJson, &quot;&quot;)) { return null; } //缓存查不到的话 Shop shop = shopMapper.selectById(id); if (shop == null) { stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY + id, &quot;&quot;, RedisConstants.CACHE_NULL_TTL, TimeUnit.MINUTES); return null; } RedisData redisData = new RedisData(); redisData.setData(shop); redisData.setExpireTime(LocalDateTime.now().plusSeconds(20L)); stringRedisTemplate.opsForValue().set(RedisConstants.CACHE_SHOP_KEY + id, JSONUtil.toJsonStr(redisData)); return shop;} 其实说了这么多，无论是缓存雪崩、缓存穿透还是缓存击穿，都是在某种情况下大量请求打到数据库上，导致数据库宕机，遇到这些问题主要还是围绕如何让数据库不被高并发的请求冲击考虑。 缓存倾斜引发原因：大量请求高并发访问高热度数据 key1，请求到达应用服务器集群，请求查询 Redis 集群，缓存中存在，但是因为高并发访问某一条数据它的 key 是固定的，导致请求全部落入固定的某台机器，最终这台缓存机器崩溃。 解决方式：添加节点的方式。热点数据所在的服务器一定是主从，我们可以做读写分离，将查询的请求都分发到 Redis 的从机上面，进行平分请求，这样一来，每个 master node 都有 slave node，主从节点，主节点主要负责增删改，从节点们主要负责查询。可使用注册中心来存取集群中的从机节点信息。其实，既然是 redis 集群的话，那么就是 redis cluster 模式，自身就已经包含了 replication+sentinel 的优点了。 缓存工具类的封装 将任意 Java 对象序列化为 json 并存储在 string 类型的 key 中，并且可以设置 TTL 过期时间 将任意 Java 对象序列化为 json 并存储在 string 类型的 key 中，并且可以设置逻辑过期时间，用于处理缓存击穿问题 根据指定的 key 查询缓存，并反序列化为指定类型，利用缓存空值的方式解决缓存穿透问题 根据指定的 key 查询缓存，并反序列化为指定类型，需要利用逻辑过期解决查询热点数据时可能发生的缓存击穿问题 根据指定的 key 查询缓存，并反序列化为指定类型，需要利用互斥锁解决查询热点数据时可能发生的缓存击穿问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235import cn.hutool.core.util.BooleanUtil;import cn.hutool.core.util.StrUtil;import cn.hutool.json.JSONObject;import cn.hutool.json.JSONUtil;import lombok.extern.slf4j.Slf4j;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.stereotype.Component;import java.time.LocalDateTime;import java.util.Objects;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.TimeUnit;import java.util.function.Function;import static com.hmdp.utils.RedisConstants.CACHE_NULL_TTL;import static com.hmdp.utils.RedisConstants.LOCK_SHOP_KEY;/** * 利用泛型和函数式接口 * @author CHAN * @since 2022-03-28 */@Slf4j@Componentpublic class CacheClient { private final StringRedisTemplate stringRedisTemplate; private static final ExecutorService CACHE_REBUILD_POOL = Executors.newFixedThreadPool(10); public CacheClient(StringRedisTemplate stringRedisTemplate) { this.stringRedisTemplate = stringRedisTemplate; } /** * 放入缓存，并设置TTL过期 * @param key 键 * @param value 值 * @param time 过期时间 * @param unit 时间单位 */ public void set(String key, Object value, Long time, TimeUnit unit) { stringRedisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(value), time, unit); } /** * 存入缓存，带逻辑过期字段 * @param key 键 * @param value 值 * @param time 过期时间 * @param unit 时间单位 */ public void setWithLogicalExpire(String key, Object value, Long time, TimeUnit unit) { //设置逻辑过期 RedisData redisData = new RedisData(); redisData.setData(value); redisData.setExpireTime(LocalDateTime.now().plusSeconds(unit.toSeconds(time))); //写入redis stringRedisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(redisData)); } /** * 使用设置空值的方式解决缓存穿透问题 * @param keyPrefix 键前缀 * @param id 根据id查询 * @param type 查询的数据类型 * @param dbFallback 查询数据库函数式接口 * @param time 时间 * @param unit 单位 * @param &lt;R&gt; 数据类型泛型 * @param &lt;ID&gt; id类型 * @return R */ public &lt;R, ID&gt; R queryByIdWithPassThroughBySetNil(String keyPrefix, ID id, Class&lt;R&gt; type, Function&lt;ID, R&gt; dbFallback, Long time, TimeUnit unit) { String key = keyPrefix + id; //从redis中查询缓存 String json = stringRedisTemplate.opsForValue().get(key); //判断是否存在 if (StrUtil.isNotBlank(json)) { //存在，直接返回 return JSONUtil.toBean(json, type); } //有效解决缓存穿透 if (Objects.equals(json, &quot;&quot;)) { return null; } //缓存中不存在，根据id查询数据库 R r = dbFallback.apply(id); //数据库中不存在，在redis中给这个键设置一个空值，防止缓存穿透，并返回错误 if (r == null) { this.set(key, &quot;&quot;, time, unit); return null; } //数据库中存在，将数据写入redis，这里设置一个超时时间，是为双写一致性方案可能会出现的纰漏兜底 //即使极端情况发生导致数据库和缓存的数据不一致，那么到达超时时间之后缓存会清空，数据再被访问时会同步新数据 this.set(key, r, time, unit); //返回 return r; } /** * 使用逻辑过期的方式解决查询热点数据时可能发生的缓存击穿问题 * @param keyPrefix 键前缀 * @param id 根据id查询 * @param type 查询的数据类型 * @param dbFallback 查询数据库函数式接口 * @param time 时间 * @param unit 单位 * @param &lt;R&gt; 数据类型泛型 * @param &lt;ID&gt; id类型泛型 * @return R */ public &lt;R, ID&gt; R queryWithLogicalExpire( String keyPrefix, ID id, Class&lt;R&gt; type, Function&lt;ID, R&gt; dbFallback, Long time, TimeUnit unit) { String key = keyPrefix + id; // 1.从redis查询缓存 String json = stringRedisTemplate.opsForValue().get(key); // 2.判断是否存在 if (StrUtil.isBlank(json)) { // 3.存在，直接返回 return null; } // 4.命中，需要先把json反序列化为对象 RedisData redisData = JSONUtil.toBean(json, RedisData.class); R r = JSONUtil.toBean((JSONObject) redisData.getData(), type); LocalDateTime expireTime = redisData.getExpireTime(); // 5.判断是否过期 if(expireTime.isAfter(LocalDateTime.now())) { // 5.1.未过期，直接返回信息 return r; } // 5.2.已过期，需要缓存重建 // 6.缓存重建 // 6.1.获取互斥锁 String lockKey = LOCK_SHOP_KEY + id; boolean isLock = tryLock(lockKey); // 6.2.判断是否获取锁成功 if (isLock){ // 6.3.成功，开启独立线程，实现缓存重建 CACHE_REBUILD_POOL.submit(() -&gt; { try { // 查询数据库 R newR = dbFallback.apply(id); // 重建缓存 this.setWithLogicalExpire(key, newR, time, unit); } catch (Exception e) { throw new RuntimeException(e); }finally { // 释放锁 unlock(lockKey); } }); } // 6.4.返回过期的信息 return r; } /** * 使用互斥锁的方式解决查询热点数据时可能发生的缓存击穿问题 * @param keyPrefix 键前缀 * @param id 根据id查询 * @param type 查询的数据类型 * @param dbFallback 查询数据库函数式接口 * @param time 时间 * @param unit 单位 * @param &lt;R&gt; 数据类型泛型 * @param &lt;ID&gt; id类型泛型 * @return R */ public &lt;R, ID&gt; R queryWithMutex( String keyPrefix, ID id, Class&lt;R&gt; type, Function&lt;ID, R&gt; dbFallback, Long time, TimeUnit unit) { String key = keyPrefix + id; // 1.从redis查询缓存 String shopJson = stringRedisTemplate.opsForValue().get(key); // 2.判断是否存在 if (StrUtil.isNotBlank(shopJson)) { // 3.存在，直接返回 return JSONUtil.toBean(shopJson, type); } // 判断命中的是否是空值 if (shopJson != null) { // 返回一个错误信息 return null; } // 4.实现缓存重建 // 4.1.获取互斥锁 String lockKey = LOCK_SHOP_KEY + id; R r = null; try { boolean isLock = tryLock(lockKey); // 4.2.判断是否获取成功 if (!isLock) { // 4.3.获取锁失败，休眠并重试 Thread.sleep(50); return queryWithMutex(keyPrefix, id, type, dbFallback, time, unit); } // 4.4.获取锁成功，根据id查询数据库 r = dbFallback.apply(id); // 5.不存在，返回错误 if (r == null) { // 将空值写入redis stringRedisTemplate.opsForValue().set(key, &quot;&quot;, CACHE_NULL_TTL, TimeUnit.MINUTES); // 返回错误信息 return null; } // 6.存在，写入redis this.set(key, r, time, unit); } catch (InterruptedException e) { throw new RuntimeException(e); }finally { // 7.释放锁 unlock(lockKey); } // 8.返回 return r; } /** * 获取互斥锁 * @param key 键 * @return boolean */ private boolean tryLock(String key) { Boolean flag = stringRedisTemplate.opsForValue().setIfAbsent(key, &quot;1&quot;, 10, TimeUnit.SECONDS); return BooleanUtil.isTrue(flag); } /** * 释放互斥锁 * @param key 键 */ private void unlock(String key) { stringRedisTemplate.delete(key); }} 优惠券秒杀Redis 的计数器、Lua 脚本 Redis、分布式锁、Redis 的三种消息队列。 全局唯一ID方案全局唯一ID生成策略： UUID Redis自增 snowflake算法 数据库自增 使用 Redis 自增方案生成全局唯一 ID 的时候，为了增加 ID 的安全性，我们可以不直接使用 Redis 自增的数值，而是拼接一些其它信息。 比如 ID 的组成部分为： 符号位：1bit，永远为0 时间戳：31bit，以秒为单位，可以使用69年 序列号：32bit，秒内的计数器（Redis 的自增计数器），支持每秒产生2^32个不同ID 123456789101112131415161718192021222324252627282930313233343536@Componentpublic class RedisIdWorker { /*LocalDateTime time = LocalDateTime.of(2022, 1, 1, 0, 0, 0); long second = time.toEpochSecond(ZoneOffset.UTC); second = 1640995200*/ private static final long BEGIN_TIMESTAMP = 1640995200L; private static final int COUNT_BITS = 32; private final StringRedisTemplate stringRedisTemplate; public RedisIdWorker(StringRedisTemplate stringRedisTemplate) { this.stringRedisTemplate = stringRedisTemplate; } public long nextId(String keyPrefix) { //1.生成时间戳 LocalDateTime now = LocalDateTime.now(); long nowSecond = now.toEpochSecond(ZoneOffset.UTC); long timestamp = nowSecond - BEGIN_TIMESTAMP; //2.生成序列号 String date = now.format(DateTimeFormatter.ofPattern(&quot;yyyy:MM:dd&quot;)); //将redis中&quot;increment:&quot; + keyPrefix + &quot;:&quot; + date键对应的值自增并返回自增之后的值，起初没有这个键的话，incr后会新建并返回1 //increment方法参数就是要自增的key，效果就是redis中这个key对应的值自增 //count 就是自增之后的计数值，也就是序列号 Long count = stringRedisTemplate.opsForValue().increment(&quot;incr:&quot; + keyPrefix + &quot;:&quot; + date);//redis的incr为原子操作，key拼接date效果就是每天一个key，也便于统计日流量。 //3.拼接并返回 return timestamp &lt;&lt; COUNT_BITS | count;//时间戳左移运算后再以或运算的方式拼接计数器 } public static void main(String[] args) { LocalDateTime time = LocalDateTime.of(2022, 1, 1, 0, 0, 0); long second = time.toEpochSecond(ZoneOffset.UTC); System.out.println(&quot;second = &quot; + second); }} Redis自增ID策略： 每天一个key，方便统计订单量 ID构造是时间戳 + 计数器 1234567891011121314151617181920212223/** * 测试IdWorker，生成30000个ID计时 */@Testpublic void testIdWorker() throws InterruptedException { CountDownLatch latch = new CountDownLatch(300);//设置从300次开始递减 long begin = System.currentTimeMillis();//开始时间 for (int i = 0; i &lt; 300; i++) { //x300 POOL.submit(() -&gt; { for (int j = 0; j &lt; 100; j++) { //x100 long orderId = idWorker.nextId(&quot;order&quot;); System.out.println(&quot;id = &quot; + orderId); } //每次-1 latch.countDown(); }); } latch.await();//等300次执行完 long end = System.currentTimeMillis();//结束时间 System.out.println(&quot;time = &quot; + (end - begin));//300次总用时} 实现优惠券秒杀下单初步流程图 客户发送请求到我们的系统，每个请求都对应着一个线程，我们的库存数据是存在数据库的，数据库中的所有数据对于每个线程来说都是共享资源。因此需要考虑多线程并发的情况下的线程安全问题。 超卖问题上面说的线程安全问题，也就是业务中优惠券的超卖问题。超卖问题是典型的多线程安全问题，针对这一问题的常见解决方案就是加锁。 悲观锁认为线程安全问题一定会发生，因此在操作数据之前先获取锁，确保线程串行执行。例如Synchronized，Lock 在某种意义上也属于悲观锁。 乐观锁认为线程安全问题不一定会发生，因此不加锁，只是在更新数据时去判断有没有其它线程对数据做了修改。 如果没有修改则认为是安全的，自己才更新数据。 如果已经被其它线程修改说明发生了安全问题，此时可以重试或异常。 版本号法 其实 Mybatis plus 里面乐观锁方案的实现就是版本号法，需要在数据库多加一个 version 字段。 取出记录时，获取当前 version 更新时，带上这个 version 一起更新 执行更新时， set version = newVersion where version = oldVersion 如果 version 不对，就更新失败 1update ... set stock = stock - 1, version = version + 1 where id = ... and version = ...; CAS 法 1update ... set stock = stock - 1 where id = ... and stock = ...; stock 的值为 … 时，才会将 stock 的值改为 stock - 1，否则就不做更改，典型的比较并置换的思想。但是如果高并发的请求来，判断完只要不等就不改，很有可能会存在成功率低的问题，因为不会自动重试。 所以最终： 1update ... set stock = stock - 1 where id = ... and stock &gt; 0; 总结超卖这样的线程安全问题，解决方案有哪些？ 悲观锁：添加同步锁，让线程串行执行 优点：简单粗暴 缺点：性能一般 乐观锁：不加锁，在更新时判断是否有其它线程在修改 优点：性能好 缺点：存在成功率低的问题 一人一单如果一个人发起高并发的秒杀下单请求，优惠券的数量有限，如果一个人高并发重复下单的话，那所有的优惠券都被他一个人抢购了，这不是黄牛是啥？这显然是不公平的，因此有一人一单的业务需求。 在根据用户 ID 和优惠券 ID 查询订单之前，需要获取锁。也就是说，只能让一个线程去查询订单。因为如果一个人发起高并发秒杀请求，这个人之前没有下过单，如果不加锁的话，多个请求并发去查询数据库订单表，都发现订单不存在，那么这些个请求就可以重复下单了，不符合一人一单。 1234567891011121314151617181920212223242526@Transactionalpublic VoucherOrder updateStockAndSaveOrder(Long voucherId) { Long userId = UserHolder.getUser().getId(); synchronized (userId.toString().intern()) { QueryWrapper&lt;VoucherOrder&gt; queryWrapper = new QueryWrapper&lt;&gt;(); queryWrapper.eq(&quot;user_id&quot;, userId); queryWrapper.eq(&quot;voucher_id&quot;, voucherId); Integer count = voucherOrderMapper.selectCount(queryWrapper); if (count &gt; 0) { return null; } UpdateWrapper&lt;SeckillVoucher&gt; updateWrapper = new UpdateWrapper&lt;&gt;(); updateWrapper.setSql(&quot;stock = stock - 1&quot;).eq(&quot;voucher_id&quot;, voucherId).gt(&quot;stock&quot;, 0); // mysql连接驱动的更新操作默认返回的并不是受影响的行数，如果想设置返回值是受影响的行数，修改数据库链接配置：增加useAffectedRows=true int modified = seckillVoucherMapper.update(null, updateWrapper); if (modified != 1) { return null; } VoucherOrder voucherOrder = new VoucherOrder(); voucherOrder.setId(idWorker.nextId(&quot;order&quot;)); voucherOrder.setUserId(userId); voucherOrder.setVoucherId(voucherId); voucherOrderMapper.insert(voucherOrder); return voucherOrder; }} 分布式锁通过加锁可以解决在单机情况下的一人一单安全问题，但是在集群模式下就不行了。我们将服务启动两份，端口分别为8081和8082。然后修改nginx的conf目录下的nginx.conf文件，配置反向代理和负载均衡： 现在，用户请求会在这两个节点上负载均衡，再次测试下是否存在线程安全问题。当然存在！ 这时就需要用到分布式锁了，什么是分布式锁？满足分布式系统或集群模式下多进程都可见并且互斥的锁。 分布式锁的实现分布式锁的核心是实现多进程之间互斥，而满足这一点的方式有很多，常见的有三种： MySQL Redis Zookeeper 互斥 利用mysql本身的互斥锁机制 利用setnx这样的互斥命令 利用节点的唯一性和有序性实现互斥 高可用 好 好 好 高性能 一般 好 一般 安全性 断开连接，自动释放锁 利用锁超时时间，到期释放 临时节点，断开连接自动释放 基于 Redis 的分布式锁实现分布式锁时需要实现的两个基本方法： 获取锁 互斥：确保只能有一个线程获取锁 非阻塞：尝试一次，成功返回 true，失败返回 false 12# 添加锁，NX是互斥，EX是设置超时时间，要添加超时时间，避免服务宕机引起的死锁，将EX写在一条命令里，保证原子性SET lock thread01 NX EX 10; 释放锁 手动释放 超时释放 1DEL lock; 细节分析1加了 Redis 分布式锁之后，业务流程大致长这样： 看起来好像没什么问题，但是如果是下图中的情况，线程1执行的时候业务阻塞了，阻塞时间超过了锁的 key 的过期时间，那么超时就会自动释放锁，这时线程2一看锁被释放了，它抢到锁了，开始执行线程2中的业务，这时线程1不阻塞了，线程1业务完成之后释放锁了，这个时候释放的是线程2持有的锁，线程2的锁被线程1释放了，线程3一看锁被释放了，它又抢到了锁开始执行线程3的业务，但是此时线程2还未执行完，线程3也开始执行了，此时线程2、3并行运行了，就很有可能出现线程安全问题。 解决方案： 添加线程标识，任何线程在释放锁之前都要去判断当前业务的锁此刻被哪个线程持有。在一个线程获得锁的时候，设置键为锁前缀加当前业务名，设置值为当前线程标识。判断之后，如果从缓存中取出的线程标识和自己当前获取的线程标识一致，那么就释放锁，否则不操作。如下图：图中的“锁标识”，就是上面说的线程标识，用来标识当前锁被哪个线程持有。 业务流程变化为下面这样子： 这样就避免细节分析1中所说的隐患。 部分业务代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100/** * @author CHAN * @since 2022-03-31 */public interface ILock { boolean getLock(long timeoutSec); void releaseLock();}/*------------------------------------------------------------------------------*//** * 基于redis实现分布式锁 * @author CHAN * @since 2022-03-31 */public class SimpleLock implements ILock{ //业务名称 private final String businessName; private final StringRedisTemplate redisTemplate; private static final String KEY_PREFIX = &quot;lock:&quot;; private static final String ID_PREFIX = UUID.randomUUID().toString(true) + &quot;-&quot;; public SimpleLock(String businessName, StringRedisTemplate redisTemplate) { this.businessName = businessName; this.redisTemplate = redisTemplate; } /** * 添加分布式锁 * @param timeoutSec 分布式锁未释放，超时自动释放 * @return boolean */ @Override public boolean getLock(long timeoutSec) { //获取当前线程标识 String threadId = ID_PREFIX + Thread.currentThread().getId(); //获取锁 Boolean success = redisTemplate.opsForValue().setIfAbsent(KEY_PREFIX + businessName, threadId, timeoutSec, TimeUnit.SECONDS); return Boolean.TRUE.equals(success); } /** * 释放分布式锁 */ @Override public void releaseLock() { //获取当前线程标识 String threadId = ID_PREFIX + Thread.currentThread().getId(); //获取redis锁中的标识 String id = redisTemplate.opsForValue().get(KEY_PREFIX + businessName); //判断标识是否一致 if (Objects.equals(threadId, id)){ //一致则释放锁 redisTemplate.delete(KEY_PREFIX + businessName); } }}/*------------------------------------------------------------------------------*/@Transactionalpublic VoucherOrder updateStockAndSaveOrder2(Long voucherId) { Long userId = UserHolder.getUser().getId(); //以userId为键，锁user，降低锁粒度，提升效率 SimpleLock simpleLock = new SimpleLock(&quot;order:&quot; + userId, stringRedisTemplate); boolean lock = simpleLock.getLock(10); if (!lock) { return null; } else { try { //这里加锁的意义在于只能有一个线程去查询数据库中的订单，确保一人一单 QueryWrapper&lt;VoucherOrder&gt; queryWrapper = new QueryWrapper&lt;&gt;(); queryWrapper.eq(&quot;user_id&quot;, userId); queryWrapper.eq(&quot;voucher_id&quot;, voucherId); Integer count = voucherOrderMapper.selectCount(queryWrapper); if (count != 0) { //证明之前购买过 return null; } //扣减库存 UpdateWrapper&lt;SeckillVoucher&gt; updateWrapper = new UpdateWrapper&lt;&gt;(); updateWrapper.setSql(&quot;stock = stock - 1&quot;); updateWrapper.eq(&quot;voucher_id&quot;, voucherId); updateWrapper.gt(&quot;stock&quot;, 0); int modified = seckillVoucherMapper.update(null, updateWrapper); if (modified != 1) { return null; } VoucherOrder voucherOrder = new VoucherOrder(); voucherOrder.setVoucherId(voucherId); voucherOrder.setUserId(userId); voucherOrder.setId(idWorker.nextId(&quot;order&quot;)); voucherOrderMapper.insert(voucherOrder); return voucherOrder; } catch (Exception e) { e.printStackTrace(); } finally { simpleLock.releaseLock(); } } return null;} 细节分析2 这种情况是一种很极端的情况。线程1执行完业务逻辑，要释放锁，从缓存中获取线程标识并判断是否一致，结果一致，可以释放锁。可是就在快要释放锁还没释放的时候，线程1阻塞了，这时的阻塞不是因为业务阻塞，而很可能是 JVM 恰好此时进行垃圾回收了，可能是回收老年代，这时整个服务器都会 STW，从而造成阻塞，然后阻塞期间，分布式锁到达过期时间，超时释放了锁。然后因为服务是集群式部署，线程2在另一个服务器上，这时线程2一看，锁被释放了，然后线程2去抢锁并且成功抢到，然后线程2开始执行自己的业务代码。然鹅过一会，线程1所在的服务器垃圾清理完，阻塞解除恢复运行，线程1啪嚓释放锁，因为线程1在前面判断过线程标识一致了，不会重复判断，直接把此时线程2持有的锁释放了。线程3一看锁被释放了，线程3去抢锁并成功抢到，线程3开始执行自己的业务代码，此时线程2、3并行执行，就会出现线程安全问题。 解决方案： 思路主要是围绕：确保判断锁标识的动作和释放锁的动作，两个动作的原子性，一起执行成功或失败。一聊到原子性，那么就很容易想到事务，没错，Redis 中也有事务，但是 Redis 中的事务和我们所了解的 MySQL 的事务是有很大差别的，因此这里不介绍 Redis 的事务方案了。我们使用 Redis 的 Lua 脚本来实现这两个动作的“原子性”。 Redis 的 Lua 脚本Redis 提供了 Lua 脚本功能，在一个脚本中编写多条 Redis 命令，确保多条命令执行时的原子性。Lua 是一种编程语言，它的基本语法大家可以参考网站：https://www.runoob.com/lua/lua-tutorial.html。这里重点介绍Redis提供的调用函数，语法如下： 12-- 执行redis命令redis.call('命令名称', 'key', '其它参数', ...) 例如，我们要执行set name jack，则脚本是这样： 12-- 执行 set name jackredis.call('set', 'name', 'jack') 例如，我们要先执行set name Rose，再执行get name，保证这两个动作的原子性，就把两条命令写入一个脚本，以脚本为单位执行。则脚本如下： 123456-- 先执行 set name jackredis.call('set', 'name', 'jack')-- 再执行 get namelocal name = redis.call('get', 'name')-- 返回return name 写好脚本以后，需要用Redis命令来调用脚本，调用脚本的常见命令如下： 例如，我们要执行 redis.call('set', 'name', 'jack') 这个脚本，语法如下：EVAL “脚本” 注：Redis 里面的参数分为两类 key 类型的参数，比如上面案例中的 name； 另一个就是其它参数，比如案例中的 jack； 如果脚本中的 key、value 不想写死，可以作为参数传递。key 类型参数会放入 KEYS 数组，其它参数会放入 ARGV 数组，在脚本中可以从 KEYS 和 ARGV 数组获取这些参数： 注：与 Java 语言不同的是，在 Lua 语言中，索引下标是从1开始的，因此这里的 KEYS[1]、ARGV[1] 都是数组中的第一个元素。 练习： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113127.0.0.1:6379&gt; keys * 1) &quot;zs&quot; 2) &quot;bbbbb&quot; 3) &quot;cache:shop:types&quot; 4) &quot;aaaaa&quot; 5) &quot;user:1&quot; 6) &quot;ls&quot; 7) &quot;cache:shop:1&quot; 8) &quot;user:2&quot; 9) &quot;stu&quot;10) &quot;incr:order:2022:03:31&quot;11) &quot;incr:order:2022:03:30&quot;12) &quot;exam&quot;127.0.0.1:6379&gt; get name(nil)----------------------------------------------------------------127.0.0.1:6379&gt; EVAL &quot;return redis.call('set','name','chan')&quot; 0OK127.0.0.1:6379&gt; get name&quot;chan&quot;------------------------------------------------------------------ 使用redis调用lua脚本的方式来存入string类型的value-- 在key、value不想写死，想作为参数传递时，KEYS和ARGV不能小写，否则报错！127.0.0.1:6379&gt; eval &quot;return redis.call('set', keys[1], argv[1])&quot; 1 name chanservy(error) ERR Error running script (call to f_a3d2706d73040d2c4e982bb2bb686692d05f34a7): @enable_strict_lua:15: user_script:1: Script attempted to access nonexistent global variable 'keys'127.0.0.1:6379&gt; eval &quot;return redis.call('set', KEYS[1], ARGV[1])&quot; 1 name chanservyOK127.0.0.1:6379&gt; get name&quot;chanservy&quot;------------------------------------------------------------------ 使用redis调用lua脚本的方式来存入多组string类型的value-- 在使用mset时，设置几组键值对，key类型的参数个数就设置几个。-- 当前面顺序是：KEYS[1], KEYS[2], ARGV[1], ARGV[2]时，后面设置值的顺序如果也是键键值值，那么设置结果会错乱。127.0.0.1:6379&gt; eval &quot;return redis.call('mset', KEYS[1], KEYS[2], ARGV[1], ARGV[2])&quot; 2 age sport 22 runOK127.0.0.1:6379&gt; keys * 1) &quot;zs&quot; 2) &quot;bbbbb&quot; 3) &quot;cache:shop:types&quot; 4) &quot;aaaaa&quot; 5) &quot;user:1&quot; 6) &quot;ls&quot; 7) &quot;cache:shop:1&quot; 8) &quot;user:2&quot; 9) &quot;age&quot;10) &quot;stu&quot;11) &quot;incr:order:2022:03:31&quot;12) &quot;name&quot;13) &quot;incr:order:2022:03:30&quot;14) &quot;22&quot;15) &quot;exam&quot;-- 结果错乱127.0.0.1:6379&gt; get age&quot;sport&quot;127.0.0.1:6379&gt; get 22&quot;run&quot;127.0.0.1:6379&gt; del age 22(integer) 2--------------------------------------------------------------------- 当前面顺序是：KEYS[1], KEYS[2], ARGV[1], ARGV[2]时，后面设置值的顺序必须是键值键值，这样设置的结果就不会错乱。127.0.0.1:6379&gt; eval &quot;return redis.call('mset', KEYS[1], KEYS[2], ARGV[1], ARGV[2])&quot; 2 age 22 sport runOK127.0.0.1:6379&gt; keys * 1) &quot;zs&quot; 2) &quot;bbbbb&quot; 3) &quot;cache:shop:types&quot; 4) &quot;aaaaa&quot; 5) &quot;user:1&quot; 6) &quot;sport&quot; 7) &quot;ls&quot; 8) &quot;cache:shop:1&quot; 9) &quot;user:2&quot;10) &quot;age&quot;11) &quot;stu&quot;12) &quot;incr:order:2022:03:31&quot;13) &quot;name&quot;14) &quot;incr:order:2022:03:30&quot;15) &quot;exam&quot;127.0.0.1:6379&gt; get age&quot;22&quot;127.0.0.1:6379&gt; get sport&quot;run&quot;---------------------------------------------------------------------------- 当前面顺序是：KEYS[1], ARGV[1], KEYS[2], ARGV[2]时，后面设置值的顺序如果也是键值键值，那么设置结果会错乱127.0.0.1:6379&gt; eval &quot;return redis.call('mset', KEYS[1], ARGV[1], KEYS[2], ARGV[2])&quot; 2 age 23 sport runningOK-- 结果错乱127.0.0.1:6379&gt; get age&quot;sport&quot;127.0.0.1:6379&gt; get 23&quot;running&quot;---------------------------------------------------------------------------- 当前面顺序是：KEYS[1], ARGV[1], KEYS[2], ARGV[2]时，后面设置值的顺序必须是键键值值，这样设置的结果就不会错乱。127.0.0.1:6379&gt; eval &quot;return redis.call('mset', KEYS[1], ARGV[1], KEYS[2], ARGV[2])&quot; 2 age sport 25 runningOK127.0.0.1:6379&gt; get age&quot;25&quot;127.0.0.1:6379&gt; get sport&quot;running&quot;----------------------------------------------------------------------------- 使用redis调用lua脚本的方式来存入hash类型的value127.0.0.1:6379&gt; eval &quot;return redis.call('hset', KEYS[1], ARGV[1], ARGV[2])&quot; 1 classroom stuNum 30(integer) 1127.0.0.1:6379&gt; hget classroom stuNum&quot;30&quot;127.0.0.1:6379&gt; 现在回到原来的问题，我们要保证判断锁标识和释放锁两个动作的原子性。基于 Redis 的分布式锁，回顾我们前面研究过的，在释放锁的时候，整体的业务流程是这样的： 从 Redis 中获取锁中的线程标识 判断是否与指定的标识（当前线程标识）一致 如果一致则释放锁（删除） 如果不一致则什么都不做 我们前面是在 Java 代码中实现上述的逻辑的，现在用 Lua 语言逻辑实现一下： 12345678910111213-- redis锁的keylocal key = &quot;lock:order:2&quot;;-- 当前线程标识local threadId = &quot;hcuisjfoehnsdkfcjnseuf-33&quot;;-- 获取锁中的线程标识local id = redis.call('get', key);-- 比较当前线程标识与锁中的线程标识是否一致if id == threadId then -- 一致，释放锁 return redis.call('del', key);end-- 不一致，什么都不做return 0; 我们稍作改进，不把脚本中的 key、value 写死，可以作为参数传递： 12345678910111213-- redis锁的key，这里作为参数在java程序中传过来local key = KEYS[1];-- 当前线程标识，这里作为参数在java程序中获取到传过来local threadId = ARGV[1];-- 获取锁中的线程标识，redis中的local id = redis.call('get', key);-- 比较当前线程标识与锁中的线程标识是否一致if id == threadId then -- 一致，释放锁 return redis.call('del', key);end-- 不一致，什么都不做return 0; 最终也可以简化为： 12345678-- 这里的 KEYS[1] 就是锁的key，这里的ARGV[1] 就是当前线程标示-- 获取锁中的标示，判断是否与当前线程标示一致if (redis.call('GET', KEYS[1]) == ARGV[1]) then -- 一致，则删除锁 return redis.call('DEL', KEYS[1])end-- 不一致，则直接返回return 0 再次改进 Redis 的分布式锁基于 Lua 脚本实现 Redis 分布式锁的释放锁逻辑，RedisTemplate 调用 Lua 脚本的 API 如下： 代码改动如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** * 基于redis实现分布式锁 * @author CHAN * @since 2022-03-31 */public class SimpleLock implements ILock{ //业务名称 private final String businessName; private final StringRedisTemplate redisTemplate; public SimpleLock(String businessName, StringRedisTemplate redisTemplate) { this.businessName = businessName; this.redisTemplate = redisTemplate; } private static final String KEY_PREFIX = &quot;lock:&quot;; private static final String ID_PREFIX = UUID.randomUUID().toString(true) + &quot;-&quot;; private static final DefaultRedisScript&lt;Long&gt; UNLOCK_SCRIPT; static { // 静态的，在类的初始化阶段执行，初始化只在类加载的时候执行一次，这样不用每次释放锁都去加载lua脚本文件，减少IO，提升效率 UNLOCK_SCRIPT = new DefaultRedisScript&lt;&gt;(); UNLOCK_SCRIPT.setLocation(new ClassPathResource(&quot;unlock.lua&quot;)); UNLOCK_SCRIPT.setResultType(Long.class); } /** * 添加分布式锁 * @param timeoutSec 分布式锁未释放，超时自动释放 * @return boolean */ @Override public boolean getLock(long timeoutSec) { //获取当前线程标识 String threadId = ID_PREFIX + Thread.currentThread().getId(); //获取锁 Boolean success = redisTemplate.opsForValue().setIfAbsent(KEY_PREFIX + businessName, threadId, timeoutSec, TimeUnit.SECONDS); return Boolean.TRUE.equals(success); } /** * 释放分布式锁，使用lua脚本的方式 */ @Override public void releaseLock() { List&lt;String&gt; key = Collections.singletonList(KEY_PREFIX + businessName); String threadID = ID_PREFIX + Thread.currentThread().getId(); //调用Lua脚本，判断线程标识和释放锁放在一个脚本中，保证原子性 redisTemplate.execute(UNLOCK_SCRIPT, key, threadID); } /* 之前的实现方式，可以看到判断线程标识和释放锁是两句代码，不能保证原子性 @Override public void releaseLock() { //获取当前线程标识 String threadId = ID_PREFIX + Thread.currentThread().getId(); //获取redis锁中的标识 String id = redisTemplate.opsForValue().get(KEY_PREFIX + businessName); //判断标识是否一致 if (Objects.equals(threadId, id)){ //一致则释放锁 redisTemplate.delete(KEY_PREFIX + businessName); } }*/} 总结大致思路：在使用 Redis 的分布式锁时：在获取锁的时候，为了防止后期死锁的问题，我们一般需要加一个锁的过期时间，并且注意获取锁和设置锁的过期时间两个操作的原子性；在释放锁的时候，需要注意，如果当前线程执行业务的时间过长，可能比我们设置的锁的过期时间还要长，导致锁到了过期时间自己释放了，这时这把分布式锁可能被其它线程获取到，然后当前线程执行到最后释放锁，这时相当于把其它线程的锁释放了，因此在获取锁的时候，我们需要把 Redis 中代表锁的 key 对应的 value 设置一个标识，这个 value 可以是 UUID + 当前线程的 id，然后在当前线程释放锁之前先获取一下 value，判断一下这把锁是否仍然被当前线程所持有，是则释放锁，否则不操作。最后注意一点：保证判断线程标识和释放锁两个动作的原子性。原因很简单：当前线程根据 key 获取到了 value，判断确实是当前线程在持有，准备释放锁，可是就在释放锁之前，恰好这时锁到期了自动释放了，而且又被其它线程获取到了。然后当前线程开始执行释放锁的代码，那就相当于又是释放了其它线程的锁。 基于 Redis 的分布式锁实现思路： 利用 set nx ex 获取锁，并根据业务估算设置过期时间，并保存线程标识 释放锁的时候先判断 Redis 锁中的线程标识与当前自己的线程标识是否一致，一致则删除锁，防止误删。 保证判断线程标识和释放锁两个动作的原子性 特性： 利用 set nx 满足互斥性 利用 set ex 保证程序故障时锁依然能释放，避免死锁，提高安全性 利用 Redis 集群保证高可用和高并发特性 至此，我们自己实现的 Redis 分布式锁，已经具备线上生产可用的能力。 Redis 的分布式锁优化虽然我们实现了一个生产可用的基于 Redis 的分布式锁，但是基于 setnx 实现的分布式锁存在下面的问题： 不可重入：同一个线程无法多次获取同一把锁。 不可重试：获取锁只尝试一次就返回 false，没有重试机制。 超时释放：锁超时释放虽然可以避免死锁，但如果是业务执行耗时较长，也会导致锁释放，存在安全隐患。 主从一致性：如果 Redis 是主从架构，主从同步存在延迟，当主宕机时，如果从节点没有同步主节点中的锁数据，则会出现锁失效。 这个时候虽然可以参考 ReentrantLock 的底层实现，但是自己实现起来很繁琐。所以我们可以借助 Redisson。 RedissonRedisson 是一个在 Redis 的基础上实现的 Java 驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的 Java 常用对象，还提供了许多分布式服务，其中就包含了各种分布式锁的实现。 通俗点讲，Redisson 是一个在 Redis 的基础上实现的一个分布式工具的集合，也就是说，在分布式系统下需要用到的各种各样的工具它都有，分布式锁只是它的一个子集，其中就包含了各种分布式锁的实现： 官网地址： https://redisson.org； GitHub地址： https://github.com/redisson/redisson。 Redisson 项目介绍 Redisson 入门1、引入依赖，注：虽然 springboot 提供了 starter 的方式引入，并且可以以 boot 的方式将配置项配置到 yml 中，但是这里不建议那样引入和配置。因为那样的话会覆盖掉 springboot 对于 redis 原有的默认配置。 12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.17.0&lt;/version&gt;&lt;/dependency&gt; 2、配置 Redisson 客户端 123456789101112@Configurationpublic class RedisConfig { @Bean public RedissonClient redisClient(){ //配置类 Config config = new Config(); // 添加redis地址，这里添加了单点的地址，也可以使用config.useClusterServers()添加集群地址 config.useSingleServer().setAddress(&quot;redis://192.168.1.107:6379&quot;).setPassword(&quot;123456&quot;); //创建客户端 return Redisson.create(config); }} 3、使用Redisson的分布式锁 1234567891011121314151617@Testpublic void testRedisson() throws InterruptedException { // 获取锁（可重入），指定锁的名称 RLock lock = redissonClient.getLock(&quot;testLock&quot;); // 尝试获取锁，参数分别是：获取锁的最大等待时间（期间会重试，不写会默认-1，不等待），锁自动释放时间（不写默认30s），时间单位 // true代表获取到分布式锁，存在redis中的格式 key:testLock field:bd32e60a-8e52-455f-a4a9-6262d39c976f:1 value:1 boolean isLock = lock.tryLock(1, 10, TimeUnit.SECONDS); // 判断释放获取成功 if (isLock) { try { System.out.println(&quot;执行业务逻辑...&quot;); } finally { // 释放锁 lock.unlock(); } }} Redisson 分布式锁可重入其实 Redisson 可重入的原理和 ReentrantLock 的可重入原理是一样的。可以看看 ReentrantLock 的可重入原理源码解析： ReentrantLock 的可重入原理 在 ReentrantLock 中，加锁时，如果发现 state 不为 0，并且 owner 是当前线程的话，就代表锁重入，让 state 自增；解锁时，让 state 自减，直到减为 0，才真正解开。所以在 Redisson 的分布式锁的可重入实现中也有一个计数，用来表示当前线程获取了几次分布式锁。前面我们自己实现的 Redis 分布式锁使用的是 String 类型的 value，但是 Redisson 的分布式锁中不仅要记录锁的线程标识还要记录重入的数值。因此，显而易见，在 Redisson 分布式锁的底层使用的是 redis 的 hash 类型的 value。 12345678910111213141516171819202122232425262728// Redisson分布式锁是可重入的RLock lock = redissonClient.getLock(&quot;lock&quot;);@Testpublic void method1() throws InterruptedException { boolean isLock = lock.tryLock(); if (!isLock) { log.error(&quot;获取锁失败，1&quot;); } try { log.info(&quot;获取锁成功，1&quot;); method2(); } finally { log.info(&quot;释放锁，1&quot;); lock.unlock(); }}public void method2() { boolean isLock = lock.tryLock(); if (!isLock) { log.error(&quot;获取锁失败，2&quot;); } try { log.info(&quot;获取锁成功，2&quot;); } finally { log.info(&quot;释放锁，2&quot;); lock.unlock(); }} 可重入原理图 获取锁的 Lua 脚本1234567891011121314151617181920local key = KEYS[1]; -- 锁的keylocal threadId = ARGV[1]; -- 线程唯一标识local releaseTime = ARGV[2]; -- 锁的自动释放时间-- 判断是否存在if(redis.call('exists', key) == 0) then -- 不存在, 获取锁 redis.call('hset', key, threadId, '1'); -- 设置有效期 redis.call('expire', key, releaseTime); return 1; -- 返回结果end;-- 锁已经存在，判断threadId是否是自己if(redis.call('hexists', key, threadId) == 1) then -- 存在(threadId是自己), 获取锁，重入次数+1 redis.call('hincrby', key, threadId, '1'); -- 重置有效期 redis.call('expire', key, releaseTime); return 1; -- 返回结果end;return 0; -- 代码走到这里,说明持有锁的不是自己，获取锁失败 释放锁的 Lua 脚本123456789101112131415161718local key = KEYS[1];-- 锁的keylocal threadId = ARGV[1]; -- 线程唯一标识local releaseTime = ARGV[2]; -- 锁的自动释放时间-- 判断当前锁是否还是被自己持有if (redis.call('HEXISTS', key, threadId) == 0) then return nil; -- 如果已经不是自己，则直接返回end;-- 是自己的锁，则重入次数-1local count = redis.call('HINCRBY', key, threadId, -1);-- 判断是否重入次数是否已经为0 if (count &gt; 0) then -- 大于0说明不能释放锁，重置有效期然后返回 redis.call('EXPIRE', key, releaseTime); return nil;else -- 等于0说明可以释放锁，直接删除 redis.call('DEL', key); return nil;end; Redisson 分布式锁原理图这张图是根据 Redisson 的底层源码逻辑流程画的，其中能充分表现 Redisson 分布式锁的“重入、可重试、超时释放机制”这几个重要的特性。 Redisson 分布式锁原理总结： 可重入：利用 redis 的 hash 结构记录线程 id 和重入次数。 可重试：利用信号量和 PubSub 功能实现等待、唤醒，就是获取锁失败的重试机制。 超时续约：利用 watchDog 看门狗机制，每隔一段时间（releaseTime / 3 = 10s），重置超时时间为 30s。具体原理看图。 主从一致性：如果 Redis 是主从架构，主从同步存在延迟，当主宕机时，如果从节点没有同步主节点中的锁数据，则会出现锁失效，其它线程可以获取锁，造成线程安全问题。为了避免上述的问题，Redisson 对于这个问题的解决方案简单粗暴，不采用一主多从模式，而是多主多从模式。也就是说多个独立的 Redis 节点，必须在所有节点都获取重入锁，才算获取锁成功。 Redisson 之分布式锁和同步器可重入锁（Reentrant Lock）基于Redis的Redisson分布式可重入锁RLock Java对象实现了java.util.concurrent.locks.Lock接口。同时还提供了异步（Async）、反射式（Reactive）和RxJava2标准的接口。 123RLock lock = redisson.getLock(&quot;anyLock&quot;);// 最常见的使用方法lock.lock();// 获取锁失败一直等待 大家都知道，如果负责储存这个分布式锁的Redisson节点宕机以后，而且这个锁正好处于锁住的状态时，这个锁会出现锁死的状态。为了避免这种情况的发生，Redisson内部提供了一个监控锁的看门狗，它的作用是在Redisson实例被关闭前，不断的延长锁的有效期。默认情况下，看门狗的检查锁的超时时间是30秒钟，也可以通过修改Config.lockWatchdogTimeout来另行指定。 另外Redisson还通过加锁的方法提供了leaseTime的参数来指定加锁的时间。超过这个时间后锁便自动解开了。 12345678910111213// 加锁以后10秒钟自动解锁// 无需调用unlock方法手动解锁lock.lock(10, TimeUnit.SECONDS);// 尝试加锁，失败最多等待100秒，上锁以后10秒自动解锁boolean res = lock.tryLock(100, 10, TimeUnit.SECONDS);if (res) { try { ... } finally { lock.unlock(); }} Redisson同时还为分布式锁提供了异步执行的相关方法： 1234RLock lock = redisson.getLock(&quot;anyLock&quot;);lock.lockAsync();lock.lockAsync(10, TimeUnit.SECONDS);Future&lt;Boolean&gt; res = lock.tryLockAsync(100, 10, TimeUnit.SECONDS); RLock对象完全符合Java的Lock规范。也就是说只有拥有锁的进程才能解锁，其他进程解锁则会抛出IllegalMonitorStateException错误。但是如果遇到需要其他进程也能解锁的情况，请使用分布式信号量Semaphore 对象. 公平锁（Fair Lock）基于Redis的Redisson分布式可重入公平锁也是实现了java.util.concurrent.locks.Lock接口的一种RLock对象。同时还提供了异步（Async）、反射式（Reactive）和RxJava2标准的接口。它保证了当多个Redisson客户端线程同时请求加锁时，优先分配给先发出请求的线程。所有请求线程会在一个队列中排队，当某个线程出现宕机时，Redisson会等待5秒后继续下一个线程，也就是说如果前面有5个线程都处于等待状态，那么后面的线程会等待至少25秒。 123RLock fairLock = redisson.getFairLock(&quot;anyLock&quot;);// 最常见的使用方法fairLock.lock(); 大家都知道，如果负责储存这个分布式锁的Redis节点宕机以后，而且这个锁正好处于锁住的状态时，这个锁会出现锁死的状态。为了避免这种情况的发生，Redisson内部提供了一个监控锁的看门狗，它的作用是在Redisson实例被关闭前，不断的延长锁的有效期。默认情况下，看门狗的检查锁的超时时间是30秒钟，也可以通过修改Config.lockWatchdogTimeout来另行指定。 另外Redisson还通过加锁的方法提供了leaseTime的参数来指定加锁的时间。超过这个时间后锁便自动解开了。 12345678// 10秒钟以后自动解锁// 无需调用unlock方法手动解锁fairLock.lock(10, TimeUnit.SECONDS);// 尝试加锁，最多等待100秒，上锁以后10秒自动解锁boolean res = fairLock.tryLock(100, 10, TimeUnit.SECONDS);...fairLock.unlock(); Redisson同时还为分布式可重入公平锁提供了异步执行的相关方法： 1234RLock fairLock = redisson.getFairLock(&quot;anyLock&quot;);fairLock.lockAsync();fairLock.lockAsync(10, TimeUnit.SECONDS);Future&lt;Boolean&gt; res = fairLock.tryLockAsync(100, 10, TimeUnit.SECONDS); 联锁（MultiLock）基于Redis的Redisson分布式联锁RedissonMultiLock对象可以将多个RLock对象关联为一个联锁，每个RLock对象实例可以来自于不同的Redisson实例。 12345678910RLock lock1 = redissonInstance1.getLock(&quot;lock1&quot;);RLock lock2 = redissonInstance2.getLock(&quot;lock2&quot;);RLock lock3 = redissonInstance3.getLock(&quot;lock3&quot;);RedissonMultiLock lock = new RedissonMultiLock(lock1, lock2, lock3);// 同时加锁：lock1 lock2 lock3// 所有的锁都上锁成功才算成功。lock.lock();...lock.unlock(); 大家都知道，如果负责储存某些分布式锁的某些Redis节点宕机以后，而且这些锁正好处于锁住的状态时，这些锁会出现锁死的状态。为了避免这种情况的发生，Redisson内部提供了一个监控锁的看门狗，它的作用是在Redisson实例被关闭前，不断的延长锁的有效期。默认情况下，看门狗的检查锁的超时时间是30秒钟，也可以通过修改Config.lockWatchdogTimeout来另行指定。 另外Redisson还通过加锁的方法提供了leaseTime的参数来指定加锁的时间。超过这个时间后锁便自动解开了。 12345678RedissonMultiLock lock = new RedissonMultiLock(lock1, lock2, lock3);// 给lock1，lock2，lock3加锁，如果没有手动解开的话，10秒钟后将会自动解开lock.lock(10, TimeUnit.SECONDS);// 为加锁等待100秒时间，并在加锁成功10秒钟后自动解开boolean res = lock.tryLock(100, 10, TimeUnit.SECONDS);...lock.unlock(); 红锁（RedLock）基于Redis的Redisson红锁RedissonRedLock对象实现了Redlock介绍的加锁算法。该对象也可以用来将多个RLock对象关联为一个红锁，每个RLock对象实例可以来自于不同的Redisson实例。 12345678910RLock lock1 = redissonInstance1.getLock(&quot;lock1&quot;);RLock lock2 = redissonInstance2.getLock(&quot;lock2&quot;);RLock lock3 = redissonInstance3.getLock(&quot;lock3&quot;);RedissonRedLock lock = new RedissonRedLock(lock1, lock2, lock3);// 同时加锁：lock1 lock2 lock3// 红锁在大部分节点上加锁成功就算成功。lock.lock();...lock.unlock(); 大家都知道，如果负责储存某些分布式锁的某些Redis节点宕机以后，而且这些锁正好处于锁住的状态时，这些锁会出现锁死的状态。为了避免这种情况的发生，Redisson内部提供了一个监控锁的看门狗，它的作用是在Redisson实例被关闭前，不断的延长锁的有效期。默认情况下，看门狗的检查锁的超时时间是30秒钟，也可以通过修改Config.lockWatchdogTimeout来另行指定。 另外Redisson还通过加锁的方法提供了leaseTime的参数来指定加锁的时间。超过这个时间后锁便自动解开了。 12345678RedissonRedLock lock = new RedissonRedLock(lock1, lock2, lock3);// 给lock1，lock2，lock3加锁，如果没有手动解开的话，10秒钟后将会自动解开lock.lock(10, TimeUnit.SECONDS);// 为加锁等待100秒时间，并在加锁成功10秒钟后自动解开boolean res = lock.tryLock(100, 10, TimeUnit.SECONDS);...lock.unlock(); 读写锁（ReadWriteLock）对比 JUC 中的读写锁：ReadWriteLock 基于Redis的Redisson分布式可重入读写锁RReadWriteLock Java对象实现了java.util.concurrent.locks.ReadWriteLock接口。其中读锁和写锁都继承了RLock接口。 分布式可重入读写锁允许同时有多个读锁和一个写锁处于加锁状态。 12345RReadWriteLock rwlock = redisson.getReadWriteLock(&quot;anyRWLock&quot;);// 最常见的使用方法rwlock.readLock().lock();// 或rwlock.writeLock().lock(); 大家都知道，如果负责储存这个分布式锁的Redis节点宕机以后，而且这个锁正好处于锁住的状态时，这个锁会出现锁死的状态。为了避免这种情况的发生，Redisson内部提供了一个监控锁的看门狗，它的作用是在Redisson实例被关闭前，不断的延长锁的有效期。默认情况下，看门狗的检查锁的超时时间是30秒钟，也可以通过修改Config.lockWatchdogTimeout来另行指定。 另外Redisson还通过加锁的方法提供了leaseTime的参数来指定加锁的时间。超过这个时间后锁便自动解开了。 123456789101112// 10秒钟以后自动解锁// 无需调用unlock方法手动解锁rwlock.readLock().lock(10, TimeUnit.SECONDS);// 或rwlock.writeLock().lock(10, TimeUnit.SECONDS);// 尝试加锁，最多等待100秒，上锁以后10秒自动解锁boolean res = rwlock.readLock().tryLock(100, 10, TimeUnit.SECONDS);// 或boolean res = rwlock.writeLock().tryLock(100, 10, TimeUnit.SECONDS);...lock.unlock(); 案例： 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 读写锁的用法：改数据加写锁，读数据加读锁 */@GetMapping(&quot;/read&quot;)@ResponseBodypublic String read() { RReadWriteLock lock = redissonClient.getReadWriteLock(&quot;rw-lock&quot;); RLock rLock = lock.readLock(); String s = &quot;&quot;; rLock.lock(); try { System.out.println(&quot;读锁加锁&quot; + Thread.currentThread().getId()); Thread.sleep(5000); s = redisTemplate.opsForValue().get(&quot;writeValue&quot;); } catch (InterruptedException e) { e.printStackTrace(); } finally { rLock.unlock(); } return &quot;读取完成:&quot; + s;}@GetMapping(&quot;/write&quot;)@ResponseBodypublic String write() { String s = &quot;&quot;; RReadWriteLock lock = redissonClient.getReadWriteLock(&quot;rw-lock&quot;); RLock wLock = lock.writeLock(); wLock.lock(); try { System.out.println(&quot;写锁加锁&quot; + Thread.currentThread().getId()); s = UUID.randomUUID().toString(); Thread.sleep(10000); redisTemplate.opsForValue().set(&quot;writeValue&quot;, s); } catch (InterruptedException e) { e.printStackTrace(); } finally { wLock.unlock(); } return &quot;写入完成:&quot; + s;} 注：写锁是一个排他锁（互斥锁、独占锁）；读锁是一个共享锁。 读 + 读：相当于无锁，并发读，只会在 redis 中记录好所有当前的读锁，它们都会同时加锁成功。 写 + 读：获取读锁要等待写锁释放。 写 + 写：阻塞、互斥。 读 + 写：获取写锁要等待读锁释放。 信号量（Semaphore）对比 JUC 中的信号量：Semaphore 基于Redis的Redisson的分布式信号量（Semaphore）Java对象RSemaphore采用了与java.util.concurrent.Semaphore相似的接口和用法。同时还提供了异步（Async）、反射式（Reactive）和RxJava2标准的接口。 123456789101112131415RSemaphore semaphore = redisson.getSemaphore(&quot;semaphore&quot;);semaphore.acquire();//或semaphore.acquireAsync();semaphore.acquire(23);semaphore.tryAcquire();//或semaphore.tryAcquireAsync();semaphore.tryAcquire(23, TimeUnit.SECONDS);//或semaphore.tryAcquireAsync(23, TimeUnit.SECONDS);semaphore.release(10);semaphore.release();//或semaphore.releaseAsync(); 案例：车库停车，一共 3 个车位。 模拟，手动将名为 park 的信号量在 redis 中放入一份，key 为 park，类型为 String，车位有三个，value 设为 3。 12345678910111213141516171819@GetMapping(&quot;/park&quot;)@ResponseBodypublic String park() { RSemaphore park = redissonClient.getSemaphore(&quot;park&quot;); try { park.acquire();// 获取一个信号，占一个车位 } catch (InterruptedException e) { e.printStackTrace(); } return &quot;ok&quot;;}@GetMapping(&quot;/go&quot;)@ResponseBodypublic String go() { RSemaphore park = redissonClient.getSemaphore(&quot;park&quot;); park.release();// 释放一个信号，腾出来一个车位 return &quot;ok&quot;;} 上面代码中使用的是park.acquire();，当三个车位全都占满，第四台车来了就得等着，一直等到有释放的车位，再将车停进去。如果使用park.tryAcquire();时，就是停车的时候车主瞅一眼，有空车位就停，没空车位不等直接溜了。就是尝试获取一下，不行就算了。 这个 Redisson 的分布式信号量也可以做分布式限流，和车库停车一个思想。 可过期性信号量（PermitExpirableSemaphore）基于Redis的Redisson可过期性信号量（PermitExpirableSemaphore）是在RSemaphore对象的基础上，为每个信号增加了一个过期时间。每个信号可以通过独立的ID来辨识，释放时只能通过提交这个ID才能释放。它提供了异步（Async）、反射式（Reactive）和RxJava2标准的接口。 123456RPermitExpirableSemaphore semaphore = redisson.getPermitExpirableSemaphore(&quot;mySemaphore&quot;);String permitId = semaphore.acquire();// 获取一个信号，有效期只有2秒钟。String permitId = semaphore.acquire(2, TimeUnit.SECONDS);// ...semaphore.release(permitId); 闭锁（CountDownLatch）基于Redisson的Redisson分布式闭锁（CountDownLatch）Java对象RCountDownLatch采用了与java.util.concurrent.CountDownLatch相似的接口和用法。 用法：在多线程任务调度的时候使用 CountDownLatch，比如有十个线程，这十个线程都给我把任务做完了，那才算全部完成，才能往下继续执行代码，否则要等待。 场景：英雄联盟十位玩家全部加载完成才能进入游戏。 Redisson 的 CountDownLatch 和 JUC 中的思想是一样的，只不过一个是单体应用中，一个是分布式场景下。 对比 JUC 中的 CountDownLatch：CountDownLatch 1234567RCountDownLatch latch = redisson.getCountDownLatch(&quot;anyCountDownLatch&quot;);latch.trySetCount(10);latch.await();// 在其他线程或其他JVM里RCountDownLatch latch = redisson.getCountDownLatch(&quot;anyCountDownLatch&quot;);latch.countDown(); 案例： 学校一共 5 个班，放学，锁门，学校的门卫要等 5 个班全部走完，才可以锁大门。 1234567891011121314151617181920@GetMapping(&quot;/lockDoor&quot;)@ResponseBodypublic String lockDoor() { RCountDownLatch latch = redissonClient.getCountDownLatch(&quot;CountDownLatch&quot;); try { latch.trySetCount(5); latch.await();// 等待闭锁都完成 } catch (InterruptedException e) { e.printStackTrace(); } return &quot;锁大门！&quot;;}@GetMapping(&quot;/leaveSchool/{id}&quot;)@ResponseBodypublic String leaveSchool(@PathVariable(&quot;id&quot;) Long id) { RCountDownLatch latch = redissonClient.getCountDownLatch(&quot;CountDownLatch&quot;); latch.countDown();// 计数-1 return id + &quot;班的人都走了。&quot;;} 总结 不可重入 Redis 分布式锁： 原理：利用 setnx 的互斥性；利用 ex 避免死锁；释放锁时判断线程标示 缺陷：不可重入、无法重试、锁超时失效 可重入的 Redis 分布式锁——Redisson： 原理：利用 hash 结构，记录线程标示和重入次数；利用 watchDog 延续锁时间；利用信号量控制锁重试等待 缺陷：redis 宕机引起锁失效问题 Redisson 的 multiLock： 原理：多个独立的 Redis 节点，必须在所有节点都获取重入锁，才算获取锁成功 缺陷：运维成本高、实现复杂 Redis优化秒杀前面几种方案，在判断完有购买资格，然后需要操作数据库扣减库存并且将订单数据入库之后，才会返回结果，这一系列的操作都是同步的，也就是说，最终是在一系列对数据库的操作之后才会返回结果给前端，进而才会给客户响应，这样的耗时可能很长。如果我们让数据库的一系列操作异步去执行，也就是在判断完购买资格之后就返回结果，然后扣减库存和订单信息入库操作异步去执行，那样用户体验感会更佳。 并且前面我们是使用了锁，在同步代码块中判断“一人一单”的逻辑，然后进行扣减库存最后释放锁，这样加锁的操作固然能避免线程安全问题，但是也同样降低了效率。我们这次将这块逻辑放在一个 lua 脚本中完成，redis 在调用脚本运行的时候，是以脚本为单位的，也就是说整个脚本中的逻辑可以保证原子性，并且可以保证线程安全。 Redis 调用 Lua 脚本的执行方式： Redis 可以保证以原子方式执行脚本：执行脚本时不会执行其他脚本或 Redis 命令。类似于给 lua 脚本中的这段代码加了锁 ，可能 redis 内部实现和我们在程序中加锁会有一定的差异，反正大致意思就是这样。 Redis 使用同一个 Lua 解释器来执行所有命令，同时，Redis 保证以一种原子性的方式来执行脚本：当 lua 脚本在执行的时候，不会有其他脚本和命令同时执行，这种语义类似于 MULTI（互斥）/EXEC。从别的客户端的视角来看，一个 lua 脚本要么不可见，要么已经执行完。 优化方式一：Lua 脚本、阻塞队列 + 线程池 + 任务。 在 lua 脚本中判断并扣减库存、判断一人一单。lua 判断后有资格，才会异步去数据库中扣减库存、订单信息入库。前提是，添加优惠券信息的时候进行缓存预热操作，将优惠券的初始库存放入缓存中，使用 String 类型的 value 就可以，因为还需要在脚本中进行一人一单的判断，我们将每次在判断完有资格的用户 id 存入缓存中，因为一人一单，所以对一个优惠券下单的用户 id 只能有一个，因此不能重复，我们使用 redis 的 set 类型的 value 。脚本代码如下： （注：不要忘记库存的数据预热，否则在执行脚本代码时会出现空指针异常！） 123456789101112131415161718192021222324252627--- 参数列表--- 优惠券idlocal voucherId = ARGV[1];--- 用户idlocal userId = ARGV[2];--- 数据key--- 库存key：id为voucherId的优惠券库存，注意lua脚本语言中拼接字符串用..local stockKey = &quot;seckill:stock:&quot;..voucherId;--- 订单key：id为voucherId的优惠券被哪些userId下了订单local orderKey = &quot;seckill:order:&quot;..voucherId;--- 脚本业务--- 判断库存是否充足，拿到的库存值是一个string，lua中的tonumber方法转成数字。if (tonumber(redis.call('get', stockKey)) &lt;= 0) then --- 库存不足，返回1 return 1;end--- 判断用户是否下过单if (redis.call('sismember', orderKey, userId) == 1) then --- 存在，说明是重复下单，返回2 return 2;end--- 符合下单条件--- 扣减库存redis.call('incrby', stockKey, -1);--- 保存下单的用户idredis.call('sadd', orderKey, userId)return 0; 业务代码改造： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127@Service@Slf4jpublic class VoucherOrderServiceImpl extends ServiceImpl&lt;VoucherOrderMapper, VoucherOrder&gt; implements IVoucherOrderService { @Resource private SeckillVoucherMapper seckillVoucherMapper; @Resource private VoucherOrderMapper voucherOrderMapper; @Resource private RedisIdWorker idWorker; @Resource private StringRedisTemplate stringRedisTemplate; @Resource private RedissonClient redissonClient; // 加载lua脚本 private static final DefaultRedisScript&lt;Long&gt; SECKILL_SCRIPT; static { SECKILL_SCRIPT = new DefaultRedisScript&lt;&gt;(); SECKILL_SCRIPT.setLocation(new ClassPathResource(&quot;secondKill.lua&quot;)); SECKILL_SCRIPT.setResultType(Long.class); } // 创建阻塞队列 private final BlockingQueue&lt;VoucherOrder&gt; orderTasksQueue = new ArrayBlockingQueue&lt;&gt;(1024 * 1024); // 单线程线程池 private static final ExecutorService SECKILL_ORDER_POOL = Executors.newSingleThreadExecutor(); // 创建任务 private class VoucherOrderHandler implements Runnable { @Override public void run() { for (; ; ) { try { // 获取队列中的订单信息 // take方法，获取和删除该队列的头部，如果队列中为空，则阻塞等待；也就是说队列中没有元素会卡在这里，有元素才会继续，不用担心死循环浪费CPU VoucherOrder voucherOrder = orderTasksQueue.take(); // 创建订单 createVoucherOrder(voucherOrder); } catch (InterruptedException e) { e.printStackTrace(); log.error(&quot;处理订单异常&quot;, e); return; } } } } // 项目一启动，用户随时都可能会来秒杀，因此我们要让类一初始化完就来执行这个任务 @PostConstruct//在当前类初始化完毕以后就来执行 private void init() { SECKILL_ORDER_POOL.submit(new VoucherOrderHandler()); } /** * 秒杀优惠券 * * @param voucherId 优惠券id * @return Result */ @Override // @Transactional public Result seckill(Long voucherId) { //根据id查询秒杀优惠券信息 SeckillVoucher seckillVoucher = seckillVoucherMapper.selectById(voucherId); //判断秒杀活动是否已经开始 LocalDateTime beginTime = seckillVoucher.getBeginTime(); if (LocalDateTime.now().isBefore(beginTime)) { return Result.fail(&quot;秒杀活动未开始！&quot;); } //判断秒杀活动是否已经结束 LocalDateTime endTime = seckillVoucher.getEndTime(); if (LocalDateTime.now().isAfter(endTime)) { return Result.fail(&quot;秒杀活动已经结束！&quot;); } //判断是否还有库存 Integer stock = seckillVoucher.getStock(); if (stock &lt; 1) { return Result.fail(&quot;库存不足！&quot;); } // 使用redis调用lua脚本的方式实现下单业务 Long userId = UserHolder.getUser().getId(); // 执行lua脚本 Long result = stringRedisTemplate.execute( SECKILL_SCRIPT, Collections.emptyList(), voucherId.toString(), userId.toString() ); // 判断结果是否为0 assert result != null; if (result.intValue() != 0) { // 不为0，根据lua脚本中我们自己写的逻辑，代表没有购买资格 return Result.fail(result.intValue() == 1 ? &quot;库存不足！&quot; : &quot;不能重复下单！&quot;); } // 为0了，有购买资格，把下订单信息保存到阻塞队列中 VoucherOrder voucherOrder = new VoucherOrder(); long orderId = idWorker.nextId(&quot;order&quot;); voucherOrder.setId(orderId); voucherOrder.setVoucherId(voucherId); voucherOrder.setUserId(userId); // 放入阻塞队列，由线程池异步处理减库存和入库任务 orderTasksQueue.add(voucherOrder); // 返回 return Result.ok(orderId); } @Transactional public void createVoucherOrder(VoucherOrder voucherOrder) { Long voucherId = voucherOrder.getVoucherId(); // 这块不用加锁，因为在lua脚本判断过“一人一单”，并且判断过“库存充足”，库存充足且符合一人一单，程序才会跑到这里 // 扣减库存 UpdateWrapper&lt;SeckillVoucher&gt; updateWrapper = new UpdateWrapper&lt;&gt;(); updateWrapper.setSql(&quot;stock = stock - 1&quot;); updateWrapper.eq(&quot;voucher_id&quot;, voucherId); updateWrapper.gt(&quot;stock&quot;, 0); seckillVoucherMapper.update(null, updateWrapper); // 订单入数据库 voucherOrderMapper.insert(voucherOrder); }} 但是这样实现，放入阻塞队列中，如果订单的数据量过大，那么会对 JVM 的内存造成很大的压力；另外如果这个服务宕机重启，那么阻塞队列中的数据就丢失了。如果我们的数据量如果在可控范围，并且 JVM 的内存参数设置加以考量，这种方案也是可行的，因为这块业务是对代金券的秒杀，因此总数量也没必要太大，但是如果是对于某个热点商品的特价秒杀，结果就可想而知了，因此基于阻塞队列这种异步处理的思想，我们引入 RabbitMQ 消息队列。 优化方式二：Lua 脚本、RabbitMQ 消息队列。 在 lua 脚本中判断并扣减库存、判断一人一单，解释如上。 在原基础上： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 123456789101112 # rabbitmq配置spring: rabbitmq: host: 127.0.0.1 username: root password: 123456 virtual-host: hmdp publisher-confirms: true # 开启发送确认 publisher-returns: true # 开启发送失败退回 listener: simple: acknowledge-mode: manual # 全局开启ACK 1234567891011121314package com.hmdp.utils;/** * @author CHAN * @since 2022/4/9 */public class RabbitMQConstants { // 异步创建订单，消息队列 public static final String ASYNC_ORDER_QUEUE = &quot;create.order.queue&quot;; // 异步创建订单，消息交换机 public static final String ASYNC_ORDER_EXCHANGE = &quot;create.order.exchange&quot;; // 异步创建订单，绑定标识 public static final String ASYNC_CREATE_ORDER_KEY = &quot;update.stock.create.order&quot;;} 异步监听消息队列中的消息： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * 异步监听消息队列中的消息 * @author CHAN * @since 2022/4/9 */@Component@Slf4jpublic class CreateOrderListener { @Resource private SeckillVoucherMapper seckillVoucherMapper; @Resource private VoucherOrderMapper voucherOrderMapper; @RabbitListener( bindings = @QueueBinding( value = @Queue(value = ASYNC_ORDER_QUEUE, durable = &quot;true&quot;), exchange = @Exchange( value = ASYNC_ORDER_EXCHANGE, ignoreDeclarationExceptions = &quot;true&quot; // type = ExchangeTypes.DIRECT//默认就是direct类型 ), key = ASYNC_CREATE_ORDER_KEY ) ) public void listen(VoucherOrder voucherOrder, Channel channel, Message message) throws IOException { try { /* * 无异常就确认消息 * basicAck(long deliveryTag, boolean multiple) * deliveryTag:取出来当前消息在队列中的的索引; * multiple:为true的话就是批量确认,如果当前deliveryTag为5,那么就会确认 * deliveryTag为5及其以下的消息;一般设置为false */ channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); log.info(&quot;接收信息成功，开始处理业务！&quot;); Long voucherId = voucherOrder.getVoucherId(); log.debug(&quot;voucherId: {}, voucherOrder: {}&quot;, voucherId, voucherOrder); // 这块不用加锁，因为在lua脚本判断过“一人一单”，并且判断过“库存充足”，库存充足且符合一人一单，程序才会跑到这里 // 扣减库存 UpdateWrapper&lt;SeckillVoucher&gt; updateWrapper = new UpdateWrapper&lt;&gt;(); updateWrapper.setSql(&quot;stock = stock - 1&quot;); updateWrapper.eq(&quot;voucher_id&quot;, voucherId); updateWrapper.gt(&quot;stock&quot;, 0); seckillVoucherMapper.update(null, updateWrapper); // 订单入数据库 voucherOrderMapper.insert(voucherOrder); } catch (Exception e) { e.printStackTrace(); /* * 有异常就拒收消息 * basicNack(long deliveryTag, boolean multiple, boolean requeue) * requeue:true:将消息重返当前消息队列,还可以重新发送给消费者; * false:将消息丢弃 */ channel.basicNack(message.getMessageProperties().getDeliveryTag(), false, true); log.info(&quot;接收信息异常！&quot;); } }} 业务代码优化： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101@Service@Slf4jpublic class VoucherOrderServiceImpl extends ServiceImpl&lt;VoucherOrderMapper, VoucherOrder&gt; implements IVoucherOrderService { @Resource private SeckillVoucherMapper seckillVoucherMapper; @Resource private VoucherOrderMapper voucherOrderMapper; @Resource private RedisIdWorker idWorker; @Resource private StringRedisTemplate stringRedisTemplate; @Resource private RedissonClient redissonClient; @Resource private RabbitTemplate rabbitTemplate; // 加载lua脚本 private static final DefaultRedisScript&lt;Long&gt; SECKILL_SCRIPT; static { SECKILL_SCRIPT = new DefaultRedisScript&lt;&gt;(); SECKILL_SCRIPT.setLocation(new ClassPathResource(&quot;secondKill.lua&quot;)); SECKILL_SCRIPT.setResultType(Long.class); } /** * 秒杀优惠券 * * @param voucherId 优惠券id * @return Result */ @Override // @Transactional public Result seckill(Long voucherId) { //根据id查询秒杀优惠券信息 SeckillVoucher seckillVoucher = seckillVoucherMapper.selectById(voucherId); //判断秒杀活动是否已经开始 LocalDateTime beginTime = seckillVoucher.getBeginTime(); if (LocalDateTime.now().isBefore(beginTime)) { return Result.fail(&quot;秒杀活动未开始！&quot;); } //判断秒杀活动是否已经结束 LocalDateTime endTime = seckillVoucher.getEndTime(); if (LocalDateTime.now().isAfter(endTime)) { return Result.fail(&quot;秒杀活动已经结束！&quot;); } //判断是否还有库存 Integer stock = seckillVoucher.getStock(); if (stock &lt; 1) { return Result.fail(&quot;库存不足！&quot;); } // 使用redis调用lua脚本的方式实现下单业务 Long userId = UserHolder.getUser().getId(); // 执行lua脚本 Long result = stringRedisTemplate.execute( SECKILL_SCRIPT, Collections.emptyList(), voucherId.toString(), userId.toString() ); // 判断结果是否为0 assert result != null; if (result.intValue() != 0) { // 不为0，根据lua脚本中我们自己写的逻辑，代表没有购买资格 return Result.fail(result.intValue() == 1 ? &quot;库存不足！&quot; : &quot;不能重复下单！&quot;); } // 为0了，有购买资格，把下订单信息保存到队列中 VoucherOrder voucherOrder = new VoucherOrder(); long orderId = idWorker.nextId(&quot;order&quot;); voucherOrder.setId(orderId); voucherOrder.setVoucherId(voucherId); voucherOrder.setUserId(userId); // 放入阻塞队列中，如果数据量过大，那么会对JVM的内存造成很大的压力；另外如果这个服务宕机重启，那么阻塞队列中的数据就丢失了 // 因此基于阻塞队列这种异步处理的思想，我们引入RabbitMQ消息队列 log.info(&quot;send voucherOrder message: {}&quot;, voucherOrder); // 生产者发送消息到exchange后没有绑定的queue时将消息退回 rabbitTemplate.setReturnCallback((message, replyCode, replyText, exchange, routingKey) -&gt; log.info(&quot;发送优惠券订单消息被退回！exchange: {}, routingKey: {}&quot;, exchange, routingKey)); // 生产者发送消息confirm检测 this.rabbitTemplate.setConfirmCallback((correlationData, ack, cause) -&gt; { if (!ack) { log.info(&quot;消息发送失败！cause：{}，correlationData：{}&quot;, cause, correlationData); } else { log.info(&quot;消息发送成功！&quot;); } }); rabbitTemplate.convertAndSend(ASYNC_ORDER_EXCHANGE, ASYNC_CREATE_ORDER_KEY, voucherOrder); // 返回 return Result.ok(orderId); }} 注：不推荐在程序中大量使用 Lua 脚本，Lua 脚本如果很多就不方便管理，我们一般使用 Lua 脚本来实现高并发的业务流程，类似上面的对于优惠券的秒杀业务。Over！ Feed流实现方案场景： 当我们关注了用户后，这个用户发了动态，那么我们应该把这些数据推送给用户，这个需求，其实我们又把他叫做Feed流，关注推送也叫做Feed流，直译为投喂。为用户持续的提供“沉浸式”的体验，通过无限下拉刷新获取新的信息。 对于传统的模式的内容解锁：我们是需要用户去通过搜索引擎或者是其他的方式去解锁想要看的内容 对于新型的Feed流的的效果：不需要我们用户再去推送信息，而是系统分析用户到底想要什么，然后直接把内容推送给用户，从而使用户能够更加的节约时间，不用主动去寻找。 Feed流的实现有两种模式： Feed流产品有两种常见模式： Timeline：不做内容筛选，简单的按照内容发布时间排序，常用于好友或关注。例如朋友圈 优点：信息全面，不会有缺失。并且实现也相对简单 缺点：信息噪音较多，用户不一定感兴趣，内容获取效率低 智能排序：利用智能算法屏蔽掉违规的、用户不感兴趣的内容。推送用户感兴趣信息来吸引用户。例如抖音。 优点：投喂用户感兴趣信息，用户粘度很高，容易沉迷 缺点：如果算法不精准，可能起到反作用 针对好友的操作，基于关注的好友来做Feed流，采用的就是Timeline的方式，只需要拿到我们关注的用户发送的动态，然后按照时间排序即可。该模式的实现方案有三种： 拉模式 推模式 推拉结合 拉模式：也叫做读扩散 该模式的核心含义就是：当张三和李四和王五发了消息后，都会保存在自己的邮箱中，假设赵六要读取信息，那么他会从读取他自己的收件箱，此时系统会从他关注的人群中，把他关注人的信息全部都进行拉取，然后在进行排序 优点：比较节约空间，因为赵六在读信息时，并没有重复读取，而且读取完之后可以把他的收件箱进行清楚。 缺点：比较延迟，当用户读取数据时才去关注的人里边去读取数据，假设用户关注了大量的用户，那么此时就会拉取海量的内容，对服务器压力巨大。 推模式：也叫做写扩散。 推模式是没有写邮箱的，当张三写了一个内容，此时会主动的把张三写的内容发送到他的粉丝收件箱中去，假设此时李四再来读取，就不用再去临时拉取了 优点：时效快，不用临时拉取 缺点：内存压力大，假设一个大V写信息，很多人关注他， 就会写很多分数据到粉丝那边去 推拉结合模式：也叫做读写混合，兼具推和拉两种模式的优点。 推拉模式是一个折中的方案，站在发件人这一段，如果是个普通的人，那么我们采用写扩散的方式，直接把数据写入到他的粉丝中去，因为普通的人他的粉丝关注量比较小，所以这样做没有压力，如果是大V，那么他是直接将数据先写入到一份到发件箱里边去，然后再直接写一份到活跃粉丝收件箱里边去，现在站在收件人这端来看，如果是活跃粉丝，那么大V和普通的人发的都会直接写入到自己收件箱里边来，而如果是普通的粉丝，由于他们上线不是很频繁，所以等他们上线时，再从发件箱里边去拉信息。 我关注的好友们，他们发送动态的时候，会保存数据到数据库的表中，并且推送到我的“收件箱”。收件箱满足可以根据时间戳排序，所谓的收件箱，其实就是Redis，必须用Redis的数据结构实现。查询Redis中保存的数据时，可以实现分页查询。 Feed流中的数据会不断更新，所以数据的角标也在变化，因此不能采用传统的分页模式。 传统的分页在feed流是不适用的，因为我们的数据会随时发生变化 假设在t1 时刻，我们去读取第一页，此时page = 1 ，size = 5 ，那么我们拿到的就是106 这几条记录，假设现在t2时候又发布了一条记录，此时t3 时刻，我们来读取第二页，读取第二页传入的参数是page=2 ，size=5 ，那么此时读取到的第二页实际上是从6 开始，然后是62 ，那么我们就读取到了重复的数据，所以feed流的分页，不能采用原始方案来做。 Feed流的滚动分页 我们需要记录每次操作的最后一条，然后从这个位置开始去读取数据 举个例子：我们从t1时刻开始，拿第一页数据，拿到了10~6，然后记录下当前最后一次拿取的记录，就是6，t2时刻发布了新的记录，此时这个11放到最顶上，但是不会影响我们之前记录的6，此时t3时刻来拿第二页，第二页这个时候拿数据，还是从6后一点的5去拿，就拿到了5-1的记录。我们这个地方可以采用sortedSet来做，可以进行范围查询，并且还可以记录当前获取数据时间戳最小值，就可以实现滚动分页了 核心的意思：就是在保存完当前用户发布的动态后，获得到当前用户的粉丝，然后把数据推送到redis（其他用户的id作为key，其实当前用户的粉丝也就是其他用户）中去。 附近的商户Redis 的 GeoHash 的应用。 GEO就是Geolocation的简写形式，代表地理坐标。Redis在3.2版本中加入了对GEO的支持，允许存储地理坐标信息，帮助我们根据经纬度来检索数据。常见的命令有： GEOADD：添加一个地理空间信息，包含：经度（longitude）、纬度（latitude）、值（member） GEODIST：计算指定的两个点之间的距离并返回 GEOHASH：将指定member的坐标转为hash字符串形式并返回 GEOPOS：返回指定member的坐标 GEORADIUS：指定圆心、半径，找到该圆内包含的所有member，并按照与圆心之间的距离排序后返回。6.以后已废弃 GEOSEARCH：在指定范围内搜索member，并按照与指定点之间的距离排序后返回。范围可以是圆形或矩形。6.2.新功能 GEOSEARCHSTORE：与GEOSEARCH功能一致，不过可以把结果存储到一个指定的key。 6.2.新功能 比如： 当我们点击美食之后，会出现一系列的商家，商家中可以按照多种排序方式，我们此时关注的是距离，这个地方就需要使用到我们的GEO，向后台传入当前app收集的地址(我们此处是写死的) ，以当前坐标作为圆心，同时绑定相同的店家类型type，以及分页信息，把这几个条件传入后台，后台查询出对应的数据再返回。 思路： 我们要做的事情是：将数据库表中的数据导入到redis中去，redis中的GEO，GEO在redis中就一个menber和一个经纬度，我们把x和y轴传入到redis做的经纬度位置去，但我们不能把所有的数据都放入到menber中去，毕竟作为redis是一个内存级数据库，如果存海量数据，redis还是力不从心，所以我们在这个地方存储他的id即可。 但是这个时候还有一个问题，就是在redis中并没有存储type，所以我们无法根据type来对数据进行筛选，所以我们可以按照商户类型做分组，类型相同的商户作为同一组，以typeId为key存入同一个GEO集合中即可。 UV 统计Redis 的 HyperLogLog 的统计功能。 UV统计-HyperLogLog首先我们搞懂两个概念： UV：全称Unique Visitor，也叫独立访客量，是指通过互联网访问、浏览这个网页的自然人。1天内同一个用户多次访问该网站，只记录1次。 PV：全称Page View，也叫页面访问量或点击量，用户每访问网站的一个页面，记录1次PV，用户多次打开页面，则记录多次PV。往往用来衡量网站的流量。 通常来说PV会比UV大很多，所以衡量同一个网站的访问量，我们需要综合考虑很多因素，所以我们只是单纯的把这两个值作为一个参考值 UV统计在服务端做会比较麻烦，因为要判断该用户是否已经统计过了，需要将统计过的用户信息保存。但是如果每个访问的用户都保存到Redis中，数据量会非常恐怖，那怎么处理呢？ Hyperloglog(HLL)是从Loglog算法派生的概率算法，用于确定非常大的集合的基数，而不需要存储其所有值。相关算法原理大家可以参考：https://juejin.cn/post/6844903785744056333#heading-0Redis中的HLL是基于string结构实现的，单个HLL的内存永远小于16kb，内存占用低的令人发指！作为代价，其测量结果是概率性的，有小于0.81％的误差。不过对于UV统计来说，这完全可以忽略。 UV统计-测试百万数据的统计测试思路：我们直接利用单元测试，向HyperLogLog中添加100万条数据，看看内存占用和统计效果如何 经过测试：我们会发生他的误差是在允许范围内，并且内存占用极小。 用户签到Redis 的 BitMap 数据统计功能。 BitMap功能演示我们针对签到功能完全可以通过mysql来完成，比如说以下这张表 用户一次签到，就是一条记录，假如有1000万用户，平均每人每年签到次数为10次，则这张表一年的数据量为 1亿条，显然不可取。 每签到一次需要使用（8 + 8 + 1 + 1 + 3 + 1）共22 字节的内存，一个月则最多需要600多字节，不可取。 我们如何能够简化一点呢？其实可以考虑小时候一个挺常见的方案，就是小时候，咱们准备一张小小的卡片，你只要签到就打上一个勾，我最后判断你是否签到，其实只需要到小卡片上看一看就知道了，我们可以采用类似这样的方案来实现我们的签到需求。 我们按月来统计用户签到信息，签到记录为1，未签到则记录为0. 把每一个bit位对应当月的每一天，形成了映射关系。用0和1标示业务状态，这种思路就称为位图（BitMap）。这样我们就用极小的空间，来实现了大量数据的表示，Redis中是利用string类型数据结构实现BitMap，因此最大上限是512M，转换为bit则是 2^32个bit位。 BitMap的操作命令有： SETBIT：向指定位置（offset）存入一个0或1 GETBIT ：获取指定位置（offset）的bit值 BITCOUNT ：统计BitMap中值为1的bit位的数量 BITFIELD ：操作（查询、修改、自增）BitMap中bit数组中的指定位置（offset）的值 BITFIELD_RO ：获取BitMap中bit数组，并以十进制形式返回 BITOP ：将多个BitMap的结果做位运算（与 、或、异或） BITPOS ：查找bit数组中指定范围内第一个0或1出现的位置 签到功能实现签到功能思路：我们可以把年和月作为bitMap的key，然后保存到一个bitMap中，每次签到就到对应的位上把数字从0变成1，只要对应是1，就表明说明这一天已经签到了，反之则没有签到。 因为 Redis 中的 BitMap 底层是基于 Redis 中 String 的数据结构，因此其操作也都封装在字符串相关的操作中了。 案例代码： 123456789101112131415@Overridepublic Result sign() { // 1.获取当前登录用户 Long userId = UserHolder.getUser().getId(); // 2.获取日期 LocalDateTime now = LocalDateTime.now(); // 3.拼接key String keySuffix = now.format(DateTimeFormatter.ofPattern(&quot;:yyyyMM&quot;)); String key = USER_SIGN_KEY + userId + keySuffix; // 4.获取今天是本月的第几天 int dayOfMonth = now.getDayOfMonth(); // 5.写入Redis SETBIT key offset 1 stringRedisTemplate.opsForValue().setBit(key, dayOfMonth - 1, true); return Result.ok();} 签到统计问题1：什么叫做连续签到天数？从最后一次签到开始向前统计，直到遇到第一次未签到为止，计算总的签到次数，就是连续签到天数。 Java逻辑代码：获得当前这个月的最后一次签到数据，定义一个计数器，然后不停的向前统计，直到获得第一个非0的数字即可，每得到一个非0的数字计数器+1，直到遍历完所有的数据，就可以获得当前月的签到总天数了 问题2：如何得到本月到今天为止的所有签到数据？ BITFIELD key GET u[dayOfMonth] 0：表示从角标0开始，查多少个。 假设今天是10号，那么我们就可以从当前月的第一天开始，获得到当前这一天的位数，是10号，那么就是10位，去拿这段时间的数据，就能拿到所有的数据了，那么这10天里边签到了多少次呢？统计有多少个1即可。 问题3：如何从后向前遍历每个bit位？ 注意：bitMap返回的数据是10进制，哪假如说返回一个数字8，那么我哪儿知道到底哪些是0，哪些是1呢？我们只需要让得到的10进制数字和1做与运算就可以了，因为1只有遇见1 才是1，其他数字都是0 ，我们把签到结果和1进行与操作，每与一次，就把签到结果向右移动一位，依次内推，我们就能完成逐个遍历的效果了。 案例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041@Overridepublic Result signCount() { // 1.获取当前登录用户 Long userId = UserHolder.getUser().getId(); // 2.获取日期 LocalDateTime now = LocalDateTime.now(); // 3.拼接key String keySuffix = now.format(DateTimeFormatter.ofPattern(&quot;:yyyyMM&quot;)); String key = USER_SIGN_KEY + userId + keySuffix; // 4.获取今天是本月的第几天 int dayOfMonth = now.getDayOfMonth(); // 5.获取本月截止今天为止的所有的签到记录，返回的是一个十进制的数字 BITFIELD sign:5:202203 GET u14 0 List&lt;Long&gt; result = stringRedisTemplate.opsForValue().bitField( key, BitFieldSubCommands.create() .get(BitFieldSubCommands.BitFieldType.unsigned(dayOfMonth)).valueAt(0) ); if (result == null || result.isEmpty()) { // 没有任何签到结果 return Result.ok(0); } Long num = result.get(0); if (num == null || num == 0) { return Result.ok(0); } // 6.循环遍历 int count = 0; while (true) { // 6.1.让这个数字与1做与运算，得到数字的最后一个bit位 // 判断这个bit位是否为0 if ((num &amp; 1) == 0) { // 如果为0，说明未签到，结束 break; }else { // 如果不为0，说明已签到，计数器+1 count++; } // 把数字右移一位，抛弃最后一个bit位，继续下一个bit位 num &gt;&gt;&gt;= 1; } return Result.ok(count);} 关于使用bitmap来解决缓存穿透的方案回顾缓存穿透： 发起了一个数据库不存在的，redis里边也不存在的数据，通常你可以把他看成一个攻击 解决方案： 判断id&lt;0 如果数据库是空，那么就可以直接往redis里边把这个空数据缓存起来 第一种解决方案：遇到的问题是如果用户访问的是id不存在的数据，则此时就无法生效 第二种解决方案：遇到的问题是：如果是不同的id那就可以防止下次过来直击数据 所以我们如何解决呢？ 我们可以将数据库的数据，所对应的id写入到一个list集合中，当用户过来访问的时候，我们直接去判断list中是否包含当前的要查询的数据，如果说用户要查询的id数据并不在list集合中，则直接返回，如果list中包含对应查询的id数据，则说明不是一次缓存穿透数据，则直接放行。 现在的问题是这个主键其实并没有那么短，而是很长的一个 主键 哪怕你单独去提取这个主键，但是在11年左右，淘宝的商品总量就已经超过10亿个 所以如果采用以上方案，这个list也会很大，所以我们可以使用bitmap来减少list的存储空间 我们可以把list数据抽象成一个非常大的bitmap，我们不再使用list，而是将db中的id数据利用哈希思想，比如： id % bitmap.size = 算出当前这个id对应应该落在bitmap的哪个索引上，然后将这个值从0变成1，然后当用户来查询数据时，此时已经没有了list，让用户用他查询的id去用相同的哈希算法， 算出来当前这个id应当落在bitmap的哪一位，然后判断这一位是0，还是1，如果是0则表明这一位上的数据一定不存在， 采用这种方式来处理，需要重点考虑一个事情，就是误差率，所谓的误差率就是指当发生哈希冲突的时候，产生的误差。 好友关注基于 Set 集合的关注、取关、共同关注、消息推送等功能。 关注、取关、共同关注功能，结合 Redis，其实思路很简单：比如 A 关注了 B、C、D。那么可以将 A 的 id 作为 key，value 就是一个 set，存入 A 关注的所有人的 id；E 关注了 B、D、F，然后将 E 的 id 作为 key，value 也是一个 set，存入 E 关注的所有人的 id。利用Redis中恰当的数据结构，实现共同关注功能。在set集合中，有交集并集补集的api，我们可以把两人的关注的人分别放入到一个set集合中，然后再通过api去查看这两个set集合中的交集数据。用户关注了某位用户后，需要将数据放入到set集合中，同时当取消关注时，也需要从set集合中进行删除。， 消息推送：比如 A 关注了 B，那么 B 发布的动态 A 能看到，相当于 B 发布的动态推送给了 A，相同的场景就是微信朋友圈，加了好友的两个人发了朋友圈，那么两个人互相都能刷到对方的动态，并且动态按照时间排序。这其实就是 Feed 流的经典案例。关于 Feed 流，可以看看前面的段落。可以使用 redis 的 sorted set 来实现存储，核心的意思：就是我发布的动态在保存完之后，再获取到我有哪些粉丝，然后把这条动态推送到粉丝的 redis 中去。 点赞功能点赞功能需求： 同一个用户只能点赞一次，再次点击则取消点赞 如果当前用户已经点赞，则点赞按钮高亮显示（前端实现，判断字段 isLike 的属性值） 假设用户是要给一个 BLOG 点赞，可以利用 Redis 的 set 集合判断是否点赞过。思路大概就是：BLOG 的 id 作为 key，value 是一个 set，set 中存放点过赞的用户的 id。点赞的时候获取到当前的用户 id，判断一下 redis 中有无即可。 案例代码： 12345678910111213141516171819202122232425@Overridepublic Result likeBlog(Long id){ // 1.获取登录用户 Long userId = UserHolder.getUser().getId(); // 2.判断当前登录用户是否已经点赞 String key = BLOG_LIKED_KEY + id; Boolean isMember = stringRedisTemplate.opsForSet().isMember(key, userId.toString()); if(BooleanUtil.isFalse(isMember)){ //3.如果未点赞，可以点赞 //3.1 数据库点赞数+1 boolean isSuccess = update().setSql(&quot;liked = liked + 1&quot;).eq(&quot;id&quot;, id).update(); //3.2 保存用户到Redis的set集合 if(isSuccess){ stringRedisTemplate.opsForSet().add(key,userId.toString()); } }else{ //4.如果已点赞，取消点赞 //4.1 数据库点赞数-1 boolean isSuccess = update().setSql(&quot;liked = liked - 1&quot;).eq(&quot;id&quot;, id).update(); //4.2 把用户从Redis的set集合移除 if(isSuccess){ stringRedisTemplate.opsForSet().remove(key,userId.toString()); } }} 需求拓展： 点赞排行榜 点赞是放到set集合，但是set集合是不能排序的，所以这个时候，咱们可以采用一个可以排序的set集合，就是咱们的sortedSet。 我们接下来来对比一下这些集合的区别是什么 所有点赞的人，需要是唯一的，所以我们应当使用set或者是sortedSet 其次我们需要排序，就可以直接锁定使用sortedSet啦 修改案例代码 1234567891011121314151617181920212223242526272829303132333435363738394041@Overridepublic Result likeBlog(Long id) { // 1.获取登录用户 Long userId = UserHolder.getUser().getId(); // 2.判断当前登录用户是否已经点赞 String key = BLOG_LIKED_KEY + id; Double score = stringRedisTemplate.opsForZSet().score(key, userId.toString()); if (score == null) { // 3.如果未点赞，可以点赞 // 3.1.数据库点赞数 + 1 boolean isSuccess = update().setSql(&quot;liked = liked + 1&quot;).eq(&quot;id&quot;, id).update(); // 3.2.保存用户到Redis的set集合 zadd key value score if (isSuccess) { stringRedisTemplate.opsForZSet().add(key, userId.toString(), System.currentTimeMillis()); } } else { // 4.如果已点赞，取消点赞 // 4.1.数据库点赞数 -1 boolean isSuccess = update().setSql(&quot;liked = liked - 1&quot;).eq(&quot;id&quot;, id).update(); // 4.2.把用户从Redis的set集合移除 if (isSuccess) { stringRedisTemplate.opsForZSet().remove(key, userId.toString()); } } return Result.ok();}private void isBlogLiked(Blog blog) { // 1.获取登录用户 UserDTO user = UserHolder.getUser(); if (user == null) { // 用户未登录，无需查询是否点赞 return; } Long userId = user.getId(); // 2.判断当前登录用户是否已经点赞 String key = &quot;blog:liked:&quot; + blog.getId(); Double score = stringRedisTemplate.opsForZSet().score(key, userId.toString()); blog.setIsLike(score != null);}","link":"/posts/20220403/redis-practical-experience.html"},{"title":"共享模型之工具","text":"线程池当我们使用线程来完成相应的任务的时候，每次都需要创建一个新的线程，在栈中，创建太多的话可能内存溢出，并且太多的线程 CPU 可能忙不过来，根据线程的抢占式调度，结果会导致系统发生频繁的上下文切换，尤其是在高并发的场景下。所以尽量不要每次任务来了都创建新的线程，而是要利用线程池，让线程重复的利用，其实这种就是享元模式的体现，和前面练习的连接池差不多的思想。 自定义线程池 步骤1：自定义拒绝策略接口 12345// 策略模式@FunctionalInterface // 函数式接口interface RejectPolicy&lt;T&gt; { void reject(BlockingQueue&lt;T&gt; queue, T task);} 步骤2：自定义任务队列 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141@Slf4j(topic = &quot;c.BlockingQueue&quot;)class BlockingQueue&lt;T&gt; { //1.任务队列 双向链表, 比LinkedList性能要好一些 private Deque&lt;T&gt; queue = new ArrayDeque&lt;&gt;(); //2.锁 private ReentrantLock lock = new ReentrantLock(); //3.生产者条件变量 private Condition producer = lock.newCondition(); //4.消费者条件变量 private Condition consumer = lock.newCondition(); //5.最大容量 private int cap; public BlockingQueue(int cap) { this.cap = cap; } // 从阻塞队列中获取消费 public T take() { lock.lock(); try { while (queue.isEmpty()) { try { consumer.await(); } catch (InterruptedException e) { e.printStackTrace(); } } T t = queue.removeFirst(); producer.signal(); return t; } finally { lock.unlock(); } } // 带超时的阻塞获取消费 public T poll(long timeout, TimeUnit unit) { lock.lock(); try { // 将timeout同一转换为纳秒 long na = unit.toNanos(timeout); while (queue.isEmpty()) { try { if (na &lt;= 0) { // 如果超时了返回null return null; } // 返回的是剩余的时间 na = consumer.awaitNanos(na); } catch (InterruptedException e) { e.printStackTrace(); } } T t = queue.removeFirst(); producer.signal(); return t; } finally { lock.unlock(); } } // 向阻塞队列中生产 死等 public void put(T task) { lock.lock(); try { while (queue.size() == this.cap) { try { log.debug(&quot;等待加入到任务队列 {}...&quot;, task); producer.await(); } catch (InterruptedException e) { e.printStackTrace(); } } log.debug(&quot;加入到任务队列 {}&quot;, task); queue.addLast(task); consumer.signal(); } finally { lock.unlock(); } } // 向阻塞队列中生产 带超时时间 public boolean offer(T task, long timeout, TimeUnit timeUnit) { lock.lock(); try { long na = timeUnit.toNanos(timeout); while (queue.size() == this.cap) { try { log.debug(&quot;等待加入到任务队列 {}...&quot;, task); if (na &lt;= 0) { return false; } // 这个方法返回的就是剩余的时间 na = producer.awaitNanos(na); } catch (InterruptedException e) { e.printStackTrace(); } } log.debug(&quot;加入到任务队列 {}&quot;, task); queue.addLast(task); consumer.signal(); return true; } finally { lock.unlock(); } } // 向阻塞队列中生产 通过策略模式将选择权下方给消费者 让消费者也就是调用方决定干嘛 public void tryPut(RejectPolicy&lt;T&gt; rejectPolicy, T task) { lock.lock(); try { // 判断队列是否已满 if (queue.size() == cap) { rejectPolicy.reject(this, task); } else { // 有空闲 log.debug(&quot;加入任务队列 {}&quot;, task); queue.addLast(task); consumer.signal(); } } finally { lock.unlock(); } } //获取大小 public int size() { lock.lock(); try { return queue.size(); } finally { lock.unlock(); } }} 步骤3：自定义线程池 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182@Slf4j(topic = &quot;c.ThreadPool&quot;)class ThreadPool { // 任务队列 private BlockingQueue&lt;Runnable&gt; taskQueue; // 线程集合 泛型中是自己对线程类的封装类 private final HashSet&lt;Worker&gt; workers = new HashSet(); // 核心线程数 private int coreSize; // 获取任务的超时时间 private long timeout; private TimeUnit timeUnit; private RejectPolicy&lt;Runnable&gt; rejectPolicy; public void execute(Runnable task) { // 当任务数没有超过 coreSize 时, 直接交给 worker 对象执行 // 如果任务数量超过了 coreSize 时, 加入任务队列暂存 synchronized (workers) { if (workers.size() &lt; coreSize) { Worker worker = new Worker(task); log.debug(&quot;新增 worker: {}&quot;, worker); workers.add(worker); new Thread(worker).start(); } else {// log.debug(&quot;加入任务队列 {}&quot;, task);// taskQueue.put(task); // 死等 // 任务队列满了之后: // 1 死等 // 2 带超时等待 // 3 让调用者线程放弃任务的执行 // 4 让调用者线程抛出异常 // 5 让调用者线程自己去执行任务 // 多种选择可能性,要使用if-else写死显然不可取,不如将决策权下放 // 策略模式: 将具体的操作抽象成一个接口,具体的实现由调用者传递,不写死. taskQueue.tryPut(rejectPolicy, task); } } } public ThreadPool(int coreSize, long timeout, TimeUnit timeUnit, int queueMaxSize, RejectPolicy&lt;Runnable&gt; rejectPolicy) { this.coreSize = coreSize; this.timeout = timeout; this.timeUnit = timeUnit; this.taskQueue = new BlockingQueue&lt;&gt;(queueMaxSize); this.rejectPolicy = rejectPolicy; } class Worker implements Runnable { private Runnable task; public Worker(Runnable task) { this.task = task; } @Override public void run() { // 执行任务 // 1.当task不为空,直接执行任务 // 2.当task执行完毕, 再接着从任务队列里面获取任务并执行// while (task != null || (task = taskQueue.take()) != null) { while (task != null || (task = taskQueue.poll(timeout, timeUnit)) != null) { try { log.debug(&quot;正在执行...{}&quot;, task); task.run(); } catch (Exception e) { e.printStackTrace(); } finally { task = null; } } synchronized (workers) { log.debug(&quot;worker 被移除 {}&quot;, this); workers.remove(this); } } }} 步骤4：测试 12345678910111213141516171819202122232425262728293031323334@Slf4j(topic = &quot;c.TestPool&quot;)public class TestPool { public static void main(String[] args) { ThreadPool threadPool = new ThreadPool(2, 1000, TimeUnit.MILLISECONDS, 10, new RejectPolicy&lt;Runnable&gt;() { @Override public void reject(BlockingQueue&lt;Runnable&gt; queue, Runnable task) { // 1. 死等// queue.put(task); // 2) 带超时等待// queue.offer(task, 1500, TimeUnit.MILLISECONDS); // 3) 让调用者放弃任务执行// log.debug(&quot;放弃{}&quot;, task); // 4) 让调用者抛出异常// throw new RuntimeException(&quot;任务执行失败 &quot; + task); // 5) 让调用者自己执行任务 task.run(); //主线程自己执行任务 而不是用start方法让另一个线程执行任务内容 } }); for (int i = 0; i &lt; 15; i++) { int j = i; threadPool.execute(() -&gt; { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } log.debug(&quot;{}&quot;, j); }); } }} ThreadPoolExecutor Executor 框架结构主要由三大部分组成 任务(Runnable /Callable) 执行任务需要实现的 Runnable 接口 或 Callable接口。Runnable 接口或 Callable 接口 实现类都可以被 ThreadPoolExecutor 或 ScheduledThreadPoolExecutor 执行。 任务的执行(Executor) 如上图所示，包括任务执行机制的核心接口 Executor ，以及继承自 Executor 接口的 ExecutorService 接口。ThreadPoolExecutor 和 ScheduledThreadPoolExecutor 这两个关键类实现了 ExecutorService 接口。 这里提了很多底层的类关系，但是，实际上我们需要更多关注的是 ThreadPoolExecutor 这个类，这个类在我们实际使用线程池的过程中，使用频率还是非常高的。 异步计算的结果(Future) Future 接口以及 Future 接口的实现类 FutureTask 类都可以代表异步计算的结果。 当我们把 Runnable接口 或 Callable 接口 的实现类提交给 ThreadPoolExecutor 或 ScheduledThreadPoolExecutor 执行。（调用 submit() 方法时会返回一个 FutureTask 对象） Executor 框架的使用示意图 主线程首先要创建实现 Runnable 或者 Callable 接口的任务对象。 把创建完成的实现 Runnable/Callable接口的 对象直接交给 ExecutorService 执行: ExecutorService.execute（Runnable command））或者也可以把 Runnable 对象或Callable 对象提交给 ExecutorService 执行（ExecutorService.submit（Runnable task）或 ExecutorService.submit（Callable &lt;T&gt; task））。 如果执行 ExecutorService.submit（…），ExecutorService 将返回一个实现Future接口的对象（我们刚刚也提到过了执行 execute()方法和 submit()方法的区别，submit()会返回一个 FutureTask 对象）。 最后，主线程可以执行 FutureTask.get()方法来等待任务执行完成。主线程也可以执行 FutureTask.cancel（boolean mayInterruptIfRunning）来取消此任务的执行。 线程池状态ThreadPoolExecutor 使用 int 的高 3 位来表示线程池状态，低 29 位表示线程数量 状态名 高3位 接收新任务 处理阻塞队列任务 说明 RUNNING 111 Y Y SHUTDOWN 000 N Y 不会接收新任务，但是会处理完阻塞队列中剩余的任务 STOP 001 N N 会中断正在执行的任务，并抛弃阻塞队列中剩余的任务 TIDYING 010 - - 任务全部执行完毕，活动线程为0，即将进入终结 TERMINATED 011 - - 终结状态 从数字上比较(第一位是符号位)，TERMINATED &gt; TIDYING &gt; STOP &gt; SHUTDOWN &gt; RUNNING 这些信息存储在一个原子变量 ctl 中，目的是将线程池状态与线程个数合二为一，这样就可以用一次 cas 原子操作进行赋值。 原子变量 ctl ： 1private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); 1234// c 为旧值， ctlOf 返回结果为新值ctl.compareAndSet(c, ctlOf(targetState, workerCountOf(c))));// rs 为高 3 位代表线程池状态， wc 为低 29 位代表线程个数，ctl 是合并它们private static int ctlOf(int rs, int wc) { return rs | wc; } 构造方法下面看一下参数最多的 一个线程方法： 12345678public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler){} corePoolSize 核心线程数目 (最多保留的线程数) maximumPoolSize 最大线程数目(核心线程数加上救急线程数) keepAliveTime 救急线程的生存时间(核心线程没有生存时间这个东西，核心线程会一直运行) unit 时间单位 - 针对救急线程 workQueue 阻塞队列 threadFactory 线程工厂 - 可以为线程创建时起个好名字 handler 拒绝策略 工作方式： 新创建的线程池中刚开始没有线程，当一个任务提交给线程池后，线程池会创建一个新线程来执行任务。 当线程数达到 corePoolSize 并没有线程空闲，这时再加入任务，新加的任务会被加入workQueue 队列排 队，直到有空闲的线程。 如果队列选择了有界队列，那么任务超过了队列大小时，会创建 maximumPoolSize - corePoolSize 数目的线程来救急。 如果线程到达 maximumPoolSize 仍然有新任务这时会执行拒绝策略。拒绝策略 jdk 提供了 下面的前4 种实现，其它著名框架也提供了实现 ThreadPoolExecutor.AbortPolicy让调用者抛出 RejectedExecutionException 异常，这是默认策略 ThreadPoolExecutor.CallerRunsPolicy 让调用者运行任务 ThreadPoolExecutor.DiscardPolicy 放弃本次任务 ThreadPoolExecutor.DiscardOldestPolicy 放弃队列中最早的任务，本任务取而代之 Dubbo 的实现，在抛出 RejectedExecutionException 异常之前会记录日志，并 dump 线程栈信息，方 便定位问题 Netty 的实现，是创建一个新线程来执行任务 ActiveMQ 的实现，带超时等待（60s）尝试放入队列，类似我们之前自定义的拒绝策略 PinPoint 的实现，它使用了一个拒绝策略链，会逐一尝试策略链中每种拒绝策略 当高峰过去后，超过corePoolSize 的救急线程如果一段时间没有任务做，需要结束节省资源，这个时间由 keepAliveTime 和 unit 来控制。 根据这个构造方法，JDK Executors 类中提供了几个现成的工厂方法来创建各种用途的线程池。 newFixedThreadPool这个是Executors类提供的工厂方法来创建线程池！Executors 是Executor 框架的工具类！ 12345public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());} 通过源码可以看到 new ThreadPoolExecutor(xxx)方法其实是是调用了之前说的完整参数的构造方法，使用了默认的线程工厂和拒绝策略！ 12345678public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);} 特点 核心线程数 == 最大线程数（没有救急线程被创建），因此也无需超时时间 阻塞队列是无界的，可以放任意数量的任务 适用于任务量已知，相对耗时的任务 newCachedThreadPool12345public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());} 特点 核心线程数是 0， 最大线程数是 Integer.MAX_VALUE，救急线程的空闲生存时间是 60s，意味着： 全部都是救急线程（60s 后可以回收） 救急线程可以无限创建 队列采用了 SynchronousQueue 实现特点是，它没有容量，没有线程来取是放不进去的（一手交钱、一手交货）SynchronousQueue测试代码： 12345678910111213141516171819202122232425262728293031SynchronousQueue&lt;Integer&gt; integers = new SynchronousQueue&lt;&gt;();new Thread(() -&gt; { try { log.debug(&quot;putting {} &quot;, 1); integers.put(1); log.debug(&quot;{} putted...&quot;, 1); log.debug(&quot;putting...{} &quot;, 2); integers.put(2); log.debug(&quot;{} putted...&quot;, 2); } catch (InterruptedException e) { e.printStackTrace(); }},&quot;t1&quot;).start();sleep(1);new Thread(() -&gt; { try { log.debug(&quot;taking {}&quot;, 1); integers.take(); } catch (InterruptedException e) { e.printStackTrace(); }},&quot;t2&quot;).start();sleep(1);new Thread(() -&gt; { try { log.debug(&quot;taking {}&quot;, 2); integers.take(); } catch (InterruptedException e) { e.printStackTrace(); }},&quot;t3&quot;).start(); 整个线程池表现为线程数会根据任务量不断增长，没有上限，当任务执行完毕，空闲 1分钟后释放线 程。 适合任务数比较密集，但每个任务执行时间较短的情况。 newSingleThreadExecutor1234public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1,0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue&lt;Runnable&gt;()));} 使用场景： 希望多个任务排队执行。线程数固定为 1，任务数多于 1 时，会放入无界队列排队。任务执行完毕，这唯一的线程也不会被释放。 区别： 和自己创建单线程执行任务的区别：自己创建一个单线程串行执行任务，如果任务执行失败而终止那么没有任何补救措施，而线程池还会新建一个线程，保证池的正常工作。 Executors.newSingleThreadExecutor() 线程个数始终为1，不能修改。 FinalizableDelegatedExecutorService 应用的是装饰器模式，只对外暴露了 ExecutorService 接口，因此不能调用 ThreadPoolExecutor 中特有的方法。 和Executors.newFixedThreadPool(1) 初始时为1时的区别：Executors.newFixedThreadPool(1) 初始时为1，以后还可以修改，对外暴露的是 ThreadPoolExecutor 对象，可以强转后调用 setCorePoolSize 等方法进行修改。 Executors 返回线程池对象的弊端如下： FixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列长度为 Integer.MAX_VALUE,可能堆积大量的请求，从而导致 OOM。 CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致 OOM。 说白了就是：要使用有界队列，要控制线程创建数量。 除了避免 OOM 的原因之外，不推荐使用 Executors提供的两种快捷的线程池的原因还有： 实际使用中需要根据自己机器的性能、业务场景来手动配置线程池的参数比如核心线程数、使用的任务队列、饱和策略等等。 我们应该显示地给我们的线程池命名，这样有助于我们定位问题。 提交任务123456789101112131415161718// 执行任务void execute(Runnable command);// 提交任务 task，用返回值 Future 获得任务执行结果，Future的原理就是利用我们之前讲到的保护性暂停模式来接受返回结果的，主线程可以执行 FutureTask.get()方法来等待任务执行完成&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);// 提交 tasks 中所有任务&lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException;// 提交 tasks 中所有任务，带超时时间&lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException;// 提交 tasks 中所有任务，哪个任务先成功执行完毕，返回此任务执行结果，其它任务取消&lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException;// 提交 tasks 中所有任务，哪个任务先成功执行完毕，返回此任务执行结果，其它任务取消，带超时时间&lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; 关闭线程池shutdown源码： 1234567891011121314151617181920212223/*线程池状态变为 SHUTDOWN- 不会接收新任务- 但已提交任务会执行完，包括等待队列里面的- 此方法不会阻塞调用线程的执行*/void shutdown(); public void shutdown() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { checkShutdownAccess(); // 修改线程池状态 advanceRunState(SHUTDOWN); // 仅会打断空闲线程 interruptIdleWorkers(); onShutdown(); // 扩展点 ScheduledThreadPoolExecutor } finally { mainLock.unlock(); } // 尝试终结(没有运行的线程可以立刻终结) tryTerminate(); } shutdownNow源码： 123456789101112131415161718192021222324252627/*线程池状态变为 STOP- 不会接收新任务- 会将队列中的任务返回- 并用 interrupt 的方式中断正在执行的任务*/List&lt;Runnable&gt; shutdownNow(); public List&lt;Runnable&gt; shutdownNow() { List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { checkShutdownAccess(); // 修改线程池状态 advanceRunState(STOP); // 打断所有线程 interruptWorkers(); // 获取队列中剩余任务 tasks = drainQueue(); } finally { mainLock.unlock(); } // 尝试终结 tryTerminate(); return tasks; } 其它方法： 123456// 不在 RUNNING 状态的线程池，此方法就返回 trueboolean isShutdown();// 线程池状态是否是 TERMINATEDboolean isTerminated();// 调用 shutdown 后，由于调用使线程结束线程的方法是异步的并不会等待所有任务运行结束就返回，因此如果它想在线程池 TERMINATED 后做些其它事情，可以利用此方法等待boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; 异步模式之工作线程定义让有限的工作线程（Worker Thread）来轮流异步处理无限多的任务。也可以将其归类为分工模式，它的典型实现就是线程池，也体现了经典设计模式中的享元模式。 例如，海底捞的服务员（线程），轮流处理每位客人的点餐（任务），如果为每位客人都配一名专属的服务员，那 么成本就太高了（对比另一种多线程设计模式：Thread-Per-Message） 注意，不同任务类型应该使用不同的线程池，这样能够避免饥饿，并能提升效率 例如，如果一个餐馆的工人既要招呼客人（任务类型A），又要到后厨做菜（任务类型B）显然效率不咋地，分成服务员（线程池A）与厨师（线程池B）更为合理，当然你能想到更细致的分工。 饥饿现象固定大小线程池会有饥饿现象，例如： 两个工人是同一个线程池中的两个线程 他们要做的事情是：为客人点餐和到后厨做菜，这是两个阶段的工作 客人点餐：必须先点完餐，等菜做好，上菜，在此期间处理点餐的工人必须等待 后厨做菜：没啥说的，做就是了 比如工人A 处理了点餐任务，接下来它要等着工人B 把菜做好，然后上菜，他俩也配合的蛮好。但现在同时来了两个客人，这个时候工人A 和工人B 都去处理点餐了，这时没人做饭了，这就是饥饿现象。 12345678910111213141516171819202122232425262728293031323334public class TestDeadLock { static final List&lt;String&gt; MENU = Arrays.asList(&quot;地三鲜&quot;, &quot;宫保鸡丁&quot;, &quot;辣子鸡丁&quot;, &quot;烤鸡翅&quot;); static Random RANDOM = new Random(); static String cooking() { return MENU.get(RANDOM.nextInt(MENU.size())); } public static void main(String[] args) { ExecutorService executorService = Executors.newFixedThreadPool(2); executorService.execute(() -&gt; { log.debug(&quot;处理点餐...&quot;); Future&lt;String&gt; f = executorService.submit(() -&gt; { log.debug(&quot;做菜&quot;); return cooking(); }); try { log.debug(&quot;上菜: {}&quot;, f.get()); } catch (InterruptedException | ExecutionException e) { e.printStackTrace(); } }); /*executorService.execute(() -&gt; { log.debug(&quot;处理点餐...&quot;); Future&lt;String&gt; f = executorService.submit(() -&gt; { log.debug(&quot;做菜&quot;); return cooking(); }); try { log.debug(&quot;上菜: {}&quot;, f.get()); } catch (InterruptedException | ExecutionException e) { e.printStackTrace(); } });*/ }} 解决方法 可以增加线程池的大小，不过不是根本解决方案，还是前面提到的，不同的任务类型，采用不同的线程池，例如： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package com.chan.concurrent.threadPool;import java.util.Arrays;import java.util.List;import java.util.Random;import java.util.concurrent.*;public class Test01 { static final List&lt;String&gt; menu = Arrays.asList(&quot;地三鲜&quot;, &quot;牛肉土豆&quot;, &quot;番茄牛腩&quot;, &quot;尖椒土豆丝&quot;); static Random random = new Random(); static String cooking() { // 随机做一道菜 return menu.get(random.nextInt(menu.size())); } public static void main(String[] args) {// ExecutorService service = Executors.newCachedThreadPool();// service.execute(// () -&gt; {// // ... do something inside runnable task//// });// service.shutdown(); ExecutorService waiterPool = Executors.newFixedThreadPool(1); ExecutorService coolPool = Executors.newFixedThreadPool(1); waiterPool.execute(new Runnable() { @Override public void run() { System.out.println(&quot;处理点餐...&quot;); Future&lt;String&gt; future = coolPool.submit(new Callable&lt;String&gt;() { @Override public String call() throws Exception { System.out.println(&quot;做菜...&quot;); return cooking(); } }); String cai = null; try { cai = future.get(); } catch (InterruptedException | ExecutionException e) { e.printStackTrace(); } System.out.println(&quot;上菜...&quot; + cai); } }); waiterPool.execute(new Runnable() { @Override public void run() { System.out.println(&quot;处理点餐...&quot;); Future&lt;String&gt; future = coolPool.submit(new Callable&lt;String&gt;() { @Override public String call() throws Exception { System.out.println(&quot;做菜...&quot;); return cooking(); } }); String cai = null; try { cai = future.get(); } catch (InterruptedException | ExecutionException e) { e.printStackTrace(); } System.out.println(&quot;上菜...&quot; + cai); } }); }} 12345617:25:14.626 c.TestDeadLock [pool-1-thread-1] - 处理点餐... 17:25:14.630 c.TestDeadLock [pool-2-thread-1] - 做菜17:25:14.631 c.TestDeadLock [pool-1-thread-1] - 上菜: 地三鲜17:25:14.632 c.TestDeadLock [pool-1-thread-1] - 处理点餐... 17:25:14.632 c.TestDeadLock [pool-2-thread-1] - 做菜17:25:14.632 c.TestDeadLock [pool-1-thread-1] - 上菜: 辣子鸡丁 创建多大的线程池合适？ 过小会导致程序不能充分地利用系统资源、容易导致饥饿，过大会导致更多的线程上下文切换，占用更多内存。 CPU 密集型运算通常采用 cpu 核数 + 1 能够实现最优的 CPU 利用率，+1 是保证当线程由于页缺失故障（操作系统）或其它原因导致暂停时，额外的这个线程就能顶上去，保证 CPU 时钟周期不被浪费。 I/O 密集型运算 CPU 不总是处于繁忙状态，例如，当你执行业务计算时，这时候会使用 CPU 资源，但当你执行 I/O 操作时、远程RPC 调用时，包括进行数据库操作时，这时候 CPU 就闲下来了，你可以利用多线程提高它的利用率。 经验公式如下：线程数 = 核数 * 期望 CPU 利用率 * 总时间(CPU计算时间+等待时间) / CPU 计算时间 例如 4 核 CPU 计算时间是 50% ，其它等待时间是 50%，期望 cpu 被 100% 利用，套用公式 4 * 100% * 100% / 50% = 8 例如 4 核 CPU 计算时间是 10% ，其它等待时间是 90%，期望 cpu 被 100% 利用，套用公式 4 * 100% * 100% / 10% = 40。 任务调度线程池在『任务调度线程池』功能加入之前，可以使用 java.util.Timer 来实现定时功能，Timer 的优点在于简单易用，但由于所有任务都是由同一个线程来调度，因此所有任务都是串行执行的，同一时间只能有一个任务在执行，前一个 任务的延迟或异常都将会影响到之后的任务。 1234567891011121314151617181920public static void main(String[] args) { Timer timer = new Timer(); TimerTask task1 = new TimerTask() { @Override public void run() { log.debug(&quot;task 1&quot;); sleep(2); } }; TimerTask task2 = new TimerTask() { @Override public void run() { log.debug(&quot;task 2&quot;); } }; // 使用 timer 添加两个任务，希望它们都在 1s 后执行 // 但由于 timer 内只有一个线程来顺序执行队列中的任务，因此『任务1』的延时，影响了『任务2』的执行 timer.schedule(task1, 1000); timer.schedule(task2, 1000);} 12320:46:09.444 c.TestTimer [main] - start... 20:46:10.447 c.TestTimer [Timer-0] - task 1 20:46:12.448 c.TestTimer [Timer-0] - task 2 使用 ScheduledExecutorService 改写： 123456789ScheduledExecutorService executor = Executors.newScheduledThreadPool(2);// 添加两个任务，希望它们都在 1s 后执行executor.schedule(() -&gt; { System.out.println(&quot;任务1，执行时间：&quot; + new Date()); try { Thread.sleep(2000); } catch (InterruptedException e) { }}, 1000, TimeUnit.MILLISECONDS);executor.schedule(() -&gt; { System.out.println(&quot;任务2，执行时间：&quot; + new Date());}, 1000, TimeUnit.MILLISECONDS); 12任务1，执行时间：Thu Jan 03 12:45:17 CST 2019 任务2，执行时间：Thu Jan 03 12:45:17 CST 2019 整个线程池表现为：线程数固定，任务数多于线程数时，会放入无界队列排队。任务执行完毕，这些线 程也不会被释放。用来执行延迟或反复执行的任务。 ScheduledExecutorService 中scheduleAtFixedRate方法的使用 12345ScheduledExecutorService pool = Executors.newScheduledThreadPool(1);log.debug(&quot;start...&quot;);pool.scheduleAtFixedRate(() -&gt; { log.debug(&quot;running...&quot;);}, 1, 1, TimeUnit.SECONDS); 1234521:45:43.167 c.TestTimer [main] - start... 21:45:44.215 c.TestTimer [pool-1-thread-1] - running... 21:45:45.215 c.TestTimer [pool-1-thread-1] - running... 21:45:46.215 c.TestTimer [pool-1-thread-1] - running... 21:45:47.215 c.TestTimer [pool-1-thread-1] - running... scheduleAtFixedRate 例子（任务执行时间超过了间隔时间）： 123456ScheduledExecutorService pool = Executors.newScheduledThreadPool(1);log.debug(&quot;start...&quot;);pool.scheduleAtFixedRate(() -&gt; { log.debug(&quot;running...&quot;); sleep(2);}, 1, 1, TimeUnit.SECONDS); 输出分析：一开始，延时 1s，接下来，由于任务执行时间 &gt; 间隔时间，间隔被『撑』到了 2s 1234521:44:30.311 c.TestTimer [main] - start... 21:44:31.360 c.TestTimer [pool-1-thread-1] - running... 21:44:33.361 c.TestTimer [pool-1-thread-1] - running... 21:44:35.362 c.TestTimer [pool-1-thread-1] - running... 21:44:37.362 c.TestTimer [pool-1-thread-1] - running... ScheduledExecutorService 中scheduleWithFixedDelay方法的使用 123456ScheduledExecutorService pool = Executors.newScheduledThreadPool(1);log.debug(&quot;start...&quot;);pool.scheduleWithFixedDelay(()-&gt; { log.debug(&quot;running...&quot;); sleep(2);}, 1, 1, TimeUnit.SECONDS); 输出分析：一开始，延时 1s，scheduleWithFixedDelay 的间隔是 上一个任务结束 &lt;-&gt; 延时 &lt;-&gt; 下一个任务开始 所以间隔都是 3s 1234521:40:55.078 c.TestTimer [main] - start... 21:40:56.140 c.TestTimer [pool-1-thread-1] - running... 21:40:59.143 c.TestTimer [pool-1-thread-1] - running... 21:41:02.145 c.TestTimer [pool-1-thread-1] - running... 21:41:05.147 c.TestTimer [pool-1-thread-1] - running... 整个线程池表现为：线程数固定，任务数多于线程数时，会放入无界队列排队。任务执行完毕，这些线程也不会被释放。用来执行延迟或反复执行的任务。 正确处理执行任务异常可以发现，如果线程池中的线程执行任务时，如果任务抛出了异常，默认是中断执行该任务而不是抛出异常或者打印异常信息。 方法1：主动捉异常 123456789ExecutorService pool = Executors.newFixedThreadPool(1);pool.submit(() -&gt; { try { log.debug(&quot;task1&quot;); int i = 1 / 0; } catch (Exception e) { log.error(&quot;error:&quot;, e); }} 方法2：使用 Future，错误信息都被封装进submit方法的返回方法中！ 1234567ExecutorService pool = Executors.newFixedThreadPool(1);Future&lt;Boolean&gt; f = pool.submit(() -&gt; { log.debug(&quot;task1&quot;); int i = 1 / 0; return true;});log.debug(&quot;result:{}&quot;, f.get()); 应用之定时任务如何让每周四 18:00:00 定时执行任务？ 123456789101112131415161718// 获得当前时间LocalDateTime now = LocalDateTime.now();// 获取本周四 18:00:00.000LocalDateTime thursday = now.with(DayOfWeek.THURSDAY).withHour(18).withMinute(0).withSecond(0).withNano(0);// 如果当前时间已经超过 本周四 18:00:00.000， 那么找下周四 18:00:00.000if(now.compareTo(thursday) &gt;= 0) { thursday = thursday.plusWeeks(1);}// 计算时间差，即延时执行时间long initialDelay = Duration.between(now, thursday).toMillis();// 计算间隔时间，即 1 周的毫秒值long oneWeek = 7 * 24 * 3600 * 1000;ScheduledExecutorService executor = Executors.newScheduledThreadPool(2);System.out.println(&quot;开始时间：&quot; + new Date());executor.scheduleAtFixedRate(() -&gt; { System.out.println(&quot;执行时间：&quot; + new Date());}, initialDelay, oneWeek, TimeUnit.MILLISECONDS); Tomcat 线程池Tomcat 在哪里用到了线程池呢 LimitLatch 用来限流，可以控制最大连接个数，类似 J.U.C 中的 Semaphore 后面再讲 Acceptor 只负责【接收新的 socket 连接】 Poller 只负责监听 socket channel 是否有【可读的 I/O 事件】 一旦可读，封装一个任务对象（socketProcessor），提交给 Executor 线程池处理 Executor 线程池中的工作线程最终负责【处理请求】 Tomcat 线程池扩展了 ThreadPoolExecutor，行为稍有不同 如果总线程数达到 maximumPoolSize，这时不会立刻抛 RejectedExecutionException 异常，而是再次尝试将任务放入队列，如果还失败，才抛出 RejectedExecutionException 异常，这时 tomcat 在线程池的原理基础上做的改进。 源码 tomcat-7.0.42 123456789101112131415161718192021222324public void execute(Runnable command, long timeout, TimeUnit unit) { submittedCount.incrementAndGet(); try { super.execute(command); } catch (RejectedExecutionException rx) { if (super.getQueue() instanceof TaskQueue) { final TaskQueue queue = (TaskQueue)super.getQueue(); try { // 使任务从新进入阻塞队列 if (!queue.force(command, timeout, unit)) { submittedCount.decrementAndGet(); throw new RejectedExecutionException(&quot;Queue capacity is full.&quot;); } } catch (InterruptedException x) { submittedCount.decrementAndGet(); Thread.interrupted(); throw new RejectedExecutionException(x); } } else { submittedCount.decrementAndGet(); throw rx; } }} TaskQueue.java 12345678public boolean force(Runnable o, long timeout, TimeUnit unit) throws InterruptedException { if ( parent.isShutdown() ) throw new RejectedExecutionException( &quot;Executor not running, can't force a command into the queue&quot; ); return super.offer(o,timeout,unit); //forces the item onto the queue, to be used if the task is rejected} Connector 配置 Executor 线程配置 守护线程的意思就是线程会随着主线程的结束而结束 Fork/Join概念 Fork/Join 是 JDK 1.7 加入的新的线程池实现，它体现的是一种分治思想，适用于能够进行任务拆分的 cpu 密集型运算。 所谓的任务拆分，是将一个大任务拆分为算法上相同的小任务，直至不能拆分可以直接求解。跟递归相关的一些计算，如归并排序、斐波那契数列、都可以用分治思想进行求解。 Fork/Join 在分治的基础上加入了多线程，可以把每个任务的分解和合并交给不同的线程来完成，进一步提升了运算效率。 Fork/Join 默认会创建与 cpu 核心数大小相同的线程池。 使用提交给 Fork/Join 线程池的任务需要继承 RecursiveTask（有返回值）或 RecursiveAction（没有返回值），例如下面定义了一个对 1~n 之间的整数求和的任务： 1234567891011121314151617181920212223242526272829@Slf4j(topic = &quot;c.AddTask&quot;)class AddTask1 extends RecursiveTask&lt;Integer&gt; { int n; public AddTask1(int n) { this.n = n; } @Override public String toString() { return &quot;{&quot; + n + '}'; } @Override protected Integer compute() { // 如果 n 已经为 1，可以求得结果了 if (n == 1) { log.debug(&quot;join() {}&quot;, n); return n; } // 将任务进行拆分(fork) AddTask1 t1 = new AddTask1(n - 1); t1.fork(); log.debug(&quot;fork() {} + {}&quot;, n, t1); // 合并(join)结果 int result = n + t1.join(); log.debug(&quot;join() {} + {} = {}&quot;, n, t1, result); return result; }} 然后提交给 ForkJoinPool 来执行： 1234public static void main(String[] args) { ForkJoinPool pool = new ForkJoinPool(4); System.out.println(pool.invoke(new AddTask1(5)));} 12345678910[ForkJoinPool-1-worker-0] - fork() 2 + {1} [ForkJoinPool-1-worker-1] - fork() 5 + {4} [ForkJoinPool-1-worker-0] - join() 1 [ForkJoinPool-1-worker-0] - join() 2 + {1} = 3 [ForkJoinPool-1-worker-2] - fork() 4 + {3} [ForkJoinPool-1-worker-3] - fork() 3 + {2} [ForkJoinPool-1-worker-3] - join() 3 + {2} = 6 [ForkJoinPool-1-worker-2] - join() 4 + {3} = 10 [ForkJoinPool-1-worker-1] - join() 5 + {4} = 15 15 做如下改进： 12345678910111213141516171819202122232425262728293031323334353637class AddTask3 extends RecursiveTask&lt;Integer&gt; { int begin; int end; public AddTask3(int begin, int end) { this.begin = begin; this.end = end; } @Override public String toString() { return &quot;{&quot; + begin + &quot;,&quot; + end + '}'; } @Override protected Integer compute() { // 5, 5 if (begin == end) { log.debug(&quot;join() {}&quot;, begin); return begin; } // 4, 5 if (end - begin == 1) { log.debug(&quot;join() {} + {} = {}&quot;, begin, end, end + begin); return end + begin; } // 1 5 int mid = (end + begin) / 2; // 3 AddTask3 t1 = new AddTask3(begin, mid); // 1,3 t1.fork(); AddTask3 t2 = new AddTask3(mid + 1, end); // 4,5 t2.fork(); log.debug(&quot;fork() {} + {} = ?&quot;, t1, t2); int result = t1.join() + t2.join(); log.debug(&quot;join() {} + {} = {}&quot;, t1, t2, result); return result; }} 然后提交给 ForkJoinPool 来执行： 1234public static void main(String[] args) { ForkJoinPool pool = new ForkJoinPool(4); System.out.println(pool.invoke(new AddTask3(1, 10)));} 12345678[ForkJoinPool-1-worker-0] - join() 1 + 2 = 3 [ForkJoinPool-1-worker-3] - join() 4 + 5 = 9 [ForkJoinPool-1-worker-0] - join() 3 [ForkJoinPool-1-worker-1] - fork() {1,3} + {4,5} = ? [ForkJoinPool-1-worker-2] - fork() {1,2} + {3,3} = ? [ForkJoinPool-1-worker-2] - join() {1,2} + {3,3} = 6 [ForkJoinPool-1-worker-1] - join() {1,3} + {4,5} = 15 15 改进后的算法逻辑图 J.U.CAQS 原理概述概述：全称是 AbstractQueuedSynchronizer，是阻塞式锁和相关的同步器工具的框架。是一个抽象父类，其它的并发工具都继承和实现它中的某个方法从而实现一些功能。 特点 用 state 属性来表示资源的状态（分独占模式和共享模式），由子类来定义如何维护这个状态，控制如何获取锁和释放锁 getState - 获取 state 状态 setState - 设置 state 状态 compareAndSetState - cas 机制设置 state 状态 独占模式是只有一个线程能够访问资源，而共享模式可以允许多个线程访问资源 提供了基于 FIFO 的等待队列，类似于 Monitor 的 EntryList 条件变量来实现等待、唤醒机制，支持多个条件变量，类似于 Monitor 的 WaitSet，但是比 synchronized 的 Monitor 强的是 AQS 支持多个条件变量，其中的某一个条件变量就相当于 Monitor 中的 WaitSet。 这里注意：AQS 是阻塞式锁的框架，并非 CAS 那种一直占 CPU 不断尝试的思想，在 CAS 思想也就是非阻塞，不断尝试的机制；但是 AQS 是阻塞式的，底层通过 CAS 来维护一个 state 状态，来表示是否获取到锁，如果线程获取锁失败则放入队列，队列是一个双向链表，这个获取锁失败的线程绑定到一个 Node 节点，作为阻塞队列中的一个元素，此时线程仍处于活跃状态，仍会继续尝试获取锁，再失败三次之后，当前线程就会被 park 住，到此就是 AQS 真正意义上的阻塞。被 park 住的线程就不会继续向下执行，需要等待被唤醒才能继续向下执行。那么被 park 的线程如何被唤醒？在线程获取锁失败绑定到阻塞队列（双向链表）的 Node 节点时，每个节点都有一个状态，节点的状态默认为 0 ，当前线程被 park 前，会判断上一个节点的状态，将上一个节点的状态从 0 改为 -1，节点状态为 -1 就表示这个节点有职责唤醒下一个节点，这样被 park 的线程就能被唤醒。 子类主要实现这样一些方法（默认抛出 UnsupportedOperationException） tryAcquire：尝试获取锁，尝试一次。 tryRelease：尝试释放锁。 tryAcquireShared：读写锁中的读锁尝试获取。写锁和普通的 ReentrantLock 无大差别，唯一不同是写锁状态占了 state 的低 16 位。而读锁使用的是 state 的高 16 位 tryReleaseShared：释放读锁。 isHeldExclusively：对于当前线程持有的锁是否是独占的方式，也即是当前的锁是否为独占锁。 1234567891011//获取锁的姿势// 如果获取锁失败if (!tryAcquire(arg)) { // 入队, 可以选择阻塞当前线程 park unpark}//释放锁的姿势// 如果释放锁成功if (tryRelease(arg)) { // 让阻塞线程恢复运行} 回顾： 可重入锁：synchronized 和 ReentrantLock 的锁都是可重入锁。即在一个线程中，在被锁住的代码中，再次获取同样的锁。不会阻塞。 不可重入锁：就是一个线程中的被锁住的代码中再次获取同样的锁，会阻塞，自己给自己堵住了。 下面实现一个不可重入的阻塞式锁：使用AbstractQueuedSynchronizer自定义一个同步器来实现自定义锁！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174package com.chan.concurrent.aqs;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.AbstractQueuedSynchronizer;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;/** * 自定义锁 * 使用aqs是阻塞式锁 */@Slf4j(topic = &quot;c.MineLock&quot;)public class MineLock { public static void main(String[] args) { MyLock lock = new MyLock(); new Thread(new Runnable() { @Override public void run() { lock.lock(); try { log.debug(&quot;locking...&quot;); TimeUnit.SECONDS.sleep(1);//让出CPU的时间片 但是并没释放锁 } catch (InterruptedException e) { e.printStackTrace(); } finally { log.debug(&quot;unlocking...&quot;); lock.unlock(); } } }, &quot;t1&quot;).start(); new Thread(new Runnable() { @Override public void run() { lock.lock(); try { log.debug(&quot;locking...&quot;); } finally { log.debug(&quot;unlocking...&quot;); lock.unlock(); } } }, &quot;t2&quot;).start(); }}/** * 自定义锁 不可重入锁 */class MyLock implements Lock { /** * 同步器类 通过AQS自定义锁要用到的一些方法和属性 * 比如我们要自定义独占锁 * 下面重写了aqs中的三个方法 都是aqs类中方法体里面只抛出异常没有具体实现的方法 我们来重写一下 */ static class MySync extends AbstractQueuedSynchronizer { /** * 尝试加锁 尝试一次 * @param arg 1 当前自定义的是不可重入锁 用不到arg 如果是可重入锁 就用到参数arg了 * @return boolean */ @Override protected boolean tryAcquire(int arg) { if (compareAndSetState(0, 1)) { // 返回true了 // 将0置换为1了 setExclusiveOwnerThread(Thread.currentThread());// 与Monitor是相似的 设置owner的 return true; } return false; } /** * 解锁 * @param arg 1 * @return boolean */ @Override protected boolean tryRelease(int arg) { // state是volatile的 写操作写在最后 加入写屏障 保证写屏障前面的写操作不会到指令重排到写屏障的后面 // 并且写屏障会将它之前写的放到主存 保证读的可见性 setExclusiveOwnerThread(null); setState(0); return true; } /** * 是否持有独占锁 * @return 布尔值 */ @Override protected boolean isHeldExclusively() { return getState() == 1;// 是1就代表加锁了 持有独占锁 } /** * 返回一个条件变量 * @return Condition */ public Condition newCondition() { return new ConditionObject();// aqs中的内部类 } } private final MySync mySync = new MySync(); // 继承Lock接口实现自定义锁 需要重写这么多方法 自己完成是很难的 我们可以借助AQS同步器类 大部分的方法都实现好了 我们只要补充几个比较重要的方法就OK /** * 继承了Lock接口 实现这个方法 加锁 * 加锁 尝试获取锁不成功 会放入队列等待 */ @Override public void lock() { //acquire方法就是aqs的方法 里面的逻辑就是尝试加锁 如果不成功就放进等待队列 mySync.acquire(1); } /** * 加锁 可打断的 能有效避免死锁 * @throws InterruptedException 打断异常 */ @Override public void lockInterruptibly() throws InterruptedException { mySync.acquireInterruptibly(1); } /** * 尝试加锁 试一次 一次不成功 就返回false 不会死等 * @return 布尔值 */ @Override public boolean tryLock() { return mySync.tryAcquire(1);// 自己重写的tryAcquire } /** * 尝试加锁 带超时时间 * @param time 时间 * @param unit 统一单位 * @return 布尔值 * @throws InterruptedException 打断异常 */ @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException { return mySync.tryAcquireNanos(1, unit.toNanos(time)); } /** * 解锁 */ @Override public void unlock() { // 这里说一下 如果是tryRelease就只是将owner设置为null并且将state设置为0 // 而release不止上面那两个 还会将等待的线程唤醒 mySync.release(1); } /** * 创建条件变量的 * @return Condition */ @Override public Condition newCondition() { return mySync.newCondition(); }} ReentrantLock 原理可以看到ReentrantLock提供了两个同步器，实现公平锁和非公平锁，默认是非公平锁！ 非公平锁实现原理图解流程加锁解锁流程，先从构造器开始看，ReentrantLock 默认为非公平锁实现 123public ReentrantLock() { sync = new NonfairSync();} NonfairSync 继承自 AQS 没有竞争时 第一个竞争出现时，查看源码的NonfairSync的lock方法 Thread-1 执行了 lock方法中CAS 尝试将 state 由 0 改为 1，结果失败 lock方法中进一步调用acquire方法，进入 tryAcquire 逻辑，这里我们认为这时 state 已经是1，结果仍然失败 接下来进入 acquire方法的addWaiter 逻辑，构造 Node 队列 图中黄色三角表示该 Node 的 waitStatus 状态，其中 0 为默认正常状态 Node 的创建是懒惰的 其中第一个 Node 称为 Dummy（哑元）或哨兵，用来占位，并不关联线程 当前线程进入 acquire方法的 acquireQueued 逻辑 acquireQueued 会在一个死循环中不断尝试获得锁，失败后进入 park 阻塞 如果自己是紧邻着 head（排第二位），那么再次 tryAcquire 尝试获取锁，我们这里设置这时 state 仍为 1，失败 进入 shouldParkAfterFailedAcquire 逻辑，将前驱 node，即 head 的 waitStatus 改为 -1，这次返回 false shouldParkAfterFailedAcquire 执行完毕回到 acquireQueued ，再次 tryAcquire 尝试获取锁，当然这时 state 仍为 1，失败 当再次进入 shouldParkAfterFailedAcquire 时，这时因为其前驱 node 的 waitStatus 已经是 -1，这次返回 true 进入 parkAndCheckInterrupt， Thread-1 park（灰色表示已经阻塞） 再次有多个线程经历上述过程竞争失败，变成这个样子 Thread-0 调用unlock方法里的release方法释放锁，进入tryRelease(使用ctrl+alt+b查看tryRelease方法的具体ReentrantLock实现) 流程，如果成功，设置 exclusiveOwnerThread 为 null，state = 0 unlock方法里的release方法方法中，如果当前队列不为 null，并且 head 的 waitStatus = -1，进入 unparkSuccessor 流程： unparkSuccessor中会找到队列中离 head 最近的一个 Node（没取消的），unpark 恢复其运行，本例中即为 Thread-1 回到 Thread-1 的 acquireQueued 流程 如果加锁成功（没有竞争），会设置 （acquireQueued 方法中） exclusiveOwnerThread 为 Thread-1，state = 1 head 指向刚刚 Thread-1 所在的 Node，该 Node 清空 Thread 原本的 head 因为从链表断开，而可被垃圾回收 如果这时候有其它线程来竞争（非公平的体现），例如这时有 Thread-4 来了 如果不巧又被 Thread-4 占了先 Thread-4 被设置为 exclusiveOwnerThread，state = 1 Thread-1 再次进入 acquireQueued 流程，获取锁失败，重新进入 park 阻塞 加锁源码线程第一次获取锁失败后，后面总共又尝试了三次获取锁。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169// Sync 继承自 AQSstatic final class NonfairSync extends Sync { private static final long serialVersionUID = 7316153563782823691L; // 加锁实现 final void lock() { // 首先用 cas 尝试（仅尝试一次）将 state 从 0 改为 1, 如果成功表示获得了独占锁 if (compareAndSetState(0, 1)) // 状态修改返回 true ,将 owner 设置为当前线程. setExclusiveOwnerThread(Thread.currentThread()); else // 如果尝试失败，进入 ㈠ acquire(1); } // ㈠ AQS 继承过来的方法, 这个方法是 AQS 中的, 为了方便阅读, 放在此处 public final void acquire(int arg) { // ㈡ tryAcquire if ( // 第一次尝试获取锁=============================== !tryAcquire(arg) &amp;&amp; // 当 tryAcquire 返回为 false 时, 接着会先调用 addWaiter ㈣, 接着 acquireQueued ㈤ // acquireQueued 方法顾名思义: 就是在队列中的线程能否获取到锁 acquireQueued(addWaiter(Node.EXCLUSIVE), arg) ) { // Thread.currentThread().interrupt(); // 上面的 tryAcquire 返回false和acquireQueued返回true 才会执行下面语句 selfInterrupt(); } } // ReentrantLock的内部类NonfairSync类中的方法, 是重写了AQS中的tryAcquire // ㈡ 进入 ㈢ protected final boolean tryAcquire(int acquires) { return nonfairTryAcquire(acquires); } // ReentrantLock类中的Sync类中的nonfairTryAcquire方法 // ㈢ Sync 继承过来的方法, 方便阅读, 放在此处 final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); // 如果还没有获得锁 if (c == 0) { // 尝试用 cas 获得, 这里体现了非公平性: 不去检查 AQS 队列 if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } // 如果已经获得了锁, 线程还是当前线程, 表示发生了锁重入 else if (current == getExclusiveOwnerThread()) { // state++ int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } // 获取失败, 回到调用处 return false; } // addWaiter 构造一个Node队列 双向链表 首次会创建两个node 第一个占位不绑定线程, 第二个绑定获取锁失败的线程 // ㈣ AQS 继承过来的方法, 这个方法是 AQS 中的, 为了方便阅读, 放在此处 private Node addWaiter(Node mode) {// 将当前线程关联到一个 Node 对象上, 模式为独占模式，新建的Node的waitstatus默认为0，因为waitstatus是成员变量，默认被初始化为0 Node node = new Node(Thread.currentThread(), mode); // 如果 tail 不为 null, cas 尝试将 Node 对象加入 AQS 队列尾部 Node pred = tail; if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { // 双向链表 pred.next = node; return node; } } //如果tail为null，尝试将 Node 加入 AQS, 进入 ㈥ enq(node); return node; } // ㈥ AQS 继承过来的方法, 这个方法是 AQS 中的, 为了 方便阅读, 放在此处 private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // 还没有, 设置 head 为哨兵节点（不对应线程，状态为 0） if (compareAndSetHead(new Node())) { tail = head; } } else { // cas 尝试将 Node 对象加入 AQS 队列尾部 node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } // ㈤ AQS 继承过来的方法, 这个方法是 AQS 中的, 为了方便阅读, 放在此处 final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; // for (;;) { final Node p = node.predecessor(); // 上一个节点是 head, 表示轮到自己（当前线程对应的 node）了, 尝试获取 // 第二次尝试获取锁====================== // 第三次尝试获取锁====================== if (p == head &amp;&amp; tryAcquire(arg)) { // 获取成功, 设置自己（当前线程对应的 node）为 head setHead(node); // 上一个节点 help GC p.next = null; failed = false; // 返回中断标记 false return interrupted; } if ( // 判断是否应当 park, 进入 ㈦ // node状态默认是0 第二次尝试获取锁失败的时候 此方法shouldParkAfterFailedAcquire返回false 并将当前线程的前驱节点的状态从0改为-1 // 第三次尝试获取锁失败的时候, 因为上一次前驱节点已经被改为了-1,因此这次shouldParkAfterFailedAcquire返回true shouldParkAfterFailedAcquire(p, node) &amp;&amp; // park 等待, 经几次尝试后没获取到锁的这个线程就在这里卡住了, 此时 Node 的状态被置为 Node.SIGNAL ㈧ parkAndCheckInterrupt() ) { interrupted = true; } } } finally { if (failed) cancelAcquire(node); } } // ㈦ AQS 继承过来的方法, 这个方法是 AQS 中的, 为了方便阅读, 放在此处 private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { // 获取上一个节点的状态 int ws = pred.waitStatus; if (ws == Node.SIGNAL) { // 上一个节点都在阻塞, 那么自己也阻塞好了 return true; } // &gt; 0 表示取消状态 if (ws &gt; 0) { // 上一个节点取消, 那么重构删除前面所有取消的节点, 返回到外层循环重试 do { node.prev = pred = pred.prev; } while (pred.waitStatus &gt; 0); pred.next = node; } else { // 这次还没有阻塞 // 但下次如果重试不成功, 则需要阻塞，这时需要设置上一个节点状态为 Node.SIGNAL compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false; } // ㈧ 阻塞当前线程 private final boolean parkAndCheckInterrupt() { LockSupport.park(this); return Thread.interrupted(); }} 解锁源码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// Sync 继承自 AQSstatic final class NonfairSync extends Sync { // 解锁实现 public void unlock() { sync.release(1); } // AQS 继承过来的方法, 方便阅读, 放在此处 public final boolean release(int arg) { // 尝试释放锁, 进入 ㈠ if (tryRelease(arg)) { // 队列头节点 unpark Node h = head; if ( // 队列不为 null h != null &amp;&amp; // waitStatus == Node.SIGNAL 才需要 unpark h.waitStatus != 0 ) { // unpark AQS 中等待的线程, 进入 ㈡ unparkSuccessor(h); } return true; } return false; } // ㈠ Sync 继承过来的方法, 方便阅读, 放在此处 protected final boolean tryRelease(int releases) { // state-- int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 支持锁重入, 只有 state 减为 0, 才释放成功 if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free; } // ㈡ AQS 继承过来的方法, 方便阅读, 放在此处 private void unparkSuccessor(Node node) { // 如果状态为 Node.SIGNAL 尝试重置状态为 0, 如果线程获取到了锁那么后来头结点会被抛弃掉 // 不成功也可以 int ws = node.waitStatus; if (ws &lt; 0) { compareAndSetWaitStatus(node, ws, 0); } // 找到需要 unpark 的节点, 但本节点从 AQS 队列中脱离, 是由唤醒节点完成的 Node s = node.next; // 不考虑已取消的节点, 从 AQS 队列从后至前找到队列最前面需要 unpark 的节点 if (s == null || s.waitStatus &gt; 0) { s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; } if (s != null) // 释放锁后, unpark 在 acquireQueued方法中parkAndCheckInterrupt()处正在park 的线程 LockSupport.unpark(s.thread); }} 可重入原理加锁时，如果发现state不为0，并且owner是当前线程的话，就代表锁重入，让state自增 解锁时，让state自减，直到减为0，才真正解开 1234567891011121314151617181920212223242526272829303132333435363738394041static final class NonfairSync extends Sync { // ... // Sync 继承过来的方法, 方便阅读, 放在此处 final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } // 如果已经获得了锁, 线程还是当前线程, 表示发生了锁重入 else if (current == getExclusiveOwnerThread()) { // state++ int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } // Sync 继承过来的方法, 方便阅读, 放在此处 protected final boolean tryRelease(int releases) { // state-- int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 支持锁重入, 只有 state 减为 0, 才释放成功 if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free; }} 可打断原理不可打断模式在此模式下，即使它被打断，仍会驻留在 AQS 队列中，一直要等到获得锁后方能得知自己被打断了 synchronized和lock()都不可被打断，但是使用这个方法可实现: lockInterruptibly()方法 通过前面，我们知道当线程几次尝试都没成功获取到锁的话，会执行到 parkAndCheckInterrupt() 方法，也即是park住线程，然后这个没获取到锁的线程就在这里阻塞，等待。然后其它线程在调用unlock释放锁的时候，在unlock方法的release方法中，如果当前阻塞队列不为空，并且head节点的状态是-1，则进入unparkSuccessor流程，（因为进入到park的线程可被在其它线程中调用这个park线程的interrupt方法唤醒，终止park），LockSupport.unpark(park的线程); 唤醒，然后刚才park的线程就会在那个位置（parkAndCheckInterrupt方法）继续向下运行。parkAndCheckInterrupt方法的第二行：return Thread.interrupted();，看线程是否被打断过，这里的目的是唤醒之后先查看这个线程之前是否被打断过，打断就意味着不等了不继续阻塞了防止死锁的现象。这个与线程对象调用isInterrupted方法不同，Thread.interrupted();返回布尔值并清除打断标记，保证下次这个线程再需要park时（比如非公平锁的特征，这个线程刚被唤醒去尝试获取锁，但是队列外面又来了个新的线程尝试获取锁，结果这个线程获取锁又失败了，需要再次park。非公平性体现在这里，而不是队列中，队列中是按顺序被唤醒的。）还可以park住。另一种方式不会清除打断标记。return Thread.interrupted();如果返回true，回到acquireQueued中，会对打断标记做一个记录。acquireQueued中的打断标记在循环之前设置为false了，一旦被打断了便设置为true，没有别的处理，线程会继续循环，如果再得不到锁，又会park，如果拿到锁了，就返回interrupted打断标记。回到acquire中，执行selfInterrupt();方法，重新产生一次中断。但是到了这里已经是获得到锁之后的打断了，我们打断park的线程是为了即使获取不到锁也不要一直死等，防止死锁的现象，但是这里已经是等到锁之后的打断了，对防止死锁没有任何意义。这就是不可打断模式。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// Sync 继承自 AQSstatic final class NonfairSync extends Sync { // ... private final boolean parkAndCheckInterrupt() { // 如果打断标记已经是 true, 则 park 会失效 LockSupport.park(this); // interrupted 会清除打断标记 return Thread.interrupted(); } final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; failed = false; // 还是需要获得锁后, 才能返回打断状态 return interrupted; } if ( shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt() ) { // 如果是因为 interrupt 被唤醒, 返回打断状态为 true interrupted = true;//记录打断标记 } } } finally { if (failed) cancelAcquire(node); } } public final void acquire(int arg) { if ( !tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg) ) { // 如果打断状态为 true selfInterrupt(); } } static void selfInterrupt() { // 重新产生一次中断，这时候线程是如果正常运行的状态，那么不是出于sleep等状态，interrupt方法就不会报错 Thread.currentThread().interrupt(); }}} 可打断模式可打断模式：doAcquireInterruptibly。表示在获取锁的过程中可被打断。 和前面的不同：throw new InterruptedException(); 抛异常了，而不是之前的记录打断标记了，不会再循环了，让这个线程不要再在AQS的这个队列中继续等了。 123456789101112131415161718192021222324252627282930313233343536static final class NonfairSync extends Sync { public final void acquireInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); // 如果没有获得到锁, 进入 ㈠ if (!tryAcquire(arg)) doAcquireInterruptibly(arg); } // ㈠ 可打断的获取锁流程 private void doAcquireInterruptibly(int arg) throws InterruptedException { final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try { for (;;) { final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return; } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) { // 在 park 过程中如果被 interrupt 会进入此 // 这时候抛出异常, 而不会再次进入 for (;;) // 不同======================= throw new InterruptedException(); } } } finally { if (failed) cancelAcquire(node); } }} 公平锁实现原理ReentrantLock 默认是非公平锁，主要体现在队列中被唤醒的线程再去争夺锁的时候可能还会有队列外新来的线程同时争夺锁，这就是不公平性的体现，注意，千万不要混淆，有些人可能会觉得队列中的线程被唤醒的顺序是随机的就是非公平性，这是不对的，因为AQS提供的阻塞队列是一个双向链表，双向链表是有序的，因此是唤醒是按照顺序的，每次都会唤醒头节点的后一个节点。 非公平锁会用 nonfairTryAcquire 方法来获取锁 公平锁：队列中优先级最高的是老二节点，老大是占位的不看。公平锁会先判断，队列中无老二或者老二不是当前线程，便加锁失败。我们知道非公平锁这块是不做判断的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051static final class FairSync extends Sync { private static final long serialVersionUID = -3000897897090466540L; final void lock() { acquire(1); } // AQS 继承过来的方法, 方便阅读, 放在此处 public final void acquire(int arg) { if ( !tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg) ) { selfInterrupt(); } } // 与非公平锁主要区别在于 tryAcquire 方法的实现 protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { // 先检查 AQS 队列中是否有前驱节点, 没有才去竞争 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; } return false; } // ㈠ AQS 继承过来的方法, 方便阅读, 放在此处 public final boolean hasQueuedPredecessors() { Node t = tail; Node h = head; Node s; // h != t 时表示队列中有 Node return h != t &amp;&amp; ( // (s = h.next) == null 表示队列中还有没有老二 (s = h.next) == null || // 或者队列中老二线程不是此线程 s.thread != Thread.currentThread() ); }} 条件变量实现原理图解流程每个条件变量其实就对应着一个等待队列，其实现类是 ConditionObject，等待队列和前面的阻塞队列的区别：最前面无占位的空节点了。新的node状态设置为-2，-2规定为等待状态。 await 流程 开始 Thread-0 持有锁，调用 await，进入 ConditionObject 的 addConditionWaiter 流程 创建新的 Node 状态为 -2（Node.CONDITION），关联 Thread-0，加入等待队列尾部 接下来进入 AQS 的 fullyRelease 流程，释放同步器上的锁 unpark AQS 队列中的下一个节点，竞争锁，假设没有其他竞争线程，那么 Thread-1 竞争成功 park 阻塞 Thread-0 signal 流程 假设 Thread-1 要来唤醒 Thread-0 进入 ConditionObject 的 doSignal 流程，取得等待队列中第一个 Node，即 Thread-0 所在 Node 执行 transferForSignal 流程，将该 Node 加入 AQS 队列尾部，将 Thread-0 的 waitStatus 改为 0，Thread-3 的waitStatus 改为 -1 Thread-1 释放锁，进入 unlock 流程，略 源码分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225public class ConditionObject implements Condition, java.io.Serializable { private static final long serialVersionUID = 1173984872572414699L; // 第一个等待节点 private transient Node firstWaiter; // 最后一个等待节点 private transient Node lastWaiter; public ConditionObject() { } // ㈠ 添加一个 Node 至等待队列 private Node addConditionWaiter() { Node t = lastWaiter; // 所有已取消的 Node 从队列链表删除, 见 ㈡ if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) { unlinkCancelledWaiters(); t = lastWaiter; } // 创建一个关联当前线程的新 Node, 添加至队列尾部 Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node; } // 唤醒 - 将没取消的第一个节点转移至 AQS 队列 private void doSignal(Node first) { do { // 已经是尾节点了 if ( (firstWaiter = first.nextWaiter) == null) { lastWaiter = null; } first.nextWaiter = null; } while ( // 将等待队列中的 Node 转移至 AQS 队列, 不成功且还有节点则继续循环 ㈢ !transferForSignal(first) &amp;&amp; // 队列还有节点 (first = firstWaiter) != null ); } // 外部类方法, 方便阅读, 放在此处 // ㈢ 如果节点状态是取消, 返回 false 表示转移失败, 否则转移成功 final boolean transferForSignal(Node node) { // 设置当前node状态为0（因为处在队列末尾），如果状态已经不是 Node.CONDITION, 说明被取消了 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; // 加入 AQS 队列尾部 Node p = enq(node); int ws = p.waitStatus; if ( // 插入节点的上一个节点被取消 ws &gt; 0 || // 插入节点的上一个节点不能设置状态为 Node.SIGNAL !compareAndSetWaitStatus(p, ws, Node.SIGNAL) ) { // unpark 取消阻塞, 让线程重新同步状态 LockSupport.unpark(node.thread); } return true; }// 全部唤醒 - 等待队列的所有节点转移至 AQS 队列private void doSignalAll(Node first) { lastWaiter = firstWaiter = null; do { Node next = first.nextWaiter; first.nextWaiter = null; transferForSignal(first); first = next; } while (first != null);} // ㈡ private void unlinkCancelledWaiters() { // ... } // 唤醒 - 必须持有锁才能唤醒, 因此 doSignal 内无需考虑加锁 public final void signal() { // 如果没有持有锁，会抛出异常 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first); } // 全部唤醒 - 必须持有锁才能唤醒, 因此 doSignalAll 内无需考虑加锁 public final void signalAll() { if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignalAll(first); } // 不可打断等待 - 直到被唤醒 public final void awaitUninterruptibly() { // 添加一个 Node 至等待队列, 见 ㈠ Node node = addConditionWaiter(); // 释放节点持有的锁, 见 ㈣ int savedState = fullyRelease(node); boolean interrupted = false; // 如果该节点还没有转移至 AQS 队列, 阻塞 while (!isOnSyncQueue(node)) { // park 阻塞 LockSupport.park(this); // 如果被打断, 仅设置打断状态 if (Thread.interrupted()) interrupted = true; } // 唤醒后, 尝试竞争锁, 如果失败进入 AQS 队列 if (acquireQueued(node, savedState) || interrupted) selfInterrupt(); } // 外部类方法, 方便阅读, 放在此处 // ㈣ 因为某线程可能重入，需要将 state 全部释放，获取state，然后把它全部减掉，以全部释放 final int fullyRelease(Node node) { boolean failed = true; try { int savedState = getState(); // 唤醒等待队列队列中的下一个节点 if (release(savedState)) { failed = false; return savedState; } else { throw new IllegalMonitorStateException(); } } finally { if (failed) node.waitStatus = Node.CANCELLED; } } // 打断模式 - 在退出等待时重新设置打断状态 private static final int REINTERRUPT = 1; // 打断模式 - 在退出等待时抛出异常 private static final int THROW_IE = -1; // 判断打断模式 private int checkInterruptWhileWaiting(Node node) { return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0; } // ㈤ 应用打断模式 private void reportInterruptAfterWait(int interruptMode) throws InterruptedException { if (interruptMode == THROW_IE) throw new InterruptedException(); else if (interruptMode == REINTERRUPT) selfInterrupt(); } // 等待 - 直到被唤醒或打断 public final void await() throws InterruptedException { if (Thread.interrupted()) { throw new InterruptedException(); } // 添加一个 Node 至等待队列, 见 ㈠ Node node = addConditionWaiter(); // 释放节点持有的锁 int savedState = fullyRelease(node); int interruptMode = 0; // 如果该节点还没有转移至 AQS 队列, 阻塞 while (!isOnSyncQueue(node)) { // park 阻塞 LockSupport.park(this); // 如果被打断, 退出等待队列 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } // 退出等待队列后, 还需要获得 AQS 队列的锁 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; // 所有已取消的 Node 从队列链表删除, 见 ㈡ if (node.nextWaiter != null) unlinkCancelledWaiters(); // 应用打断模式, 见 ㈤ if (interruptMode != 0) reportInterruptAfterWait(interruptMode); } // 等待 - 直到被唤醒或打断或超时 public final long awaitNanos(long nanosTimeout) throws InterruptedException { if (Thread.interrupted()) { throw new InterruptedException(); } // 添加一个 Node 至等待队列, 见 ㈠ Node node = addConditionWaiter(); // 释放节点持有的锁 int savedState = fullyRelease(node); // 获得最后期限 final long deadline = System.nanoTime() + nanosTimeout; int interruptMode = 0; // 如果该节点还没有转移至 AQS 队列, 阻塞 while (!isOnSyncQueue(node)) { // 已超时, 退出等待队列 if (nanosTimeout &lt;= 0L) { transferAfterCancelledWait(node); break; } // park 阻塞一定时间, spinForTimeoutThreshold 为 1000 ns if (nanosTimeout &gt;= spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); // 如果被打断, 退出等待队列 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; nanosTimeout = deadline - System.nanoTime(); } // 退出等待队列后, 还需要获得 AQS 队列的锁 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; // 所有已取消的 Node 从队列链表删除, 见 ㈡ if (node.nextWaiter != null) unlinkCancelledWaiters(); // 应用打断模式, 见 ㈤ if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return deadline - System.nanoTime(); } // 等待 - 直到被唤醒或打断或超时, 逻辑类似于 awaitNanos public final boolean awaitUntil(Date deadline) throws InterruptedException { // ... } // 等待 - 直到被唤醒或打断或超时, 逻辑类似于 awaitNanos public final boolean await(long time, TimeUnit unit) throws InterruptedException { // ... } // 工具方法 省略 ...} 读写锁ReentrantReadWriteLock当读操作远远高于写操作时，这时候使用读写锁让读-读可以并发，提高性能。读-写，写-写都是相互互斥的！ 提供一个数据容器类内部分别使用读锁保护数据的read()方法，写锁保护数据的write()方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980package com.chan.concurrent.rwlock;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.ReentrantReadWriteLock;/** * 读写锁案例 */public class Demo { public static void main(String[] args) { DataContainer container = new DataContainer(); new Thread(new Runnable() { @Override public void run() { try { container.read(); } catch (InterruptedException e) { e.printStackTrace(); } } }, &quot;t1&quot;).start(); new Thread(new Runnable() { @Override public void run() { try { container.read(); } catch (InterruptedException e) { e.printStackTrace(); } } }, &quot;t2&quot;).start(); }}@Slf4j(topic = &quot;c.DataContainer&quot;)class DataContainer { private int data; private final ReentrantReadWriteLock rw = new ReentrantReadWriteLock(); private final ReentrantReadWriteLock.ReadLock readLock = rw.readLock(); private final ReentrantReadWriteLock.WriteLock writeLock = rw.writeLock(); public Object read() throws InterruptedException { log.debug(&quot;获取读锁...&quot;); readLock.lock(); try { log.debug(&quot;读取...&quot;); TimeUnit.MILLISECONDS.sleep(1000); return data; } finally { log.debug(&quot;释放读锁...&quot;); readLock.unlock(); } } public void write() throws InterruptedException { log.debug(&quot;获取写锁...&quot;); writeLock.lock(); try { log.debug(&quot;写入...&quot;); TimeUnit.MILLISECONDS.sleep(1000); } finally { log.debug(&quot;释放写锁...&quot;); writeLock.unlock(); } }}输出:22:25:08 [t2] c.DataContainer - 获取读锁...22:25:08 [t1] c.DataContainer - 获取读锁...22:25:08 [t2] c.DataContainer - 读取...22:25:08 [t1] c.DataContainer - 读取...22:25:09 [t1] c.DataContainer - 释放读锁...22:25:09 [t2] c.DataContainer - 释放读锁... 不难看出,读读是并发的 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package com.chan.concurrent.rwlock;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.ReentrantReadWriteLock;/** * 读写锁案例 */public class Demo { public static void main(String[] args) throws InterruptedException { DataContainer container = new DataContainer(); new Thread(new Runnable() { @Override public void run() { try { container.read(); } catch (InterruptedException e) { e.printStackTrace(); } } }, &quot;t1&quot;).start(); Thread.sleep(100);//主线程100毫秒之后再执行下面的 new Thread(new Runnable() { @Override public void run() { try { container.write(); } catch (InterruptedException e) { e.printStackTrace(); } } }, &quot;t2&quot;).start(); }}@Slf4j(topic = &quot;c.DataContainer&quot;)class DataContainer { private int data; private final ReentrantReadWriteLock rw = new ReentrantReadWriteLock(); private final ReentrantReadWriteLock.ReadLock readLock = rw.readLock(); private final ReentrantReadWriteLock.WriteLock writeLock = rw.writeLock(); public Object read() throws InterruptedException { log.debug(&quot;获取读锁...&quot;); readLock.lock(); try { log.debug(&quot;读取...&quot;); TimeUnit.MILLISECONDS.sleep(1000); return data; } finally { log.debug(&quot;释放读锁...&quot;); readLock.unlock(); } } public void write() throws InterruptedException { log.debug(&quot;获取写锁...&quot;); writeLock.lock(); try { log.debug(&quot;写入...&quot;); TimeUnit.MILLISECONDS.sleep(1000); } finally { log.debug(&quot;释放写锁...&quot;); writeLock.unlock(); } }}输出:22:30:18 [t1] c.DataContainer - 获取读锁...22:30:18 [t1] c.DataContainer - 读取...22:30:18 [t2] c.DataContainer - 获取写锁...22:30:19 [t1] c.DataContainer - 释放读锁...22:30:19 [t2] c.DataContainer - 写入...22:30:20 [t2] c.DataContainer - 释放写锁... 由此可见读写互斥,此案例只是为了验证读写锁是互斥的 读写锁的工作方式：读读可并发，读写、写写要互斥。 有人问既然读读可并发，那读的时候还加读锁干嘛？读锁和普通锁不同，加读锁，是因为要保证读的同时，写操作不能进行，也就是说，当读锁被持有时，写操作是拿不到写锁的。读写锁并用，就能保证读读可并发，读写、写写互斥的效果，这样比单独加一个 lock 普通的锁更加提高了读的并发量和效率。 加读锁是因为读锁相对读锁不互斥（shared），但是读锁相对写锁是互斥的。相比于之前，减少了读读互斥的成本。 ReentrantLock 是可重入的锁。但是 ReentrantReadWriteLock 就有说法了。一个线程得到了读锁，同一个线程再想得到写锁是不可以的，必须提前释放读锁，也就是说锁升级不支持；但是相反，一个线程如果先得到了写锁，同一个线程再想得到读锁是可以的，也就是说锁可以降级。 读锁不支持条件变量。 注意事项 读锁不支持条件变量 重入时升级不支持：即持有读锁的情况下去获取写锁，会导致获取写锁永久等待 123456789101112r.lock();try { // ... w.lock(); try { // ... } finally{ w.unlock(); }} finally{ r.unlock();} 重入时降级支持：即持有写锁的情况下去获取读锁 1234567891011121314151617181920212223242526272829303132 class CachedData { Object data; // 是否有效，如果失效，需要重新计算 data volatile boolean cacheValid; final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); void processCachedData() { rwl.readLock().lock(); if (!cacheValid) { // 获取写锁前必须释放读锁 rwl.readLock().unlock(); rwl.writeLock().lock(); try { // 判断是否有其它线程已经获取了写锁、更新了缓存, 避免重复更新 if (!cacheValid) { data = ... cacheValid = true; } // 降级为读锁, 释放写锁, 这样能够让其它线程读取缓存 rwl.readLock().lock(); } finally { rwl.writeLock().unlock(); } } // 自己用完数据, 释放读锁 try { use(data); } finally { rwl.readLock().unlock(); } }} 应用之缓存缓存更新策略注：以下都是在一个 JVM 中的情况，多线程什么的。不适用于分布式场景。 更新时，是先清缓存还是先更新数据库？ 先清缓存 先更新数据库 补充一种情况，假设查询线程 A 查询数据时恰好缓存数据由于时间到期失效，或是第一次查询：这种情况的出现几率非常小 注：在一台 JVM 中和在分布式环境中对于缓存的更新策略不是完全相同的。 读写锁实现一致性缓存1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374class GenericCachedDao&lt;T&gt; { // HashMap 作为缓存非线程安全, 需要保护 HashMap&lt;SqlPair, T&gt; map = new HashMap&lt;&gt;(); ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); GenericDao genericDao = new GenericDao(); public int update(String sql, Object... params) { SqlPair key = new SqlPair(sql, params); // 加写锁, 防止其它线程对缓存读取和更改 lock.writeLock().lock(); try { int rows = genericDao.update(sql, params); map.clear(); return rows; } finally { lock.writeLock().unlock(); } } public T queryOne(Class&lt;T&gt; beanClass, String sql, Object... params) { SqlPair key = new SqlPair(sql, params); // 加读锁, 防止其它线程对缓存更改 lock.readLock().lock(); try { T value = map.get(key); if (value != null) { return value; } } finally { lock.readLock().unlock(); } // 加写锁, 防止其它线程对缓存读取和更改 lock.writeLock().lock(); try { // get 方法上面部分是可能多个线程进来的, 可能已经向缓存填充了数据 // 为防止重复查询数据库, 再次验证 T value = map.get(key); if (value == null) { // 如果没有, 查询数据库 value = genericDao.queryOne(beanClass, sql, params); map.put(key, value); } return value; } finally { lock.writeLock().unlock(); } } // 作为 key 保证其是不可变的 class SqlPair { private String sql; private Object[] params; public SqlPair(String sql, Object[] params) { this.sql = sql; this.params = params; } @Override public boolean equals(Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()) { return false; } SqlPair sqlPair = (SqlPair) o; return sql.equals(sqlPair.sql) &amp;&amp; Arrays.equals(params, sqlPair.params); } @Override public int hashCode() { int result = Objects.hash(sql); result = 31 * result + Arrays.hashCode(params); return result; } }} 读写锁原理图解流程读写锁用的是同一个 Sycn 同步器，因此等待队列、state 等也是同一个 下面执行：t1 w.lock，t2 r.lock 1） t1 成功上锁，流程与 ReentrantLock 加锁相比没有特殊之处，不同是写锁状态占了 state 的低 16 位，而读锁 使用的是 state 的高 16 位 2）t2 执行 r.lock，这时进入读锁的 sync.acquireShared(1) 流程，首先会进入 tryAcquireShared 流程。如果有写 锁占据，那么 tryAcquireShared 返回 -1 表示失败 tryAcquireShared 返回值表示 -1 表示失败 0 表示成功，但后继节点不会继续唤醒 正数表示成功，而且数值是还有几个后继节点需要唤醒，我们这里的读写锁返回 1 3）这时会进入 sync.doAcquireShared(1) 流程，首先也是调用 addWaiter 添加节点，不同之处在于节点被设置为 Node.SHARED 模式而非 Node.EXCLUSIVE 模式，注意此时 t2 仍处于活跃状态 4）t2 会看看自己的节点是不是老二，如果是，还会再次调用 tryAcquireShared(1) 来尝试获取锁 5）如果没有成功，在 doAcquireShared 内 for (;;) 循环一次，把前驱节点的 waitStatus 改为 -1，再 for (;;) 循环一 次尝试 tryAcquireShared(1) 如果还不成功，那么在 parkAndCheckInterrupt() 处 park 又继续执行：t3 r.lock，t4 w.lock 这种状态下，假设又有 t3 加读锁和 t4 加写锁，这期间 t1 仍然持有锁，就变成了下面的样子 继续执行t1 w.unlock 这时会走到写锁的 sync.release(1) 流程，调用 sync.tryRelease(1) 成功，变成下面的样子 接下来执行唤醒流程 sync.unparkSuccessor，即让老二恢复运行，这时 t2 在 doAcquireShared 内 parkAndCheckInterrupt() 处恢复运行，图中的t2从黑色变成了蓝色（注意这里只是恢复运行而已，并没有获取到锁！） 这回再来一次 for (;;) 执行 tryAcquireShared 成功则让读锁计数加一 这时 t2 已经恢复运行，接下来 t2 调用 setHeadAndPropagate(node, 1)，它原本所在节点被置为头节点 事情还没完，在 setHeadAndPropagate 方法内还会检查下一个节点是否是 shared，如果是则调用 doReleaseShared() 将 head 的状态从 -1 改为 0 并唤醒老二，这时 t3 在 doAcquireShared 内 parkAndCheckInterrupt() 处恢复运行 这回再来一次 for (;;) 执行 tryAcquireShared 成功则让读锁计数加一 这时 t3 已经恢复运行，接下来 t3 调用 setHeadAndPropagate(node, 1)，它原本所在节点被置为头节点 下一个节点不是 shared 了，因此不会继续唤醒 t4 所在节点 再继续执行t2 r.unlock，t3 r.unlock t2 进入 sync.releaseShared(1) 中，调用 tryReleaseShared(1) 让计数减一，但由于计数还不为零 t3 进入 sync.releaseShared(1) 中，调用 tryReleaseShared(1) 让计数减一，这回计数为零了，进入 doReleaseShared() 将头节点从 -1 改为 0 并唤醒老二，即 之后 t4 在 acquireQueued 中 parkAndCheckInterrupt 处恢复运行，再次 for (;;) 这次自己是老二，并且没有其他 竞争，tryAcquire(1) 成功，修改头结点，流程结束 源码分析写锁上锁流程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364static final class NonfairSync extends Sync { // ... 省略无关代码 // 外部类 WriteLock 方法, 方便阅读, 放在此处 public void lock() { sync.acquire(1); } // AQS 继承过来的方法, 方便阅读, 放在此处 public final void acquire(int arg) { if ( // 尝试获得写锁失败 !tryAcquire(arg) &amp;&amp; // 将当前线程关联到一个 Node 对象上, 模式为独占模式 // 进入 AQS 队列阻塞 acquireQueued(addWaiter(Node.EXCLUSIVE), arg) ) { selfInterrupt(); } } // Sync 继承过来的方法, 方便阅读, 放在此处 protected final boolean tryAcquire(int acquires) { // 获得低 16 位, 代表写锁的 state 计数 Thread current = Thread.currentThread(); int c = getState(); int w = exclusiveCount(c); if (c != 0) { if ( // c != 0 and w == 0 表示有读锁返回错误，读锁不支持锁升级, 或者 w == 0 || // c != 0 and w == 0 表示有写，如果 exclusiveOwnerThread 不是自己 current != getExclusiveOwnerThread() ) { // 获得锁失败 return false; } // 写锁计数超过低 16 位, 报异常 if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(&quot;Maximum lock count exceeded&quot;); // 写锁重入, 获得锁成功 setState(c + acquires); return true; } if ( // 判断写锁是否该阻塞这里返回false, 或者 writerShouldBlock() || // 尝试更改计数失败 !compareAndSetState(c, c + acquires) ) { // 获得锁失败 return false; } // 获得锁成功 setExclusiveOwnerThread(current); return true; } // 非公平锁 writerShouldBlock 总是返回 false, 无需阻塞 final boolean writerShouldBlock() { return false; }} 写锁释放流程 1234567891011121314151617181920212223242526272829303132333435static final class NonfairSync extends Sync { // ... 省略无关代码 // WriteLock 方法, 方便阅读, 放在此处 public void unlock() { sync.release(1); } // AQS 继承过来的方法, 方便阅读, 放在此处 public final boolean release(int arg) { // 尝试释放写锁成功 if (tryRelease(arg)) { // unpark AQS 中等待的线程 Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } // Sync 继承过来的方法, 方便阅读, 放在此处 protected final boolean tryRelease(int releases) { if (!isHeldExclusively()) throw new IllegalMonitorStateException(); int nextc = getState() - releases; // 因为可重入的原因, 写锁计数为 0, 才算释放成功 boolean free = exclusiveCount(nextc) == 0; if (free) { setExclusiveOwnerThread(null); } setState(nextc); return free; }} 读锁上锁流程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153static final class NonfairSync extends Sync { // ReadLock 方法, 方便阅读, 放在此处 public void lock() { sync.acquireShared(1); } // AQS 继承过来的方法, 方便阅读, 放在此处 public final void acquireShared(int arg) { // tryAcquireShared 返回负数, 表示获取读锁失败 if (tryAcquireShared(arg) &lt; 0) { doAcquireShared(arg); } } // Sync 继承过来的方法, 方便阅读, 放在此处 protected final int tryAcquireShared(int unused) { Thread current = Thread.currentThread(); int c = getState(); // 如果是其它线程持有写锁, 获取读锁失败 if ( exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current ) { return -1; } int r = sharedCount(c); if ( // 读锁不该阻塞(如果老二是写锁，读锁该阻塞), 并且 !readerShouldBlock() &amp;&amp; // 小于读锁计数, 并且 r &lt; MAX_COUNT &amp;&amp; // 尝试增加计数成功 compareAndSetState(c, c + SHARED_UNIT) ) { // ... 省略不重要的代码 return 1; } return fullTryAcquireShared(current); } // 非公平锁 readerShouldBlock 看 AQS 队列中第一个节点是否是写锁 // true 则该阻塞, false 则不阻塞 final boolean readerShouldBlock() { return apparentlyFirstQueuedIsExclusive(); } // AQS 继承过来的方法, 方便阅读, 放在此处 // 与 tryAcquireShared 功能类似, 但会不断尝试 for (;;) 获取读锁, 执行过程中无阻塞 final int fullTryAcquireShared(Thread current) { HoldCounter rh = null; for (;;) { int c = getState(); if (exclusiveCount(c) != 0) { if (getExclusiveOwnerThread() != current) return -1; } else if (readerShouldBlock()) { // ... 省略不重要的代码 } if (sharedCount(c) == MAX_COUNT) throw new Error(&quot;Maximum lock count exceeded&quot;); if (compareAndSetState(c, c + SHARED_UNIT)) { // ... 省略不重要的代码 return 1; } } } // AQS 继承过来的方法, 方便阅读, 放在此处 private void doAcquireShared(int arg) { // 将当前线程关联到一个 Node 对象上, 模式为共享模式 final Node node = addWaiter(Node.SHARED); boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); if (p == head) { // 再一次尝试获取读锁 int r = tryAcquireShared(arg); // 成功 if (r &gt;= 0) { // ㈠ // r 表示可用资源数, 在这里总是 1 允许传播 //（唤醒 AQS 中下一个 Share 节点） setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; } } if ( // 是否在获取读锁失败时阻塞（前一个阶段 waitStatus == Node.SIGNAL） shouldParkAfterFailedAcquire(p, node) &amp;&amp; // park 当前线程 parkAndCheckInterrupt() ) { interrupted = true; } } } finally { if (failed) cancelAcquire(node); } } // ㈠ AQS 继承过来的方法, 方便阅读, 放在此处 private void setHeadAndPropagate(Node node, int propagate) { Node h = head; // Record old head for check below // 设置自己为 head setHead(node); // propagate 表示有共享资源（例如共享读锁或信号量） // 原 head waitStatus == Node.SIGNAL 或 Node.PROPAGATE // 现在 head waitStatus == Node.SIGNAL 或 Node.PROPAGATE if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) { Node s = node.next; // 如果是最后一个节点或者是等待共享读锁的节点 if (s == null || s.isShared()) { // 进入 ㈡ doReleaseShared(); } } } // ㈡ AQS 继承过来的方法, 方便阅读, 放在此处 private void doReleaseShared() { // 如果 head.waitStatus == Node.SIGNAL ==&gt; 0 成功, 下一个节点 unpark // 如果 head.waitStatus == 0 ==&gt; Node.PROPAGATE, 为了解决 bug, 见后面分析，参考这里：http://www.tianxiaobo.com/2018/05/01/AbstractQueuedSynchronizer-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90-%E7%8B%AC%E5%8D%A0-%E5%85%B1%E4%BA%AB%E6%A8%A1%E5%BC%8F/#5propagate-%E7%8A%B6%E6%80%81%E5%AD%98%E5%9C%A8%E7%9A%84%E6%84%8F%E4%B9%89 for (;;) { Node h = head; // 队列还有节点 if (h != null &amp;&amp; h != tail) { int ws = h.waitStatus; if (ws == Node.SIGNAL) { if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases // 下一个节点 unpark 如果成功获取读锁 // 并且下下个节点还是 shared, 继续 doReleaseShared unparkSuccessor(h); } else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS } if (h == head) // loop if head changed break; } }} 读锁释放流程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455static final class NonfairSync extends Sync { // ReadLock 方法, 方便阅读, 放在此处 public void unlock() { sync.releaseShared(1); } // AQS 继承过来的方法, 方便阅读, 放在此处 public final boolean releaseShared(int arg) { if (tryReleaseShared(arg)) { doReleaseShared(); return true; } return false; } // Sync 继承过来的方法, 方便阅读, 放在此处 protected final boolean tryReleaseShared(int unused) { // ... 省略不重要的代码 for (;;) { int c = getState(); int nextc = c - SHARED_UNIT; if (compareAndSetState(c, nextc)) { // 读锁的计数不会影响其它获取读锁线程, 但会影响其它获取写锁线程 // 计数为 0 才是真正释放 return nextc == 0; } } } // AQS 继承过来的方法, 方便阅读, 放在此处 private void doReleaseShared() { // 如果 head.waitStatus == Node.SIGNAL ==&gt; 0 成功, 下一个节点 unpark // 如果 head.waitStatus == 0 ==&gt; Node.PROPAGATE for (;;) { Node h = head; if (h != null &amp;&amp; h != tail) { int ws = h.waitStatus; // 如果有其它线程也在释放读锁，那么需要将 waitStatus 先改为 0 // 防止 unparkSuccessor 被多次执行 if (ws == Node.SIGNAL) { if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); } // 如果已经是 0 了，改为 -3，用来解决传播性，见后文信号量 bug 分析 else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS } if (h == head) // loop if head changed break; } }} StampedLockStampedLock 是为了进一步优化读写锁。ReentrantReadWriteLock 即使可以读并发，比 ReentrantLock 提上了效率，但是仍然可以优化效率。因为ReentrantReadWriteLock的底层毕竟每次都用CAS来修改state状态，这样性能比不上不加锁。 该类自 JDK 8 加入，是为了进一步优化读性能，它的特点是在使用读锁、写锁时都必须配合【戳】使用。整体流程就是：先乐观读，得到“戳”之后，验戳，如果失败也就是验戳返回false（可能因为有写锁做了更改），那么这时才会升级成读锁。 加解读锁： 12long stamp = lock.readLock();lock.unlockRead(stamp); 加解写锁： 12long stamp = lock.writeLock();lock.unlockWrite(stamp); 乐观读，StampedLock 支持 tryOptimisticRead() 方法（乐观读），读取完毕后需要做一次戳校验，如果校验通过，表示这期间确实没有写操作，数据可以安全使用，如果校验没通过，需要重新获取读锁，原来读的作废，升级完读锁再读，保证数据安全。 12345long stamp = lock.tryOptimisticRead();// 验戳if(!lock.validate(stamp)){ // 锁升级} 提供一个 数据容器类 内部分别使用读锁保护数据的 read() 方法，写锁保护数据的 write() 方法，案例如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Slf4j(topic = &quot;c.DataContainer&quot;)class DataContainer { private int data; private final StampedLock lock = new StampedLock(); public DataContainer(int data) { this.data = data; } public int read(int readTime) throws InterruptedException { // 乐观读 不加锁 long stamp = lock.tryOptimisticRead(); log.debug(&quot;optimistic read locking...{}&quot;, stamp); TimeUnit.SECONDS.sleep(1);// 模拟读取耗时 // 返回数据之前,先校验乐观读到的数据是否有效 if (lock.validate(stamp)) { // 有效 返回读取的值 log.debug(&quot;read finish...{}, data:{}&quot;, stamp, data); return data; } try { log.debug(&quot;updating to read lock... {}&quot;, stamp); // 无效 升级成加读锁 stamp = lock.readLock(); log.debug(&quot;read lock {}&quot;, stamp); // 再读 TimeUnit.SECONDS.sleep(1);// 模拟读取耗时 log.debug(&quot;read finish...{}, data:{}&quot;, stamp, data); // 返回 return data; } finally { log.debug(&quot;read unlock {}&quot;, stamp); // 释放读锁 lock.unlockRead(stamp); } } public void write(int newData) throws InterruptedException { long stamp = lock.writeLock(); log.debug(&quot;write lock {}&quot;, stamp); try { TimeUnit.SECONDS.sleep(2); this.data = newData; } finally { log.debug(&quot;write unlock {}&quot;, stamp); lock.unlockWrite(stamp); } }} 测试 读-读 可以优化 12345678910111213141516171819202122232425public static void main(String[] args) { DataContainer container = new DataContainer(2); new Thread(new Runnable() { @Override public void run() { try { int result = container.read(1); } catch (InterruptedException e) { e.printStackTrace(); } } }, &quot;T1&quot;).start(); new Thread(new Runnable() { @Override public void run() { try { int result = container.read(1); } catch (InterruptedException e) { e.printStackTrace(); } } }, &quot;T2&quot;).start(); } 输出结果，可以看到实际没有加读锁。是乐观锁optimistic的方式读的，stamp的值是256一直没变。所以乐观读到的数据有效。 123420:08:10 [T2] c.DataContainer - optimistic read locking...25620:08:10 [T1] c.DataContainer - optimistic read locking...25620:08:11 [T1] c.DataContainer - read finish...256, data:220:08:11 [T2] c.DataContainer - read finish...256, data:2 测试 读-写 时优化读补加读锁 12345678910111213141516171819202122232425262728293031323334353637package com.chan.concurrent.stampedLock;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.StampedLock;public class Demo { public static void main(String[] args) throws InterruptedException { DataContainer container = new DataContainer(2); new Thread(new Runnable() { @Override public void run() { try { int result = container.read(1); } catch (InterruptedException e) { e.printStackTrace(); } } }, &quot;T1&quot;).start(); Thread.sleep(1000);// 1s后创建线程T2 此时T1还没有执行完 因为模拟读耗时2s new Thread(new Runnable() { @Override public void run() { try { container.write(6666666); } catch (InterruptedException e) { e.printStackTrace(); } } }, &quot;T2&quot;).start(); }} 输出结果 123456720:30:21 [T1] c.DataContainer - optimistic read locking...25620:30:22 [T2] c.DataContainer - write lock 38420:30:23 [T1] c.DataContainer - updating to read lock... 25620:30:24 [T2] c.DataContainer - write unlock 38420:30:24 [T1] c.DataContainer - read lock 51320:30:26 [T1] c.DataContainer - read finish...513, data:666666620:30:26 [T1] c.DataContainer - read unlock 513 总结来说，ReentrantReadWriteLock 和 StampedLock 都是可以实现读读可并发，读写、写写操作是互斥的，只不过 StampedLock 是对 ReentrantReadWriteLock 读并发的性能优化，都可以保证数据的安全性。在可能发生多线程操作共享资源的业务中，可以将读操作的代码设计用读锁，写操作的代码加写锁，保证读读并发，读写、写写互斥。 StampedLock 无论是读锁还是写锁都不支持条件变量 StampedLock 无论是读锁还是写锁都不支持可重入 因此并不能取代ReentrantReadWriteLock，具体的使用还需要看场景。 Semaphore基本使用信号量工具类，用来限制能同时访问共享资源的线程上限。这个是与ReentrantLock不同的，ReentrantLock是独占锁，同一时刻只允许一个线程访问这个共享资源。但是Semaphore适用于共享资源有多个，也允许有多个线程来访问资源，只不过是希望对访问的线程上限加以限制。 这样说可能会有一些朦胧不好理解，下面我举个栗子。 比如说一个停车场，汽车可以临时停泊，那么这个停车场的车位就是属于共享资源，数量是有限的，汽车就属于线程，所以这个停车上限就有限制。不能一个车位停多台车，只能一个车位对应停一台车。 由此可见Semaphore信号量可以实现限流，但是只适合单机版限流，并不适用于分布式的场景。 12345678910111213141516171819202122232425262728293031323334353637package com.chan.concurrent.semaphore;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.Semaphore;import java.util.concurrent.TimeUnit;@Slf4j(topic = &quot;c.Demo&quot;)public class Demo { public static void main(String[] args) { // 好比车库中三个车位 Semaphore semaphore = new Semaphore(3); // 10个线程同时运行 比如十台车一起来了 for (int i = 0; i &lt; 10; i++) { new Thread(new Runnable() { @Override public void run() { try { // 获取许可 有空余的车位才许可(打比方) semaphore.acquire(); // 线程执行自己的内容 好比车停进来了 log.debug(&quot;running...&quot;); TimeUnit.SECONDS.sleep(1); log.debug(&quot;end...&quot;); } catch (InterruptedException e) { e.printStackTrace(); } finally { // 释放许可 有车开走了空出车位给之前没车位的车 semaphore.release(); } } }).start(); } }} 123456789101112131415161718192020:49:00 [Thread-2] c.Demo - running...20:49:00 [Thread-0] c.Demo - running...20:49:00 [Thread-1] c.Demo - running...20:49:01 [Thread-2] c.Demo - end...20:49:01 [Thread-0] c.Demo - end...20:49:01 [Thread-1] c.Demo - end...20:49:01 [Thread-3] c.Demo - running...20:49:01 [Thread-5] c.Demo - running...20:49:01 [Thread-4] c.Demo - running...20:49:02 [Thread-3] c.Demo - end...20:49:02 [Thread-5] c.Demo - end...20:49:02 [Thread-4] c.Demo - end...20:49:02 [Thread-6] c.Demo - running...20:49:02 [Thread-9] c.Demo - running...20:49:02 [Thread-7] c.Demo - running...20:49:03 [Thread-7] c.Demo - end...20:49:03 [Thread-9] c.Demo - end...20:49:03 [Thread-6] c.Demo - end...20:49:03 [Thread-8] c.Demo - running...20:49:04 [Thread-8] c.Demo - end... 图解流程Semaphore 有点像一个停车场，permits 就好像停车位数量，当线程获得了 permits 就像是获得了停车位，然后停车场显示空余车位减一刚开始，permits（state）为 3，这时 5 个线程来获取资源 假设其中 Thread-1，Thread-2，Thread-4 cas 竞争成功，而 Thread-0 和 Thread-3 竞争失败，进入 AQS 队列park 阻塞 这时 Thread-4 释放了 permits，状态如下 接下来 Thread-0 竞争成功，permits 再次设置为 0，设置自己为 head 节点，断开原来的 head 节点，unpark 接下来的 Thread-3 节点，但由于 permits 是 0，因此 Thread-3 在尝试不成功后再次进入 park 状态 源码分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899static final class NonfairSync extends Sync { private static final long serialVersionUID = -2694183684443567898L; NonfairSync(int permits) { // permits 即 state super(permits); } // Semaphore 方法, 方便阅读, 放在此处 public void acquire() throws InterruptedException { sync.acquireSharedInterruptibly(1); } // AQS 继承过来的方法, 方便阅读, 放在此处 public final void acquireSharedInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg); } // 尝试获得共享锁 protected int tryAcquireShared(int acquires) { return nonfairTryAcquireShared(acquires); } // Sync 继承过来的方法, 方便阅读, 放在此处 final int nonfairTryAcquireShared(int acquires) { for (;;) { int available = getState(); int remaining = available - acquires; if ( // 如果许可已经用完, 返回负数, 表示获取失败, 进入 doAcquireSharedInterruptibly remaining &lt; 0 || // 如果 cas 重试成功, 返回正数, 表示获取成功 compareAndSetState(available, remaining) ) { return remaining; } } } // AQS 继承过来的方法, 方便阅读, 放在此处 private void doAcquireSharedInterruptibly(int arg) throws InterruptedException { final Node node = addWaiter(Node.SHARED); boolean failed = true; try { for (;;) { final Node p = node.predecessor(); if (p == head) { // 再次尝试获取许可 int r = tryAcquireShared(arg); if (r &gt;= 0) { // 成功后本线程出队（AQS）, 所在 Node设置为 head // 如果 head.waitStatus == Node.SIGNAL ==&gt; 0 成功, 下一个节点 unpark // 如果 head.waitStatus == 0 ==&gt; Node.PROPAGATE // r 表示可用资源数, 为 0 则不会继续传播 setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; } } // 不成功, 设置上一个节点 waitStatus = Node.SIGNAL, 下轮进入 park 阻塞 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); } } finally { if (failed) cancelAcquire(node); } } // Semaphore 方法, 方便阅读, 放在此处 public void release() { sync.releaseShared(1); } // AQS 继承过来的方法, 方便阅读, 放在此处 public final boolean releaseShared(int arg) { if (tryReleaseShared(arg)) { doReleaseShared(); return true; } return false; } // Sync 继承过来的方法, 方便阅读, 放在此处 protected final boolean tryReleaseShared(int releases) { for (;;) { int current = getState(); int next = current + releases; if (next &lt; current) // overflow throw new Error(&quot;Maximum permit count exceeded&quot;); if (compareAndSetState(current, next)) return true; } }} 信号量应用 使用 Semaphore 限流，在访问高峰期时，让请求线程阻塞，高峰期过去再释放许可，当然它只适合限制单机线程数量，并且仅是限制线程数，而不是限制资源数（例如连接数，请对比 Tomcat LimitLatch 的实现） 用 Semaphore 实现简单连接池，对比『享元模式』下的实现（用wait notify），性能和可读性显然更好，注意下面的实现中线程数和数据库连接数是相等的 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Slf4j(topic = &quot;c.Pool&quot;)class Pool { // 1. 连接池大小 private final int poolSize; // 2. 连接对象数组 private Connection[] connections; // 3. 连接状态数组 0 表示空闲， 1 表示繁忙 private AtomicIntegerArray states; private Semaphore semaphore; // 4. 构造方法初始化 public Pool(int poolSize) { this.poolSize = poolSize; // 让许可数与资源数一致 this.semaphore = new Semaphore(poolSize); this.connections = new Connection[poolSize]; this.states = new AtomicIntegerArray(new int[poolSize]); for (int i = 0; i &lt; poolSize; i++) { connections[i] = new MockConnection(&quot;连接&quot; + (i+1)); } } // 5. 借连接 public Connection borrow() {// t1, t2, t3 // 获取许可 try { semaphore.acquire(); // 没有许可的线程，在此等待 } catch (InterruptedException e) { e.printStackTrace(); } for (int i = 0; i &lt; poolSize; i++) { // 获取空闲连接 if(states.get(i) == 0) { if (states.compareAndSet(i, 0, 1)) { log.debug(&quot;borrow {}&quot;, connections[i]); return connections[i]; } } } // 不会执行到这里 return null; } // 6. 归还连接 public void free(Connection conn) { for (int i = 0; i &lt; poolSize; i++) { if (connections[i] == conn) { states.set(i, 0); log.debug(&quot;free {}&quot;, conn); semaphore.release(); break; } } }} CountdownLatchCountdown：倒计时；Latch：锁。可以配合线程池用。 CountDownLatch 是共享锁的一种实现，它默认构造 AQS 的 state 值为 count。当线程使用 countDown 方法时，其实使用了tryReleaseShared方法以 CAS 的操作来让 state-1 ，直至 state 减到 0 就代表 count 数量的线程都调用了 countDown 方法。当调用 await 方法的时候，如果 state 不为 0，就代表仍然有线程没有调用 countDown 方法，那么就把已经调用过 countDown 方法的线程都放入阻塞队列 Park 住，并自旋 CAS 判断 state == 0 是否成立，直至最后一个（第 count 个）线程调用了countDown 方法，使得 state == 0，于是乎阻塞的线程便判断成功，全部往下继续执行。这块很重要！！！ 主要是用来进行线程同步协作，等待所有线程完成倒计时。其中构造参数用来初始化等待计数值，await() 用来等待计数归零，countDown() 用来让计数减一并等待计数归零。让一个线程等待所有线程完成倒计时后再恢复运行。 这可能会让人联想到 join()，我们使用线程一般都是使用线程池的，所以 join 方法并不适合在我们创建线程池的时候使用，并且是有区别的。 这里也要说一下，CountdownLatch 适用于线程间无需传递结果的场景，如果需要线程间传递结果，也就是说一个线程的结果需要被另一个线程用到，那么 CountdownLatch 是不适合的，这时就要用 submit 配合 Future 了。 应用之同步等待多线程执行完毕1234567891011121314151617181920212223242526272829303132333435363738394041package com.chan.concurrent.countDownLatch;import java.util.Arrays;import java.util.Random;import java.util.concurrent.CountDownLatch;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class Demo1 { public static void main(String[] args) throws InterruptedException { ExecutorService service = Executors.newFixedThreadPool(10); CountDownLatch latch = new CountDownLatch(10); String[] allPlayers = new String[10]; Random random = new Random(); for (int i = 0; i &lt; 10; i++) { // i是个变量 在下面的lambda不能用 int p = i; service.submit(new Runnable() { @Override public void run() { for (int j = 0; j &lt;= 100; j++) { try { Thread.sleep(random.nextInt(100)); } catch (InterruptedException e) { e.printStackTrace(); } allPlayers[p] = j + &quot;%&quot;; System.out.print(&quot;\\r&quot; + Arrays.toString(allPlayers)); } latch.countDown();// count-1 } }); } latch.await();// 如果上一步count-1结果不为0，这里会先阻塞，等待count减到0才继续执行下面的。 System.out.println(&quot;\\n游戏开始&quot;); service.shutdown(); }}//模拟LOL10人加载界面[100%, 100%, 100%, 100%, 100%, 100%, 100%, 100%, 100%, 100%]游戏开始 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.chan.concurrent.countDownLatch;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.CountDownLatch;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.TimeUnit;@Slf4j(topic = &quot;c.Demo2&quot;)public class Demo2 { public static void main(String[] args) { CountDownLatch latch = new CountDownLatch(3); ExecutorService service = Executors.newFixedThreadPool(4); service.submit(() -&gt; { log.debug(&quot;begin...&quot;); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } latch.countDown();// count-1 判断count是否为0 为0才继续执行下面的 不为0先阻塞 log.debug(&quot;end...{}&quot;, latch.getCount()); }); service.submit(() -&gt; { log.debug(&quot;begin...&quot;); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } latch.countDown();// count-1 判断count是否为0 为0才继续执行下面的 不为0先阻塞 log.debug(&quot;end...{}&quot;, latch.getCount()); }); service.submit(() -&gt; { log.debug(&quot;begin...&quot;); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } latch.countDown();// count-1 判断count是否为0 为0才继续执行下面的 不为0先阻塞 log.debug(&quot;end...{}&quot;, latch.getCount()); }); service.submit(() -&gt; { try { log.debug(&quot;waiting...&quot;); latch.await();//count是否为0 其它线程将count减为0才继续执行下面的 没减到0先阻塞等待 log.debug(&quot;wait end...&quot;); } catch (InterruptedException e) { e.printStackTrace(); } }); }}//输出:21:30:34 [pool-1-thread-4] c.Demo2 - waiting...21:30:34 [pool-1-thread-3] c.Demo2 - begin...21:30:34 [pool-1-thread-2] c.Demo2 - begin...21:30:34 [pool-1-thread-1] c.Demo2 - begin...21:30:35 [pool-1-thread-4] c.Demo2 - wait end...21:30:35 [pool-1-thread-1] c.Demo2 - end...021:30:35 [pool-1-thread-2] c.Demo2 - end...021:30:35 [pool-1-thread-3] c.Demo2 - end...0 CyclicBarrierCyclicBarri[ˈsaɪklɪk ˈbæriɚ] 循环栅栏，用来进行线程协作，等待线程满足某个计数。 看到这是不是觉得和 CountdownLatch 很相似？是的，功能是基本相近的，只不过有个区别，就是 CountdownLatch 初始化之后，构造中传的 count 值是不可变的，不能改了，是不可重用的，用完（也就是说 count 被减为 0 ，之后是不能复原的）要重新创建对象与 CyclicBarrier 不同。 CyclicBarrier，构造时两个参数，第一个设置『计数个数』第二个传一个线程（lambda 表达式或者匿名内部类都可），这个线程就相当于 CountdownLatch 的那个等待线程。然后每个线程执行到某个需要“同步”的时刻调用 await() 方法进行等待，当等待的线程数满足『计数个数』时，继续执行，其它的线程都执行完之后，最后等待线程中的代码运行。跟CountdownLatch差不多，这里面的 await 也是会 -1 操作的，和 CountdownLatch 的 countDown 对应。但主要是 CyclicBarrier 这个构造完 count 可以重用，方便下面这种循环执行的场景，就不用每次循环都创建一次 CountdownLatch 对象了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.chan.concurrent.cyclicBarrier;import java.util.Date;import java.util.concurrent.BrokenBarrierException;import java.util.concurrent.CyclicBarrier;public class Demo { public static void main(String[] args) { CyclicBarrier cb = new CyclicBarrier(2, new Runnable() { @Override public void run() { // 通过其它线程调用await 让2减到0之后,这里才会执行 System.out.println(&quot;end...&quot; + new Date()); } }); for (int i = 0; i &lt; 3; i++) {//这里循环 每次循环需要重置CyclicBarrier构造中的count 因此用CyclicBarrier而非CountdownLatch new Thread(() -&gt; { System.out.println(&quot;线程1开始..&quot; + new Date()); try { Thread.sleep(1000); } catch (InterruptedException ignored) { } try { cb.await(); // 当个数不足时，2-1=1，等待 } catch (InterruptedException | BrokenBarrierException e) { e.printStackTrace(); } System.out.println(&quot;线程1继续向下运行...&quot; + new Date()); }, &quot;t1&quot;).start(); new Thread(() -&gt; { System.out.println(&quot;线程2开始..&quot; + new Date()); try { Thread.sleep(2000); } catch (InterruptedException ignored) { } try { cb.await(); // 2秒后，线程个数够2，1-1=0，继续运行 } catch (InterruptedException | BrokenBarrierException e) { e.printStackTrace(); } System.out.println(&quot;线程2继续向下运行...&quot; + new Date()); }, &quot;t2&quot;).start(); } }} 输出： 123456789101112131415线程1开始..Thu Oct 14 21:17:34 CST 2021线程1开始..Thu Oct 14 21:17:34 CST 2021线程2开始..Thu Oct 14 21:17:34 CST 2021线程2开始..Thu Oct 14 21:17:34 CST 2021线程2开始..Thu Oct 14 21:17:34 CST 2021线程1开始..Thu Oct 14 21:17:34 CST 2021end...Thu Oct 14 21:17:34 CST 2021线程1继续向下运行...Thu Oct 14 21:17:34 CST 2021线程1继续向下运行...Thu Oct 14 21:17:34 CST 2021end...Thu Oct 14 21:17:36 CST 2021线程2继续向下运行...Thu Oct 14 21:17:36 CST 2021end...Thu Oct 14 21:17:36 CST 2021线程2继续向下运行...Thu Oct 14 21:17:36 CST 2021线程1继续向下运行...Thu Oct 14 21:17:36 CST 2021线程2继续向下运行...Thu Oct 14 21:17:36 CST 2021 这个案例如果用线程池的话，线程数要和计数的数值一致！ CompletableFuture异步编排线程回顾初始化线程的 4 种方式1、继承Thread 12MyThread th = new MyThread();th.start();// 启动线程 2、实现Runnable接口 12MyRunnableImpl myRunnable = new MyRunnableImpl();new Thread(myRunnable).start(); 3、实现Callable接口 + FutureTask（可以拿到返回结果，可以处理异常） 1234FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(new MyCallable());new Thread(futureTask).start();// 阻塞等待整个线程执行完成，获取返回结果Integer res = futureTask.get(); 4、线程池 给线程池直接提交任务。通过如下两种方式初始化线程池： 1234Executors.newFiexedThreadPool(3);// 少用，其源码中使用的new LinkedBlockingQueue&lt;Runnable&gt;()默认是Integer的最大值，内存不够。// new LinkedBlockingQueue&lt;&gt;():默认是Integer的最大值，内存不够。//或者new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, TimeUnit unit, workQueue, threadFactory, handler); 通过线程池性能稳定，也可以获取执行结果，并捕获异常。但是，在业务复杂情况下，一个异步调用可能会依赖于另一个异步调用的执行结果。 区别： 1、2不能得到返回值，3可以获取返回值 1、2、3都不能控制资源，4可以控制资源，性能稳定。 线程池的七大参数 corePoolSize：核心线程数【这些核心线程一直存在除非设置了（allowCoreThreadTimeOut）】，线程池创建好以后就准备就绪。比如corePoolSize设置为5，那么内部就会创建5个线程，5个 Thread t = new Thread(); 就绪，一个任务来了就 t.start(); 执行。 maximumPoolSize：线程池中允许的最大线程数量，控制资源。 keepAliveTime：存活时间，这个存活时间是针对于“临时工”线程。如果池中当前的线程数量大于 core ，那么只要线程空闲时间到了指定的 keepAliveTime，就会释放这个空闲的线程，最终线程池维持在 corePoolSize 大小。“临时工”线程总数为 maximumPoolSize - corePoolSize。 unit：时间单位。 BlockingQueue workQueue：阻塞队列，用来存储等待执行的任务，如果当前对线程的需求超过了 corePoolSize大小，就会放在这里等待空闲线程执行。只要有线程空闲，就会去队列里面取出新的任务继续执行。 threadFactory：创建线程的工厂，比如指定线程名等。默认的就好，也可自定义。如果在每次自己创建线程时，线程的名字有自己的约束，那么可以自己写一个线程的创建工厂，继承threadFactory。 RejectedExecutionHandler handler：如果队列满了，就用拒绝策略，按照我们指定的拒绝策略来拒绝执行任务。 运行流程： 线程池创建，准备好 core 数量的核心线程，准备接受任务 新的任务进来，用 core 准备好的空闲线程执行。 （1）core 满了，就将再进来的任务放入阻塞队列中。空闲的 core 就会自己去阻塞队列获取任务执行 （2）阻塞队列满了，就直接开新线程执行，最大只能开到 max 指定的数量 （3）max 都执行好了。Max-core 数量空闲的线程会在 keepAliveTime 指定的时间后自动销毁。最终保持到 core 大小 （4）如果线程数开到了 max 的数量，还有新任务进来，就会使用 reject 指定的拒绝策略进行处理 所有的线程创建都是由指定的 factory 创建的。 面试问题： 问：一个线程池 core 7； max 20 ，queue：50，100 并发进来怎么分配的？ 答：先有 7 个能直接得到执行，接下来 50 个进入队列排队，在多开 13 个继续执行。现在 70 个被安排上了。剩下 30 个默认拒绝策略。 常见的 4 种线程池 newCachedThreadPool：创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。 newFixedThreadPool：创建一个定长线程池（core = max），可控制线程最大并发数，超出的线程会在队列中等待 newScheduledThreadPool：创建一个定长线程池，支持定时及周期性任务执行。 newSingleThreadExecutor：创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序（FIFO，LIFO，优先级）执行。 开发中为什么使用线程池 降低资源的消耗 通过重复利用已经创建好的线程降低线程的创建和销毁带来的损耗 提高响应速度 因为线程池中的线程数没有超过线程池的最大上限时，有的线程处于等待分配任务的状态，当任务来时无需创建新的线程就能执行 提高线程的可管理性 线程池会根据当前系统特点对池内的线程进行优化处理，减少创建和销毁线程带来的系统开销。无限的创建和销毁线程不仅消耗系统资源，还降低系统的稳定性，使用线程池进行统一分配。 CompletableFuture 异步编排业务场景： 查询商品详情页的逻辑比较复杂，有些数据还需要远程调用，必然需要花费更多的时间。 假如商品详情页的每个查询，需要如下标注的时间才能完成，那么，用户需要 5.5s 后才能看到商品详情页的内容。很显然是不能接受的。如果有多个线程同时完成这 6 步操作，也许只需要 1.5s 即可完成响应。 Future 是 Java 5 添加的类，用来描述一个异步计算的结果。你可以使用isDone方法检查计算是否完成，或者使用get阻塞住调用线程，直到计算完成返回结果，你也可以使用cancel 方法停止任务的执行。 虽然Future以及相关使用方法提供了异步执行任务的能力，但是对于结果的获取却是很不方便，只能通过阻塞或者轮询的方式得到任务的结果。阻塞的方式显然和我们的异步编程的初衷相违背，轮询的方式又会耗费无谓的 CPU 资源，而且也不能及时地得到计算结果，为什么不能用观察者设计模式当计算结果完成及时通知监听者呢？ 很多语言，比如 Node.js，采用回调的方式实现异步编程。Java 的一些框架，比如 Netty，自己扩展了 Java 的 Future接口，提供了addListener等多个扩展方法；Google guava 也提供了通用的扩展 Future；Scala 也提供了简单易用且功能强大的 Future/Promise 异步编程模式。作为正统的 Java 类库，是不是应该做点什么，加强一下自身库的功能呢？ 在 Java 8 中，新增加了一个包含 50 个方法左右的类：CompletableFuture，提供了非常强大的Future 的扩展功能，可以帮助我们简化异步编程的复杂性，提供了函数式编程的能力，可以通过回调的方式处理计算结果，并且提供了转换和组合 CompletableFuture 的方法。 CompletableFuture 类实现了 Future 接口，所以你还是可以像以前一样通过get方法阻塞或者轮询的方式获得结果，但是这种方式不推荐使用。CompletableFuture 和 FutureTask 同属于 Future 接口的实现类，都可以获取线程的执行结果。 创建异步对象CompletableFuture 提供了四个静态方法来创建一个异步操作。 1、runXxxx 都是没有返回结果的，supplyXxx 都是可以获取返回结果的 2、可以传入自定义的线程池，否则就用默认的线程池； 计算完成时回调方法 whenComplete 可以处理正常和异常的计算结果 exceptionally 处理异常情况。 whenComplete 和 whenCompleteAsync 的区别： whenComplete：是执行当前任务的线程执行继续执行 whenComplete 的任务。 whenCompleteAsync：是执行把 whenCompleteAsync 这个任务继续提交给线程池来进行执行。 注：方法不以 Async 结尾，意味着 Action 使用相同的线程执行；而 Async 可能会使用其他线程执行（如果是使用相同的线程池，也可能会被同一个线程选中执行。） handle 方法 和 complete 一样，可对结果做最后的处理（可处理异常），可改变返回值。 线程串行化方法 thenApply 方法：当一个线程依赖另一个线程时，获取上一个任务返回的结果，并返回当前任务的返回值。 thenAccept 方法：消费处理结果。接收任务的处理结果，并消费处理，无返回结果。 thenRun 方法：只要上面的任务执行完成，就开始执行 thenRun，只是处理完任务后，执行 thenRun 的后续操作 带有 Async 默认是异步执行的。同之前。以上都要前置任务成功完成。 Function&lt;? super T,? extends U&gt; T：上一个任务返回结果的类型 U：当前任务的返回值类型 两任务组合 - 都要完成 两个任务必须都完成，触发该任务。 thenCombine：组合两个 future，获取两个 future 的返回结果，并返回当前任务的返回值 thenAcceptBoth：组合两个 future，获取两个 future 任务的返回结果，然后处理任务，没有返回值。 runAfterBoth：组合两个 future，不需要获取 future 的结果，只需两个 future 处理完任务后，处理该任务 两任务组合 - 一个完成 当两个任务中，任意一个 future 任务完成的时候，执行任务。 applyToEither：两个任务有一个执行完成，获取它的返回值，处理任务并有新的返回值。 acceptEither：两个任务有一个执行完成，获取它的返回值，处理任务，没有新的返回值。 runAfterEither：两个任务有一个执行完成，不需要获取 future 的结果，处理任务，也没有返回值 多任务组合 allOf：等待所有任务完成 anyOf：只要有一个任务完成","link":"/posts/20211124/java-concurrent-6.html"},{"title":"并发模块之基础","text":"并发与并行它们的目标都是最大化 CPU 的使用率。 并行parallel：指在同一时刻，有多条指令在多个处理器上同时执行。所以无论从微观还是从宏观来看，二者都是一起执行的。 并发concurrency：指在同一个时间段内多条指令执行，但是在同一时刻只能有一条指令执行，多个指令被快速的轮换执行，使得在宏观上具有多个进程同时执行的效果，但在微观上并不是同时执行的，宏观并行，微观串行，只是把时间分成若干时间片，OS 中有一个组件叫任务调度器，将CPU的时间片分给不同的程序使用，使多个进程快速交替的执行。 在操作系统中，安装了多个程序。在单 CPU 的系统中，虽然宏观上看起来可能多个程序都打开同时运行着，但是其实每个时刻只能有一道程序执行，即微观上这些程序是分时交替运行的，只不过是给人的感觉是同时运行，那是因为分时交替运行的时间是非常短的，CPU 在不同进程的不同线程任务间高速的切换。 而在多个 CPU 系统中，则可以实现多任务并行执行，即利用每个处理器核心来处理一个可以并发执行的程序，这样多个程序便可以同时执行。目前电脑市场上说的多核 CPU，便是多核处理器，核越多，并行处理的程序越多，能大大的提高电脑运行的效率。 单核处理器的计算机肯定是不能并行的处理多个任务的，只能是多个任务在单个 CPU 上并发运行。同理，线程也是一样的，从宏观角度上理解线程是并行运行的，但是从微观角度上分析却是串行运行的，即一个线程一个线程的去运行，当系统只有一个 CPU 时，会以某种顺序执行多个线程，我们把这种情况称之为线程调度，如果没有特殊的设定，线程间就是抢占式调度。 并行在多处理器系统中存在，而并发可以在单处理器和多处理器系统中都存在，并发能够在单处理器系统中存在是因为并发是并行的假象，并行要求程序能够同时执行多个操作，而并发只是要求程序假装同时执行多个操作（每个小时间片执行一个操作，多个操作串行快速切换执行）。 进程与线程我们的程序下载到电脑是放在硬盘中的，当我们点击应用程序执行，程序就会进入到内存中，占用一些内存空间去执行，进入到内存的程序叫做进程。一个进程中可能会有多个线程。所以我们的电脑的运行内存中可能会有多个进程，每个进程中可能又有多个线程。线程是进程中的一个执行单元，一个进程中至少有一个线程，一个进程中是可以有多个线程的。 比如腾讯电脑管家这个软件，我们下载到电脑的硬盘中，存入下载路径，当我们点击执行腾讯电脑管家的时候，这个程序会进入到内存中，就是一个电脑管家进程，那我们知道腾讯电脑管家里面有不同的功能，比如病毒查杀，清理垃圾，电脑加速等等，这就是这个进程中的多个线程。我们依次点击病毒查杀，清理垃圾，电脑加速执行，就会依次开启一条应用程序到 CPU 的执行路径，CPU 就可以通过这个路径执行功能，那么这个路径就叫做线程。这三个线程并发执行，CPU 在多个线程之间做高速的切换，轮流执行多个线程。 主线程执行的时候，jvm 执行 main 方法，main 方法会进入到栈内存，栈内存中的每一个栈帧对应着一个方法的执行内存。jvm 会找 os 开辟一条 main 方法通向 CPU 的执行路径，CPU 就可以通过这个路径来执行 main 方法，这个路径有一个名字就叫做主线程。 多线程的创建继承 Thread 的方式创建多线程启动的第一种方法：继承Thread类，并重写run方法。创建子类对象调用start方法。 Thread 类构造方法： public Thread() :分配一个新的线程对象。 public Thread(String name) :分配一个指定名字的新的线程对象。 public Thread(Runnable target) :分配一个带有指定目标新的线程对象。 public Thread(Runnable target, String name) :分配一个带有指定目标新的线程对象并指定名字。 Thread 类常用方法： public String getName() :获取当前线程名称。 public void start() :导致此线程开始执行; Java虚拟机调用此线程的run方法。 public void run() :此线程要执行的任务在此处定义代码。 public static void sleep(long millis) :使当前正在执行的线程以指定的毫秒数暂停（暂时停止执行）。 public static Thread currentThread() :返回对当前正在执行的线程对象的引用。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class MyThread extends Thread { @Override public void run() { for (int i = 0; i &lt; 10; i++) { System.out.println(Thread.currentThread().getName()+ &quot;：&quot; + i); } }}/** * 模拟秒表 */public class MyThread1 extends Thread { public MyThread1(){} public MyThread1(String name){ super(name); } @Override public void run() { for (int i = 1; i &lt;= 60; i++) { try { System.out.println(Thread.currentThread().getName() + &quot;:&quot; + i); Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } }}public class Test { public static void main(String[] args) { //开启一个线程 MyThread mt = new MyThread(); mt.start(); //主线程 for (int i = 0; i &lt; 10; i++) { System.out.println(Thread.currentThread().getName()+ &quot;：&quot; + i); } //开启一个线程 MyThread1 mt1 = new MyThread1(&quot;秒表&quot;);//通过构造函数设置线程名称 mt1.start(); }} 程序启动运行 main 时候，java 虚拟机启动一个进程，主线程 main 在 main() 调用时候被创建。随着调用自定义的线程 mt 对象的 start 方法，另外一个新的线程也启动了，这样，整个应用就在多线程下运行。通过这张图我们可以很清晰的看到多线程的执行流程，那么为什么可以完成并发执行呢？多线程执行时，到底在内存中是如何运行的呢？以上个程序为例，大致进行图解说明： 多线程执行时，其实每一个执行线程都有一片自己所属的栈内存空间，因为要用来进行方法的压栈和弹栈，而每个方法就对应着栈内存中的每个栈帧。 由 JVM 完成主线程的开启这样一个 main 的栈空间，当 main 线程运行到 start 方法的时候，就会通知 JVM 要开启一个新的栈空间了，并且在新的栈空间里执行线程对象中的任务方法，也就是 run 方法。每个线程都有自己独立的栈空间。当执行线程的任务结束了，线程就自动在栈内存中释放了。当所有执行的线程都结束了，那么进程就结束了。 实现 Runnable 的方式创建多线程启动的第二种方法：实现Runnable接口，并重写run方法。创建线程Thread对象，将实现类传入构造，然后线程对象调用start方法。 步骤如下： 定义Runnable接口的实现类，并重写该接口的run()方法，该run()方法的方法体同样是该线程的线程执行体。 创建Runnable实现类的实例，并以此实例作为Thread的target来创建Thread对象，该Thread对象才是真正的线程对象。 调用线程对象的start()方法来启动线程。 123456789101112131415161718192021222324252627282930313233343536373839404142public class RunnableImpl implements Runnable { @Override public void run() { for (int i = 0; i &lt; 10; i++) { System.out.println(Thread.currentThread().getName() + &quot;：&quot; + i); } }}public class Test { public static void main(String[] args) { //通过实现Runnable接口创建线程 RunnableImpl target = new RunnableImpl(); Thread thread = new Thread(target); // Thread thread = new Thread(target,&quot;自定义线程&quot;);//自定义线程名称 thread.start(); //main线程自己做的 for (int i = 0; i &lt; 10; i++) { System.out.println(Thread.currentThread().getName() + &quot;：&quot; +i); } //匿名内部类的方法创建线程 Runnable runnable = new Runnable() { @Override public void run() { System.out.println(Thread.currentThread().getName()); } }; Thread thread1 = new Thread(runnable); thread1.start(); //匿名内部类的方法创建线程 new Thread(new Runnable() { @Override public void run() { System.out.println(Thread.currentThread().getName()); } }).start(); }} Thread和Runnable的区别 实现 Runnable 接口比继承 Thread 类所具有的优势： 适合多个相同的程序代码的线程去共享同一个资源。 可以避免 java 中的单继承的局限性。 增加程序的健壮性，实现解耦操作，代码可以被多个线程共享，代码和线程独立。 线程池只能放入实现 Runable 或 Callable 类线程，不能直接放入继承 Thread 的类。 扩充：在 java 中，每次程序运行至少启动 2 个线程。一个是 main 线程，一个是垃圾收集线程。每当使用 java 命令执行一个类的时候，实际上都会启动一个 JVM，每一个 JVM 其实在就是在操作系统中启动了一个进程。 FutureTask 配合 Thread 创建和运行线程123456789101112131415161718192021222324public class Test { public static void main(String[] args) { // 创建任务对象 FutureTask&lt;String&gt; task = new FutureTask&lt;&gt;(new Callable&lt;String&gt;() { @Override public String call() throws Exception { return Thread.currentThread().getName(); } }); // 参数1 是任务对象; 参数2 是线程名字，推荐 new Thread(task, &quot;myThread&quot;).start(); try { // 主线程阻塞，同步等待 task 执行完毕返回的结果 String s = task.get(); System.out.println(&quot;线程名称为: &quot; + s); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } }} 同步和异步从调用方角度来讲： 需要等待结果返回，才能继续运行就是同步； 不需要等待结果返回，就能继续运行就是异步。 应用 异步调用 多线程可以让方法执行变为异步的（即不要巴巴干等着）比如说读取磁盘文件时，假设读取操作花费了 5 秒钟，如果没有线程调度机制，这 5 秒 cpu 什么都做不了，其它代码都得暂停。 比如在项目中，视频文件需要转换格式等操作比较费时，这时开一个新线程处理视频转换，避免阻塞主线程。 tomcat 的异步 servlet 也是类似的目的，让用户线程处理耗时较长的操作，避免阻塞 tomcat 的工作线程 提高效率 多核CPU下，多线程并行执行可以提升效率； 单核CPU下，即使是多线程也无法提升效率，因为只能并发而不能并行，仍然是轮流执行的。 结论 单核 cpu 下，多线程不能实际提高程序运行效率，只是为了能够在不同的任务之间切换，不同线程轮流使用 cpu ，不至于一个线程总占用 cpu，别的线程没法干活。 多核 cpu 可以并行跑多个线程，但能否提高程序运行效率还是要分情况的。 IO 操作不占用 cpu，只是我们一般拷贝文件使用的是【阻塞 IO】，这时相当于线程虽然不用 cpu，但需要一直等待 IO 结束，没能充分利用 CPU。所以才有后面的【非阻塞 IO】和【异步 IO】优化。 线程调度 分时调度 所有线程轮流使用 CPU 的使用权，平均分配每个线程占用 CPU 的时间。 抢占式调度 优先让优先级高的线程使用CPU，如果线程的优先级相同，那么会随机选择一个（线程随机性），Java使用的为抢占式调度。 多线程并发执行的时候的随机性打印： 查看进程线程的方法 linux ps -fe 查看所有进程 ps -fT -p 查看某个进程（PID）的所有线程 kill 杀死进程 top -H -p 查看某个进程（PID）的所有线程 原理之线程运行栈与栈帧Java Virtual Machine Stacks （Java 虚拟机栈） 我们都知道 JVM 由堆、栈、方法区所组成，其中栈内存是给谁用的呢？其实就是线程，每个线程启动后，虚拟机都会为其分配一块栈内存。 每个栈由多个栈帧（Frame）组成，对应着每次方法调用时所占用的内存。Frame 在 idea 中通过 debug 调试的时候能看到。 每个线程只能有一个活动栈帧，对应着当前正在执行的那个方法。 运行一个类的时候，使用类加载机制，将类的字节码加载到 JVM 中，加载的位置是将字节码放到方法区。。。 主线程一启动，JVM 为主线程分配了一块栈内存（后进先出），这个栈内存其实就是个壳，里面由多个栈帧组成。主线程调用了主方法（main方法），那 JVM 就会为主方法在这个栈内存中生成一个栈帧 Frames。这个方法的局部变量、方法参数、返回地址等都会在这个栈帧中存储。 如果在主方法中又调用了其它方法，那就会产生一个新的栈帧，这个新栈帧又储存了这个方法的局部变量、方法参数、返回地址等。如果这个方法中又调用了另一个方法，那么以此类推。栈内存中的每个栈帧都对应一次方法的调用。方法对应栈帧，线程对应栈，线程的栈内存之间是相互独立的。 栈内存很简单，在这些方法都执行完了之后就会释放内存了。不像堆内存，还需要垃圾回收。这里提一点，Java程序自运行就是一个多线程程序，有一个主线程，还有一个垃圾回收线程。 线程上下文切换（Thread Context Switch）因为以下一些原因导致 cpu 不再执行当前的线程，转而执行另一个线程的代码 线程的 cpu 时间片用完 垃圾回收 有更高优先级的线程需要运行 线程自己调用了 sleep、yield、wait、join、park、synchronized、lock 等方法 当 Context Switch 发生时，需要由操作系统保存当前线程的状态，并恢复另一个线程的状态，Java 中对应的概念就是程序计数器（Program Counter Register），它的作用是记住下一条 jvm 指令的执行地址，是线程私有的。 状态包括程序计数器、虚拟机栈中每个栈帧的信息，如局部变量、操作数栈、返回地址等 Context Switch 频繁发生会影响性能 常见方法静态方法调用就用Thread.，非静态方法调用就用创建出来的线程对象。 方法名 是否static 功能说明 注意 start() 启动一个新线程，在新的线程运行run方法中的代码 start只是让线程进入就绪状态，run里面的代码不一定立刻运行，因为有可能CPU的时间片还没分给它，每个线程对象的start方法只能调用一次，多次调用会出现IllegalThreadStateException run() 新线程启动后会执行的方法 如果在构造 Thread 对象时传递了 Runnable 参数，则线程启动后会调用 Runnable 实现类中重写后的 run 方法。run默认不执行任何操作，可以创建 Thread 的子类对象，来覆盖默认行为。 join() 一个线程等待另一个线程运行结束，再向下执行 join(long n) 一个线程等待另一个线程运行结束，最多等n毫秒，n毫秒到了另一个线程就算没结束也向下执行，n毫秒没到另一个线程就执行完了，计算时间的话按照另一个线程的实际时间算 getId() 获取线程长整型的 id id 唯一 getName() 获取线程名 setName(String) 修改线程名 getPriority() 获取线程优先级 setPriority(int) 修改线程优先级 java中规定线程优先级是1~10 的整数，较大的优先级能提高该线程被 CPU 调度的机率，默认是5 getState() 获取线程状态 Java 中线程状态是用 6 个 enum 表示，分别为：NEW, RUNNABLE, BLOCKED, WAITING,TIMED_WAITING, TERMINATED isInterrupted() 判断是否被interrupt()打断 此方法判断完之后不会清除打断标记 isAlive() 线程是否存活（还没有运行完毕） interrupt() 打断线程 如果被打断线程正在 sleep，wait，join 会导致被打断的线程抛出 InterruptedException，并清除打断标记；如果打断的正在正常运行的线程，则会设置打断标记，不会抛异常；；park 的线程被打断，也会设置打断标记 interrupted() static 判断当前线程是否被打断 会清除打断标记 currentThread() static 获取当前正在执行的线程 sleep(long n) static 让当前执行的线程休眠n毫秒，休眠时让出 cpu的时间片给其它线程，让线程从RUNNING&gt;TIMED_WAITING yield() static 提示线程调度器让出当前线程对CPU的使用，强调的是让出、谦让，让线程从RUNNING&gt;READY 主要是为了测试和调试 start 与 run 直接调用 run 是在主线程中执行了 run，没有启动新的线程 使用 start 是启动新的线程，通过新的线程间接执行 run 中的代码 sleep与yieldsleep1、调用 sleep 会让当前线程从 Running 进入 Timed Waiting 状态 2、其它线程可以使用 interrupt 方法打断正在睡眠的线程，这时 sleep 方法会抛出 InterruptedException 3、睡眠结束后的线程未必会立刻得到执行 4、建议用 TimeUnit 的 sleep 代替 Thread 的 sleep 来获得更好的可读性 123Thread.sleep(1000);//睡一秒TimeUnit.SECOND.sleep(1);//睡一秒 yield1、调用 yield 会让当前线程从 Running 进入 READY 就绪状态，然后调度执行其它线程 2、具体的实现依赖于操作系统的任务调度器 这里说一下，切换到READY状态还是有CPU的抢夺权的，yield仅是谦让、让出的意思，就是说也有可能想让出CPU的执行权但是没让出去，具体依赖OS的任务调度器。 线程优先级 线程优先级会提示（hint）调度器优先调度该线程，但它仅仅是一个提示，调度器可以忽略它，主要取决于任务调度器 如果 cpu 比较忙，那么优先级高的线程会获得更多的时间片，但 cpu 闲时，优先级几乎没作用 sleep的小应用：防止CPU占用100%，当程序中需需要用到死循环的时候，并且在我们没有用CPU来计算时，while(true)也会空转浪费CPU，这是可以在没有使用CPU计算时，使用yield或者sleep来让出CPU的使用权交给其它程序。 join 方法详解join方法的底层原理就是wait方法 为什么需要 join？下面的代码执行，打印 r 是什么？ 12345678910111213141516171819202122232425262728293031323334import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;@Slf4j(topic = &quot;c.Test&quot;)//日志的配置文件配置的c打头public class Test { static int r = 0; public static void main(String[] args) throws InterruptedException { test1(); } private static void test1() { log.debug(&quot;开始&quot;); Thread t1 = new Thread(() -&gt; { log.debug(&quot;开始&quot;); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } log.debug(&quot;结束&quot;); r = 10; }); t1.start(); log.debug(&quot;结果为:{}&quot;, r); log.debug(&quot;结束&quot;); }}//输出 出现线程名是因为在日志的配置文件配置了21:56:15 [main] c.Test - 开始21:56:16 [Thread-0] c.Test - 开始21:56:16 [main] c.Test - 结果为:021:56:16 [main] c.Test - 结束21:56:17 [Thread-0] c.Test - 结束 我们是多核CPU，就算不是多核CPU不能并行只能并发，结果也是一样的，sleep让出了时间片，照样先执行main先输出0。 分析： 因为主线程和线程 t1 是并行执行的，t1 线程需要 1 秒之后才能算出 r=10，而主线程一开始就要打印 r 的结果，所以只能打印出 r=0 解决方法： 用 sleep 行不行？为什么？ 方案：用 join，加在 t1.start() 之后即可，让主线程同步等待另一线程运行结束 线程是异步执行的，因此不会等待另一个线程将r赋值为10，主线程就会输出r的值为0，想要输出r = 10，就需要使用join让主线程同步等待另一线程运行结束。 从调用方的角度来讲： 需要等待结果返回，才能继续运行就是同步 不需要等待结果返回，就能继续运行就是异步 改成： 123456789101112131415161718192021222324252627282930313233import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;@Slf4j(topic = &quot;c.Test&quot;)public class Test { static int r = 0; public static void main(String[] args) throws InterruptedException { test1(); } private static void test1() throws InterruptedException { log.debug(&quot;开始&quot;); Thread t1 = new Thread(() -&gt; { log.debug(&quot;开始&quot;); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } log.debug(&quot;结束&quot;); r = 10; }); t1.start(); t1.join(); log.debug(&quot;结果为:{}&quot;, r); log.debug(&quot;结束&quot;); }}//22:26:22 [main] c.Test - 开始22:26:22 [Thread-0] c.Test - 开始22:26:23 [Thread-0] c.Test - 结束22:26:23 [main] c.Test - 结果为:1022:26:23 [main] c.Test - 结束 等待多个结果问，下面代码 cost 大约多少秒？ 12345678910111213141516171819202122232425262728293031323334353637@Slf4j(topic = &quot;c.Test2&quot;)public class Test2 { static int r1 = 0; static int r2 = 0; public static void main(String[] args) throws InterruptedException { test2(); } private static void test2() throws InterruptedException { Thread t1 = new Thread(() -&gt; { try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } r1 = 10; }); Thread t2 = new Thread(() -&gt; { try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } r2 = 20; }); long start = System.currentTimeMillis(); t1.start(); t2.start(); t1.join(); t2.join(); long end = System.currentTimeMillis(); log.debug(&quot;r1: {} r2: {} cost: {}&quot;, r1, r2, end - start); }}//输出22:31:34 [main] c.Test2 - r1: 10 r2: 20 cost: 2008 分析如下： 第一个 join：等待 t1 时, t2 并没有停止, 而在运行 第二个 join：1s 后, 执行到此, t2 也运行了 1s, 因此也只需再等待 1s 如果颠倒两个 join 呢？最终都是一样的输出 有时效的join一个线程等待另一个线程运行结束，最多等n毫秒，n毫秒到了另一个线程就算没结束也向下执行，n毫秒没到另一个线程就执行完了，计算时间的话按照另一个线程的实际时间算。 等够时间案例 123456789101112131415161718192021static int r1 = 0;static int r2 = 0;public static void main(String[] args) throws InterruptedException { test3();}public static void test3() throws InterruptedException { Thread t1 = new Thread(() -&gt; { sleep(1); r1 = 10; }); long start = System.currentTimeMillis(); t1.start(); // 线程执行结束会导致 join 结束 t1.join(1500); long end = System.currentTimeMillis(); log.debug(&quot;r1: {} r2: {} cost: {}&quot;, r1, r2, end - start);}//20:48:01.320 [main] c.TestJoin - r1: 10 r2: 0 cost: 1010 没等够时间案例 1234567891011121314151617181920 static int r1 = 0; static int r2 = 0; public static void main(String[] args) throws InterruptedException { test3(); } public static void test3() throws InterruptedException { Thread t1 = new Thread(() -&gt; { sleep(2); r1 = 10; }); long start = System.currentTimeMillis(); t1.start(); // 线程执行结束会导致 join 结束 t1.join(1500); long end = System.currentTimeMillis(); log.debug(&quot;r1: {} r2: {} cost: {}&quot;, r1, r2, end - start); }//20:52:15.623 [main] c.TestJoin - r1: 0 r2: 0 cost: 1502 interrupt 方法详解使用interrupt方法打断正常会有个打断标记，记录线程是否被打断。打断过为true；没打断过为false。 sleep、wait、join这几个方法都会让线程进入等待状态，当打断正在sleep、wait、join的线程后，打断标记会被自动清空，重置为false，并且会出现异常。 正常运行的线程（没有sleep、join、wait）被打断后不会出现异常，并且打断标记也不会清空，就是true。 打断sleep的线程： 1234567891011121314151617181920212223 public static void main(String[] args) throws InterruptedException { test1(); } private static void test1() throws InterruptedException { Thread t1 = new Thread(()-&gt;{ sleep(1); }, &quot;t1&quot;); t1.start(); Thread.sleep(500);//这块让主线程睡0.5秒，是为了防止主线程执行太快，还没等t1线程睡呢，就先interrupt了 t1.interrupt(); log.debug(&quot; 打断状态: {}&quot;, t1.isInterrupted()); } // java.lang.InterruptedException: sleep interruptedat java.lang.Thread.sleep(Native Method)at java.lang.Thread.sleep(Thread.java:340)at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)at cn.itcast.n2.util.Sleeper.sleep(Sleeper.java:8)at cn.itcast.n4.TestInterrupt.lambda$test1$3(TestInterrupt.java:59)at java.lang.Thread.run(Thread.java:745)21:18:10.374 [main] c.TestInterrupt - 打断状态: false 打断正常运行的线程： 123456789101112131415161718192021 public static void main(String[] args) throws InterruptedException { test2(); } private static void test2() throws InterruptedException { Thread t2 = new Thread(()-&gt;{ while(true) { Thread current = Thread.currentThread(); boolean interrupted = current.isInterrupted(); if(interrupted) { log.debug(&quot; 打断状态: {}&quot;, interrupted); break; } } }, &quot;t2&quot;); t2.start(); sleep(0.5); t2.interrupt(); }//20:57:37.964 [t2] c.TestInterrupt - 打断状态: true 设计模式之两阶段终止模式解析：在一个线程t1中，如何优雅的终止线程t2？这里的优雅，指的是给t2一个善后的机会，interrupt能实现这个效果。 因为interrupt不会阻止线程任务的继续执行，并且打断之后会有一个标记，可以通过这个标记来设置这个线程任务被打断之后要做的事儿。优雅~ 但是要注意情况分为等待时被打断和正常运行时被打断，这块注意一下：因为sleep、wait、join的线程被打断后会清除打断标记，并且抛异常，再继续执行，既然我们要通过这个标记来设置这个线程任务被打断之后要做的事，所以我们要捕捉抛出的异常并且在捕捉异常的时候重新将打断标记设置为true，就是当前线程再调用一次interrupt方法，打断标记就是true了；正常的线程打断后不会抛异常，标记也不会被清除，会直接继续运行。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.chan.concurrent.TwoPhaseTermination;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;/** * 在一个线程main中，如何优雅的终止线程thread？ * 场景:main线程想要开启一个监控线程来监控自己,过了一会之后,又想关闭监控线程,停止对自己监控 */@Slf4j(topic = &quot;c.TPTInterrupt&quot;)public class TPTInterrupt { // 监控线程 private Thread thread; /** * 开启监控线程(给其它线程使用,让这个监控线程启动并对自己监控) */ public void start() { thread = new Thread(() -&gt; { while (true) { Thread current = Thread.currentThread();//就是当前的监控线程thread if (current.isInterrupted()){ log.debug(&quot;打断之后要做的事...&quot;);//优雅永不过时 break; } try { // 模拟监控线程每隔一秒进行一次监控并将监控结果保存 TimeUnit.SECONDS.sleep(1); log.debug(&quot;将结果保存...&quot;); } catch (InterruptedException e) { // 被监控的线程在睡眠时被打断的话没有打断标记,并且会抛出异常,在异常里面重新打断设置打断标记 current.interrupt(); } } },&quot;监控线程&quot;); thread.start(); } /** * 关闭监控线程(给其它线程使用,优雅的停止监控线程对自己的监控) */ public void stop() { thread.interrupt(); } public static void main(String[] args) throws InterruptedException { TPTInterrupt tptInterrupt = new TPTInterrupt(); tptInterrupt.start(); Thread.sleep(4000); log.debug(&quot;stop&quot;); tptInterrupt.stop(); }} 打断park线程打断 park 线程, 不会清空打断状态。park也是等待，但是这个不会清空打断状态。park方法不是Thread的，是LockSupport类的静态方法。 打断正在park的线程后，打断标记不会清除，为true，但是再次使用park方法的时候，它就失效了，不会等待了，那是因为park方法在打断标记为true 的时候是不生效的。因此想要继续让它生效的话，在判断打断状态的时候就不能用当前线程对象调用isInterrupted()方法了，因为这个方法只判断状态。这个时候使用Thread.interrupted()方法来判断状态，这个方法在判断打断状态并返回结果之后，会自动清除打断状态。这样一来，再次使用park方法就生效了。 12345678910111213141516private static void test3() throws InterruptedException { Thread t1 = new Thread(() -&gt; { log.debug(&quot;park...&quot;); LockSupport.park();//这是程序等待了，就不往下执行了，直到t1.interrupt();之后再执行下一步 log.debug(&quot;unpark...&quot;); log.debug(&quot;打断状态：{}&quot;, Thread.currentThread().isInterrupted()); }, &quot;t1&quot;); t1.start(); sleep(0.5); t1.interrupt();}//21:11:52.795 [t1] c.TestInterrupt - park...21:11:53.295 [t1] c.TestInterrupt - unpark...21:11:53.295 [t1] c.TestInterrupt - 打断状态：true 如果打断标记已经是 true, 则 park 会失效 123456789101112131415161718192021222324private static void test4() { Thread t1 = new Thread(() -&gt; { for (int i = 0; i &lt; 5; i++) { log.debug(&quot;park...&quot;); LockSupport.park(); log.debug(&quot;打断状态：{}&quot;, Thread.currentThread().isInterrupted()); } }); t1.start(); sleep(1); t1.interrupt();}//21:13:48.783 [Thread-0] c.TestInterrupt - park...21:13:49.809 [Thread-0] c.TestInterrupt - 打断状态：true21:13:49.812 [Thread-0] c.TestInterrupt - park...21:13:49.813 [Thread-0] c.TestInterrupt - 打断状态：true21:13:49.813 [Thread-0] c.TestInterrupt - park...21:13:49.813 [Thread-0] c.TestInterrupt - 打断状态：true21:13:49.813 [Thread-0] c.TestInterrupt - park...21:13:49.813 [Thread-0] c.TestInterrupt - 打断状态：true21:13:49.813 [Thread-0] c.TestInterrupt - park...21:13:49.813 [Thread-0] c.TestInterrupt - 打断状态：true 可以使用 Thread.interrupted() 清除打断状态 主线程与守护线程默认情况下，Java 进程需要等待所有线程都运行结束，才会结束。有一种特殊的线程叫做守护线程，只要其它非守护线程运行结束了，即使守护线程的代码没有执行完，也会强制结束。 12345678910111213141516 log.debug(&quot;开始运行...&quot;); Thread t1 = new Thread(() -&gt; { log.debug(&quot;开始运行...&quot;); sleep(2); log.debug(&quot;运行结束...&quot;); }, &quot;daemon&quot;); // 设置该线程为守护线程 t1.setDaemon(true); t1.start(); sleep(1); log.debug(&quot;运行结束...&quot;); //08:26:38.123 [main] c.TestDaemon - 开始运行...08:26:38.213 [daemon] c.TestDaemon - 开始运行...08:26:39.215 [main] c.TestDaemon - 运行结束... 注意： 垃圾回收器线程就是一种守护线程 Tomcat 中的 Acceptor 和 Poller 线程都是守护线程，所以 Tomcat 接收到 shutdown 命令后，不会等待它们处理完当前请求 五种状态这是从操作系统层面来描述：初始状态、就绪状态、运行状态、阻塞状态、终止状态 【初始状态】仅是在语言层面创建了线程对象，还未与操作系统线程关联，刚刚new完，还没start呢。 【就绪状态】指该线程已经被创建（与操作系统线程关联），start完了，可以由 CPU 调度执行，但是还没时间片 【运行状态】指获取了 CPU 时间片，运行中的状态 当 CPU 时间片用完，会从【运行状态】转换至【就绪状态】，会导致线程的上下文切换 【阻塞状态】 如果调用了阻塞 API，如 BIO 读写文件，这时该线程实际不会用到 CPU，会导致线程上下文切换，进入【阻塞状态】 等 BIO 操作完毕，会由操作系统唤醒 阻塞的线程，转换至【就绪状态】 与【就绪状态】的区别是，对【阻塞状态】的线程来说只要它们一直不唤醒，调度器就一直不会考虑调度它们，而就绪状态的线程是拥有CPU的抢夺权的 【终止状态】表示线程已经执行完毕，生命周期已经结束，不会再转换为其它状态 六种状态这是从 Java API 层面来描述的，根据 Thread.State 枚举，分为六种状态：图中“可运行状态”改为“就绪状态”！ NEW：线程刚被创建，但是还没有调用 start() 方法 RUNNABLE：当调用了 start() 方法之后，注意，Java API 层面的 RUNNABLE 状态涵盖了操作系统层面的【就绪状态】、【运行状态】和【阻塞状态（操作系统层面的IO阻塞状态，比如由于 BIO 导致的线程阻塞，一些阻塞API，阻塞的IO读取文件等等，在 Java 里无法区分，仍然认为是RUNNABLE的）】 BLOCKED：Java层面的阻塞状态，锁的情况等等。 WAITING：join()、wait()方法。 TIMED_WAITING：sleep(long n)、wait(long n)方法。 TERMINATED 当线程代码运行结束 其实BLOCKED ， WAITING ， TIMED_WAITING 都是 Java API 层面对【阻塞状态】的细分，状态转换部分会在后面博客详述。 阶段总结 线程创建三种方式以及原理 线程重要 api，如 start，run，sleep，join，interrupt 等。 线程的状态 应用方面 异步调用：主线程执行期间，其它线程异步执行耗时操作 提高效率：并行计算，缩短运算时间 同步等待：join 原理方面 线程运行流程：栈、栈帧、上下文切换 Thread 两种创建方式的源码 设计模式方面 设计模式之两阶段终止模式","link":"/posts/20211119/java-concurrent-1.html"},{"title":"共享模型之无锁","text":"本章内容： CAS 与 volatile 原子整数 原子引用 原子累加器 Unsafe 取款案例其实主要就是保证取款的时候如果是高并发的情况的线程安全性。 不安全实现 12345678910111213package com.chan.concurrent.cas;/** * 账户接口 */public interface Account { // 获取余额 Integer getBalance(); // 取款 void withdraw(Integer amount);} 123456789101112131415161718192021222324252627282930313233package com.chan.concurrent.cas;// 实现类public class AccountImpl implements Account { // 余额 private Integer balance; /** * 构造函数 初始化条件 * @param balance 余额 */ public AccountImpl(Integer balance) { this.balance = balance; } /** * 余额 * @return 余额 */ @Override public Integer getBalance() { return balance; } /** * 取款 * @param amount 金额 */ @Override public void withdraw(Integer amount) { balance = balance - amount; }} 1234567891011121314151617181920212223242526272829303132333435package com.chan.concurrent.cas;import lombok.extern.slf4j.Slf4j;import java.util.ArrayList;import java.util.List;/** * 方法内会启动 1000 个线程，每个线程做 -10 元 的操作 * 如果初始余额为 10000 那么正确的结果应当是 0 */@Slf4j(topic = &quot;c.Test&quot;)public class Test { public static void main(String[] args) { Account account = new AccountImpl(10000);//账户起始10000元 List&lt;Thread&gt; tasks = new ArrayList&lt;&gt;(); long startTime = System.nanoTime();//起始时间 for (int i = 0; i &lt; 1000; i++) {//1000个线程循环加到集合容器 tasks.add(new Thread(() -&gt; account.withdraw(10)));//每个线程的任务是转出10元，1000*10=10000 正常最后余额为0 } for (Thread task : tasks) { task.start();//循环启动这1000个线程 } for (Thread task : tasks) { try { task.join(); //主线程等待所有的t线程执行完之后在向下进行 } catch (InterruptedException e) { e.printStackTrace(); } } long endTime = System.nanoTime();//结束时间 System.out.println(account.getBalance() + &quot; cost:&quot; + (endTime - startTime) / 1000000 + &quot;ms&quot;);//结果 }} 1530 cost:830ms 正常情况应该是余额为 0 。上面的实现，取款之后的余额是 530。 因为有很多个线程取款，出现了高并发的情况，造成了线程同步问题。 解决思路： 锁123456789101112131415161718192021222324252627282930package com.chan.concurrent.cas.locksafe;public class AccountImpl implements Account { //余额 private Integer balance; public AccountImpl(Integer balance) { this.balance = balance; } /** * 得到余额 * @return */ @Override public synchronized Integer getBalance() { return balance; } /** * 取钱 * @param amount */ @Override public synchronized void withdraw(Integer amount) { balance = balance - amount; }} 10 cost:299ms 解决思路： 无锁12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.chan.concurrent.cas.cassafe;import java.util.concurrent.atomic.AtomicInteger;/** * 使用cas保证线程安全性 */public class AccountImpl implements Account { AtomicInteger balance; public AccountImpl(Integer balance) { this.balance = new AtomicInteger(10000); } @Override public Integer getBalance() { return balance.get(); } @Override public void withdraw(Integer amount) { // 需要不断尝试，直到成功为止 while (true) { // 比如拿到了旧值 1000 int export = balance.get(); // 在这个基础上 1000-10 = 990 int next = export - amount; /* * * compareAndSet 正是做这个检查，在 set 前，先比较 export 与当前主内存中的balance值 - 不一致了，next 作废，返回 false 表示失败 比如，别的线程已经做了减法，当前值已经被减成了 990 那么本线程的这次 990 就作废了，进入 while 下次循环重试 - 一致，以 next 设置为新值，返回 true 表示成功 * * */ if (balance.compareAndSet(export, next)){ break; } } // 可以简化为下面的方法 // balance.addAndGet(-1 * amount); }} 10 cost:366ms CAS 与 volatile前面看到的 AtomicInteger 的解决方法，内部并没有用锁来保护共享变量的线程安全。那么它是如何实现的呢？ 1234567891011121314151617181920212223public void withdraw(Integer amount) { // 需要不断尝试，直到成功为止 while (true) { // 比如拿到了旧值 1000 int export = balance.get(); // 在这个基础上 1000-10 = 990 int next = export - amount; /* * * compareAndSet 正是做这个检查，在 set 前，先比较 export 与当前主内存中的balance值 - 不一致了，next 作废，返回 false 表示失败 比如，别的线程已经做了减法，当前值已经被减成了 990 那么本线程的这次 990 就作废了，进入 while 下次循环重试 - 一致，以 next 设置为新值，返回 true 表示成功 * * */ if (balance.compareAndSet(export, next)){ break; } } // 可以简化为下面的方法 // balance.addAndGet(-1 * amount);} 上面案例的代码是不断尝试直到成功。 其中的关键是 compareAndSet，它的简称就是 CAS （也有 Compare And Swap 的说法），它必须是原子操作。CAS 必须配合 volatile 才会发挥作用，底层代码中的共享变量，也就代表我们传入的参数，底层是通过 volatile 来修饰的。 部分源码： 1234567891011121314151617181920212223242526public class AtomicInteger extends Number implements java.io.Serializable { private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static { try { valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); } catch (Exception ex) { throw new Error(ex); } } private volatile int value; /** * Creates a new AtomicInteger with the given initial value. * * @param initialValue the initial value */ public AtomicInteger(int initialValue) { value = initialValue; } // ...} CAS 只有在多核 CPU 下对比起锁的实现才有明显的性能提升，并且线程数要少于 CPU 的核数性能提升显著。 volatile获取共享变量时，为了保证该变量的可见性，需要使用 volatile 修饰。 它可以用来修饰成员变量和静态成员变量，他可以避免线程从自己的工作缓存中查找变量的值，必须到主存中获取它的值，线程操作 volatile 变量都是直接操作主存。即一个线程对 volatile 变量的修改，对另一个线程可见。 volatile 仅仅保证了共享变量的可见性，让其它线程能够看到最新值，能保证有序性，也就是禁止本线程发生指令重排，但不能解决指令交错问题（不能保证原子性） CAS 必须借助 volatile 才能读取到共享变量的最新值来实现【比较并交换】的效果。 为什么无锁效率高 无锁情况下，即使重试失败，线程始终在高速运行，没有停歇，而 synchronized 会让线程在没有获得锁的时候，发生上下文切换，进入阻塞。 线程就好像高速跑道上的赛车，高速运行时，速度超快，一旦发生上下文切换，就好比赛车要减速、熄火，等被唤醒又得重新打火、启动、加速。。。 恢复到高速运行，代价比较大 但无锁情况下，因为线程要保持运行，需要额外 CPU 的支持，CPU 在这里就好比高速跑道，没有额外的跑道，线程想高速运行也无从谈起，虽然不会进入阻塞，但由于没有分到时间片，仍然会进入可运行状态，还是会导致上下文切换，不过总体上依然是无锁效率高。 CAS 的特点结合 CAS 和 volatile 可以实现无锁并发，适用于线程数少、多核 CPU 的场景下。 CAS 是基于乐观锁的思想：最乐观的估计，不怕别的线程来修改共享变量，就算改了也没关系，我吃亏点再重试呗。 synchronized 是基于悲观锁的思想：最悲观的估计，得防着其它线程来修改共享变量，我上了锁你们都别想改，我改完了解开锁，你们才有机会。 CAS 体现的是无锁并发、无阻塞并发，请仔细体会这两句话的意思 因为没有使用 synchronized，所以线程不会陷入阻塞，这是效率提升的因素之一 但如果竞争激烈，可以想到重试必然频繁发生，反而效率会受影响 原子整数J.U.C 并发包提供了： AtomicBoolean AtomicInteger AtomicLong 以 AtomicInteger 为例 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.chan.concurrent.cas.atomicIntegerExample;import java.util.concurrent.atomic.AtomicInteger;public class Test { public static void main(String[] args) { // 按需设置参数值 如果没有要求起始值为0 AtomicInteger i = new AtomicInteger(0);// i = 0 // 获取并自增（i = 0, 结果 i = 1, 返回 0），类似于 i++ System.out.println(i.getAndIncrement());// 此时i = 1 // 自增并获取（i = 1, 结果 i = 2, 返回 2），类似于 ++i System.out.println(i.incrementAndGet());// 此时i = 2 // 自减并获取（i = 2, 结果 i = 1, 返回 1），类似于 --i System.out.println(i.decrementAndGet());// 此时i = 1 // 获取并自减（i = 1, 结果 i = 0, 返回 1），类似于 i-- System.out.println(i.getAndDecrement());// 此时i = 0 // 获取并加值（i = 0, 结果 i = 5, 返回 0） System.out.println(i.getAndAdd(5));// 此时i = 5 // 加值并获取（i = 5, 结果 i = 0, 返回 0） System.out.println(i.addAndGet(-5));// 此时i = 0 // 获取并更新（i = 0, p 为 i 的当前值, 结果 i = -2, 返回 0） System.out.println(i.getAndUpdate(p -&gt; p - 2));// 此时i = -2 这个方法就可以随便运算了 // 更新并获取（i = -2, p 为 i 的当前值, 结果 i = 0, 返回 0） System.out.println(i.updateAndGet(p -&gt; p + 2));// 此时i = 0 // 获取并计算（i = 0, p 为 i 的当前值, x 为参数1, 结果 i = 10, 返回 0） // getAndUpdate 如果在 lambda 中引用了外部的局部变量，要保证该局部变量是 final 的 // getAndAccumulate 可以通过 参数1 来引用外部的局部变量，但因为其不在 lambda 中因此不必是 final System.out.println(i.getAndAccumulate(10, (p, x) -&gt; p + x));// 此时i = 10// System.out.println(i.getAndAccumulate(10, Integer::sum));// 此时i = 10 // 计算并获取（i = 10, p 为 i 的当前值, x 为参数1, 结果 i = 0, 返回 0） System.out.println(i.accumulateAndGet(-10, (p, x) -&gt; p + x));// 此时i = 0// System.out.println(i.accumulateAndGet(-10, Integer::sum));// 此时i = 0 }} 原子引用为什么需要原子引用类型？ AtomicReference AtomicStampedReference AtomicMarkableReference 上面的例子我们使用的是 Integer 类型，就是整数类型，这次使用 BigDecimal 引用类型实现。 不安全实现123456789101112131415package com.chan.concurrent.cas.unsafeRef;import java.math.BigDecimal;/** * 账户接口 */public interface Account { // 获取余额 BigDecimal getBalance(); // 取款 void withdraw(BigDecimal amount);} 123456789101112131415161718192021222324252627282930313233343536package com.chan.concurrent.cas.unsafeRef;import java.math.BigDecimal;public class AccountImpl implements Account { // 余额 private BigDecimal balance; /** * 构造函数 初始化条件 * @param balance 余额 */ public AccountImpl(BigDecimal balance) { this.balance = balance; } /** * 余额 * @return 余额 */ @Override public BigDecimal getBalance() { return balance; } /** * 取款 * @param amount 金额 */ @Override public void withdraw(BigDecimal amount) { BigDecimal balance = this.getBalance(); this.balance = balance.subtract(amount); }} 123456789101112131415161718192021222324252627282930313233343536package com.chan.concurrent.cas.unsafeRef;import lombok.extern.slf4j.Slf4j;import java.math.BigDecimal;import java.util.ArrayList;import java.util.List;/** * 方法内会启动 1000 个线程，每个线程做 -10 元 的操作 * 如果初始余额为 10000 那么正确的结果应当是 0 */@Slf4j(topic = &quot;c.Test&quot;)public class Test { public static void main(String[] args) { Account account = new AccountImpl(BigDecimal.valueOf(10000));//账户起始10000元 List&lt;Thread&gt; tasks = new ArrayList&lt;&gt;(); long startTime = System.nanoTime();//起始时间 for (int i = 0; i &lt; 1000; i++) {//1000个线程循环加到集合容器 tasks.add(new Thread(() -&gt; account.withdraw(BigDecimal.TEN)));//每个线程的任务是转出10元，1000*10=10000 正常最后余额为0 } for (Thread task : tasks) { task.start();//循环启动这1000个线程 } for (Thread task : tasks) { try { task.join(); //主线程等待所有的t线程执行完之后在向下进行 } catch (InterruptedException e) { e.printStackTrace(); } } long endTime = System.nanoTime();//结束时间 System.out.println(account.getBalance() + &quot; cost:&quot; + (endTime - startTime) / 1000000 + &quot;ms&quot;);//结果 }} 12700 cost:501ms 解决思路： 锁12345678910111213141516171819202122232425262728package com.chan.concurrent.cas.locksafeRef;import java.math.BigDecimal;public class AccountImpl implements Account { BigDecimal balance; final Object obj = new Object(); public AccountImpl(BigDecimal balance) { this.balance = balance; } @Override public BigDecimal getBalance() { synchronized (obj) { return balance; } } @Override public void withdraw(BigDecimal amount) { synchronized (obj) { balance = balance.subtract(amount); } }} 10 cost:374ms 解决思路： 无锁123456789101112131415161718192021222324252627282930package com.chan.concurrent.cas.cassafeRef;import java.math.BigDecimal;import java.util.concurrent.atomic.AtomicReference;public class AccountImpl implements Account { private AtomicReference&lt;BigDecimal&gt; balance; public AccountImpl(BigDecimal balance) { this.balance = new AtomicReference&lt;&gt;(balance); } @Override public BigDecimal getBalance() { return balance.get(); } @Override public void withdraw(BigDecimal amount) { while (true) { BigDecimal perv = balance.get(); BigDecimal next = perv.subtract(amount); if (balance.compareAndSet(perv, next)){ break; } } }} 10 cost:330ms ABA 问题及解决ABA 问题1234567891011121314151617181920212223242526272829303132333435363738394041package com.chan.concurrent.cas.ABA;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicReference;@Slf4j(topic = &quot;c.Test&quot;)public class Test { static AtomicReference&lt;String&gt; ref = new AtomicReference&lt;&gt;(&quot;A&quot;); public static void main(String[] args) throws InterruptedException { log.debug(&quot;main start...&quot;); // 获取值 A // 这个共享变量被它线程修改过？ String prev = ref.get(); otherThread(); TimeUnit.SECONDS.sleep(2); log.debug(&quot;change A-&gt;C {}&quot;, ref.compareAndSet(prev, &quot;C&quot;)); } public static void otherThread() throws InterruptedException { new Thread(new Runnable() { @Override public void run() { String prev = ref.get(); log.debug(&quot;change A-&gt;B {}&quot;, ref.compareAndSet(prev, &quot;B&quot;)); } }, &quot;t1&quot;).start(); TimeUnit.SECONDS.sleep(1); new Thread(new Runnable() { @Override public void run() { log.debug(&quot;change B-&gt;A {}&quot;, ref.compareAndSet(ref.get(), &quot;A&quot;)); } }, &quot;t2&quot;).start(); }} 输出： 123417:21:35 [main] c.Test - main start...17:21:35 [t1] c.Test - change A-&gt;B true17:21:36 [t2] c.Test - change B-&gt;A true17:21:38 [main] c.Test - change A-&gt;C true 主线程仅能判断出共享变量的值与最初值 A 是否相同，不能感知到这种从 A 改为 B 又改回 A 的情况，如果主线程希望： 只要有其它线程【动过了】共享变量，那么自己的 cas 就算失败，这时，仅比较值是不够的，需要再加一个版本号。 AtomicStampedReference1234567891011121314151617181920212223242526272829303132333435363738package com.chan.concurrent.cas.ABA;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.atomic.AtomicStampedReference;@Slf4j(topic = &quot;c.Test2&quot;)public class Test2 { static AtomicStampedReference&lt;String&gt; ref = new AtomicStampedReference&lt;&gt;(&quot;A&quot;, 0); public static void main(String[] args) throws InterruptedException { log.debug(&quot;main start...&quot;); // 获取值 A String prev = ref.getReference(); // 获取版本号 int stamp = ref.getStamp(); log.debug(&quot;版本 {}&quot;, stamp); // 如果中间有其它线程干扰，发生了 ABA 现象 other(); Thread.sleep(2000); // 尝试改为 C log.debug(&quot;change A-&gt;C {}&quot;, ref.compareAndSet(prev, &quot;C&quot;, stamp, stamp + 1)); } private static void other() throws InterruptedException { new Thread(() -&gt; { log.debug(&quot;change A-&gt;B {}&quot;, ref.compareAndSet(ref.getReference(), &quot;B&quot;, ref.getStamp(), ref.getStamp() + 1)); log.debug(&quot;更新版本为 {}&quot;, ref.getStamp()); }, &quot;t1&quot;).start(); Thread.sleep(1000); new Thread(() -&gt; { log.debug(&quot;change B-&gt;A {}&quot;, ref.compareAndSet(ref.getReference(), &quot;A&quot;, ref.getStamp(), ref.getStamp() + 1)); log.debug(&quot;更新版本为 {}&quot;, ref.getStamp()); }, &quot;t2&quot;).start(); }} 123456717:35:48 [main] c.Test2 - main start...17:35:48 [main] c.Test2 - 版本 017:35:48 [t1] c.Test2 - change A-&gt;B true17:35:48 [t1] c.Test2 - 更新版本为 117:35:49 [t2] c.Test2 - change B-&gt;A true17:35:49 [t2] c.Test2 - 更新版本为 217:35:51 [main] c.Test2 - change A-&gt;C false AtomicStampedReference 可以给原子引用加上版本号，追踪原子引用整个的变化过程，如： A -&gt; B -&gt; A -&gt; C ，通过AtomicStampedReference，另外我们可以知道，引用变量中途被更改了几次。 但是有时候，并不关心引用变量更改了几次，只是单纯的关心是否更改过，所以就有了 AtomicMarkableReference AtomicMarkableReference注释掉打扫卫生线程代码和不注释相比较，观察输出 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.chan.concurrent.cas.ABA;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.atomic.AtomicMarkableReference;@Slf4j(topic = &quot;c.TestABAAtomicMarkableReference&quot;)public class TestABAAtomicMarkableReference { public static void main(String[] args) throws InterruptedException { GarbageBag bag = new GarbageBag(&quot;装满了垃圾&quot;); // 参数2 mark 可以看作一个标记，表示垃圾袋满了 AtomicMarkableReference&lt;GarbageBag&gt; ref = new AtomicMarkableReference&lt;&gt;(bag, true); log.debug(&quot;主线程 start...&quot;); GarbageBag prev = ref.getReference(); log.debug(prev.toString());// new Thread(() -&gt; {// log.debug(&quot;打扫卫生的线程 start...&quot;);// bag.setDesc(&quot;空垃圾袋&quot;);// while (!ref.compareAndSet(bag, bag, true, false)) {}// log.debug(bag.toString());// }).start(); Thread.sleep(1000); log.debug(&quot;主线程想换一只新垃圾袋？&quot;); boolean success = ref.compareAndSet(prev, new GarbageBag(&quot;空垃圾袋&quot;), true, false); log.debug(&quot;换了么？&quot; + success); log.debug(ref.getReference().toString()); }}class GarbageBag { String desc; public GarbageBag(String desc) { this.desc = desc; } public void setDesc(String desc) { this.desc = desc; } @Override public String toString() { return &quot;GarbageBag{&quot; + &quot;desc='&quot; + desc + '\\'' + '}'; }} 输出 1234517:57:42 [main] c.TestABAAtomicMarkableReference - 主线程 start...17:57:42 [main] c.TestABAAtomicMarkableReference - GarbageBag{desc='装满了垃圾'}17:57:43 [main] c.TestABAAtomicMarkableReference - 主线程想换一只新垃圾袋？17:57:43 [main] c.TestABAAtomicMarkableReference - 换了么？true17:57:43 [main] c.TestABAAtomicMarkableReference - GarbageBag{desc='空垃圾袋'} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.chan.concurrent.cas.ABA;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.atomic.AtomicMarkableReference;@Slf4j(topic = &quot;c.TestABAAtomicMarkableReference&quot;)public class TestABAAtomicMarkableReference { public static void main(String[] args) throws InterruptedException { GarbageBag bag = new GarbageBag(&quot;装满了垃圾&quot;); // 参数2 mark 可以看作一个标记，表示垃圾袋满了 AtomicMarkableReference&lt;GarbageBag&gt; ref = new AtomicMarkableReference&lt;&gt;(bag, true); log.debug(&quot;主线程 start...&quot;); GarbageBag prev = ref.getReference(); log.debug(prev.toString()); new Thread(() -&gt; { log.debug(&quot;打扫卫生的线程 start...&quot;); bag.setDesc(&quot;空垃圾袋&quot;); while (!ref.compareAndSet(bag, bag, true, false)) {} log.debug(bag.toString()); }).start(); Thread.sleep(1000); log.debug(&quot;主线程想换一只新垃圾袋？&quot;); boolean success = ref.compareAndSet(prev, new GarbageBag(&quot;空垃圾袋&quot;), true, false); log.debug(&quot;换了么？&quot; + success); log.debug(ref.getReference().toString()); }}class GarbageBag { String desc; public GarbageBag(String desc) { this.desc = desc; } public void setDesc(String desc) { this.desc = desc; } @Override public String toString() { return &quot;GarbageBag{&quot; + &quot;desc='&quot; + desc + '\\'' + '}'; }} 输出 123456717:59:42 [main] c.TestABAAtomicMarkableReference - 主线程 start...17:59:42 [main] c.TestABAAtomicMarkableReference - GarbageBag{desc='装满了垃圾'}17:59:42 [Thread-0] c.TestABAAtomicMarkableReference - 打扫卫生的线程 start...17:59:42 [Thread-0] c.TestABAAtomicMarkableReference - GarbageBag{desc='空垃圾袋'}17:59:43 [main] c.TestABAAtomicMarkableReference - 主线程想换一只新垃圾袋？17:59:43 [main] c.TestABAAtomicMarkableReference - 换了么？false17:59:43 [main] c.TestABAAtomicMarkableReference - GarbageBag{desc='空垃圾袋'} 目的就是保证垃圾袋是空的，线程 t 就好比把垃圾到了，垃圾袋没换，主线程就是将垃圾袋整个换成新的垃圾袋，这两种做法都可以保证垃圾袋是空的，上面的代码，主线程在换垃圾袋之前睡了一秒，所以是 t 线程先执行完倒垃圾，但是倒垃圾并不是换一个新的垃圾袋，因此还是之前的旧的对象，当主线程执行的时候，如果按照一般的 CAS 思路，比较并替换，我们知道引用类型的对象比较的是对象的内存地址，我们的垃圾袋对象一直没变，因此是符合置换要求的可以替换，因此这时主线程又用new GarbageBag(“空垃圾袋”)，去替换了prev，但是实际上有意义么? 是没意义的，因为我们的垃圾袋已经是空的了，需求已经达成，就不需要再去换一个新的垃圾袋了，所以我们这个时候使用的是 AtomicMarkableReference 类，设置了一个标记，倒垃圾之后将标记更改，等主线程来了想要换垃圾袋的时候查看标记，如果标记垃圾袋已经为空了，那就不用再换新的垃圾袋了。 原子数组 AtomicIntegerArray 整数 Integer 类型的数组 AtomicLongArray 整数 Long 类型的数组 AtomicReferenceArray 引用类型的数组，String 或者自定义类等 不安全的数组函数式接口： 在下面实现了一个通用的比较方法(demo)，让 LongAdder 对象 和 AtomicLong 对象 都使用这同一个方法的流程，保证公平性。Supplier接口 和 Consumer接口 都是 函数式接口（即有且仅有一个抽象方法，但是可以有多个非抽象方法的接口）Supplier接口的抽象方法可作为提供者，不传入参数，但返回结果；Consumer接口的抽象方法可作为消费者，传入一个参数，但不返回结果。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package com.chan.concurrent.cas.atomicArray;import java.util.ArrayList;import java.util.Arrays;import java.util.List;import java.util.function.BiConsumer;import java.util.function.Consumer;import java.util.function.Function;import java.util.function.Supplier;public class Test { public static void main(String[] args) { // 不安全的数组 demo( () -&gt; new int[10], (array) -&gt; array.length, (array, index) -&gt; array[index]++, (array) -&gt; System.out.println(Arrays.toString(array)) ); } /** * 参数1，提供数组、可以是线程不安全数组或线程安全数组 * 参数2，获取数组长度的方法 * 参数3，自增方法，传 array, index * 参数4，打印数组的方法 */ // 函数式接口 接口中定义一个方法 // supplier 提供者 无中生有 ()-&gt;结果 // function 函数 一个参数一个结果 (参数)-&gt;结果 , BiFunction (参数1,参数2)-&gt;结果 // consumer 消费者 一个参数没结果 (参数)-&gt;void, BiConsumer (参数1,参数2)-&gt; private static &lt;T&gt; void demo( Supplier&lt;T&gt; arraySupplier, Function&lt;T, Integer&gt; lengthFun, BiConsumer&lt;T, Integer&gt; putConsumer, Consumer&lt;T&gt; printConsumer ) { List&lt;Thread&gt; threads = new ArrayList&lt;&gt;(); T array = arraySupplier.get(); int length = lengthFun.apply(array); for (int i = 0; i &lt; length; i++) { // 一共length个线程,每个线程对数组作 10000 次操作 threads.add(new Thread(new Runnable() { @Override public void run() { for (int j = 0; j &lt; 10000; j++) { putConsumer.accept(array, j % length); } } })); } for (Thread thread : threads) { // 启动所有线程 thread.start(); } for (Thread thread : threads) { try { thread.join(); } catch (InterruptedException e) { e.printStackTrace(); } } // 等所有线程结束 printConsumer.accept(array); }} 1[8958, 8925, 8936, 8947, 8959, 8944, 8934, 8939, 8960, 8972] 安全的数组1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.chan.concurrent.cas.atomicArray;import java.util.ArrayList;import java.util.List;import java.util.concurrent.atomic.AtomicIntegerArray;import java.util.function.BiConsumer;import java.util.function.Consumer;import java.util.function.Function;import java.util.function.Supplier;public class Test2 { public static void main(String[] args) { // 安全的数组 demo( () -&gt; new AtomicIntegerArray(10), (array) -&gt; array.length(), (array, index) -&gt; array.getAndIncrement(index), (array) -&gt; System.out.println(array) ); } /** * 参数1，提供数组、可以是线程不安全数组或线程安全数组 * 参数2，获取数组长度的方法 * 参数3，自增方法，传 array, index * 参数4，打印数组的方法 */ // supplier 提供者 无中生有 ()-&gt;结果 // function 函数 一个参数一个结果 (参数)-&gt;结果 , BiFunction (参数1,参数2)-&gt;结果 // consumer 消费者 一个参数没结果 (参数)-&gt;void, BiConsumer (参数1,参数2)-&gt; private static &lt;T&gt; void demo( Supplier&lt;T&gt; arraySupplier, Function&lt;T, Integer&gt; lengthFun, BiConsumer&lt;T, Integer&gt; putConsumer, Consumer&lt;T&gt; printConsumer ) { List&lt;Thread&gt; threads = new ArrayList&lt;&gt;(); T array = arraySupplier.get(); int length = lengthFun.apply(array); for (int i = 0; i &lt; length; i++) { // 一共length个线程,每个线程对数组作 10000 次操作 threads.add(new Thread(new Runnable() { @Override public void run() { for (int j = 0; j &lt; 10000; j++) { putConsumer.accept(array, j % length); } } })); } for (Thread thread : threads) { thread.start(); } for (Thread thread : threads) { try { thread.join(); } catch (InterruptedException e) { e.printStackTrace(); } } printConsumer.accept(array); }} 1[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000] 字段更新器 AtomicReferenceFieldUpdater 域字段是引用类型 AtomicIntegerFieldUpdater 域字段是整数类型 AtomicLongFieldUpdater 利用字段更新器，可以针对对象的某个域（Field）进行原子操作，只能配合 volatile 修饰的字段使用，否则会出现异常 1Exception in thread &quot;main&quot; java.lang.IllegalArgumentException: Must be volatile type 代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.chan.concurrent.cas.atomicFieldUpdater;import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;public class Test { private volatile int field; public static void main(String[] args) { // AtomicIntegerFieldUpdater 处理int类型的字段的原子性 AtomicIntegerFieldUpdater&lt;Test&gt; fieldUpdater = AtomicIntegerFieldUpdater.newUpdater(Test.class, &quot;field&quot;); Test test = new Test(); boolean a = fieldUpdater.compareAndSet(test, 0, 10);//返回布尔值 为true则将新的值设置 为false则保持旧值不变 System.out.println(a);// 修改成功 field = 10 System.out.println(test.field); boolean b = fieldUpdater.compareAndSet(test, 10, 20); System.out.println(b);// 修改成功 field = 20 System.out.println(test.field); boolean c = fieldUpdater.compareAndSet(test, 10, 30); System.out.println(c);// 修改失败 field = 20 System.out.println(test.field); // AtomicReferenceFieldUpdater 处理引用类型的字段的原子性 AtomicReferenceFieldUpdater&lt;Student, String&gt; updater = AtomicReferenceFieldUpdater.newUpdater(Student.class, String.class, &quot;name&quot;); Student student = new Student(); boolean d = updater.compareAndSet(student, null, &quot;陈陈陈&quot;); System.out.println(d);// 修改成功 name = &quot;陈陈陈&quot; System.out.println(student); }}class Student { volatile String name; @Override public String toString() { return &quot;Student{&quot; + &quot;name='&quot; + name + '\\'' + '}'; }} 12345678true10true20false20trueStudent{name='陈陈陈'} 原子累加器累加器性能比较比较 AtomicLong 与 LongAdder 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.chan.concurrent.cas.longAdder;import java.util.ArrayList;import java.util.List;import java.util.concurrent.atomic.AtomicLong;import java.util.concurrent.atomic.LongAdder;import java.util.function.Consumer;import java.util.function.Supplier;public class Test { public static void main(String[] args) { // 比较 AtomicLong 与 LongAdder for (int i = 0; i &lt; 5; i++) { demo(() -&gt; new AtomicLong(), (adder) -&gt; adder.incrementAndGet()); } for (int i = 0; i &lt; 5; i++) { demo(() -&gt; new LongAdder(), (adder) -&gt; adder.increment()); } } private static &lt;T&gt; void demo(Supplier&lt;T&gt; supplier, Consumer&lt;T&gt; consumer) { T adder = supplier.get();// adder为共享变量 List&lt;Thread&gt; threads = new ArrayList&lt;&gt;(); long start = System.nanoTime(); // 4 个线程，每个线程都去主内存中拿adder, 每个线程对adder各累加 50 万, 在线程安全的情况下, adder最后应该是2000000 for (int i = 0; i &lt; 4; i++) { threads.add(new Thread(new Runnable() { @Override public void run() { for (int j = 0; j &lt; 500000; j++) { consumer.accept(adder); } } })); } for (Thread thread : threads) { thread.start(); } for (Thread thread : threads) { try { thread.join(); } catch (InterruptedException e) { e.printStackTrace(); } } long end = System.nanoTime(); System.out.println(adder + &quot; cost:&quot; + (end - start)/1000000 + &quot;ms&quot;); }} 123456789102000000 cost:298ms2000000 cost:253ms2000000 cost:229ms2000000 cost:221ms2000000 cost:235ms2000000 cost:69ms2000000 cost:29ms2000000 cost:28ms2000000 cost:29ms2000000 cost:22ms 性能提升的原因如果使用 AtomicLong 实现累加，底层是 cas 思想，在多线程竞争时，它要使用 while(true) 循环不断尝试更新，直到能成功，但是竞争如果比较激烈，往一个共享变量上做累加，必然竞争比较激烈，重试的次数越多，累加的速率越低。 如果使用 LongAdder 实现累加，它是在有竞争的时候设置多个累加单元，不是在一个共享变量上累加，这样比如 Therad-0 累加 Cell[0]，而 Thread-1 累加 Cell[1]。。。 线程 1 向共享变量 1 上累加，线程 2 向共享变量 2 上累加，最后将结果汇总。这样它们在累加时操作的不同的共享变量 Cell 变量(累加单元)，因此减少了 CAS 失败重试的次数，从而提高性能。这个增加累加单元的思想很像 forkjoin。 累加单元与 CPU 的核数有关，再多不会超过 CPU 的核数，因为超了核心数的话，CAS 便意义不大了。 所以核心数越多，性能越好。 LongAdder源码剖析LongAdder 是并发大师 @author Doug Lea 的作品，设计的非常精巧。 前面介绍的 Java 中的一些原子类，基本都是通过 CAS 来实现原子性操作，白白浪费 CPU 资源。JDK8 中新增了一个原子性递增或者递减类 LongAdder 用来克服高并发下使用 AtomicLong 的缺点。LongAdder 的思路是把一个变量分解为多个变量，让同样多的线程去竞争多个资源。 首先，LongAdder 类有几个关键域。 LongAdder继承自Striped64，在Striped64中维护者三个变量：base、cellsBusy、Cell数组。base是个基础知识，默认为0。cellsBusy用来实现自旋锁，状态值只有0和1，当创建Cell元素，扩容Cell数组或者初始化Cell数组时，使用CAS操作该变量来保证同时只有一个线程可以进行其中之一的操作。所以cells是volatile的，但没有加锁，而是用的自旋锁。 123456// 累加单元数组, 懒惰初始化, 有竞争的时候用transient volatile Cell[] cells;// 基础值, 如果没有竞争, 则用 cas 累加这个域transient volatile long base;// 在 cells 创建或扩容时, 置为 1, 表示加锁transient volatile int cellsBusy; 使用LongAdder时，内部维护了多个Cell变量(多个累加单元)，每个Cell里面有一个初始值为0的long型变量，这样同时竞争一个变量的线程数量就变少了，而是所有线程分散成对多个变量的竞争，减少了失败次数。如果竞争某个Cell变量失败，它不会一直在这个Cell变量上自旋CAS重试，而是尝试在其他的Cell变量上进行CAS尝试，这个改变增加了当前线程重试CAS成功的可能性。最后，在获取LongAdder当前值时，是把所有Cell变量的value值累加后再加上base返回的。 LongAdder里面有一个Cell数组，是惰性加载的，即需要时创建。当并发线程较少时，所有累加操作都是针对base变量进行。Cell类型是AtomicLong的一个改进，用来减少缓存的争用，也就是解决伪共享问题。因为Cell数组元素的内存地址是连续的，所以数组内的多个元素能经常共享缓存行，因此这里使用@sun.misc.Contended注解对Cell类进行字节填充，防止数组中多个元素共享一个缓存行，提升性能。 transient ： 序列化时不会把这些进行序列化 LongAdder 源码底层用到 cas 加锁，也即是 cellsBusy 为 1 的标记加锁，这种机制来保护 cells 创建或扩容时的安全。 下面的代码不要用在项目中，因为是有风险的，空运转可能导致对性能的影响。 cas 锁 demoLongAdder 里面就是使用了 cas 方式实现的锁，所以在这里预演一个 demo，方便理解 cellsBusy 的实现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package com.chan.concurrent.cas.longAdder;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger;// 使用cas思想实现的锁, 这个方式拿不到锁不是阻塞而是一直循环, 不要用于生产实践@Slf4j(topic = &quot;c.CasLock&quot;)public class CasLock { // 初始值设置为0 AtomicInteger ai = new AtomicInteger(0);//状态只有0和1 public void lock() { while (true) { int prev = ai.get();// 期望值为0 int next = 1;// 新值 if (ai.compareAndSet(prev, next)) { break; } } } public void unlock() { log.debug(&quot;unlock...&quot;); ai.set(0); }}@Slf4j(topic = &quot;c.CasLockTest&quot;)class CasLockTest { public static void main(String[] args) { CasLock casLock = new CasLock(); new Thread(() -&gt; { log.debug(&quot;begin...&quot;); casLock.lock();// 使用cas实现的锁, 要么成功拿到锁向下执行, 要么空转一直循环尝试, 这里就不叫阻塞了, 而是一直尝试,自旋锁 try { log.debug(&quot;lock...&quot;); TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } finally { casLock.unlock(); } }, &quot;t1&quot;).start(); new Thread(() -&gt; { log.debug(&quot;begin...&quot;); casLock.lock(); try { log.debug(&quot;lock...&quot;); } finally { casLock.unlock(); } }, &quot;t2&quot;).start(); }} 1234567输出：21:46:54 [t2] c.CasLockTest - begin...21:46:54 [t2] c.CasLockTest - lock...21:46:54 [t1] c.CasLockTest - begin...21:46:54 [t2] c.CasLock - unlock...21:46:54 [t1] c.CasLockTest - lock...21:46:55 [t1] c.CasLock - unlock... LongAdder 源码分析接下来的的解析都围绕着六个问题来进行： LongAdder的结构是怎样的？ 线程访问Cell数组的哪一个Cell元素？ 如何初始化Cell数组？ Cell数组如何扩容？ 线程访问分配的Cell元素有冲突后如何处理？ 如何保证线程操作被分配的Cell元素的原子性？ 1234567// 比较 AtomicLong 与 LongAdder for (int i = 0; i &lt; 5; i++) { demo(() -&gt; new AtomicLong(), (adder) -&gt; adder.incrementAndGet()); } for (int i = 0; i &lt; 5; i++) { demo(() -&gt; new LongAdder(), (adder) -&gt; adder.increment()); } 我们从 adder.increment() 的方法点进去 123456/** * Equivalent to {@code add(1)}. */public void increment() { add(1L);} 再点 add 方法进到里面： 123456789101112131415/** * Adds the given value. * * @param x the value to add */public void add(long x) { Cell[] as; long b, v; int m; Cell a; if ((as = cells) != null || !casBase(b = base, b + x)) { boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[getProbe() &amp; m]) == null || !(uncontended = a.cas(v = a.value, v + x))) longAccumulate(x, null, uncontended); }} 先不看别的，再点击 longAccumulate 方法进到里面： 提前说明一下源码中的几个方法 12345int getProbe() //方法，用来获得线程对应的probe值，类似于hash值，是一种hash函数映射。int advanceProbe(int probe) //方法：用来重新生成一个probe值，为什么要重新生成呢？因为在之前的probe映射到的cell中累加，一直失败。boolean casCellsBusy() //方法：用来上cas锁 ——— 上锁成功则返回true，此时cellsBusy应为1；上锁失败则返回false，证明有其他线程正在使用锁；使用锁结束后，应该让cellsBusy = 0，变成无锁状态。 源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170/** * Handles cases of updates involving initialization, resizing, * creating new Cells, and/or contention. See above for * explanation. This method suffers the usual non-modularity * problems of optimistic retry code, relying on rechecked sets of * reads. * * @param x the value * @param fn the update function, or null for add (this convention * avoids the need for an extra field or function in LongAdder). * @param wasUncontended false if CAS failed before call */ //都有哪些情况会调用？ //1.true-&gt; cells 未初始化，也就是多线程写base发生竞争了[初始化cells] // 执行CASE2 //2.true-&gt; cells 已初始化，但是当前线程对应下标的cell为空，需要创建 longAccumulate 支持 // 执行CASE1.1 //3.true-&gt; cas失败，意味着当前线程对应的cell 有竞争[重试|扩容] // 执行CASE1.3 失败 -&gt; CASE1.5 -&gt; rehash，即执行advanceProbe(h) -&gt; 自旋 -&gt; 执行CASE1.3 再失败 -&gt; CASE1.6()因为CASE1.5中将设置扩容意向为true // wasUncontended：只有cells初始化之后，并且当前线程 竞争修改失败，才会是false final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) { //h 表示线程hash值 int h; //条件成立：说明当前线程 还未分配hash值 if ((h = getProbe()) == 0) { //给当前线程分配hash值 ThreadLocalRandom.current(); // force initialization //取出当前线程的hash值 赋值给h h = getProbe(); //为什么wasUncontended设置为true？ //代码执行到这里，说明线程没有分配hash值(hash=0) //所以 当前线程 肯定是写入到了 cells[0] 位置(0 &amp; 任意数 = 0)。 不把它当做一次真正的竞争 wasUncontended = true; } //表示扩容意向。 false 一定不会扩容；true 可能会扩容。 boolean collide = false; // True if last slot nonempty //自旋 for (;;) { //as 表示cells引用 //a 表示当前线程命中的cell //n 表示cells数组长度 //v 表示 期望值 Cell[] as; Cell a; int n; long v; //CASE1： 表示cells已经初始化了，当前线程应该将数据写入到对应的cell中 if ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) { //进入这个if，有下面两种情况 //2.true-&gt; 说明当前线程对应下标的cell为空，需要创建 longAccumulate 支持 //3.true-&gt;表示cas失败，意味着当前线程对应的cell 有竞争[重试|扩容] //CASE1.1：true-&gt;表示当前线程对应的下标位置的cell为null，需要创建new Cell if ((a = as[(n - 1) &amp; h]) == null) { //true-&gt;表示当前锁 未被占用； false-&gt;表示锁被占用 if (cellsBusy == 0) { // Try to attach new Cell //拿当前的x创建Cell Cell r = new Cell(x); // Optimistically create //条件一：true-&gt;表示当前锁 未被占用； false-&gt;表示锁被占用 //条件二：true-&gt;表示当前线程获取锁成功； false-&gt;当前线程获取锁失败。 if (cellsBusy == 0 &amp;&amp; casCellsBusy()) { //是否创建成功的标记 boolean created = false; try { // Recheck under lock //rs 表示当前cells 引用 //m 表示cells长度 //j 表示当前线程命中的下标 Cell[] rs; int m, j; //条件一 条件二 为true //条件三：rs[j = (m - 1) &amp; h] == null 为了防止其它线程初始化过该位置，然后当前线程再次初始化该位置，导致丢失数据 if ((rs = cells) != null &amp;&amp; (m = rs.length) &gt; 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) { rs[j] = r; created = true; } } finally { cellsBusy = 0; } if (created) break; continue; // Slot is now non-empty } } //扩容意向 强制改为了false collide = false; } // CASE1.2：true -&gt; wasUncontended：只有cells初始化之后，并且当前线程 竞争修改失败，才会是false else if (!wasUncontended) // CAS already known to fail wasUncontended = true; // Continue after rehash //CASE 1.3：当前线程rehash过hash值，然后新命中的cell不为空 //true -&gt; 写成功,退出循环 //false -&gt; 表示rehash之后命中的新的cell 也有竞争 else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; //CASE 1.4： //条件一：n &gt;= NCPU 为 true-&gt;就会把扩容意向改为false，不再扩容； false-&gt; 说明cells数组还可以扩容 //条件二：cells != as 为 true-&gt;其它线程已经扩容过了，当前线程rehash之后重试即可 else if (n &gt;= NCPU || cells != as) //扩容意向为false，表示不扩容了 collide = false; // At max size or stale //CASE 1.5： //!collide == true 设置扩容意向 为true 但是不一定真的发生扩容 else if (!collide) collide = true; //CASE 1.6：真正扩容的逻辑 //条件一：cellsBusy == 0 true-&gt;表示当前无锁状态，当前线程可以去竞争这把锁 //条件二：casCellsBusy true-&gt;表示当前线程 获取锁 成功，可以执行扩容逻辑 // false-&gt;表示当前时刻有其它线程在做扩容相关的操作。 else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) { try { //这里又判断了一次cells == as。 防止其它线程已经扩容了，当前线程再次扩容。cells的引用就会发生变化，导致数据流失 if (cells == as) { // Expand table unless stale //数组长度扩容，得到新数组，新长度等于旧长度左移1位，等价于 新长度=旧长度*2 Cell[] rs = new Cell[n &lt;&lt; 1]; //遍历旧数组，将旧数组对应位置的值放到新数组中 for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; //将新数组的引用赋值给全局的cells cells = rs; } } finally { //释放锁 cellsBusy = 0; } collide = false; continue; // Retry with expanded table } //修改失败，就会重置当前线程Hash值，然后当前线程自旋，再次修改时，就会到不同的cell上 h = advanceProbe(h); } //CASE2：前置条件cells还未初始化，as 为null //条件一：true 表示当前未加锁 //条件二：为什么cells == as？短路原则，当判断这个条件时，条件一为true，表示其他线程已经持有锁了 // 那么其它线程在执行下面的初始化方法，可能会在你给as赋值为null之后修改了 cells，所以这里再判断一次 //条件三：true 表示获取锁成功 会把cellsBusy = 1，false 表示其它线程正在持有这把锁 else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) { boolean init = false; try { // Initialize table //这里又判断了一次cells == as。 防止其它线程已经初始化了，当前线程再次初始化 导致丢失数据 if (cells == as) { Cell[] rs = new Cell[2]; rs[h &amp; 1] = new Cell(x); cells = rs; init = true; } } finally { cellsBusy = 0; } if (init) break; } //CASE3：前面两个if中所有条件都为false才会执行到这，说明： //1.当前cellsBusy加锁状态，表示其它线程正在初始化cells，所以当前线程将值累加到base //2.cells被其它线程初始化后，当前线程需要将数据累加到base else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; // Fall back on using base } } 现在是在 Striped64 类中，我们继续向上翻，找到学习 LongAdder 的核心以及出发点，也就是下面的 Cell 累加单元类. 为什么说它是核心以及出发点，我们都知道 LongAdder 和 AtomicLong 的功能是一样的都是累加，但是 LongAdder 的速率要高于 AtomicLong ，那么为什么比 AtomicLong 的速度快，就是因为 LongAdder 改进了可以增加累加单元，那累加单元类就是下面的： 123456789101112131415161718192021222324252627/** * Padded variant of AtomicLong supporting only raw accesses plus CAS. * * JVM intrinsics note: It would be possible to use a release-only * form of CAS here, if it were provided. */@sun.misc.Contended static final class Cell { volatile long value; Cell(long x) { value = x; } final boolean cas(long cmp, long val) { return UNSAFE.compareAndSwapLong(this, valueOffset, cmp, val); } // Unsafe mechanics private static final sun.misc.Unsafe UNSAFE; private static final long valueOffset; static { try { UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; ak = Cell.class; valueOffset = UNSAFE.objectFieldOffset (ak.getDeclaredField(&quot;value&quot;)); } catch (Exception e) { throw new Error(e); } }} 很简单，一个Cell维护一个volatile的变量，和Cell数组类似，这里设置成volatile但并没有加锁主要是利用了cas来保证内部value的原子性更改，这也回答了问题6，即如何保证线程操作被分配的Cell元素的原子性 。类Cell使用@sun.misc.Contended修饰是为了避免伪共享，因为Cell数组是连续的，很容易出现这种问题。我们也弄懂了问题1，即LongAdder的结构是怎样的。 原理之伪共享@sun.misc.Contended 看这个注解： 这个注解的作用就是为了防止缓存行共享 缓存行共享就是我们说的伪共享，要先从缓存说起。 从 CPU 到 大约需要的时钟周期 寄存器 1 cycle (4GHz 的 CPU 约为0.25ns) L1 3~4 cycle L2 10~20cycle L3 40~45cycle 主内存 120~240cycle 因为 CPU 与 内存的速度差异很大，需要靠预读数据至缓存来提升效率。 而缓存以缓存行为单位，每个缓存行对应着一块内存，一般是 64 byte（8 个 long） 缓存的加入会造成数据副本的产生，即同一份数据会缓存在不同核心的缓存行中 CPU 要保证数据的一致性，如果某个 CPU 核心更改了数据，其它 CPU 核心对应的整个缓存行必须失效 注： CPU 的三级缓存，为了方便在下图中统一画一个缓存行 因为 Cell 是数组形式，在内存中是连续存储的，一个 Cell 为 24 字节（16 字节的对象头和 8 字节的 value），因此缓存行可以存下 2 个的 Cell 对象。这样问题来了： Core-0 要修改 Cell[0] Core-1 要修改 Cell[1] 无论谁修改成功，都会导致对方 Core 的缓存行失效，比如 Core-0 中 Cell[0]=6000，Cell[1]=8000 要累加 Cell[0]=6001，Cell[1]=8000 ，这时会让 Core-1 的缓存行失效。 @sun.misc.Contended 用来解决这个问题，它的原理是在使用此注解的对象或字段的前后各增加 128 字节大小的 padding，从而让 CPU 将对象预读至缓存时占用不同的缓存行，这样，不会造成对方缓存行的失效。 其实就是空间换取时间，让每个累加单元独占一个核心的缓存行。 我们将这种一个核心的缓存行中加入了多个累加单元的现象成为伪共享，一个改动，其它整体失效，其它都要重新加载，会影响效率，这个注解的作用就是防止伪共享。 提高效率。 接下来回过头来看前面的 add 方法，累加主要调用这个方法： 123456789101112131415161718192021222324public void add(long x) { // as 为累加单元数组 // b 为基础值 // x 为累加值 Cell[] as; long b, v; int m; Cell a; // 进入 if 的两个条件 // 1. as 有值, 表示已经发生过竞争, 进入 if // 2. cas 给 base 累加时失败了, 表示 base 发生了竞争, 进入 if if ((as = cells) != null || !casBase(b = base, b + x)) { //(1) // uncontended 表示 cell 没有竞争 boolean uncontended = true; if ( // as 还没有创建 as == null || (m = as.length - 1) &lt; 0 || //(2) // 当前线程对应的 cell 还没有 (a = as[getProbe() &amp; m]) == null || //(3) // cas 给当前线程的 cell 累加失败 uncontended=false ( a 为当前线程的 cell ) !(uncontended = a.cas(v = a.value, v + x)) //(4) ) { // 进入 cell 数组创建、cell 创建的流程 longAccumulate(x, null, uncontended); //(5) } }} 要注意这个函数里面的判断条件虽然是或的关系，其实是层层递进的。 代码（1）先看cells是否为null，如果不为空则直接执内部代码块，为空则先尝试在base变量上进行累加。 如果累加base变量成功了，则直接返回，失败了则执行内部代码块。 代码（2）如果cells是空的（as==null或者as的长度为0），则执行代码（5）进行累加；不为空则得到要当前线程要访问的cell（即变量a，下标是通过getProb() &amp; m获取的）。 如果要访问的cell为空，则执行代码（5），否则就对访问的cas进行原子改变操作，并返回uncontended变量查看是否执行成功，成功了直接返回，失败了还是要执行代码（5）。 这个地方我们就回答了问题2，即如何知道当前线程是访问哪一个cell呢，通过getProbe() &amp; m获取下标，进而从cells数组中取得。m代表当前cells数组元素个数-1，getProbe()用于获取当前线程中变量threadLocalRandomProbe的值，它一开始为0，在代码5中会对其进行初始化。 接下来就是longAccumulate方法了，我们通过分析add方法的逻辑，知道了LongAdder中调用longAccumulate的原因：（三者之一） cells 未初始化，但是多线程写base发生竞争了[进入longAccumulate初始化cells] cells 已初始化，但是当前线程对应下标的cell为空，需要创建 longAccumulate 支持 cas失败，意味着当前线程对应的cell 有竞争[重试|扩容] 情况一：说明 cells 未初始化，也就是多线程写base发生竞争了[初始化cells]，会进入case2，当前线程拿到锁并进入扩容；如果当前线程没有获取到锁或者其他线程已经初始化了，则进入case3，表示其它线程正在初始化cells，所以当前线程将值累加到base 情况二、情况三都会进入case1，表示cells已经初始化了，当前线程应该将数据写入到对应的cell中 情况二：说明当前线程对应下标的cell为空，需要创建 longAccumulate 支持，进入case1.1，创建new Cell 情况三：表示cas失败，意味着当前线程对应的cell 有竞争[重试|扩容] cell已经有了但是在写的时候发生了竞争，进入case1.2，这时wasUncontended为false，取反为true，进入该条件，将这个值设置为true，进行rehash 自旋重新进入case1，cell不为空的话进入case1.3尝试一次，成功则退出自旋循环，否则进入case1.5，将collide设置为true，再次rehash，再次查看case1.3条件是否满足，不满足则会直接进入到case1.6，这里才是真正的扩容方法。 注意：这里的case1.4是累加单元数组的长度不能超过cpu核心的数量，因为我们要保证一个核心的缓存行对应一个累加单元。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170/** * Handles cases of updates involving initialization, resizing, * creating new Cells, and/or contention. See above for * explanation. This method suffers the usual non-modularity * problems of optimistic retry code, relying on rechecked sets of * reads. * * @param x the value * @param fn the update function, or null for add (this convention * avoids the need for an extra field or function in LongAdder). * @param wasUncontended false if CAS failed before call */ //都有哪些情况会调用？ //1.true-&gt; cells 未初始化，也就是多线程写base发生竞争了[初始化cells] // 执行CASE2 //2.true-&gt; cells 已初始化，但是当前线程对应下标的cell为空，需要创建 longAccumulate 支持 // 执行CASE1.1 //3.true-&gt; cas失败，意味着当前线程对应的cell 有竞争[重试|扩容] // 执行CASE1.3 失败 -&gt; CASE1.5 -&gt; rehash，即执行advanceProbe(h) -&gt; 自旋 -&gt; 执行CASE1.3 再失败 -&gt; CASE1.6()因为CASE1.5中将设置扩容意向为true // wasUncontended：只有cells初始化之后，并且当前线程 竞争修改失败，才会是false final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) { //h 表示线程hash值 int h; //条件成立：说明当前线程 还未分配hash值 if ((h = getProbe()) == 0) { //给当前线程分配hash值 ThreadLocalRandom.current(); // force initialization //取出当前线程的hash值 赋值给h h = getProbe(); //为什么wasUncontended设置为true？ //代码执行到这里，说明线程没有分配hash值(hash=0) //所以 当前线程 肯定是写入到了 cells[0] 位置(0 &amp; 任意数 = 0)。 不把它当做一次真正的竞争 wasUncontended = true; } //表示扩容意向。 false 一定不会扩容；true 可能会扩容。 boolean collide = false; // True if last slot nonempty //自旋 for (;;) { //as 表示cells引用 //a 表示当前线程命中的cell //n 表示cells数组长度 //v 表示 期望值 Cell[] as; Cell a; int n; long v; //CASE1： 表示cells已经初始化了，当前线程应该将数据写入到对应的cell中 if ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) { //进入这个if，有下面两种情况 //2.true-&gt; 说明当前线程对应下标的cell为空，需要创建 longAccumulate 支持 //3.true-&gt;表示cas失败，意味着当前线程对应的cell 有竞争[重试|扩容] //CASE1.1：true-&gt;表示当前线程对应的下标位置的cell为null，需要创建new Cell if ((a = as[(n - 1) &amp; h]) == null) { //true-&gt;表示当前锁 未被占用； false-&gt;表示锁被占用 if (cellsBusy == 0) { // Try to attach new Cell //拿当前的x创建Cell Cell r = new Cell(x); // Optimistically create //条件一：true-&gt;表示当前锁 未被占用； false-&gt;表示锁被占用 //条件二：true-&gt;表示当前线程获取锁成功； false-&gt;当前线程获取锁失败。 if (cellsBusy == 0 &amp;&amp; casCellsBusy()) { //是否创建成功的标记 boolean created = false; try { // Recheck under lock //rs 表示当前cells 引用 //m 表示cells长度 //j 表示当前线程命中的下标 Cell[] rs; int m, j; //条件一 条件二 为true //条件三：rs[j = (m - 1) &amp; h] == null 为了防止其它线程初始化过该位置，然后当前线程再次初始化该位置，导致丢失数据 if ((rs = cells) != null &amp;&amp; (m = rs.length) &gt; 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) { rs[j] = r; created = true; } } finally { cellsBusy = 0; } if (created) break; continue; // Slot is now non-empty } } //扩容意向 强制改为了false collide = false; } // CASE1.2：true -&gt; wasUncontended：只有cells初始化之后，并且当前线程 竞争修改失败，才会是false else if (!wasUncontended) // CAS already known to fail wasUncontended = true; // Continue after rehash //CASE 1.3：当前线程rehash过hash值，然后新命中的cell不为空 //true -&gt; 写成功,退出循环 //false -&gt; 表示rehash之后命中的新的cell 也有竞争 else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; //CASE 1.4： //条件一：n &gt;= NCPU 为 true-&gt;就会把扩容意向改为false，不再扩容； false-&gt; 说明cells数组还可以扩容 //条件二：cells != as 为 true-&gt;其它线程已经扩容过了，当前线程rehash之后重试即可 else if (n &gt;= NCPU || cells != as) //扩容意向为false，表示不扩容了 collide = false; // At max size or stale //CASE 1.5： //!collide == true 设置扩容意向 为true 但是不一定真的发生扩容 else if (!collide) collide = true; //CASE 1.6：真正扩容的逻辑 //条件一：cellsBusy == 0 true-&gt;表示当前无锁状态，当前线程可以去竞争这把锁 //条件二：casCellsBusy true-&gt;表示当前线程 获取锁 成功，可以执行扩容逻辑 // false-&gt;表示当前时刻有其它线程在做扩容相关的操作。 else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) { try { //这里又判断了一次cells == as。 防止其它线程已经扩容了，当前线程再次扩容。cells的引用就会发生变化，导致数据流失 if (cells == as) { // Expand table unless stale //数组长度扩容，得到新数组，新长度等于旧长度左移1位，等价于 新长度=旧长度*2 Cell[] rs = new Cell[n &lt;&lt; 1]; //遍历旧数组，将旧数组对应位置的值放到新数组中 for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; //将新数组的引用赋值给全局的cells cells = rs; } } finally { //释放锁 cellsBusy = 0; } collide = false; continue; // Retry with expanded table } //修改失败，就会重置当前线程Hash值，然后当前线程自旋，再次修改时，就会到不同的cell上 h = advanceProbe(h); } //CASE2：前置条件cells还未初始化，as 为null //条件一：true 表示当前未加锁 //条件二：为什么cells == as？短路原则，当判断这个条件时，条件一为true，表示其他线程已经持有锁了 // 那么其它线程在执行下面的初始化方法，可能会在你给as赋值为null之后修改了 cells，所以这里再判断一次 //条件三：true 表示获取锁成功 会把cellsBusy = 1，false 表示其它线程正在持有这把锁 else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) { boolean init = false; try { // Initialize table //这里又判断了一次cells == as。 防止其它线程已经初始化了，当前线程再次初始化 导致丢失数据 if (cells == as) { Cell[] rs = new Cell[2]; rs[h &amp; 1] = new Cell(x); cells = rs; init = true; } } finally { cellsBusy = 0; } if (init) break; } //CASE3：前面两个if中所有条件都为false才会执行到这，说明： //1.当前cellsBusy加锁状态，表示其它线程正在初始化cells，所以当前线程将值累加到base //2.cells被其它线程初始化后，当前线程需要将数据累加到base else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; // Fall back on using base } } 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) { //(6) 初始化当前线程的变量threadLocalRandomProbe的值 int h; if ((h = getProbe()) == 0) { ThreadLocalRandom.current(); // force initialization h = getProbe(); wasUncontended = true; } boolean collide = false; // True if last slot nonempty for (;;) { Cell[] as; Cell a; int n; long v; if ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) { //(7) if ((a = as[(n - 1) &amp; h]) == null) { //(8) if (cellsBusy == 0) { // Try to attach new Cell Cell r = new Cell(x); // Optimistically create if (cellsBusy == 0 &amp;&amp; casCellsBusy()) { boolean created = false; try { // Recheck under lock Cell[] rs; int m, j; if ((rs = cells) != null &amp;&amp; (m = rs.length) &gt; 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) { rs[j] = r; created = true; } } finally { cellsBusy = 0; } if (created) break; continue; // Slot is now non-empty } } collide = false; } else if (!wasUncontended) // CAS already known to fail wasUncontended = true; // Continue after rehash //当前Cell存在，则执行CAS设置（9） else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; //当前Cells数组元素个数大于CPU个数（10） else if (n &gt;= NCPU || cells != as) collide = false; // At max size or stale else if (!collide) //是否有冲突（11） collide = true; //如果当前元素个数没有达到CPU个数并且有冲突则扩容（12） else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) { try { if (cells == as) { // Expand table unless stale Cell[] rs = new Cell[n &lt;&lt; 1]; for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; cells = rs; } } finally { cellsBusy = 0; } collide = false; continue; // Retry with expanded table } //（13）为了能够找到一个空闲的Cell，重新计算hash值，xorshift算法生成随机数 h = advanceProbe(h); } //初始化Cell数组（14） else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) { boolean init = false; try { // Initialize table if (cells == as) { //14.1 Cell[] rs = new Cell[2]; //14.2 rs[h &amp; 1] = new Cell(x); cells = rs; init = true; } } finally { cellsBusy = 0; } if (init) break; } else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; // Fall back on using base } } 代码很长很复杂，这里我们还是针对开头提出的问题3、问题4、问题5。 问题3：如何初始化Cell数组？cells数组初始化是在代码（14）中进行的，cellsBusy是一个标示，为0说明当前cells数组没有在被初始化或者扩容，也没有在新建Cell元素（没有发生结构化改变），为1说明cells数组再被扩容、初始化或创建新的Cell元素，只有通过casCellsBusy()函数将cellsBusy变量成功由0设置为1才可继续初始化。然后就是申请数组空间，然后计算本线程要访问的cell下标，设置初始化标志，最后要重置cellsBusy标记。 问题4：Cell数组如何扩容？cells数组扩容是在代码（12）中进行的，对cells扩容是有条件的，也就是代码（10）（11）的条件都不满足，即当前cells的元素个数小于当前机器CPU个数并且当前多个线程访问了cells中同一个元素，从而导致冲突使其中一个线程CAS失败时才会进行扩容操作。因为最好让每个CPU只运行一个线程时效果最好，扩容也会进行casCellsBusy()操作。扩容后将原来的复制到新的数组中，剩余的还未初始化，为Null。 问题5：线程访问分配的Cell元素有冲突后如何处理？代码（7）（8）中，当前线程调用add方法并根据当前线程的随机数threadLocakRandomProbe和cells元素个数计算要访问的cell元素下标，然后如果发现对应下标元素的值为null，则新增一个Cell元素到cells数组，并且在将其添加到cells数组之前要竞争设置cellsBusy为1。代码（13）对CAS失败的线程重新计算当前线程的随机值threadLocalRandomProbe，以减少下次访问cells元素时的冲突机会。 UnsafeUnsafe 对象提供了非常底层的，操作内存、线程的方法，Unsafe 对象不能直接调用，只能通过反射获得。Unsafe 并不是指线程安全方面的不安全，而是指这个类比较底层，操作内存、线程，不建议我们编程人员直接对其使用，误用会导致不安全的发生，并不是指它本身是线程不安全的。前面介绍的所有的原子整数、原子引用这些原子类，它们的底层都是调用使用了 Unsafe，而 Unsafe 的底层调用了 CPU 的一些 cas 指令（以 lock 打头的一些指令）来保证比较和交换的原子性。 案例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.chan.concurrent.cas.baseUnsafe;import lombok.Data;import sun.misc.Unsafe;import java.lang.reflect.Field;public class UnsafeAccessor { // 这个对象普通获取不到 要通过反射获取 static Unsafe unsafe; static { try { Field theUnsafe = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);// 反射获取Unsafe类中的字段 theUnsafe.setAccessible(true);// 因为这个字段是private的域,所以要设置权限为true unsafe = (Unsafe) theUnsafe.get(null);// 因为这个字段是static的从属于类的因此参数传递null 111 } catch (NoSuchFieldException | IllegalAccessException e) { throw new Error(e); } } static Unsafe getUnsafe() { return unsafe; } public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException { Field id = Student.class.getDeclaredField(&quot;id&quot;); Field name = Student.class.getDeclaredField(&quot;name&quot;); Unsafe unsafe = UnsafeAccessor.getUnsafe(); // 获得成员变量的偏移量 long idOffset = UnsafeAccessor.unsafe.objectFieldOffset(id); long nameOffset = UnsafeAccessor.unsafe.objectFieldOffset(name); Student student = new Student(); // 使用cas方法替换成员变量的值 // 新建好的对象还没赋过值 所以旧值默认为0和null UnsafeAccessor.unsafe.compareAndSwapInt(student, idOffset, 0, 20);// 返回true UnsafeAccessor.unsafe.compareAndSwapObject(student, nameOffset, null, &quot;迩东陈&quot;);// 返回true System.out.println(student); System.out.println(id.get(student));// 因为这个字段不是static的,因此参数传递对象 222 System.out.println(name.get(student)); }}@Dataclass Student { volatile int id; volatile String name;} 123Student(id=20, name=迩东陈)20迩东陈 前面的取款案例，现在再使用底层的 Unsafe 来实现一次线程安全的原子操作。如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.chan.concurrent.cas.baseUnsafe;import lombok.extern.slf4j.Slf4j;import sun.misc.Unsafe;import java.lang.reflect.Field;@Slf4j(topic = &quot;c.AtomicData&quot;)public class AtomicData { private volatile int data; static final Unsafe unsafe; static final long DATA_OFFSET; static { try { // 先获取unsafe Field theUnsafe = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); theUnsafe.setAccessible(true); unsafe = (Unsafe) theUnsafe.get(null);//通过反射得到unsafe对象 // 获取变量的偏移量 Field dataField = AtomicData.class.getDeclaredField(&quot;data&quot;); DATA_OFFSET = unsafe.objectFieldOffset(dataField);//得到data的偏移量 } catch (NoSuchFieldException | IllegalAccessException e) { throw new Error(e);//重点 一定注意！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！ } } public AtomicData(int data) { this.data = data; } public void decrease(int amount) { while (true) { //从主存中拿到共享变量的旧值 int prev = data; //计算新值 int next = prev - amount; //cas 尝试修改 data 为 旧值 - amount，如果期间旧值被别的线程改了，返回 false if (unsafe.compareAndSwapInt(this, DATA_OFFSET, prev, next)) { break; } } } public int getData() { return data; }} 123456789101112131415161718192021222324252627282930313233package com.chan.concurrent.cas.baseUnsafe;import java.util.ArrayList;import java.util.List;public class Test { public static void main(String[] args) { List&lt;Thread&gt; threads = new ArrayList&lt;&gt;(); AtomicData atomicData = new AtomicData(10000); long startTime = System.nanoTime(); for (int i = 0; i &lt; 1000; i++) { threads.add(new Thread(new Runnable() { @Override public void run() { atomicData.decrease(10); } })); } for (Thread thread : threads) { thread.start(); } for (Thread thread : threads) { try { thread.join(); } catch (InterruptedException e) { e.printStackTrace(); } } long endTime = System.nanoTime(); System.out.println(atomicData.getData() + &quot; cost:&quot; + (endTime - startTime) / 1000000 + &quot;ms&quot;); }} 10 cost:277ms 本章小结 CAS 与 volatile API 原子整数 原子引用 原子数组 字段更新器 原子累加器 Unsafe 原理方面 LongAdder源码 伪共享","link":"/posts/20211122/java-concurrent-4.html"},{"title":"共享模型之管程","text":"共享带来的问题临界区 Critical Section 临界区其实就是操作共享数据的代码的部分。 一个程序运行多个线程本身是没有问题的 问题出在多个线程访问共享资源 多个线程读共享资源其实也没有问题 在多个线程对共享资源读写操作时发生指令交错，就会出现问题 一段代码块内如果存在对共享资源的多线程读写操作，称这段代码块为临界区 竞态条件 Race Condition：多个线程在临界区内执行，由于代码的执行序列不同而导致结果无法预测，称之为发生了竞态条件。 synchronized解决方案为了避免临界区的竞态条件发生，有多种手段可以达到目的。 阻塞式的解决方案：synchronized，Lock 非阻塞式的解决方案：原子变量 如果使用阻塞式的解决方案：synchronized，来解决上述问题，即俗称的【对象锁】，它采用互斥的方式让同一时刻至多只有一个线程能持有【对象锁】，其它线程再想获取这个【对象锁】时就会阻塞住。这样就能保证拥有锁的线程可以安全的执行临界区内的代码，不用担心线程上下文切换。 synchronized对象锁1234Object obj = new Object();synchronized(obj){ //操作共享资源的代码} 可以看到我们新建了一个Object对象，其实锁对象是可以为任意对象，但是只能有一个锁对象。 synchronized 实际是用对象锁保证了临界区内代码的原子性，临界区内的代码对外是不可分割的，不会被线程切换所打断。 使用面向对象做改进思想就是把需要保护的共享变量放入一个类。 12345678910111213141516171819202122232425262728293031323334353637383940class Room { int value = 0; public void increment() { synchronized (this) { value++; } } public void decrement() { synchronized (this) { value--; } } public int get() { synchronized (this) { return value; } }}@Slf4jpublic class Test1 { public static void main(String[] args) throws InterruptedException { Room room = new Room(); Thread t1 = new Thread(() -&gt; { for (int j = 0; j &lt; 5000; j++) { room.increment(); } }, &quot;t1&quot;); Thread t2 = new Thread(() -&gt; { for (int j = 0; j &lt; 5000; j++) { room.decrement(); } }, &quot;t2&quot;); t1.start(); t2.start(); t1.join(); t2.join(); log.debug(&quot;count: {}&quot; , room.get()); }} 方法上的 synchronized1234567891011121314151617181920212223242526class Test{ public synchronized void test() { }}等价于class Test{ public void test() { synchronized(this) { } }}class Test{ public synchronized static void test() { }}等价于class Test{ public static void test() { synchronized(Test.class) { } }} 所谓的“线程八锁”其实就是考察 synchronized 锁住的是哪个对象。 情况1：锁的都是Number的对象，或者说Number类中的this，输出12 或 21 123456789101112131415@Slf4j(topic = &quot;c.Number&quot;)class Number{ public synchronized void a() { log.debug(&quot;1&quot;); } public synchronized void b() { log.debug(&quot;2&quot;); }}public static void main(String[] args) { Number n1 = new Number(); new Thread(()-&gt;{ n1.a(); }).start(); new Thread(()-&gt;{ n1.b(); }).start();} 情况2：锁的都是Number的对象，或者说Number类中的this，1s后12，或 2 1s后 1 123456789101112131415@Slf4j(topic = &quot;c.Number&quot;)class Number{ public synchronized void a() { sleep(1); log.debug(&quot;1&quot;); } public synchronized void b() { log.debug(&quot;2&quot;); }}public static void main(String[] args) { Number n1 = new Number(); new Thread(()-&gt;{ n1.a(); }).start(); new Thread(()-&gt;{ n1.b(); }).start();} 情况3：a和b方法锁的都是Number的对象，或者说Number类中的this，c方法没锁。 3 1s 12 或 23 1s 1 或 32 1s 1 1234567891011121314151617181920@Slf4j(topic = &quot;c.Number&quot;)class Number{ public synchronized void a() { sleep(1); log.debug(&quot;1&quot;); } public synchronized void b() { log.debug(&quot;2&quot;); } public void c() { log.debug(&quot;3&quot;); }}public static void main(String[] args) { Number n1 = new Number(); new Thread(()-&gt;{ n1.a(); }).start(); new Thread(()-&gt;{ n1.b(); }).start(); new Thread(()-&gt;{ n1.c(); }).start();} 情况4：锁的都是Number的对象，或者说Number类中的this，但是调用时候是不同的Number对象，因此相当于两把锁，锁并没有实质性的作用。没有互斥作用。2 1s 后 1 12345678910111213141516@Slf4j(topic = &quot;c.Number&quot;)class Number{ public synchronized void a() { sleep(1); log.debug(&quot;1&quot;); } public synchronized void b() { log.debug(&quot;2&quot;); }}public static void main(String[] args) { Number n1 = new Number(); Number n2 = new Number(); new Thread(()-&gt;{ n1.a(); }).start(); new Thread(()-&gt;{ n2.b(); }).start();} 情况5：a方法锁的是Number这个类，b方法锁的是Number的对象，或者说Number类中的this。 因此锁住的是不同的对象，所以相当于两把锁，锁并没有实质性作用。没有互斥作用。2 1s 后 1 12345678910111213141516@Slf4j(topic = &quot;c.Number&quot;)class Number{ public static synchronized void a() { sleep(1); log.debug(&quot;1&quot;); } public synchronized void b() { log.debug(&quot;2&quot;); }}public static void main(String[] args) { Number n1 = new Number(); new Thread(()-&gt;{ n1.a(); }).start();//a方法锁的是类本身 new Thread(()-&gt;{ n1.b(); }).start();//b方法锁的是Number的对象，或者说Number类中的this} 情况6：锁的都是Number类本身，有互斥作用。1s 后12， 或 2 1s后 1 123456789101112131415@Slf4j(topic = &quot;c.Number&quot;)class Number{ public static synchronized void a() { sleep(1); log.debug(&quot;1&quot;); } public static synchronized void b() { log.debug(&quot;2&quot;); }}public static void main(String[] args) { Number n1 = new Number(); new Thread(()-&gt;{ n1.a(); }).start(); new Thread(()-&gt;{ n1.b(); }).start();} 情况7：a方法锁的是Number这个类，b方法锁的是Number的对象，或者说Number类中的this。无互斥效果。2 1s 后 1 12345678910111213141516@Slf4j(topic = &quot;c.Number&quot;)class Number{ public static synchronized void a() { sleep(1); log.debug(&quot;1&quot;); } public synchronized void b() { log.debug(&quot;2&quot;); } } public static void main(String[] args) { Number n1 = new Number(); Number n2 = new Number(); new Thread(()-&gt;{ n1.a(); }).start(); new Thread(()-&gt;{ n2.b(); }).start();} 情况8：锁的都是Number类本身，n1和n2都是属于Number类的，因此是同一个锁。有互斥作用。 1s 后12， 或 2 1s后 1 1234567891011121314151617@Slf4j(topic = &quot;c.Number&quot;)class Number{ public static synchronized void a() { sleep(1); log.debug(&quot;1&quot;); } public static synchronized void b() { log.debug(&quot;2&quot;); }}public static void main(String[] args) { Number n1 = new Number(); Number n2 = new Number(); new Thread(()-&gt;{ n1.a(); }).start(); new Thread(()-&gt;{ n2.b(); }).start();} 变量的线程安全分析1、成员变量和静态变量是否线程安全？ 如果它们没有被共享，则线程安全 如果它们被共享了，根据它们的状态是否能够改变，又分两种情况 如果只有读操作，则线程安全 如果有读写操作，则这段代码是临界区，需要考虑线程安全 2、局部变量是否线程安全？ 局部变量是线程安全的 但局部变量的引用稍有不同 如果该对象没有逃离方法的作用范围，它是线程安全的 如果该对象逃离方法的作用范围，需要考虑线程安全问题 局部变量线程安全分析 局部变量的引用稍有不同先看一个成员变量的例子： 123456789101112131415161718class ThreadUnsafe { ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); public void method1(int loopNumber) { for (int i = 0; i &lt; loopNumber; i++) { // { 临界区, 会产生竞态条件 method2(); method3(); // } 临界区 } } private void method2() { list.add(&quot;1&quot;); } private void method3() { list.remove(0); }} 执行 12345678910static final int THREAD_NUMBER = 2;static final int LOOP_NUMBER = 200;public static void main(String[] args) { ThreadUnsafe test = new ThreadUnsafe(); for (int i = 0; i &lt; THREAD_NUMBER; i++) { new Thread(() -&gt; { test.method1(LOOP_NUMBER); }, &quot;Thread&quot; + i).start(); }} 其中一种情况是，如果线程2 还未 add，线程1 remove 就会报错： 1234Exception in thread &quot;Thread1&quot; java.lang.IndexOutOfBoundsException: Index: 0, Size: 0at java.util.ArrayList.rangeCheck(ArrayList.java:657)at java.util.ArrayList.remove(ArrayList.java:496)... 分析： 无论哪个线程中的 method2 引用的都是同一个对象中的 list 成员变量 method3 与 method2 分析相同 再将 list 修改为局部变量： 123456789101112131415class ThreadSafe { public final void method1(int loopNumber) { ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;();//方法局部变量，不再是类的成员变量了 for (int i = 0; i &lt; loopNumber; i++) { method2(list); method3(list); } } private void method2(ArrayList&lt;String&gt; list) { list.add(&quot;1&quot;); } private void method3(ArrayList&lt;String&gt; list) { list.remove(0); }} 那么就不会有上述问题了 分析： list 是局部变量，每个线程调用时会创建其不同实例，没有共享 而 method2 的参数是从 method1 中传递过来的，与 method1 中引用同一个对象 method3 的参数分析与 method2 相同 方法访问修饰符带来的思考： 如果把 method2 和 method3 的方法修改为 public 会不会出现线程安全问题？ 情况1：有其它线程调用 method2 和 method3 情况1解析：其它线程调用的时候，不会出现线程安全问题，因为不涉及到共享，其他线程也会有自己的list传到方法中。 情况2：在 情况1 的基础上，为 ThreadSafe 类添加子类，子类覆盖 method2 或 method3 方法，即 123456789101112131415161718192021222324class ThreadSafe { public final void method1(int loopNumber) { ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; loopNumber; i++) { method2(list); method3(list); } } public void method2(ArrayList&lt;String&gt; list) { list.add(&quot;1&quot;); } public void method3(ArrayList&lt;String&gt; list) { list.remove(0); }}class ThreadSafeSubClass extends ThreadSafe{ @Override public void method3(ArrayList&lt;String&gt; list) { new Thread(() -&gt; { list.remove(0); }).start(); }} 情况2解析：有可能会出现线程安全问题！因为ThreadSafeSubClass继承自ThreadSafe，又因为父类中的方法都是public的，所以子类是包含父类的成员方法的，并且方法上并没有final修饰符，所以子类不仅可以使用父类的方法而且可以重写并且覆盖。 上面代码中，子类重写了父类的method3方法，在method3中再次开启一个线程操作list集合，这个时候的list变量虽然是局部变量但是已经被子类和父类共享了，属于共享资源，因此可能会出现线程安全问题。 执行： 1234567891011static final int THREAD_NUMBER = 2;static final int LOOP_NUMBER = 200;public static void main(String[] args) { ThreadSafeSubClass test = new ThreadSafeSubClass(); for (int i = 0; i &lt; THREAD_NUMBER; i++) { new Thread(() -&gt; { test.method1(LOOP_NUMBER); }, &quot;Thread&quot; + i).start(); }}//java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 会出错的 我们有代码可知，在每个线程任务中，ThreadSafeSubClass的对象调用method1方法，会找到父类的method1方法，这个时候method1方法中有一个list的局部变量，我们在method1方法中，又调用了method2和method3，此时，method2仍然完全是父类的方法，但是method3已经是子类重写之后的方法了，在重写的method3中，我们又开启了一个线程让list去remove(0)，此时我们知道这个list逃离了method1方法的作用范围，就需要考虑线程安全问题了。 从这个例子可以看出 private 或 ﬁnal 提供【安全】的意义所在，请体会开闭原则中的【闭】 常见线程安全类 String Integer StringBuﬀer Random Vector Hashtable java.util.concurrent 包下的类 这里说它们是线程安全的是指，多个线程调用它们同一个实例的某个方法时，是线程安全的。也可以理解为 123456789Hashtable table = new Hashtable();new Thread(()-&gt;{ table.put(&quot;key&quot;, &quot;value1&quot;);}).start();new Thread(()-&gt;{ table.put(&quot;key&quot;, &quot;value2&quot;);}).start(); 它们的每个方法是原子的 但注意它们多个方法的组合不是原子的，见后面分析 线程安全类方法的组合分析下面代码是否线程安全？ 12345Hashtable table = new Hashtable();// 比如线程1，线程2 并发的执行到下面if( table.get(&quot;key&quot;) == null) { table.put(&quot;key&quot;, value);} 很显然是线程不安全的。看代码逻辑，我们原本想要的是table的”key”为null时，将value放进去，不为null的时候不要放value，所以自始至终我们只想要一对key-value。但是上面代码可能会发生一种情况，就是：线程1来了发现table中key的值是null，想要将value放进去，但是还没等放进去，时间片用完了，CPU将时间片分给了线程2，线程2一看，诶发现table中key的值是null，将value放进去了，这是时间片轮到了线程1，线程1根据上下文切换的标记，继续前面的指令操作，将value放进去了，这时会将线程2放进去的value覆盖。整个流程下来，可以发现出现了线程安全问题。 思考一下：这种每个方法是原子的，但是两个方法组合就不是原子的了。为啥呢？ 因为key是相同的，所以两个原子操作存在依赖关系，因此需要考虑线程安全问题。当下面的原子操作不依赖上面的原子操作的结果的话，就不用考虑两个原子操作合在一起的线程安全问题。 不可变类线程安全性String、Integer 等都是不可变类，因为其内部的状态不可以改变，因此它们的方法都是线程安全的。 Monitor概念更深入的学习synchronized 的底层。 Java对象头以 32 位虚拟机为例 普通对象： 数组对象： 其中的Mark Word的结构为： 64 位虚拟机 Mark Word： 原理之Monitor（重量级锁）Monitor被翻译为监视器 或者管程 每个Java对象都可以关联一个Monitor对象，什么时候会关联呢？就是当我们使用synchronized(obj)尝试给对象上锁的时候，就会将java的对象与OS的Monitor关联。怎么关联的呢？靠一个指针关联，该对象头的Mark Word中就被设置一个指向Monitor对象的指针。 Monitor结构如下：synchronized对象锁（重量级锁）的底层原理 解析： 刚开始的时候Monitor中的Owner为null 当Thread-2执行synchronized(obj)就会将Monitor的所有者Owner置为Thread-2，Monitor中只能有一个Owner。Owner表示谁是这把锁的主人，也就是所有者。 在Thread-2上锁的过程中，如果Thread-1，Thread-3，也来执行synchronized(obj)，就会进入EntryList中BLOCKED状态。 Thread-2执行完同步代码块的内容，然后唤醒EntryList中等待的线程来竞争锁，竞争是非公平的 图中WaitSet中的Thread-0是之前获得过锁，但条件不满足，所以进入到WAITING状态的线程，在后面介绍wait-notify时会分析。 注意： synchronized必须是进入同一个对象的monitor才有上述的效果，不同线程争夺的锁对象必须是同一个对象，并且monitor只能有一个owner 不加synchronized的对象不会关联Monitor监视器，就不会做monitor的检查，也根本不会看对象的mark word，不遵从上述规则。 字节码之synchronized12345678static final Object lock = new Object();static int counter = 0;public static void main(String[] args) { synchronized(lock) { counter++; }} 注意：上面的例子是同步代码块级别的，方法级别的synchronized不会在字节码指令中有所体现。 synchronized原理进阶轻量级锁轻量级锁的使用场景：如果一个对象虽然有多线程要加锁，但加锁的时间是错开的（也就是没有竞争），那么可以使用轻量级锁来优化。 轻量级锁对使用者是透明的，即语法仍然是 synchronized，和正常加锁是一样的，其实，当一个线程中加锁默认先是轻量级锁，当有其它线程来抢同一把锁的时候，轻量级锁会发生锁膨胀，这时轻量级锁才会升级成重量级锁，也就是底层以Monitor来实现的。 案例：假设有两个方法同步块，利用同一个对象加锁 123456789101112static final Object obj = new Object();public static void method1() { synchronized( obj ) { // 同步块 A method2(); }}public static void method2() { synchronized( obj ) { // 同步块 B }} 每次指向到synchronized代码块时，都会创建锁记录（Lock Record）对象，如果线程加了锁，每个线程的栈帧都会包含一个锁记录的结构，锁记录内部可以存储锁定对象的Mark Word和这个锁对象的引用地址reference。 让锁记录中 Object reference 指向锁对象，并尝试用 cas 方式来替换 Object 的 Mark Word，将 Mark Word 的值存入锁记录中。 如果 cas 替换成功，对象头中存储了锁记录地址和状态 00 ，表示由该线程给对象加锁，这时图示如下 如果 cas 失败，有两种情况： 如果是其它线程已经持有了该 Object 的轻量级锁，这时表明有竞争，进入锁膨胀过程 如果是自己执行了 synchronized 锁重入，那么再添加一条 Lock Record 作为重入的计数 当退出 synchronized 代码块（解锁时）如果有取值为 null 的锁记录，表示有重入，这时重置锁记录，表示重入计数减一，就是如下图这样的： 当退出 synchronized 代码块（解锁时）锁记录的值不为 null，这时使用 cas 将 Mark Word 的值恢复给对象头 成功，则解锁成功 失败，说明轻量级锁进行了锁膨胀或已经升级为重量级锁，失败是因为此时锁对象头的位置会指向Monitor，所以进入重量级锁解锁流程 锁膨胀如果线程在尝试加轻量级锁的过程中，CAS 操作无法成功，这时一种情况就是已经有其它线程为此对象加上了轻量级锁（有竞争），这时需要进行锁膨胀，将轻量级锁变为重量级锁。 123456static Object obj = new Object();public static void method1() { synchronized( obj ) { // 同步块 }} 当 Thread-1 进行轻量级加锁时，Thread-0 已经对该对象加了轻量级锁 这时 Thread-1 加轻量级锁失败，进入锁膨胀流程 即为 Object 对象申请 Monitor 锁，让 Object 指向重量级锁地址，Thread-0就是Monitor的Owner 然后Thread-1自己进入 Monitor 的 EntryList BLOCKED 当 Thread-0 退出同步块解锁时，使用 cas 将 Mark Word 的值恢复给对象头，失败。这时会进入重量级解锁流程：即按照 Monitor 地址找到 Monitor 对象，设置 Owner 为 null，唤醒 EntryList 中 BLOCKED 线程。 自旋优化重量级锁竞争的时候，还可以使用自旋来进行优化，就是当线程竞争锁，如果发现锁已经被占用，不会立刻进入到阻塞状态，会先自旋重试，如果当前线程自旋成功（即这时候持锁线程已经退出了同步块，释放了锁），这时当前线程就可以避免阻塞。 自旋会占用 CPU 时间，单核 CPU 自旋就是浪费，多核 CPU 自旋才能发挥优势。 在 Java 6 之后自旋锁是自适应的，比如对象刚刚的一次自旋操作成功过，那么认为这次自旋成功的可能性会高，就多自旋几次；反之，就少自旋甚至不自旋，总之，比较智能。 Java 7 之后不能控制是否开启自旋功能 偏向锁轻量级锁在没有竞争时（就自己这个线程），每次重入锁仍然需要执行 CAS 操作。 Java 6 中引入了偏向锁来做进一步优化：只有第一次使用 CAS 将线程 ID 设置到对象的 Mark Word 头，之后发现这个线程 ID 是自己的就表示没有竞争，不用重新 CAS。以后只要不发生竞争，这个对象就归该线程所有。 例如： 12345678910111213141516171819static final Object obj = new Object();public static void m1() { synchronized( obj ) { // 同步块 A m2(); }}public static void m2() { synchronized( obj ) { // 同步块 B m3(); }}public static void m3() { synchronized( obj ) { // 同步块 C }} 偏向状态： 回忆一下对象头格式 一个对象创建时： 如果开启了偏向锁（默认是开启的），那么对象刚创建之后，markword 值为 0x05 即最后 3 位为 101，并且这时它的Thread，epoch，age都是0，在加锁的时候进行设置这些的值。 偏向锁默认是延迟的，不会在程序启动的时候立刻生效，如果想避免延迟，可以添加虚拟机参数来禁用延迟：-XX:BiasedLockingStartupDelay=0来禁用延迟 注意：处于偏向锁的对象解锁后，线程 id 仍存储于锁对象的对象头中 当偏向锁被禁用：添加 VM 参数-XX:-UseBiasedLocking禁用偏向锁，如果没有开启偏向锁，那么对象创建后，markword 值为 0x01 即最后 3 位为 001，这时它的 hashcode、age 都为 0，第一次用到 hashcode 时才会赋值，也就是说正常状态对象一开始是没有 hashCode 的，第一次调用才生成。 （markdown后三位：正常对象001，偏向锁对象101，轻量级锁对象000，重量级锁对象010） 撤销： 1、撤销 - 调用对象 hashCode 观察上面的对象头表格，偏向锁的对象 MarkWord 中存储的是线程 id，没有hashcode值，因此如果调用 锁对象的hashCode 会导致偏向锁被撤销（禁用这个对象的偏向锁），变成正常对象， 轻量级锁会在锁记录中记录 hashCode。 重量级锁会在 Monitor 中记录 hashCode。 2、撤销 - 其它线程使用对象 当有其它线程使用偏向锁对象时，会将偏向锁升级为轻量级锁。 这里我提一嘴：只有一个线程，就是说我自己用同一对象来回加锁适合使用偏向锁。当多线程时，偏向锁不合适，多线程时就得视情况区分轻量级锁和重量级锁了。轻量级锁的场景：如果一个对象，虽然多个线程都要对它synchronized加锁，但是加锁的时间是错开的，也就是说虽然多个线程对同一对象加锁但是没有竞争的时候使用轻量级锁。当出现多个线程竞争同一把锁的时候，轻量级锁会膨胀升级成重量级锁。 有偏向锁时用偏向锁，有其它线程来用同一个对象上锁时，就撤销偏向锁，变为轻量级锁（此时就禁用偏向锁了），执行完同步代码块轻量级锁释放，锁对象变为正常对象。加轻量级锁有竞争发生时，就会发生锁膨胀，升级为重量级锁。 3、撤销 - 调用 wait/notify 会使对象锁变成重量级锁，因为wait/notify方法只有重量级锁才支持 批量重偏向： 如果对象虽然被多个线程访问，但没有竞争，这时偏向了线程 T1 的对象仍有机会重新偏向 T2，重偏向会重置对象的 Thread ID。 当撤销偏向锁阈值超过 20 次后，jvm 会这样觉得，我是不是偏向错了呢，于是会在给这些对象加锁时重新偏向至新的加锁线程。 批量撤销： 当撤销偏向锁阈值超过 40 次后，jvm 会这样觉得，自己确实偏向错了，根本就不该偏向。于是整个类的所有对象都会变为不可偏向的，新建的对象也是不可偏向的。 wait notifywait notify原理 Owner 线程发现条件不满足，调用 wait 方法，即可进入 WaitSet 变为 WAITING 状态 BLOCKED 和WAITING 的线程都处于阻塞状态，不占用 CPU 时间片 BLOCKED 线程会在 Owner 线程释放锁时唤醒 WAITING 线程会在 Owner 线程调用 notify 或 notifyAll 时唤醒，但唤醒后并不意味者立刻获得锁，仍需进入EntryList 重新竞争 API介绍 obj.wait() 让进入 object 监视器的线程到 waitSet 等待 obj.notify() 在 object 上正在 waitSet 等待的线程中挑一个唤醒 obj.notifyAll() 让 object 上正在 waitSet 等待的线程全部唤醒 它们都是线程之间进行协作通信的手段，都属于 Object 对象的方法。必须获得此对象的锁，才能调用这几个方法。 wait() 方法会释放对象的锁，进入 WaitSet 等待区，从而让其他线程就机会获取对象的锁。无限制等待，直到notify 为止 wait(long n) 有时限的等待, 到 n 毫秒后结束等待，或是被 notify wait notify 的正确姿势sleep(long n) 和 wait(long n) 的区别 sleep 是 Thread 方法，而 wait 是 Object 的方法 sleep 不需要强制和 synchronized 配合使用，但 wait 需要和 synchronized 一起用 sleep 在睡眠时 ，如果在同步代码块中睡眠，虽然不占用CPU时间片，但是不会释放对象锁的 ，其他线程要阻塞等锁被释放再抢锁，如果不在同步代码块里面睡，不占CPU时间片，其他线程就会抢夺时间片去执行。wait必须在synchronized中，并且 wait 在等待的时候会释放对象锁 。 它们状态 TIMED_WAITING 注意： notify 只能随机唤醒一个 WaitSet 中的线程，这时如果有其它线程也在等待，那么就可能唤醒不了正确的线 程，称之为【虚假唤醒】，就是说唤醒了错误的线程，人家等的条件还没达到就给唤醒了。 解决方案：改为 notifyAll，全给唤醒，全唤醒就是肯定对的符合条件线程也被唤醒了。 用 notifyAll 仅解决某个线程的唤醒问题，保证了对的线程被唤醒但是也同样把错的线程唤醒了，但使用 if + wait 判断仅有一次机会，一旦条件不成立，错的线程（也就是没等到条件达成的线程）就没有重新判断的机会了。 解决方法：用 while + wait，当条件不成立，再次 wait。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package com.chan.concurrent.waitnotify;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;@Slf4j(topic = &quot;c.Step1&quot;)public class Step1 { static boolean hasCigarette = false; static boolean hasWaiMai = false; static final Object room = new Object(); public static void main(String[] args) throws InterruptedException { /** * 小南 */ Runnable task1 = () -&gt; { synchronized (room) { log.debug(&quot;有烟没？[{}]&quot;, hasCigarette); while (!hasCigarette) { log.debug(&quot;没烟，先歇会&quot;); try { room.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } log.debug(&quot;有烟没？[{}]&quot;, hasCigarette); log.debug(&quot;可以干活了&quot;); } }; /** * 小女 */ Runnable task2 = () -&gt; { synchronized (room) { log.debug(&quot;有外卖没?[{}]&quot;, hasWaiMai); while (!hasWaiMai){ log.debug(&quot;没外卖,先歇会&quot;); try { room.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } log.debug(&quot;有外卖没?[{}]&quot;, hasWaiMai); log.debug(&quot;可以干活了&quot;); } }; /** * 送烟的 */ Runnable task3 = () -&gt; { synchronized (room) { hasCigarette = true; log.debug(&quot;烟来了&quot;); room.notifyAll(); } }; /** * 送外卖的 */ Runnable task4 = () -&gt; { synchronized (room) { hasWaiMai = true; log.debug(&quot;外卖来了&quot;); room.notifyAll(); } }; new Thread(task1, &quot;小南&quot;).start(); new Thread(task2, &quot;小女&quot;).start(); TimeUnit.SECONDS.sleep(1); new Thread(task3, &quot;送烟的&quot;).start(); TimeUnit.SECONDS.sleep(2); new Thread(task4, &quot;送外卖的&quot;).start(); }} 输出： 123456789101121:28:20 [小南] c.Step1 - 有烟没？[false]21:28:20 [小南] c.Step1 - 没烟，先歇会21:28:20 [小女] c.Step1 - 有外卖没?[false]21:28:20 [小女] c.Step1 - 没外卖,先歇会21:28:21 [送烟的] c.Step1 - 烟来了21:28:21 [小女] c.Step1 - 没外卖,先歇会21:28:21 [小南] c.Step1 - 有烟没？[true]21:28:21 [小南] c.Step1 - 可以干活了21:28:23 [送外卖的] c.Step1 - 外卖来了21:28:23 [小女] c.Step1 - 有外卖没?[true]21:28:23 [小女] c.Step1 - 可以干活了 固定套路： 1234567891011synchronized(lock) { while(条件不成立) { lock.wait(); } // 干活}// 另一个线程synchronized(lock) { // 让条件成立 lock.notifyAll();} 设计模式的同步模式之保护性暂停即 Guarded Suspension，用在一个线程等待另一个线程的执行结果。 要点： 有一个结果需要从一个线程传递到另一个线程，让他们关联同一个 GuardedObject 如果有结果不断从一个线程到另一个线程那么可以使用消息队列（见生产者/消费者） JDK 中，join 的实现、Future 的实现，采用的就是此模式 因为要等待另一方的结果，因此归类到同步模式 实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697package com.chan.concurrent.guardedSuspension;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStream;import java.io.InputStreamReader;import java.net.HttpURLConnection;import java.net.URL;import java.nio.charset.StandardCharsets;import java.util.ArrayList;import java.util.List;public class Downloader { public static List&lt;String&gt; download() throws IOException { HttpURLConnection connection = (HttpURLConnection) new URL(&quot;https://www.baidu.com&quot;).openConnection(); List&lt;String&gt; lines = new ArrayList&lt;&gt;(); InputStream in = connection.getInputStream(); try (BufferedReader reader = new BufferedReader(new InputStreamReader(in, StandardCharsets.UTF_8))) { String line; while ((line = reader.readLine()) != null){ lines.add(line); } } return lines; }}package com.chan.concurrent.guardedSuspension;public class GuardedObject { private Object response; private final Object lock = new Object(); /** * 产生结果 */ public void complete(Object response) { synchronized (lock) { this.response = response; lock.notifyAll(); } } public Object get() { synchronized (lock) { while (response == null){ try { lock.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } return response; } }}package com.chan.concurrent.guardedSuspension;import lombok.extern.slf4j.Slf4j;import java.io.IOException;import java.util.List;@Slf4j(topic = &quot;c.Test&quot;)public class Test { // 线程1等待线程2的下载结果 public static void main(String[] args) { GuardedObject guardedObject = new GuardedObject(); Runnable task1 = new Runnable() { @Override public void run() { log.debug(&quot;等待结果&quot;); List&lt;String&gt; list = (List&lt;String&gt;) guardedObject.get(); log.debug(&quot;结果的大小:{}&quot;, list); } }; Runnable task2 = new Runnable() { @Override public void run() { try { log.debug(&quot;执行下载&quot;); List&lt;String&gt; list = Downloader.download(); guardedObject.complete(list); } catch (IOException e) { e.printStackTrace(); } } }; new Thread(task1, &quot;t1&quot;).start(); new Thread(task2, &quot;t2&quot;).start(); }} 功能增强：增加等待超时机制。 分为三种情况： 要么在等时范围内，这个线程被其他线程唤醒（等待的条件达成，不符合while条件了，不进入下次循环不用再wait了，在循环外直接进行唤醒之后要做的事）； 要么在等时范围内，这个线程被其他线程唤醒（等待的条件未达成【虚假唤醒】，符合while条件，进入下次循环，继续wait）； 要么超时还未被唤醒，到时间自己唤醒，然后判断不满足等待的条件，进到下次循环之后，判断没时间了直接break跳出循环。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package com.chan.concurrent.guardedSuspension;public class GuardedObject { private Object response; private final Object lock = new Object(); /** * 产生结果 */ public void complete(Object response) { synchronized (lock) { this.response = response; lock.notifyAll(); } } public Object get(long timeout) { synchronized (lock) { // 开始时间 long begin = System.currentTimeMillis(); // 经历的时间 long passed = 0; while (response == null){ // 这一轮循环剩余的可以等待的时间 long waitTime = timeout - passed; // 如果经历的时间超过了最大等待时间就退出循环 if (waitTime &lt;= 0) { break; } try { lock.wait(waitTime); } catch (InterruptedException e) { e.printStackTrace(); } // 求得经历时间 passed = System.currentTimeMillis() - begin; } return response; } }}package com.chan.concurrent.guardedSuspension;import lombok.extern.slf4j.Slf4j;import java.io.IOException;import java.util.List;@Slf4j(topic = &quot;c.Test&quot;)public class Test { // 线程1等待线程2的下载结果 public static void main(String[] args) { GuardedObject guardedObject = new GuardedObject(); Runnable task1 = new Runnable() { @Override public void run() { log.debug(&quot;等待结果&quot;); List&lt;String&gt; list = (List&lt;String&gt;) guardedObject.get(3000); log.debug(&quot;结果的大小:{}&quot;, list); } }; Runnable task2 = new Runnable() { @Override public void run() { try { log.debug(&quot;执行下载&quot;); List&lt;String&gt; list = Downloader.download(); guardedObject.complete(list); } catch (IOException e) { e.printStackTrace(); } } }; new Thread(task1, &quot;t1&quot;).start(); new Thread(task2, &quot;t2&quot;).start(); }} 多任务版 GuardedObject上一个例子是单任务版的GuardedObject案例，一个下载任务，结果（本案例就是下载的资源）提取到GuardedObject，两个线程一个设置结果，一个获得结果，一个线程等另一个线程完善的结果，这种就是同步模式之保护性暂停。 案例： 图中 Futures 就好比居民楼一层的蜂巢（GO对象就是蜂巢的每个快递箱，response就是快递，id用来标识Guarded Object），左侧的 t0，t2，t4 就好比等待快递的居民，右侧的 t1，t3，t5 就好比快递小哥。 在这个多版本的案例中，“结果”是多个，就是每对儿快递员和居民都有一个“结果”就是快递包裹，这样如果需要在多个类之间使用 GuardedObject 对象，作为参数传递不是很方便，因此设计一个用来解耦的中间类，这样不仅能够解耦【结果等待者】和【结果生产者】，还能够同时支持多个任务的管理。 代码： 新增 id 用来标识 Guarded Object 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package com.chan.concurrent.guardedSuspensionManyTask;public class GuardedObject { //结果 private Object response; //编号 标识guardedObject private Integer id; public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } /** * 获取结果,居民取快递 * @param timeout 时间 * @return 结果(快递) */ public Object getFastMail (long timeout){ synchronized (this) { //开始时间 long beginTime = System.currentTimeMillis(); //过去的时间 long passedTime = 0; while (response == null) { if (passedTime &gt;= timeout) { break; } try { //没有结果,等待 this.wait(timeout - passedTime); } catch (InterruptedException e) { e.printStackTrace(); } passedTime = System.currentTimeMillis() - beginTime; } return response; } } /** * 设置结果,快递员将快递按编号放入蜂巢的某个快递箱 * @param response 结果(快递) */ public void setFastMail (Object response){ synchronized (this) { //设置结果 this.response = response; //唤醒 this.notifyAll(); } }} 中间解耦类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.chan.concurrent.guardedSuspensionManyTask;import java.util.Map;import java.util.Set;import java.util.concurrent.ConcurrentHashMap;/** * 快递柜(蜂巢) 中间解耦类 */public class FastMailBox { //编号 标识guardedObject private static int id = 1; //蜂巢的多个快递箱 private static final Map&lt;Integer, GuardedObject&gt; boxes = new ConcurrentHashMap&lt;&gt;(); /** * 产生唯一id * @return 编号 */ public static synchronized int generateId() { return id++; } /** * 创建快递,放入快递柜,返回快递 * * @return GuardedObject */ public static GuardedObject createGuardedObject() { GuardedObject guardedObject = new GuardedObject(); guardedObject.setId(generateId()); boxes.put(guardedObject.getId(), guardedObject); return guardedObject; } /** * 得到所有编号 * * @return 编号集合 */ public static Set&lt;Integer&gt; getIds() { return boxes.keySet(); } /** * 快递员揽件,揽件之后删除,因为都是静态的,属于类的,不删除的话,会伴随类一直不会被回收会占用内存 * * @return GuardedObject */ public static GuardedObject getGuardedObject(int id) { return boxes.remove(id); }} 业务相关类 123456789101112131415161718192021222324252627282930313233343536373839package com.chan.concurrent.guardedSuspensionManyTask;import lombok.extern.slf4j.Slf4j;@Slf4j(topic = &quot;c.People&quot;)public class People implements Runnable { @Override public void run() { //买快递 GuardedObject guardedObject = FastMailBox.createGuardedObject(); log.debug(&quot;准备取快递,快递编号id: {}&quot;, guardedObject.getId()); Object fastMail = guardedObject.getFastMail(5000); log.debug(&quot;收到快递啦,快速编号id: {}, 快递: {}&quot;, guardedObject.getId(), fastMail); }}package com.chan.concurrent.guardedSuspensionManyTask;import lombok.extern.slf4j.Slf4j;@Slf4j(topic = &quot;c.Postman&quot;)public class Postman implements Runnable { //送快递的一定知道快递和编号 private final int id; private final String fastMail; public Postman(int id, String fastMail) { this.id = id; this.fastMail = fastMail; } @Override public void run() { GuardedObject guardedObject = FastMailBox.getGuardedObject(id); log.debug(&quot;送快递 快递编号id: {}, 快递: {}&quot;, id, fastMail); guardedObject.setFastMail(fastMail); }} 测试 12345678910111213141516package com.chan.concurrent.guardedSuspensionManyTask;import java.util.concurrent.TimeUnit;public class Test { public static void main(String[] args) throws InterruptedException { for (int i = 0; i &lt; 3; i++) { new Thread(new People(), &quot;居民&quot; + i).start(); } TimeUnit.SECONDS.sleep(2); for (Integer id : FastMailBox.getIds()) { new Thread(new Postman(id, &quot;快递&quot; + id), &quot;快递员&quot; + id).start(); } }} 某次运行结果 12345678922:32:51 [居民2] c.People - 准备取快递,快递编号id: 322:32:51 [居民0] c.People - 准备取快递,快递编号id: 122:32:51 [居民1] c.People - 准备取快递,快递编号id: 222:32:53 [快递员1] c.Postman - 送快递 快递编号id: 1, 快递: 快递122:32:53 [快递员2] c.Postman - 送快递 快递编号id: 2, 快递: 快递222:32:53 [居民0] c.People - 收到快递啦,快速编号id: 1, 快递: 快递122:32:53 [居民1] c.People - 收到快递啦,快速编号id: 2, 快递: 快递222:32:53 [快递员3] c.Postman - 送快递 快递编号id: 3, 快递: 快递322:32:53 [居民2] c.People - 收到快递啦,快速编号id: 3, 快递: 快递3 设计模式之生产者消费者定义： 与前面的保护性暂停中的 GuardObject 不同，不需要产生结果和消费结果的线程一一对应 消费队列可以用来平衡生产和消费的线程资源 生产者仅负责产生结果数据，不关心数据该如何处理，而消费者专心处理结果数据 消息队列是有容量限制的，满时不会再加入数据，空时不会再消耗数据 JDK 中各种阻塞队列，采用的就是这种模式 我们使用的消息中间件MQ什么的，也是消费者生产者模式的思想是一致的。但是MQ属于进程间通信，这块是线程间通信。 实现案例： 消息： 注：想要类中的属性不可变，只提供相应的构造函数和get方法即可，保险点属性再加上final和private。 1234567891011121314151617181920212223package com.chan.concurrent.producercustomer;public class Message { //由于涉及到并发,因此都是不可变属性,使用private,final修饰,不提供set方法 //只在构造里面提供设置属性的功能,对象一旦创建内容就不可再改变 private final int id; private final Object message; public Message(int id, Object message) { this.id = id; this.message = message; } public int getId() { return id; } public Object getMessage() { return message; }} 消息队列： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package com.chan.concurrent.producercustomer;import lombok.extern.slf4j.Slf4j;import java.util.LinkedList;@Slf4j(topic = &quot;c.MessageQueue&quot;)public class MessageQueue { //消息队列,消息先进先出,使用双向链表作为容器 private final LinkedList&lt;Message&gt; queue; //消息队列容量 private final int capacity; /** * 构造函数,将消息队列的大小设置成活的,有调用者指定消息队列的大小 * 创建对象时再初始化queue,在构造函数中初始化等价于在成员位置new * @param capacity 消息队列容量 */ public MessageQueue(int capacity) { this.capacity = capacity; queue = new LinkedList&lt;&gt;(); } /** * 在消息队列中取 消息 * @return 消息对象 */ public Object getMessage() { synchronized (queue) { while (queue.isEmpty()) { try { log.debug(&quot;消息队列为空...wait, plz...&quot;); queue.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } //遵循先进先出,从头拿,返回,被消费之后消息就删了 Message message = queue.removeFirst(); //唤醒,消息队列又有剩余空间了 queue.notifyAll(); return message; } } /** * 向消息队列中放 消息 * @param message 消息对象 */ public void putMessage(Message message) { synchronized (queue) { while (queue.size() == capacity) { try { log.debug(&quot;消息队列容量已达上限: {} wait, plz...&quot;, capacity); queue.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } //后进后出,加在尾部 queue.addLast(message); //唤醒,消息队列又有新消息了 queue.notifyAll(); } }} 测试： 123456789101112131415161718192021222324252627282930313233343536373839package com.chan.concurrent.producercustomer;import lombok.extern.slf4j.Slf4j;import java.io.IOException;import java.util.List;@Slf4j(topic = &quot;c.Test&quot;)public class Test { public static void main(String[] args) { MessageQueue messageQueue = new MessageQueue(3); //4 个生产者线程, 下载任务,下载之后放入队列 for (int i = 0; i &lt; 4; i++) { int id = i; new Thread(() -&gt; { try { log.debug(&quot;download...&quot;); List&lt;String&gt; download = Downloader.download(); Message message = new Message(id, download); log.debug(&quot;try putting message {}&quot;, id); messageQueue.putMessage(message); } catch (IOException e) { e.printStackTrace(); } }, &quot;生产者&quot; + i).start(); } // 1 个消费者线程, 处理结果 new Thread(() -&gt; { while (true) { Message message = (Message) messageQueue.getMessage(); List&lt;String&gt; response = (List&lt;String&gt;) message.getMessage(); log.debug(&quot;get message id({}): 一共[{}]lines&quot;, message.getId(), response.size()); } }, &quot;消费者&quot;).start(); }} 下载工具类： 123456789101112131415161718192021222324252627package com.chan.concurrent.producercustomer;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStream;import java.io.InputStreamReader;import java.net.HttpURLConnection;import java.net.URL;import java.nio.charset.StandardCharsets;import java.util.ArrayList;import java.util.List;public class Downloader { public static List&lt;String&gt; download() throws IOException { HttpURLConnection connection = (HttpURLConnection) new URL(&quot;https://www.baidu.com&quot;).openConnection(); List&lt;String&gt; lines = new ArrayList&lt;&gt;(); InputStream in = connection.getInputStream(); try (BufferedReader reader = new BufferedReader(new InputStreamReader(in, StandardCharsets.UTF_8))) { String line; while ((line = reader.readLine()) != null){ lines.add(line); } } return lines; }} 结果： 123456789101112131418:22:01 [生产者2] c.Test - download...18:22:01 [消费者] c.MessageQueue - 消息队列为空...wait, plz...18:22:01 [生产者0] c.Test - download...18:22:01 [生产者3] c.Test - download...18:22:01 [生产者1] c.Test - download...18:22:03 [生产者0] c.Test - try putting message 018:22:03 [生产者1] c.Test - try putting message 118:22:03 [消费者] c.Test - get message id(0): 一共[3]lines18:22:03 [生产者2] c.Test - try putting message 218:22:03 [生产者3] c.Test - try putting message 318:22:03 [消费者] c.Test - get message id(1): 一共[3]lines18:22:03 [消费者] c.Test - get message id(2): 一共[3]lines18:22:03 [消费者] c.Test - get message id(3): 一共[3]lines18:22:03 [消费者] c.MessageQueue - 消息队列为空...wait, plz... Park &amp; Unpark基本使用它们是LockSupport类中的方法 12345// 暂停当前线程LockSupport.park();// 恢复某个线程的运行LockSupport.unpark(暂停的线程对象); 先park再unpark 123456789101112Thread t1 = new Thread(() -&gt; { log.debug(&quot;start...&quot;); sleep(1); log.debug(&quot;park...&quot;); LockSupport.park();//暂停 log.debug(&quot;resume...&quot;);},&quot;t1&quot;);t1.start();sleep(2);log.debug(&quot;unpark...&quot;);LockSupport.unpark(t1);//在main线程中唤醒暂停的t1 输出: 123418:42:52.585 c.TestParkUnpark [t1] - start...18:42:53.589 c.TestParkUnpark [t1] - park...18:42:54.583 c.TestParkUnpark [main] - unpark...18:42:54.583 c.TestParkUnpark [t1] - resume... 先 unpark 再 park 123456789101112Thread t1 = new Thread(() -&gt; { log.debug(&quot;start...&quot;); sleep(2); log.debug(&quot;park...&quot;); LockSupport.park(); log.debug(&quot;resume...&quot;);}, &quot;t1&quot;);t1.start();sleep(1);log.debug(&quot;unpark...&quot;);LockSupport.unpark(t1); 输出: 123418:43:50.765 c.TestParkUnpark [t1] - start...18:43:51.764 c.TestParkUnpark [main] - unpark...18:43:52.769 c.TestParkUnpark [t1] - park...18:43:52.769 c.TestParkUnpark [t1] - resume... 特点与 Object 的 wait &amp; notify 相比 wait，notify 和 notifyAll 必须配合 Object Monitor (重量级锁) 一起使用，而 park，unpark 不必 park &amp; unpark 是以线程为单位来【阻塞】和【唤醒】线程，而 notify 只能随机唤醒一个等待线程，notifyAll是唤醒所有等待线程，就不那么【精确】 park &amp; unpark 可以先 unpark，而 wait &amp; notify 不能先 notify unpark既可以在park之前用也可以在park之后用, 都可以将对应的park线程unpark. 重新深入理解线程状态转换 假设有线程Thread t： 情况1 NEW—&gt;RUNNABLE 当调用 t.start() 方法时，由 NEW –&gt; RUNNABLE, 这个时候不一定就直接RUNNING了, 有可能先READY状态, 主要取决于CPU的时间片, 抢占式调度. 图中的可运行状态就是READY. READY和RUNNING和OS层面的BLOCKED都属于RUNNABLE. 情况2 RUNNABLE &lt;–&gt; WAITINGt 线程用 synchronized(obj) 获取了对象锁后 调用 obj.wait() 方法时，t 线程从 RUNNABLE –&gt; WAITING 调用 obj.notify() ， obj.notifyAll() ， t.interrupt() 时: 竞争锁成功，t 线程从 WAITING –&gt; RUNNABLE 竞争锁失败，t 线程从 WAITING –&gt; BLOCKED 123456789101112131415161718192021222324252627282930313233public class TestWaitNotify { final static Object obj = new Object(); public static void main(String[] args) { new Thread(() -&gt; { synchronized (obj) { log.debug(&quot;执行....&quot;); try { obj.wait(); } catch (InterruptedException e) { e.printStackTrace(); } log.debug(&quot;其它代码....&quot;); // 断点 } },&quot;t1&quot;).start(); new Thread(() -&gt; { synchronized (obj) { log.debug(&quot;执行....&quot;); try { obj.wait(); } catch (InterruptedException e) { e.printStackTrace(); } log.debug(&quot;其它代码....&quot;); // 断点 } },&quot;t2&quot;).start(); sleep(0.5); log.debug(&quot;唤醒 obj 上其它线程&quot;); synchronized (obj) { obj.notifyAll(); // 唤醒obj上所有等待线程断点 } }} 情况3 RUNNABLE &lt;–&gt; WAITING 当前线程 调用 t.join() 方法时，当前线程从 RUNNABLE –&gt; WAITING 注意是当前线程 在t 线程对象 的监视器上等待 t 线程 运行结束，或调用了当前线程 的 interrupt() 时，当前线程 从 WAITING –&gt; RUNNABLE 情况4 RUNNABLE &lt;–&gt; WAITING 当前线程调用 LockSupport.park() 方法会让当前线程从 RUNNABLE –&gt; WAITING 调用 LockSupport.unpark(目标线程) 或调用了线程 的 interrupt() ，会让目标线程从 WAITING –&gt;RUNNABLE, 直接回到RUNNABLE状态, 不用像wait()那样重新竞争锁. 情况5 RUNNABLE &lt;–&gt; TIMED_WAITINGt 线程用 synchronized(obj) 获取了对象锁后 调用 obj.wait(long n) 方法时，t 线程从 RUNNABLE –&gt; TIMED_WAITING t 线程等待时间超过了 n 毫秒，或调用 obj.notify() ， obj.notifyAll() ， t.interrupt() 时 竞争锁成功，t 线程从 TIMED_WAITING –&gt; RUNNABLE 竞争锁失败，t 线程从 TIMED_WAITING –&gt; BLOCKED 情况6 RUNNABLE &lt;–&gt; TIMED_WAITING 当前线程 调用 t.join(long n) 方法时，当前线程 从 RUNNABLE –&gt; TIMED_WAITING 注意是当前线程 在t 线程对象 的监视器上等待 当前线程 等待时间超过了 n 毫秒，或t 线程 运行结束，或调用了当前线程 的 interrupt() 时，当前线程 从TIMED_WAITING –&gt; RUNNABLE 情况7 RUNNABLE &lt;–&gt; TIMED_WAITING 当前线程调用 Thread.sleep(long n) ，当前线程从 RUNNABLE –&gt; TIMED_WAITING 当前线程等待时间超过了 n 毫秒，当前线程从 TIMED_WAITING –&gt; RUNNABLE, 这里是直接回到RUNNABLE状态, 不用像wait()那样重新竞争锁. 情况8 RUNNABLE &lt;–&gt; TIMED_WAITING 当前线程调用 LockSupport.parkNanos(long nanos) 或 LockSupport.parkUntil(long millis) 时，当前线程从 RUNNABLE –&gt; TIMED_WAITING 调用 LockSupport.unpark(目标线程) 或调用了线程 的 interrupt() ，或是等待超时，会让目标线程从TIMED_WAITING–&gt; RUNNABLE, 这里是直接回到RUNNABLE状态, 不用像wait()那样重新竞争锁. 情况9 RUNNABLE &lt;–&gt; BLOCKED t 线程用 synchronized(obj) 获取了对象锁时如果竞争失败，从 RUNNABLE –&gt; BLOCKED 持 obj 锁线程的同步代码块执行完毕，会唤醒该对象上所有 BLOCKED 的线程重新竞争，如果其中 t 线程竞争成功，从 BLOCKED –&gt; RUNNABLE ，其它失败的线程仍然 BLOCKED 情况10 RUNNABLE &lt;–&gt; TERMINATED当前线程所有代码运行完毕，进入 TERMINATED 多把锁我们知道，当多个线程操作共享资源的时候，为了防止线程同步问题，我们使用一把锁来保证不会发生线程安全问题。 当业务资源无相关的时候，也就是说互不相干，这个时候，我们就会使用两把锁了，因为这样可以细分锁粒度，增加并发度。 但是如果一个线程需要同时获得多把锁的时候，这个时候就容易发生死锁。 将锁的粒度细分： 好处，是可以增强并发度 坏处，如果一个线程需要同时获得多把锁，就容易发生死锁 定位死锁使用jstack工具，JDK自带的工具。 https://www.cnblogs.com/chenpi/p/5377445.html 12chanservy@ChanServy:~/idea/projects/concurrent$ jps #列出每个线程idchanservy@ChanServy:~/idea/projects/concurrent$ jstack 17256 #查看对应的 活跃性死锁死锁是由于2个线程互相持有对方想要的锁，导致谁都无法继续向下运行，2个线程都阻塞住了，2个线程都结束不了。 一个线程需要同时获取多把锁，这时就容易发生死锁。 t1 线程获得 A 对象锁，接下来想获取 B 对象的锁，t2 线程获得 B 对象锁，接下来想获取 A对象的锁，例： 123456789101112131415161718192021222324252627public static void main(String[] args) { Object A = new Object(); Object B = new Object(); Thread t1 = new Thread(() -&gt; { synchronized (A) { log.debug(&quot;lock A&quot;); sleep(1); synchronized (B) { log.debug(&quot;lock B&quot;); log.debug(&quot;操作...&quot;); } } }, &quot;t1&quot;); Thread t2 = new Thread(() -&gt; { synchronized (B) { log.debug(&quot;lock B&quot;); sleep(0.5); synchronized (A) { log.debug(&quot;lock A&quot;); log.debug(&quot;操作...&quot;); } } }, &quot;t2&quot;); t1.start(); t2.start();} 结果: 1212:22:06.962 [t2] c.TestDeadLock - lock B12:22:06.962 [t1] c.TestDeadLock - lock A 避免死锁要注意加锁顺序 另外如果由于某个线程进入了死循环，导致其它线程一直等待，对于这种情况 linux 下可以通过 top 先定位到CPU 占用高的 Java 进程，再利用 top -Hp 进程id 来定位是哪个线程，最后再用 jstack 排查。 上面的案例中，两个线程的加锁顺序不同，线程t1先获得A锁再嵌套获得B锁，线程t2反之，这样造成了死锁问题。 解决方案：2个线程用相同的顺序加锁，这样就可以避免死锁问题，顺序加锁的解决方案： 但是又可能迎来了新的问题：饥饿 饥饿饥饿：没有死锁，大家都没有相互占有对应所需的资源，但是有的线程得到锁的机会太少了，都被其它线程抢去了，导致它得不到执行，从而饥饿。 活锁活锁：2个线程无阻塞，都在使用CPU不断的向下运行，但是由于改变了对方的结束条件，导致2个线程都结束不了。这种现象就是活锁。 解决方案：让2个线程的执行时间有一定的交错，在线程执行任务时增加随机的睡眠时间。 哲学家就餐问题 有五位哲学家，围坐在圆桌旁。 他们只做两件事，思考和吃饭，思考一会吃口饭，吃完饭后接着思考。 吃饭时要用两根筷子吃，桌上共有 5 根筷子，每位哲学家左右手边各有一根筷子。 如果筷子被身边的人拿着，自己就得等待 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// 筷子类class Chopstick { String name; public Chopstick(String name) { this.name = name; } @Override public String toString() { return &quot;筷子{&quot; + name + '}'; }}//哲学家类class Philosopher extends Thread { Chopstick left; Chopstick right; public Philosopher(String name, Chopstick left, Chopstick right) { super(name); this.left = left; this.right = right; } private void eat() { log.debug(&quot;eating...&quot;); Sleeper.sleep(1); } @Override public void run() { while (true) { // 获得左手筷子 synchronized (left) { // 获得右手筷子 synchronized (right) { // 吃饭 eat(); } // 放下右手筷子 } // 放下左手筷子 } }}public class Test { public static void main(){ Chopstick c1 = new Chopstick(&quot;1&quot;); Chopstick c2 = new Chopstick(&quot;2&quot;); Chopstick c3 = new Chopstick(&quot;3&quot;); Chopstick c4 = new Chopstick(&quot;4&quot;); Chopstick c5 = new Chopstick(&quot;5&quot;); new Philosopher(&quot;苏格拉底&quot;, c1, c2).start(); new Philosopher(&quot;柏拉图&quot;, c2, c3).start(); new Philosopher(&quot;亚里士多德&quot;, c3, c4).start(); new Philosopher(&quot;赫拉克利特&quot;, c4, c5).start(); new Philosopher(&quot;阿基米德&quot;, c5, c1).start(); }} ReentrantLock前面线程活跃性提到的：死锁；饥饿；活锁，其中除了活锁用2个线程的执行时间交错开来解决之外，其它的现象都可以使用ReentrantLock来解决。 ReentrantLock：可重入锁，JUC下面的类。 相对于 synchronized 它具备如下特点： 可中断：尝试获得锁，可被打断。防死锁，被动。 可以设置超时时间：规定时间内如果获取不到锁，那我就放弃争抢锁了。防死锁，主动。 可以设置为公平锁：不会像之前那样不按顺序争抢锁了，而是先到先得。防饥饿。（ReentrantLock 默认是不公平的） 支持多个条件变量：比如可以有多个WaitSet，“不同种类的等待室”，可细分。 与 synchronized 一样，都支持可重入 基本语法： 12345678910111213141516171819// 获取锁reentrantLock.lock();//放在try里面也行 没区别try { // 临界区} finally { // 释放锁 reentrantLock.unlock();}/************************************************************************************重要*///1Object obj = new Object();//obj就是锁对象, 真正的锁是这个锁对象关联的Monitorsynchronized(obj) { //同步代码}//2ReentrantLock lock = new ReentrantLock();// lock就是锁对象, 这个对象取代了之前的 obj+Monitor 了lock.lock(); 可重入可重入是指同一个线程如果首次获得了这把锁，那么因为它是这把锁的拥有者，因此有权利再次获取这把锁。 如果是不可重入锁，那么第二次获得锁时，自己也会被锁挡住。 123456789101112131415161718192021222324252627282930313233static ReentrantLock lock = new ReentrantLock(); public static void main(String[] args) { method1(); } public static void method1() { lock.lock(); try { log.debug(&quot;execute method1&quot;); method2(); } finally { lock.unlock(); } } public static void method2() { lock.lock(); try { log.debug(&quot;execute method2&quot;); method3(); } finally { lock.unlock(); } } public static void method3() { lock.lock(); try { log.debug(&quot;execute method3&quot;); } finally { lock.unlock(); } }17:59:11.862 [main] c.TestReentrant - execute method117:59:11.865 [main] c.TestReentrant - execute method217:59:11.865 [main] c.TestReentrant - execute method3 可打断解释：一个线程在等待锁的过程中，其它线程可用interrupt() 方法终止它的等待，（尝试获得锁，可被打断） 实现：synchronized和lock()都不可被打断，但是使用一个方法实现：lockInterruptibly()方法。 如果没竞争，那么lockInterruptibly()此方法就会获取lock对象锁。 如果有竞争，进入了阻塞队列的话，可被其它线程使用interrupt打断，就不要继续等待锁了，不用死等，有效避免了死锁的发生，但是这种方式是被动的，因为是靠其它线程打断的。另外，如果被打断，没获取到锁，那就不会继续向下运行了。lockInterruptibly()方法会要求捕获一个异常，在catch中直接return。 实例: 12345678910111213141516171819202122232425262728293031323334353637383940 ReentrantLock lock = new ReentrantLock(); Thread t1 = new Thread(() -&gt; { log.debug(&quot;启动...&quot;); try { lock.lockInterruptibly(); } catch (InterruptedException e) { e.printStackTrace(); log.debug(&quot;等锁的过程中被打断&quot;); return; } try { log.debug(&quot;获得了锁&quot;); } finally { lock.unlock(); } }, &quot;t1&quot;); lock.lock(); log.debug(&quot;获得了锁&quot;); t1.start(); try { sleep(1); t1.interrupt(); log.debug(&quot;执行打断&quot;); } finally { lock.unlock(); } //输出18:02:40.520 [main] c.TestInterrupt - 获得了锁18:02:40.524 [t1] c.TestInterrupt - 启动...18:02:41.530 [main] c.TestInterrupt - 执行打断java.lang.InterruptedExceptionatjava.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireInterruptibly(AbstractQueuedSynchronizer.java:898)atjava.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1222)at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:335)at cn.itcast.n4.reentrant.TestInterrupt.lambda$main$0(TestInterrupt.java:17)at java.lang.Thread.run(Thread.java:748)18:02:41.532 [t1] c.TestInterrupt - 等锁的过程中被打断 注意如果是不可中断模式，那么即使使用了 interrupt 也不会让等待中断。 123456789101112131415161718192021222324252627 ReentrantLock lock = new ReentrantLock(); Thread t1 = new Thread(() -&gt; { log.debug(&quot;启动...&quot;); lock.lock(); try { log.debug(&quot;获得了锁&quot;); } finally { lock.unlock(); } }, &quot;t1&quot;); lock.lock(); log.debug(&quot;获得了锁&quot;); t1.start(); try { sleep(1); t1.interrupt(); log.debug(&quot;执行打断&quot;); } finally { lock.unlock(); } //输出18:06:56.261 [main] c.TestInterrupt - 获得了锁18:06:56.265 [t1] c.TestInterrupt - 启动...18:06:57.266 [main] c.TestInterrupt - 执行打断 // 这时 t1 并没有被真正打断, 而是仍继续等待锁18:06:58.267 [main] c.TestInterrupt - 释放了锁18:06:58.267 [t1] c.TestInterrupt - 获得了锁 锁超时尝试去获取锁时，等待的超时时间，防止一直等待的情况，避免死锁。这个方式是主动的，因为是自己设置的超时时间，在设定的时间内拿到锁那就继续执行，到了设定时间依然没拿到锁的话直接放弃获取锁，不会无限等待。 boolean tryLock() 返回布尔值；空参数：立刻返回结果，不会等待。 true：代表获取到了锁，就是已经获取到了lock锁对象，并且返回true false：获取不到锁。不再向下运行，直接return。 123456789101112131415161718192021222324252627 ReentrantLock lock = new ReentrantLock(); Thread t1 = new Thread(() -&gt; { log.debug(&quot;启动...&quot;); if (!lock.tryLock()) { log.debug(&quot;获取立刻失败，返回&quot;); return; } try { log.debug(&quot;获得了锁&quot;); } finally { lock.unlock(); } }, &quot;t1&quot;); lock.lock(); log.debug(&quot;获得了锁&quot;); t1.start(); try { sleep(2); } finally { lock.unlock(); }//输出18:15:02.918 [main] c.TestTimeout - 获得了锁18:15:02.921 [t1] c.TestTimeout - 启动...18:15:02.921 [t1] c.TestTimeout - 获取立刻失败，返回 boolean tryLock(long timeout, TimeUnit unit) 返回布尔值；有参数：在设定的时间内拿到锁返回true继续执行，到了设定时间依然没拿到锁返回false放弃获取锁。 true：代表在设定时间内获取到了锁，就是已经获取到了lock锁对象，并且返回true false：设定时间内获取不到锁。（主动打断）不再向下运行，直接return。在if逻辑中return一次，在捕获打断异常的catch中再return一次。 12345678910111213141516171819202122232425262728293031 ReentrantLock lock = new ReentrantLock(); Thread t1 = new Thread(() -&gt; { log.debug(&quot;启动...&quot;); try { if (!lock.tryLock(1, TimeUnit.SECONDS)) { log.debug(&quot;获取等待 1s 后失败，返回&quot;); return; } } catch (InterruptedException e) { e.printStackTrace(); return; } try { log.debug(&quot;获得了锁&quot;); } finally { lock.unlock(); } }, &quot;t1&quot;); lock.lock(); log.debug(&quot;获得了锁&quot;); t1.start(); try { sleep(2); } finally { lock.unlock(); }// 输出18:19:40.537 [main] c.TestTimeout - 获得了锁18:19:40.544 [t1] c.TestTimeout - 启动...18:19:41.547 [t1] c.TestTimeout - 获取等待 1s 后失败，返回 所以由于synchronized的嵌套并且锁对象不同时，容易产生的死锁问题，可通过ReentrantLock来解决。 使用 tryLock 解决哲学家就餐问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Chopstick extends ReentrantLock { String name; public Chopstick(String name) { this.name = name; } @Override public String toString() { return &quot;筷子{&quot; + name + '}'; }}class Philosopher extends Thread { Chopstick left; Chopstick right; public Philosopher(String name, Chopstick left, Chopstick right) { super(name); this.left = left; this.right = right; } @Override public void run() { while (true) { // 尝试获得左手筷子 if (left.tryLock()) { try { // 尝试获得右手筷子 if (right.tryLock()) { try { eat(); } finally { right.unlock(); } } } finally { left.unlock(); } } } } private void eat() { log.debug(&quot;eating...&quot;); Sleeper.sleep(1); }} 公平锁ReentrantLock默认是不公平的，synchronized也是不公平的，都是抢占的获取锁，不按照先来后到的。 在ReentrantLock中可以设置为公平的，先到先得，获取锁。 改为公平锁： 1ReentrantLock lock = new ReentrantLock(true); 公平锁的本意是解决饥饿问题, 但是没必要, 公平锁一般不用设置，会降低并发度, 影响性能. 条件变量synchronized 中也有条件变量，就是我们讲原理时那个 waitSet 休息室，当条件不满足时进入 waitSet 等待。 ReentrantLock 的条件变量比 synchronized 强大之处在于，它是支持多个条件变量的，这就好比： synchronized 是那些不满足条件的线程都在一间休息室等消息 而 ReentrantLock 支持多间休息室，有专门等烟的休息室、专门等早餐的休息室、唤醒时也是按休息室来唤醒。 使用要点： await 前需要获得锁 await 执行后，会释放锁，进入 conditionObject 等待 await 的线程被唤醒signal(), signalAll()（或打断interrupt、或超时）去重新竞争 lock 锁 竞争 lock 锁成功后，从 await 后继续执行 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package com.chan.concurrent.condition;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.ReentrantLock;@Slf4j(topic = &quot;c.Test&quot;)public class Test { static ReentrantLock lock = new ReentrantLock(); static Condition waitCigaretteQueue = lock.newCondition(); static Condition waitTakeoutQueue = lock.newCondition(); static boolean hasCigarette = false; static boolean hasTakeout = false; public static void main(String[] args) throws InterruptedException { new Thread(() -&gt; { lock.lock(); try { while (!hasCigarette) { log.debug(&quot;没有烟,先歇着...&quot;); waitCigaretteQueue.await(); } log.debug(&quot;烟来了,开始工作了...&quot;); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } }, &quot;小南&quot;).start(); new Thread(() -&gt; { lock.lock(); try { while (!hasTakeout) { log.debug(&quot;没有外卖,先歇着...&quot;); waitTakeoutQueue.await(); } log.debug(&quot;外卖到了,开始工作...&quot;); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } }, &quot;小女&quot;).start(); TimeUnit.SECONDS.sleep(2); lock.lock(); try { log.debug(&quot;烟来了...&quot;); hasCigarette = true; waitCigaretteQueue.signal(); } finally { lock.unlock(); } TimeUnit.SECONDS.sleep(2); lock.lock(); try { log.debug(&quot;外卖来了...&quot;); hasTakeout = true; waitTakeoutQueue.signal(); } finally { lock.unlock(); } }} 同步模式之顺序控制固定运行顺序比如，必须先 2 后 1 打印 wait notify 版 123456789101112131415161718192021222324252627282930313233343536373839package com.chan.concurrent.controlOrder;import lombok.extern.slf4j.Slf4j;/** * 先打印2后打印1 */@Slf4j(topic = &quot;c.Test&quot;)public class Test { static final Object obj = new Object(); static volatile boolean t2Run = false; public static void main(String[] args) { new Thread(() -&gt; { synchronized (obj) { while (!t2Run) { try { log.debug(&quot;线程2还没执行,我得等着...&quot;); obj.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } log.debug(&quot;轮到我输出1啦...&quot;); System.out.println(1); } }, &quot;t1&quot;).start(); new Thread(() -&gt; { synchronized (obj) { log.debug(&quot;我先输出2...&quot;); System.out.println(2); t2Run = true; obj.notifyAll(); } }, &quot;t2&quot;).start(); }} Park Unpark 版 12345678910111213141516171819202122232425262728293031package com.chan.concurrent.controlOrder;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.locks.LockSupport;/** * 先输出2后输出1 */@Slf4j(topic = &quot;c.Test3&quot;)public class Test3 { public static void main(String[] args) { Thread t1 = new Thread(new Runnable() { @Override public void run() { LockSupport.park(); System.out.println(1); } },&quot;t1&quot;); t1.start(); new Thread(new Runnable() { @Override public void run() { System.out.println(2); LockSupport.unpark(t1); } },&quot;t2&quot;).start(); }} ReentrantLock 版 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.chan.concurrent.controlOrder;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.ReentrantLock;/** * 先打印2后打印1 */@Slf4j(topic = &quot;c.Test2&quot;)public class Test2 { static ReentrantLock lock = new ReentrantLock(); static Condition condition = lock.newCondition(); static volatile boolean t2HasRun = false; public static void main(String[] args) { new Thread(new Runnable() { @Override public void run() { lock.lock(); try { while (!t2HasRun) { log.debug(&quot;没输出2,先等待...&quot;); condition.await(); } log.debug(&quot;2输出了,我现在输出1...&quot;); System.out.println(1); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } },&quot;t1&quot;).start(); new Thread(new Runnable() { @Override public void run() { lock.lock(); try { log.debug(&quot;输出2...&quot;); System.out.println(2); t2HasRun = true; condition.signal(); }finally { lock.unlock(); } } },&quot;t2&quot;).start(); }} 交替输出线程 1 输出 a 5 次，线程 2 输出 b 5 次，线程 3 输出 c 5 次。现在要求输出 abcabcabcabcabc 怎么实现 wait notify 版 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.chan.concurrent.jiaotishuchu;/** * 线程 1 输出 a 5 次，线程 2 输出 b 5 次，线程 3 输出 c 5 次。现在要求输出 abcabcabcabcabc 怎么实现 * 思路: 在类通过构造初始化的时候带一个值(1,2,3随便),然后这个值代表线程的编号; * 每个线程运行的时候,如果初始化的值对应自己编号的值那么就输出并且将flag改为自己线程编号值的下一个值,对应不上就等待; * 1--&gt;2; 2--&gt;3; 3--&gt;1 */public class AlternatePrint1 { public static void main(String[] args) { SyncWaitNotifyAll syncWaitNotifyAll = new SyncWaitNotifyAll(1, 5); new Thread(() -&gt; syncWaitNotifyAll.print(1, 2, &quot;a&quot;)).start(); new Thread(() -&gt; syncWaitNotifyAll.print(2, 3, &quot;b&quot;)).start(); new Thread(() -&gt; syncWaitNotifyAll.print(3, 1, &quot;c&quot;)).start(); }}/** * 交替输出 */class SyncWaitNotifyAll { //线程编号 private int flag; //每个字母一共输出几次 private final int total; public SyncWaitNotifyAll(int flag, int total) { this.flag = flag; this.total = total; } public void print(int waitFlag, int nextFlag, String str) { for (int i = 0; i &lt; total; i++) { synchronized (this) { while (this.flag != waitFlag) { try { this.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } System.out.print(str); flag = nextFlag; this.notifyAll(); } } }} Lock 条件变量版 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.chan.concurrent.jiaotishuchu;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.ReentrantLock;public class AlternatePrint2 { public static void main(String[] args) { SyncAwaitSignal syncAwaitSignal = new SyncAwaitSignal(5); Condition waitSet1 = syncAwaitSignal.newCondition(); Condition waitSet2 = syncAwaitSignal.newCondition(); Condition waitSet3 = syncAwaitSignal.newCondition(); new Thread(() -&gt; syncAwaitSignal.printer(waitSet1, waitSet2, &quot;a&quot;)).start(); new Thread(() -&gt; syncAwaitSignal.printer(waitSet2, waitSet3, &quot;b&quot;)).start(); new Thread(() -&gt; syncAwaitSignal.printer(waitSet3, waitSet1, &quot;c&quot;)).start(); syncAwaitSignal.start(waitSet1); }}class SyncAwaitSignal extends ReentrantLock { private final int total; public SyncAwaitSignal(int total) { this.total = total; } public void start(Condition current) { lock(); try { current.signal(); } finally { unlock(); } } public void printer(Condition current, Condition next, String str) { for (int i = 0; i &lt; total; i++) { lock(); try { current.await(); System.out.print(str); next.signal(); } catch (InterruptedException e) { e.printStackTrace(); } finally { unlock(); } } }} Park Unpark 版 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.chan.concurrent.jiaotishuchu;import java.util.concurrent.locks.LockSupport;public class AlternatePrint3 { public static void main(String[] args) { SyncPark syncPark = new SyncPark(5); Thread t1 = new Thread(() -&gt; syncPark.print(&quot;a&quot;)); Thread t2 = new Thread(() -&gt; syncPark.print(&quot;b&quot;)); Thread t3 = new Thread(() -&gt; syncPark.print(&quot;c\\n&quot;)); syncPark.setThreads(t1, t2, t3); syncPark.start(); }}class SyncPark { private final int total; private Thread[] threads; public SyncPark(int total) { this.total = total; } public void setThreads(Thread... threads) { this.threads = threads; } public void print(String string) { for (int i = 0; i &lt; total; i++) { LockSupport.park(); System.out.print(string); LockSupport.unpark(nextThread()); } } private Thread nextThread() { Thread current = Thread.currentThread(); int index = 0; for (int i = 0; i &lt; threads.length; i++) { if (threads[i] == current) { index = i; break; } } if (index &lt; threads.length - 1) { return threads[index + 1]; } else { return threads[0]; } } public void start() { for (Thread thread : threads) { thread.start(); } LockSupport.unpark(threads[0]); }} 阶段总结这块我们需要重点掌握的是： 分析多线程访问共享资源时，哪些代码片段属于临界区 使用 synchronized 互斥解决临界区的线程安全问题 掌握 synchronized 锁对象语法 掌握 synchronzied 加载成员方法和静态方法语法 掌握 wait/notify 同步方法 使用 lock 互斥解决临界区的线程安全问题 掌握 lock 的使用细节：可打断、锁超时、公平锁、条件变量 学会分析变量的线程安全性、掌握常见线程安全类的使用 了解线程活跃性问题：死锁、活锁、饥饿 应用方面 互斥：使用 synchronized 或 Lock 达到共享资源互斥效果 同步：使用 wait/notify 或 Lock 的条件变量来达到线程间通信效果 原理方面 monitor、synchronized 、wait/notify 原理 synchronized 进阶原理 park &amp; unpark 原理 模式方面 同步模式之保护性暂停 异步模式之生产者消费者 同步模式之顺序控制","link":"/posts/20211120/java-concurrent-2.html"},{"title":"线程安全的集合类和一些其它知识点","text":"线程安全集合类可以分为三大类： 遗留的线程安全集合如 Hashtable ， Vector 使用 Collections 装饰的线程安全集合，如： Collections.synchronizedCollection Collections.synchronizedList Collections.synchronizedMap Collections.synchronizedSet Collections.synchronizedNavigableMap Collections.synchronizedNavigableSet Collections.synchronizedSortedMap Collections.synchronizedSortedSet java.util.concurrent.* 重点介绍 java.util.concurrent.* 下的线程安全集合类，可以发现它们有规律，里面包含三类关键词：Blocking、CopyOnWrite、Concurrent Blocking 大部分实现基于锁，并提供用来阻塞的方法 CopyOnWrite 之类容器修改开销相对较重 Concurrent 类型的容器 内部很多操作使用 cas 优化，一般可以提供较高吞吐量 弱一致性 遍历时弱一致性，例如，当利用迭代器遍历时，如果容器发生修改，迭代器仍然可以继续进行遍历，这时内容是旧的 求大小弱一致性，size 操作未必是 100% 准确 读取弱一致性 遍历时如果发生了修改，对于非安全容器来讲，使用 fail-fast 机制也就是让遍历立刻失败，抛出ConcurrentModificationException，不再继续遍历 ConcurrentHashMap 注意ConcurrentHashMap 是一个线程安全的集合，ConcurrentHashMap 中的方法，每个方法都能保证在多线程下是原子的，线程安全的，但是业务中有时候会有需求，用 ConcurrentHashMap 中的方法组合使用从而实现某些业务场景，组合去操作同一个共享资源。这样的话，组合的这段代码就可能有线程安全问题。意思就是每个方法是原子的，但是方法组合使用，这段代码就不能保证原子了，其实这儿在前面也提到过。 比如说有一个需求，需要从 map 集合中检查某个 key 是否存在，如果不存在，说明这个 key 是没有的，没有的话需要 put 一个 key，并且给这个 key 对应的 value 一个初始值，将来要累加。 例如下面的代码： 123Integer counter = map.get(word);int newValue = counter == null ? 1 : counter + 1;map.put(word, newValue); 这就是组合使用了。上面的案例中，其实如果在多线程的情况下，ConcurrentHashMap 的 map 对象是一个共享资源，尽管 ConcurrentHashMap 的 get 和 put 方法每个都是原子的，但是这一段代码组合起来就是线程不安全的。 ConcurrentHashMap 提供解决这种场景的方案： 123// 注意不能使用 putIfAbsent，此方法返回的是上一次的 value，首次调用返回 nullLongAdder value = map.computeIfAbsent(word, (key) -&gt; new LongAdder());//LongAdder原子累加器，基础是从0开始实现累加效果的value.increment();// 0--&gt;1、1--&gt;2 上面代码中，如果 map 中这个 key 没有，生成一个累加器，将累加器返回；key 有的话，就无需再创建累加器了，一直是同一个累加器来执行这个累加操作的。 JDK7 中 HashMap 的并发死链注意，HashMap 的并发死链只是在 JDK7 中才有可能复现，最根本的原因就是并发扩容时的“头插法”。 首先回顾 HashMap 的数据结构：它的数据结构其实就是哈希表，往细了说在 jdk7 中是数组＋链表的结构；在 jdk8 中，就是数组＋链表＋红黑树的结构。 当一个 key 被放入 HashMap 时，首先会计算这个 key 的 hash 值，然后对整个数组的长度进行取模，得到桶下标，然后放入数组下标值与桶下标对应的位置。这样的查找效率非常高，因为是底层数据结构是数组。但是因为数组的容量有限，因此随着存入数量的增加，不可避免会有取模值相同的情况，也就是所谓的“桶下标冲突”，有可能 key 是值不相同的 key 但是它们的桶下标相同，这时 jdk 会让桶下标相同的 key 在数组的同一索引位置形成一个链表，来解决桶下标冲突。将来查找 key 时，先得到 key 的 hash 值，不冲突的情况下直接返回，一旦发生了桶下标冲突，那么再在链表头用 equals 一个一个比较，来查找这个 key。虽然性能上稍微有所损失，但是可解决桶下标冲突。这便是 JDK7 的 HashMap 的基本结构。 有必要说一下：JDK7 为链表头插法，也就是如果没有桶下标冲突，那么数组每个索引的数据都好比链表的头节点，当有了冲突的时候，这个新的冲突的 key 会放在对应索引对应链表的头节点的位置，也就是数组和链表交界的位置节点。但是 JDK8 中，为链表的尾插法，当有了冲突的时候，这个新的冲突的 key 会放在对应索引对应链表的尾节点的位置。 接下来说一说扩容的问题，JDK8 中除了对插入方式进行了改善，并且对扩容策略也进行了升级。首先，随着元素越来越多，必然导致链的长度越来越大，进而查找性能必然受到影响，因为数组结构是查询快，增删慢（因为需要考虑复制成本），链表是增删快，查询慢，所以链表的长度越长，查找的性能越慢。因此为了解决这个问题，JDK 会在数组元素超过阈值（0.75）时，进行一次扩容。 Hashmap的扩容需要满足两个条件：当前数据存储的数量（即size()）大小必须大于等于阈值；当前加入的数据是否发生了hash冲突。因为上面这两个条件，所以存在下面这些情况 （1）、就是hashmap在存值的时候（默认大小为16，负载因子0.75，阈值12），可能达到最后存满16个值的时候，再存入第17个值才会发生扩容现象，因为前16个值，每个值在底层数组中分别占据一个位置，并没有发生hash碰撞。 （2）、当然也有可能存储更多值（超多16个值，最多可以存26个值）都还没有扩容。原理：前11个值全部hash碰撞，存到数组的同一个位置（这时元素个数小于阈值12，不会扩容），后面所有存入的15个值全部分散到数组剩下的15个位置（这时元素个数大于等于阈值，但是每次存入的元素并没有发生hash碰撞，所以不会扩容），前面11+15=26，所以在存入第27个值的时候才同时满足上面两个条件，这时候才会发生扩容现象。 扩容实际上就是产生一个新的数组，容量是原来数组的2倍，并且扩容会重新计算桶下标，原来的链表中的一个一个元素会迁移到新的数组中。扩容后链表的长度缩短，查找性能提升。但是在 JDK7 中也就是因为在多线程下进行扩容时，可能会造成并发死链的问题，这里在 jdk8 中改用了尾插法得到了避免。另外，JDK8 中对于扩容做了改善。HashMap 数组的初始长度为16，当发生扩容时，数组长度最大扩容到64之后，如果链表的长度还是 &gt;= 8（树化阈值），将进行链表转化为红黑树的操作。 HashSet 是不允许存入重复的数据的，如果存入的数据之前存过了，那么 add 方法会返回 false， HashMap 是不允许存入相同的 key 值，如果存的 key 之前存过了相同的 key，那么这后面存的键值对会覆盖前面存的键值对，比如 key valueNew 会覆盖 key valueOld，就相当于更改。那底层是怎么判断重复的呢？比如新存一个值，那么 HashSet 底层会先求出这个值的 Hash值，然后在数组中查找，是否有同样的 Hash 值的元素，如果没有直接存入，如果有相同的哈希值那么进而使用 equals 判断，看这个哈希值对应的链表上是否有 equals 判断后返回 true 的节点，有的话证明之前存过相同的值，那么 add 方法返回 false，没有的话证明之前没有存过，add 方法返回 true。或者新存一个键值对，那么在 HashMap 中就是判断 key 值，原理和 HashSet 一致。 HashMap 详细剖析问：HashMap 的底层数据结构，在 1.7 与 1.8 中有何不同？ 1）基本数据结构 1.7 数组 + 链表 1.8 数组 + （链表 | 红黑树） 问：为何要用红黑树？为何一上来不树化？树化阈值为何是 8？何时会树化？何时会退化为链表？ 2）树化与退化树化意义 红黑树用来避免 DoS 攻击，防止链表超长时性能下降，树化应当是偶然情况，是保底策略 hash 表的查找，更新的时间复杂度是 $O(1)$，而红黑树的查找，更新的时间复杂度是 $O(log_2⁡n )$，TreeNode 占用空间也比普通 Node 的大，并且长度短的链表在挨个查找时的效率不见得比红黑树差。因此如非必要，尽量还是使用链表 hash 值如果足够随机，则在 hash 表内按泊松分布，在负载因子 0.75 的情况下，长度超过 8 的链表出现概率是 0.00000006，树化阈值选择 8 就是为了让树化几率足够小 树化规则 当链表长度超过树化阈值 8 时，先尝试扩容来减少链表长度，如果数组容量已经 &gt;=64，才会进行树化 退化规则 情况1：在扩容时，如果拆分树了，导致树元素个数 &lt;= 6 时，树则会退化为链表 情况2：remove 树节点时，若 root、root.left、root.right、root.left.left 有一个为 null ，也会退化为链表 阶段小总结： HashMap 中存入的是 key-value 结构的键值对，key 是不可重复的，如果重复那么这个 key 对应的新的 value 就会覆盖原来的 value。 HashMap 在 1.8 中，是数组 + （链表 | 红黑树）的底层结构。在 HashMap 存入键值对的时候，是根据 key 来做运算的，对 key 进行 hashCode() 运算，再进行调用 HashMap 的 hash() 方法进行二次哈希，得到哈希值，然后让这个哈希值与底层数组的初始长度（16）取模运算，得到桶下标，也就是对应底层数组的索引位置，然后就将这个 key 放到这个索引位置。如果出现哈希碰撞的情况，也就是有可能在数组的同一个索引处放入多个值，那么这些值就组成了一个链表。如果发生哈希碰撞的值较多，链表的长度会逐渐增加，但是链表超长时性能下降，因此等链表达到一定长度（8）时，再向这个链表对应的索引放入数据时，会先尝试扩容数组（+16）来减少链表长度，但如果数组长度已经 &gt;=64 时，此时链表就会转换为红黑树。 数组扩容的两个情况： 负载因子 0.75：HashMap 中 key 的数量大于底层数组长度的 3/4 时，扩容。 链表达到一定长度（8），并且数组长度 ＜64 时，再向这个链表对应的索引放入数据时，可能此时没达到 0.75 阈值，但也会先尝试扩容数组（+16）来减少链表长度。 树化条件（必须同时满足下面两个）： 当链表长度超过树化阈值 8 数组长度已经 &gt;=64 树退化回链表的两种情况： 情况1：在扩容时，如果拆分树了，导致树元素个数 &lt;= 6 时，树则会退化为链表 情况2：remove 树节点时，若 root、root.left、root.right、root.left.left 有一个为 null 时，也会退化为链表 问：索引如何计算？hashCode 都有了，为何还要提供 hash() 方法？数组容量为何是 2 的 n 次幂？ 3）索引计算索引计算方法 首先，计算对象的 hashCode() 再进行调用 HashMap 的 hash() 方法进行二次哈希 二次 hash() 是为了综合高位数据，让哈希分布更为均匀 最后哈希值 % capacity 得到索引。或者 哈希值 &amp; (capacity - 1) 按位与运算代替取模运算，因为按位与运算效率偏高，但是要注意，只有在 capacity 是 2 的 n 次幂的时候，才可以使用位与运算代替取模。 数组容量为何是 2 的 n 次幂 计算索引时效率更高：如果是 2 的 n 次幂可以使用位与运算代替取模 扩容时重新计算索引效率更高： hash &amp; oldCap == 0 的元素留在原来位置 ，否则新位置 = 旧位置 + oldCap 注意 二次 hash 是为了配合 容量是 2 的 n 次幂 这一设计前提，如果 hash 表的容量不是 2 的 n 次幂，则不必二次 hash 容量是 2 的 n 次幂 这一设计计算索引效率更好，但 hash 的分散性就不好，需要二次 hash 来作为补偿，没有采用这一设计的典型例子是 Hashtable 问：介绍一下 put 方法流程，1.7 与 1.8 有何不同？ 4）put 与扩容put 流程 HashMap 是懒惰创建数组的（并不是一上来就创建一个长度为16的数组），首次使用（调用 put 方法时），才创建数组 计算索引（桶下标） 如果桶下标还没人占用，创建 Node 占位返回 如果桶下标已经有人占用 已经是 TreeNode 走红黑树的添加或更新逻辑 是普通 Node，走链表的添加或更新逻辑，如果链表长度超过树化阈值，根据树化规则走树化逻辑 返回前检查容量是否超过阈值，一旦超过进行扩容（也就是先把元素加到旧数组，然后扩容迁移元素） 1.7 与 1.8 的区别 链表插入节点时，1.7 是头插法，1.8 是尾插法 1.7 是大于等于阈值且没有空位（表示新加的元素要加到的索引位置上是空着的）时才扩容，而 1.8 是大于阈值就扩容 1.8 在扩容计算 Node 索引时，会优化（优化方案：将哈希值跟旧的数组长度做按位与，如果结果是0，表示这个元素在扩容后不用动位置，如果不是0，表示这个元素在扩容之后要移动到一个新位置，新位置 = 这个元素的旧的索引 + 旧的数组长度） 问：扩容（加载）因子为何默认是 0.75f？ 在空间占用与查询时间之间取得较好的权衡 大于这个值，空间节省了，但链表就会比较长影响性能 小于这个值，冲突减少了，但扩容就会更频繁，空间占用也更多 5）并发问题扩容死链（1.7 会存在） 1.7 源码如下： 123456789101112131415void transfer(Entry[] newTable, boolean rehash) { int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) { while(null != e) { Entry&lt;K,V&gt; next = e.next; if (rehash) { e.hash = null == e.key ? 0 : hash(e.key); } int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; } }} e 和 next 都是局部变量，用来指向当前节点和下一个节点 线程1（绿色）的临时变量 e 和 next 刚引用了这俩节点，还未来得及移动节点，此时发生了线程切换，线程 2 得到了 CPU 执行权，由线程2（蓝色）完成扩容和迁移 注：图中 e 表示当前要迁移的节点，next 表示下一个节点。 注：每轮迁移结束会把 e 指向 next 所指向的节点，下一轮开始会把 next 指向当前节点的下一个节点。 线程2 扩容完成，并完成迁移，但由于头插法，链表顺序颠倒。但此时线程 1 的临时变量 e 和 next 依然正在引用这俩节点，因此当线程 1 重新得到 CPU 的执行权之后，还要再来一遍迁移。 第一次循环 循环接着线程切换前运行，注意此时 e 指向的是节点 a，next 指向的是节点 b e 头插 a 节点，注意图中画了两份 a 节点，但事实上只有一个（为了不让箭头特别乱画了两份） 当循环结束是 e 会指向 next 也就是 b 节点 第二次循环 next 指向了节点 a e 头插节点 b 当循环结束时，e 指向 next 也就是节点 a 第三次循环 next 指向了 null e 头插节点 a，a 的 next 指向了 b（之前 a.next 一直是 null），b 的 next 指向 a，死链已成 当循环结束时，e 指向 next 也就是 null，因此第四次循环时会正常退出 数据错乱（1.7，1.8 都会存在） 多线程下，如果是多个线程并发操作 HashMap，向其中 putVal，有可能造成数据丢失的。 代码参考 day01.map.HashMapMissData，具体调试步骤参考视频 补充代码说明 day01.map.HashMapDistribution 演示 map 中链表长度符合泊松分布 day01.map.DistributionAffectedByCapacity 演示容量及 hashCode 取值对分布的影响 day01.map.DistributionAffectedByCapacity#hashtableGrowRule 演示了 Hashtable 的扩容规律 day01.sort.Utils#randomArray 如果 hashCode 足够随机，容量是否是 2 的 n 次幂影响不大 day01.sort.Utils#lowSameArray 如果 hashCode 低位一样的多，容量是 2 的 n 次幂会导致分布不均匀 day01.sort.Utils#evenArray 如果 hashCode 偶数的多，容量是 2 的 n 次幂会导致分布不均匀 由此得出对于容量是 2 的 n 次幂的设计来讲，二次 hash 非常重要 day01.map.HashMapVsHashtable 演示了对于同样数量的单词字符串放入 HashMap 和 Hashtable 分布上的区别 6）key 的设计key 的设计要求 HashMap 的 key 可以为 null，但 Map 的其他实现则不然 作为 key 的对象，必须实现 hashCode 和 equals，并且 key 的内容不能修改（不可变）。注：两个值，hashCode 相同不一定 equals，但是 equals 的话 hashCode 一定相同。 key 的 hashCode 应该有良好的散列性 如果 key 可变，例如修改了 age 会导致再次查询时查询不到 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class HashMapMutableKey { public static void main(String[] args) { HashMap&lt;Student, Object&gt; map = new HashMap&lt;&gt;(); Student stu = new Student(&quot;张三&quot;, 18); map.put(stu, new Object()); System.out.println(map.get(stu)); stu.age = 19; System.out.println(map.get(stu)); } static class Student { String name; int age; public Student(String name, int age) { this.name = name; this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Student student = (Student) o; return age == student.age &amp;&amp; Objects.equals(name, student.name); } @Override public int hashCode() { return Objects.hash(name, age); } }} String 对象的 hashCode() 设计 目标是达到较为均匀的散列效果，每个字符串的 hashCode 足够独特 字符串中的每个字符都可以表现为一个数字，称为 $S_i$，其中 i 的范围是 0 ~ n - 1 散列公式为： $S_0∗31^{(n-1)}+ S_1∗31^{(n-2)}+ … S_i ∗ 31^{(n-1-i)}+ …S_{(n-1)}∗31^0$ 31 代入公式有较好的散列特性，并且 31 * h 可以被优化为 即 $32 ∗h -h $ 即 $2^5 ∗h -h$ 即 $h≪5 -h$ 7）JDK1.8中的线程不安全为什么说 HashMap 线程不安全？因为并发插入数据时数据可能会被覆盖，那为什么说JDK1.8会出现数据覆盖的情况喃，我们来看一下下面这段JDK1.8中的put操作代码： 123456789101112131415161718192021222324252627282930313233343536373839404142final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) // 如果没有hash碰撞则直接插入元素，并发不安全 tab[i] = newNode(hash, key, value, null); else { Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; if (++size &gt; threshold)// 并发不安全 resize(); afterNodeInsertion(evict); return null; } 其中第六行代码是判断是否出现hash碰撞，假设两个线程A、B都在进行put操作，并且hash函数计算出的插入下标是相同的，当线程A执行完第六行代码后由于时间片耗尽导致被挂起，而线程B得到时间片后在该下标处插入了元素，完成了正常的插入，然后线程A获得时间片，由于之前已经进行了hash碰撞的判断，所有此时不会再进行判断，而是直接进行插入，这就导致了线程B插入的数据被线程A覆盖了，从而线程不安全。 除此之外，还有就是代码的倒数第五行处有个++size，我们这样想，还是线程A、B，这两个线程同时进行put操作时，假设当前HashMap的zise大小为10，当线程A执行到倒数第五行代码时，从主内存中获得size的值为10，后准备进行+1操作，但是还没等执行+1时，由于时间片耗尽只好让出CPU，线程B快乐的拿到CPU还是从主内存中拿到size的值10进行+1操作，完成了put操作并将size=11写回主内存，然后线程A再次拿到CPU并继续执行(此时size的值仍为10)，当执行完put操作后，还是将size=11写回内存，此时，线程A、B都执行了一次put操作，但是size的值只增加了1，所有说还是由于数据覆盖又导致了线程不安全。 JDK8 的 ConcurrentHashMap重要属性和内部类12345678910111213141516171819// 默认为 0// 当初始化时, 为 -1// 当扩容时, 为 -(1 + 扩容线程数)// 当初始化或扩容完成后，为 下一次的扩容的阈值大小private transient volatile int sizeCtl;// 整个 ConcurrentHashMap 就是一个 Node[]static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; {}// hash 表transient volatile Node&lt;K,V&gt;[] table;// 扩容时的 新 hash 表private transient volatile Node&lt;K,V&gt;[] nextTable;// 扩容时如果某个 bin 迁移完毕, 用 ForwardingNode 作为旧 table bin 的头结点static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; {}// 用在 compute 以及 computeIfAbsent 时, 用来占位, 计算完成后替换为普通 Nodestatic final class ReservationNode&lt;K,V&gt; extends Node&lt;K,V&gt; {}// 作为 treebin 的头节点, 存储 root 和 firststatic final class TreeBin&lt;K,V&gt; extends Node&lt;K,V&gt; {}// 作为 treebin 的节点, 存储 parent, left, rightstatic final class TreeNode&lt;K,V&gt; extends Node&lt;K,V&gt; {} 重要方法12345678// 获取 Node[] 中第 i 个 Nodestatic final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) // cas 修改 Node[] 中第 i 个 Node 的值, c 为旧值, v 为新值static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) // 直接修改 Node[] 中第 i 个 Node 的值, v 为新值static final &lt;K,V&gt; void setTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; v) 构造器分析可以看到实现了懒惰初始化，在构造方法中仅仅计算了 table 的大小，以后在第一次使用时才会真正创建 1234567891011121314// initialCapacity 初始容量也就是初始大小；loadFactor 负载因子。3/4 表示将来扩容的阈值；concurrencyLevel 并发度。public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) { if (!(loadFactor &gt; 0.0f) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); // 如果初始容量小于并发度 if (initialCapacity &lt; concurrencyLevel) // Use at least as many bins // 初始容量最小要保证并发度这么大，将并发度的值给初始容量 initialCapacity = concurrencyLevel; // as estimated threads long size = (long)(1.0 + (long)initialCapacity / loadFactor); // tableSizeFor 仍然是保证计算的大小是 2^n, 即 16,32,64 ... int cap = (size &gt;= (long)MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)size); this.sizeCtl = cap;} JDK8 中的 ConcurrentHashMap 是懒惰初始化的，上来并不是将数组先创建出来，而是将来真正用到的时候才会创建。在 7 中是不管用没用，一上来就会创建一个 segment 数组，这样会增加内存的成本，在 8 中改进了。 get 流程123456789101112131415161718192021222324252627public V get(Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; // spread 方法能确保返回结果是正数,因为哈希码可能存在负数的情况 int h = spread(key.hashCode());// 这个h是进行put或者get时真正用到的哈希码 // 先判断table，table中如果有元素则往里寻找key，否则直接返回null if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; // tabAt方法，找到某一个链表，先定位一个桶下标根据桶下标找到对应的链表 // 如何找到桶下标？(n-1)&amp;h 数组长-1按位与相当于取模运算，但是按位与效率更高 // 找到头节点看是否不为空，如果不为空，比较头节点的哈希码是否=刚才的key的哈希码 (e = tabAt(tab, (n - 1) &amp; h)) != null) { if ((eh = e.hash) == h) { // 进一步判断这个key是否和我们查找的key是一样的 一样返回value，不一样进一步用equals对key进行判断 if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; } // hash 为负数表示该 bin 在扩容中或是 treebin, 这时调用 find 方法来查找 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; // 正常遍历链表, 用 equals 比较 while ((e = e.next) != null) { if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; } } return null;} put 流程以下数组简称（table），链表简称（bin） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162public V put(K key, V value) { return putVal(key, value, false);}final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); // 其中 spread 方法会综合高位低位, 具有更好的 hash 性 int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) { // f 是链表头节点 // fh 是链表头结点的 hash // i 是链表在 table 中的下标 Node&lt;K,V&gt; f; int n, i, fh; // 要创建 table if (tab == null || (n = tab.length) == 0) // 初始化 table 使用了 cas, 无需 synchronized 创建成功, 进入下一轮循环 tab = initTable(); // 要创建链表头节点 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) { // 添加链表头使用了 cas, 无需 synchronized if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; } // 帮忙扩容 else if ((fh = f.hash) == MOVED) // 帮忙之后, 进入下一轮循环 tab = helpTransfer(tab, f); else { V oldVal = null; // 锁住链表头节点 synchronized (f) { // 再次确认链表头节点没有被移动 if (tabAt(tab, i) == f) { // 链表 if (fh &gt;= 0) { binCount = 1; // 遍历链表 for (Node&lt;K,V&gt; e = f;; ++binCount) { K ek; // 找到相同的 key if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) { oldVal = e.val; // 更新 if (!onlyIfAbsent) e.val = value; break; } Node&lt;K,V&gt; pred = e; // 已经是最后的节点了, 新增 Node, 追加至链表尾 if ((e = e.next) == null) { pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; } } } // 红黑树 else if (f instanceof TreeBin) { Node&lt;K,V&gt; p; binCount = 2; // putTreeVal 会看 key 是否已经在树中, 是, 则返回对应的 TreeNode if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } } // 释放链表头节点的锁 } if (binCount != 0) { if (binCount &gt;= TREEIFY_THRESHOLD) // 如果链表长度 &gt;= 树化阈值(8), 进行链表转为红黑树 treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } // 增加 size 计数 addCount(1L, binCount); return null;}private final Node&lt;K,V&gt;[] initTable() { Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) { if ((sc = sizeCtl) &lt; 0) Thread.yield(); // 尝试将 sizeCtl 设置为 -1（表示初始化 table） else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) { // 获得锁, 创建 table, 这时其它线程会在 while() 循环中 yield 直至 table 创建 try { if ((tab = table) == null || tab.length == 0) { int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; sc = n - (n &gt;&gt;&gt; 2); } } finally { sizeCtl = sc; } break; } } return tab;}// check 是之前 binCount 的个数private final void addCount(long x, int check) { CounterCell[] as; long b, s; if ( // 已经有了 counterCells, 向 cell 累加 (as = counterCells) != null || // 还没有, 向 baseCount 累加 !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x) ) { CounterCell a; long v; int m; boolean uncontended = true; if ( // 还没有 counterCells as == null || (m = as.length - 1) &lt; 0 || // 还没有 cell (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || // cell cas 增加计数失败 !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x)) ) { // 创建累加单元数组和cell, 累加重试 fullAddCount(x, uncontended); return; } if (check &lt;= 1) return; // 获取元素个数 s = sumCount(); } if (check &gt;= 0) { Node&lt;K,V&gt;[] tab, nt; int n, sc; while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) { int rs = resizeStamp(n); if (sc &lt; 0) { if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; // newtable 已经创建了，帮忙扩容 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); } // 需要扩容，这时 newtable 未创建 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); s = sumCount(); } }} size 计算流程size 计算实际发生在 put，remove 改变集合元素的操作之中 没有竞争发生，向 baseCount 累加计数 有竞争发生，新建 counterCells，向其中的一个 cell 累加计数 counterCells 初始有两个 cell 如果计数竞争比较激烈，会创建新的 cell 来累加计数 123456789101112131415161718public int size() { long n = sumCount(); return ((n &lt; 0L) ? 0 : (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n);}final long sumCount() { CounterCell[] as = counterCells; CounterCell a; // 将 baseCount 计数与所有 cell 计数累加 long sum = baseCount; if (as != null) { for (int i = 0; i &lt; as.length; ++i) { if ((a = as[i]) != null) sum += a.value; } } return sum;} 总结Java 8 数组（Node） +（ 链表 Node | 红黑树 TreeNode ） 以下数组简称（table），链表简称（bin） 初始化，使用 cas 来保证并发安全，懒惰初始化 table 树化，当 table.length &lt; 64 时，先尝试扩容，超过 64 时，并且 bin.length &gt; 8 时，会将链表树化，树化过程会用 synchronized 锁住链表头 put，如果该 bin 尚未创建，只需要使用 cas 创建 bin；如果已经有了，锁住链表头进行后续 put 操作，元素添加至 bin 的尾部 get，无锁操作仅需要保证可见性，扩容过程中 get 操作拿到的是 ForwardingNode 它会让 get 操作在新 table 进行搜索 扩容，扩容时以 bin 为单位进行，需要对 bin 进行 synchronized，但这时妙的是其它竞争线程也不是无事可做，它们会帮助把其它 bin 进行扩容，扩容时平均只有 1/6 的节点会把复制到新 table 中 size，元素个数保存在 baseCount 中，并发时的个数变动保存在 CounterCell[] 当中。最后统计数量时累加即可 HashMap 允许有空 key 空 value，也就是可以为 null；但是 ConcurrentHashMap 不允许，会抛异常。 程序员小灰——什么是 ConcurrentHashMap （JDK7） Hashtable vs ConcurrentHashMapHashtable 对比 ConcurrentHashMap Hashtable 与 ConcurrentHashMap 都是线程安全的 Map 集合，它们的键值都是不能为空的。 Hashtable 并发度低，整个 Hashtable 对应一把锁，同一时刻，只能有一个线程操作它 ConcurrentHashMap 并发度高，整个 ConcurrentHashMap 对应多把锁，只要线程访问的是不同锁，那么不会冲突 ConcurrentHashMap 1.7 数据结构：Segment(大数组) + HashEntry(小数组) + 链表，每个 Segment 对应一把锁，如果多个线程访问不同的 Segment，则不会冲突 并发度：Segment 数组大小即并发度，决定了同一时刻最多能有多少个线程并发访问。Segment 数组不能扩容，意味着并发度在 ConcurrentHashMap 创建时就固定了 索引计算 假设大数组长度是 $2^m$，key 在大数组内的索引是 key 的二次 hash 值的高 m 位 假设小数组长度是 $2^n$，key 在小数组内的索引是 key 的二次 hash 值的低 n 位 扩容：每个小数组的扩容相对独立，小数组在超过扩容因子时会触发扩容，每次扩容翻倍 Segment[0] 原型：首次创建其它小数组时，会以此原型为依据，数组长度，扩容因子都会以原型为准 ConcurrentHashMap 1.8 数据结构：Node 数组 + 链表或红黑树，每个链表的头节点作为锁，如果多个线程访问的头节点不同，则不会冲突。首次生成头节点时如果发生竞争，利用 cas 而非 syncronized，进一步提升性能 并发度：Node 数组有多大，并发度就有多大，与 1.7 不同，Node 数组可以扩容，数组的容量决定了它的并发度。 扩容条件：Node 数组满 3/4 时就会扩容 扩容单位：以链表为单位从后向前迁移链表，迁移完成的将旧数组头节点替换为 ForwardingNode 扩容时并发 get 根据是否为 ForwardingNode 来决定是在新数组查找还是在旧数组查找，不会阻塞 如果链表长度超过 1，则需要对节点进行复制（创建新节点），怕的是节点迁移后 next 指针改变 如果链表最后几个元素扩容后索引不变，则节点无需复制 扩容时并发 put 如果 put 的线程与扩容线程操作的链表是同一个，put 线程会阻塞 如果 put 的线程操作的链表还未迁移完成，即头节点不是 ForwardingNode，则可以并发执行 如果 put 的线程操作的链表已经迁移完成，即头结点是 ForwardingNode，则可以协助扩容 与 1.7 相比是懒惰初始化 capacity 代表预估的元素个数，capacity / factor 来计算出初始数组大小，需要贴近 $2^n$ loadFactor 只在计算初始数组大小时被使用，之后扩容固定为 3/4 超过树化阈值时的扩容问题，如果容量已经是 64，直接树化，否则在原来容量基础上做 3 轮扩容 LinkedBlockingQueue基本的入队出队1234567891011121314public class LinkedBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable { static class Node&lt;E&gt; { E item; /** * 下列三种情况之一 * - 真正的后继节点 * - 自己, 发生在出队时 * - null, 表示是没有后继节点, 是最后了 */ Node&lt;E&gt; next; Node(E x) { item = x; } }} 初始化链表 last = head = new Node&lt;E&gt;(null); Dummy 节点用来占位，item 为 null 当一个节点入队 last = last.next = node; 再来一个节点入队 last = last.next = node; 出队 1234567Node&lt;E&gt; h = head;Node&lt;E&gt; first = h.next;h.next = h; // help GC 自己指向自己，不在被引用，方便垃圾回收head = first;E x = first.item;first.item = null;return x; h = head first = h.next h.next = h head = first 1234// Dummy节点就是占位节点，是空的没有数据的，真正的数据在第一个NodeE x = first.item;first.item = null;return x; 加锁分析**==高明之处==**在于用了两把锁和 dummy 节点，占位的头节点，是空的，这个和研究 ReentrantLock 底层时阻塞队列的占位 Dummy 节点是一样的，都是空的占位节点，也叫哨兵节点。 用一把锁，同一时刻，最多只允许有一个线程（生产者或消费者，二选一）执行 用两把锁，同一时刻，可以允许两个线程同时（一个生产者与一个消费者）执行 消费者与消费者线程仍然串行 生产者与生产者线程仍然串行 保证消费者和消费者间的互斥，生产者与生产者间的互斥就行 线程安全分析 当节点总数大于 2 时（包括 dummy 节点），putLock 保证的是 last 节点的线程安全，takeLock 保证的是 head 节点的线程安全。两把锁保证了入队和出队没有竞争 当节点总数等于 2 时（即一个 dummy 节点，一个正常节点）这时候，仍然是两把锁锁两个对象，不会竞争，由此可见，Dummy 占位节点就是为了有两把锁对象，因为假设没有它的话，剩一个正常节点，是不可以有两把锁的，也没办法提升效率。 当节点总数等于 1 时（就一个 dummy 节点）这时 take 线程会被 notEmpty 条件阻塞，有竞争，会阻塞 1234// 用于 put(阻塞) offer(非阻塞)private final ReentrantLock putLock = new ReentrantLock();// 用户 take(阻塞) poll(非阻塞)private final ReentrantLock takeLock = new ReentrantLock(); put 操作12345678910111213141516171819202122232425262728public void put(E e) throws InterruptedException { if (e == null) throw new NullPointerException(); int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; // count 用来维护元素计数 final AtomicInteger count = this.count; putLock.lockInterruptibly(); try { // 满了等待 while (count.get() == capacity) { // 倒过来读就好: 等待 notFull notFull.await(); } // 有空位, 入队且计数加一 enqueue(node); c = count.getAndIncrement(); // 除了自己 put 以外, 队列还有空位, 由自己叫醒其他 put 线程 if (c + 1 &lt; capacity) notFull.signal(); } finally { putLock.unlock(); } // 如果队列中有一个元素, 叫醒 take 线程 if (c == 0) // 这里调用的是 notEmpty.signal() 而不是 notEmpty.signalAll() 是为了减少竞争 signalNotEmpty();} take 操作123456789101112131415161718192021222324public E take() throws InterruptedException { E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try { while (count.get() == 0) { notEmpty.await(); } x = dequeue(); c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); } finally { takeLock.unlock(); } // 如果队列中只有一个空位时, 叫醒 put 线程 // 如果有多个线程进行出队, 第一个线程满足 c == capacity, 但后续线程 c &lt; capacity if (c == capacity) // 这里调用的是 notFull.signal() 而不是 notFull.signalAll() 是为了减少竞争 signalNotFull() return x;} 由 put 唤醒 put 是为了避免信号不足 性能比较主要列举 LinkedBlockingQueue 与 ArrayBlockingQueue 的性能比较 Linked 支持有界，Array 强制有界 Linked 实现是链表，Array 实现是数组 Linked 是懒惰的，而 Array 需要提前初始化 Node 数组 Linked 每次入队会生成新 Node，而 Array 的 Node 是提前创建好的 Linked 两把锁，Array 一把锁 ConcurrentLinkedQueueConcurrentLinkedQueue 的设计与 LinkedBlockingQueue 非常像，也是 两把【锁】，同一时刻，可以允许两个线程同时（一个生产者与一个消费者）执行 dummy 节点的引入让两把【锁】将来锁住的是不同对象，避免竞争 只是这【锁】使用了 cas 来实现，LinkedBlockingQueue 的【锁】用的是 ReentrantLock 事实上，ConcurrentLinkedQueue 应用还是非常广泛的 例如之前讲的 Tomcat 的 Connector 结构时，Acceptor 作为生产者向 Poller 消费者传递事件信息时，正是采用了 ConcurrentLinkedQueue 将 SocketChannel 给 Poller 使用。 CopyOnWriteArrayListCopyOnWriteArraySet 是它的马甲 底层实现采用了 写入时拷贝 的思想，增删改操作会将底层数组拷贝一份，更改操作在新数组上执行，这时不影响其它线程的并发读，读写分离。 以新增为例： 1234567891011121314public boolean add(E e) { synchronized (lock) { // 获取旧的数组 Object[] es = getArray(); int len = es.length; // 拷贝新的数组（这里是比较耗时的操作，但不影响其它读线程） es = Arrays.copyOf(es, len + 1); // 添加新元素 es[len] = e; // 替换旧的数组 setArray(es); return true; }} 这里的源码版本是 Java 11，在 Java 1.8 中使用的是可重入锁而不是 synchronized 其它读操作并未加锁，例如： 1234567public void forEach(Consumer&lt;? super E&gt; action) { Objects.requireNonNull(action); for (Object x : getArray()) { @SuppressWarnings(&quot;unchecked&quot;) E e = (E) x; action.accept(e); }} 适合『读多写少』的应用场景， get 弱一致性 时间点 操作 1 Thread-0 getArray() 2 Thread-1 getArray() 3 Thread-1 setArray(arrayCopy) 4 Thread-0 array[index] 1 是能得到的。。。 不容易测试，但问题确实存在 迭代器弱一致性12345678910111213CopyOnWriteArrayList&lt;Integer&gt; list = new CopyOnWriteArrayList&lt;&gt;();list.add(1);list.add(2);list.add(3);Iterator&lt;Integer&gt; iter = list.iterator();new Thread(() -&gt; { list.remove(0); System.out.println(list);}).start();sleep1s();while (iter.hasNext()) { System.out.println(iter.next());} 就是怎么说呢。。读的可能是旧的，读写并发可能得到的是旧数据，适合读多写少，因为读的效率高，写的效率底，因为每次写都要复制一个新的数组来操作，这样成本高，并且写写是互斥的，CopyOnWriteArrayList 相当于用空间换线程安全。 这弱一致性，将读写分离，不光做到了读读并发，而且还做到了读写并发，只有写写互斥，这比之前的读写锁的效率更高。 不要觉得弱一致性就不好 数据库的 MVCC 都是弱一致性的表现 并发高和一致性是矛盾的，需要权衡 ThreadLocalMapThreadLocalMap 不涉及到线程安全问题，因为是每个线程私有的，不会出现多个线程并发操作共享变量的情况。与 ThreadLocal 结合使用。 作用： ThreadLocal 可以实现【资源对象】的线程隔离，让每个线程各用各的【资源对象】，避免争用引发的线程安全问题 ThreadLocal 同时实现了线程内的资源共享 线程之间可以实现【资源对象】的线程隔离，又实现了线程内的资源共享。线程间资源隔离，线程内资源共享。 原理： 每个线程内有一个 ThreadLocalMap 类型的成员变量，用来存储资源对象 调用 set 方法，就是以 ThreadLocal 自己作为 key，资源对象作为 value，放入当前线程的 ThreadLocalMap 集合中 调用 get 方法，就是以 ThreadLocal 自己作为 key，到当前线程中的 ThreadLocalMap 中查找关联的资源值 调用 remove 方法，就是以 ThreadLocal 自己作为 key，移除当前线程关联的资源值 ThreadLocalMap 的一些特点 key 的 hash 值统一分配 初始容量 16，扩容因子 2/3，扩容容量翻倍 key 索引冲突后用开放寻址法解决冲突 弱引用 key ThreadLocalMap 中的 key 被设计为弱引用，原因如下 Thread 可能需要长时间运行（如线程池中的线程），如果 key 不再使用，需要在内存不足（GC）时释放其占用的内存 但是 GC 仅仅是让 key 的内存释放，后续还要根据 key 是否为 null 来进一步释放值的内存，释放时机如下： 内存释放时机 被动 GC 释放 key 仅是让 key 的内存释放，关联 value 的内存并不会释放 懒惰被动释放 value get key 时，发现是 null key，则释放其 value 内存 set key 时，会使用启发式扫描，清除临近的 null key 的 value 内存，启发次数（临近几个）与元素个数、是否发现 null key 有关 主动 remove 释放 key，value 会同时释放 key，value 的内存，也会清除临近的 null key 的 value 内存 推荐使用它，因为一般使用 ThreadLocal 时都把它作为静态变量（即强引用），因此无法被动依靠 GC 回收，因此前两种用不上。","link":"/posts/20211125/java-concurrent-7.html"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","link":"/tags/Elasticsearch/"},{"name":"Kibana","slug":"Kibana","link":"/tags/Kibana/"},{"name":"IK","slug":"IK","link":"/tags/IK/"},{"name":"NIO","slug":"NIO","link":"/tags/NIO/"},{"name":"RabbitMQ","slug":"RabbitMQ","link":"/tags/RabbitMQ/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"Netty","slug":"Netty","link":"/tags/Netty/"},{"name":"并发编程","slug":"并发编程","link":"/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"Experience","slug":"Experience","link":"/tags/Experience/"}],"categories":[{"name":"ELK","slug":"ELK","link":"/categories/ELK/"},{"name":"NIO","slug":"NIO","link":"/categories/NIO/"},{"name":"消息队列","slug":"消息队列","link":"/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Redis","slug":"Redis","link":"/categories/Redis/"},{"name":"并发编程","slug":"并发编程","link":"/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"JVM","slug":"JVM","link":"/categories/JVM/"}]}